{"meta":{"title":"秋季的blog","subtitle":"everyday","description":"","author":"他维忠","url":"http://peapod.top","root":"/"},"pages":[{"title":"文档","date":"2023-06-08T11:08:04.000Z","updated":"2023-06-10T09:07:50.000Z","comments":true,"path":"doc/index.html","permalink":"http://peapod.top/doc/index.html","excerpt":"","text":"Web 框架Ginhttps://gin-gonic.com/zh-cn/docs/Irishttps://www.iris-go.com/docs/#/Goframehttps://goframe.org/pages/viewpage.action?pageId=1114119gofiberhttps://docs.gofiber.io/数据读写Gormhttps://gorm.io/zh_CN/docs/Xormhttps://xorm.io/docs/chapter-13/readme/Inihttps://ini.unknwon.io/docsRedishttps://redis.uptrace.dev/zh/微服务Protocol Buffershttps://protobuf.dev/Grpchttps://grpc.io/docs/Microhttps://doc.rpcx.io/Go-zerohttps://go-zero.dev/来自 GitHub 的朋友以下友链通过 GitHub Issue 提交，按 issue 最后更新时间排序："},{"title":"examples","date":"2022-09-08T11:08:04.000Z","updated":"2023-06-10T07:12:02.000Z","comments":true,"path":"examples/index.html","permalink":"http://peapod.top/examples/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2022-09-08T11:04:02.000Z","updated":"2022-09-08T11:13:16.000Z","comments":true,"path":"categories/index.html","permalink":"http://peapod.top/categories/index.html","excerpt":"","text":""},{"title":"文档","date":"2023-06-08T11:08:04.000Z","updated":"2023-06-23T09:05:23.000Z","comments":true,"path":"learning/index.html","permalink":"http://peapod.top/learning/index.html","excerpt":"","text":"Go 语言学习路线 Go 语言入门 Go语言基础知识学习，主要包括：基本结构、基本数据类型、复杂类型（数组、切片、Map、结构体）、函数和方法、接口、异常、并发、反射机制。视频课程包括Go语言基础视频、原理视频等。 入门视频： 点击查看 郭宏志-老郭 Go语言基础语法和标准库的简单使用。码神之路 Go语言标准库，包含Context、io、fmt等 参考书籍包括Go语言基础知识、三方库的使用等。 入门书籍： 点击查看 Go语言入门指南 Go语言基础语法和标准库的简单使用。Go语言中文文档 Go语言基础知识及导航。 Linux 基础知识学习，文件操作、系统管理、权限管理。Shell 编程学习，基本命令的使用、函数的使用。Makefile学习。Web编程原理，各种网络协议、session和cookie原理及实现。 GO 语言进阶 Go语言框架的使用及各种中间件的学习，主要包括：Web框架的使用，中间件jwt、参数验证、数据库的调用等。Go Web框架 视频： 点击查看 郭宏志-老郭 Go语言基础语法和标准库的简单使用。码神之路 Go语言标准库，包含Context、io、fmt等 Go ORM 视频： 点击查看 Go语言入门指南 Go语言基础语法和标准库的简单使用。Go语言中文文档 Go语言基础知识及导航。 Mysql学习。Redis学习。Docker、docker-compose。Web常用中间件。 Go语言高级 Go语言微服务架构，主要包括：GRPC的使用、微服务的理解、微服务框架的使用。Go Grpc 视频： 点击查看 郭宏志-老郭 Go语言基础语法和标准库的简单使用。码神之路 Go语言标准库，包含Context、io、fmt等 Go-zero 视频： 点击查看 Go语言入门指南 Go语言基础语法和标准库的简单使用。Go语言中文文档 Go语言基础知识及导航。 Mysql学习。Redis学习。Docker、docker-compose。Web常用中间件。"},{"title":"项目","date":"2023-06-08T11:08:04.000Z","updated":"2023-06-10T07:44:36.000Z","comments":true,"path":"project/index.html","permalink":"http://peapod.top/project/index.html","excerpt":"","text":""},{"title":"mylist","date":"2022-09-08T11:04:41.000Z","updated":"2022-09-08T11:14:30.000Z","comments":true,"path":"mylist/index.html","permalink":"http://peapod.top/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2022-09-08T11:04:28.000Z","updated":"2022-09-08T11:13:14.000Z","comments":true,"path":"tags/index.html","permalink":"http://peapod.top/tags/index.html","excerpt":"","text":""},{"title":"我的朋友们","date":"2022-09-08T11:04:53.000Z","updated":"2023-06-10T08:27:49.000Z","comments":true,"path":"friends/index.html","permalink":"http://peapod.top/friends/index.html","excerpt":"","text":"这里写友链上方的内容。"},{"title":"about","date":"2022-09-08T11:03:19.000Z","updated":"2022-09-08T11:13:18.000Z","comments":true,"path":"about/index.html","permalink":"http://peapod.top/about/index.html","excerpt":"","text":"人的一生"}],"posts":[{"title":"velero k8s备份","slug":"velero-k8s备份","date":"2025-06-16T01:43:54.000Z","updated":"2025-06-16T01:44:21.403Z","comments":true,"path":"2025/06/16/velero-k8s备份/","link":"","permalink":"http://peapod.top/2025/06/16/velero-k8s%E5%A4%87%E4%BB%BD/","excerpt":"","text":"velero （k8s备份）简介Velero (原名 Heptio Ark) 是一个开源工具，专门用于安全地备份、恢复和迁移 Kubernetes 集群资源和持久卷。它提供了一种可靠的方法来保护 Kubernetes 应用程序和数据。 Velero 的核心能力 备份和恢复 Kubernetes 集群资源： Velero 可以备份和恢复 Kubernetes 集群中的几乎所有对象，包括 Deployment、Service、ConfigMap、Secret、PersistentVolumeClaim (PVC)、Ingress 等等。 这些资源定义会以 YAML&#x2F;JSON 文件的形式存储到对象存储中。 备份和恢复持久卷 (Persistent Volumes)： 这是 Velero 的一个关键能力。它支持两种主要的持久卷备份方式： 卷快照 (Volume Snapshots)： 对于支持云提供商原生卷快照的存储（如 AWS EBS、GCP Persistent Disk、Azure Managed Disks 等），Velero 可以直接调用云 API 创建和管理卷快照。 Restic 文件系统备份： 对于不支持原生卷快照的存储，或者当您需要更细粒度的文件级备份时，Velero 可以与 Restic（一个开源文件系统备份工具）集成，直接备份 Pod 内部的文件系统数据到对象存储中。 集群迁移： 通过备份一个集群的资源和数据，然后将其恢复到另一个不同的 Kubernetes 集群（甚至不同云提供商或本地环境），Velero 可以实现集群间的应用迁移。 灾难恢复： 当集群发生意外故障、数据损坏或配置错误时，Velero 允许您将集群恢复到之前的某个已知良好状态，从而最小化停机时间。 按计划执行备份： 您可以配置 Velero 定期自动创建备份，确保数据的时效性。 灵活的过滤和选择： Velero 允许您根据命名空间、标签、资源类型等条件来选择要备份或恢复的具体内容，提供高度的灵活性。 备份&#x2F;恢复前后的钩子 (Hooks)： 支持在备份或恢复操作的不同阶段执行自定义脚本，例如在备份前暂停应用，或在恢复后执行数据一致性检查。 velero 安装（k8s版本1.20.4）下载所需镜像 1234docker pull velero/velero:v1.9.2docker pull velero-plugin-for-aws:v1.5.5// 按需安装restic恢复备份时需要docker pull velero/velero-restic-restore-helper:v1.9.2 下载velero cli工具 12345// 根据k8s版本选择https://github.com/vmware-tanzu/velero/releases// v1.9.2cp velero /usr/local/binchmod +x /usr/local/bin velero 组件安装 1234567891011121314velero install \\ --provider aws \\ --image velero/velero:v1.9.2 \\ --plugins velero/velero-plugin-for-aws:v1.5.5 \\ --bucket velero \\ --use-restic \\ --secret-file ./credentials-velero \\ --use-volume-snapshots=false \\ --namespace velero \\ --backup-location-config region=minio,s3ForcePathStyle=&quot;true&quot;,s3Url=http://127.0.0.1:9000 \\ --wait // 该选项可以打印安装的配置信息 --dry-run -o yaml &gt; velero.yaml --provider aws &#x2F; --plugins velero/velero-plugin-for-aws: 指定 aws 提供商和插件，为了兼容 S3 协议。 --bucket velero: 备份数据将存放在名为 velero 的存储桶里。 --use-restic: 启用 Restic，用于备份和恢复 Kubernetes 持久卷（文件系统级别）。 --secret-file ./credentials-velero: 指定一个文件，里面包含连接存储服务（比如 MinIO）所需的认证信息。 --use-volume-snapshots=false: 禁用云服务商的卷快照功能，因为要使用文件级备份（Restic）或者 MinIO 不支持原生快照。 --namespace velero: Velero 组件将安装到 velero 这个 Kubernetes 命名空间中。 --backup-location-config region=minio,s3ForcePathStyle=&quot;true&quot;,s3Url=http://127.00.1:9000: 这是关键！ 它告诉 Velero 备份的目标是一个运行在 http://127.0.0.1:9000 的 MinIO 服务器，并且以 S3 路径样式访问。 --wait: 安装命令会等待所有 Velero 组件都成功启动并运行后才结束，这在自动化脚本中非常有用，可以确保 Velero 已经准备就绪。 卸载 12kubectl delete namespace/velero clusterrolebinding/velerokubectl delete crds -l component=velero 备份12345678910// 备份（包含所有PVC）velero backup create nexus-backup --include-namespaces nexus --default-volumes-to-restic --waitvelero backup create monitoring-backup --include-namespaces monitoring --default-volumes-to-restic --wait// 获取备份velero backup get// 恢复备份velero restore create --from-backup nexus-backupvelero restore create --from-backup nexus-backup --namespace-mappings nexus:nexus-restore// 重新绑定PVCkubectl patch pv nfs-nexus-pv -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;claimRef&quot;: null&#125;&#125;&#x27; velero backup create nexus-backup: 创建一个名为 nexus-backup 的备份。 --include-namespaces nexus: 只备份 nexus 这个命名空间里的所有 Kubernetes 资源。 --default-volumes-to-restic: 默认使用 Restic 工具来备份 nexus 命名空间中所有相关的持久卷数据，这是一种文件级别的备份方式。 --wait: 命令会等到整个备份过程完成（无论是成功还是失败）后才结束。","categories":[],"tags":[]},{"title":"使用 Helm 部署 HAMi 项目","slug":"使用-Helm-部署-HAMi-项目","date":"2025-05-30T09:29:07.000Z","updated":"2025-05-30T09:29:28.603Z","comments":true,"path":"2025/05/30/使用-Helm-部署-HAMi-项目/","link":"","permalink":"http://peapod.top/2025/05/30/%E4%BD%BF%E7%94%A8-Helm-%E9%83%A8%E7%BD%B2-HAMi-%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"使用 Helm 部署 HAMiHAMi简介基于K8s的GPU虚拟化工具，提供多种厂家显卡类型的显卡虚拟化，并使用监控采集显卡使用的信息。 前提条件 配置 nvidia-container-toolkit Docker运行 Kubernetes时 节点打标签 1kubectl label nodes &#123;nodeid&#125; gpu=on 离线安装准备 Helm Chart（离线包） 123helm repo add hami-charts https://project-hami.github.io/HAMi/helm pull hami-charts/hami --untartar czf hami.tar.gz hami/ 离线环境中解压并本地安装（与 Kubernetes 服务器版本匹配） 123tar xzf hami.tar.gzhelm install hami ./hami -n kube-system \\ --set scheduler.kubeScheduler.imageTag=v1.20.2 下载所需镜像 1234567891011# HAMi 核心镜像docker pull --platform=linux/amd64 projecthami/hami:v2.5.1# kube-scheduler（匹配 Kubernetes v1.20.2）docker pull --platform=linux/amd64 registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.20.2# webhook 证书镜像 1docker pull --platform=linux/amd64 docker.io/jettech/kube-webhook-certgen:v1.5.2# webhook 证书镜像 2（HAMi 默认用）docker pull --platform=linux/amd64 liangjw/kube-webhook-certgen:v1.1.1 12345docker save -o hami-images.tar \\ projecthami/hami:v2.5.1 \\ registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.20.2 \\ docker.io/jettech/kube-webhook-certgen:v1.5.2 \\ liangjw/kube-webhook-certgen:v1.1.1 1docker load -i hami-images.tar 在离线集群中安装 Helm Chart 1tar zxvf hami.tar.gz ./ 12helm install hami ./hami -n kube-system \\ --set scheduler.kubeScheduler.imageTag=v1.20.2 验证12345678910111213141516171819202122232425262728293031323334353637383940414243444546apiVersion: apps/v1kind: Deploymentmetadata: name: vllm-deployment namespace: prod labels: app: vllmspec: replicas: 1 selector: matchLabels: app: vllm template: metadata: labels: app: vllm spec: containers: - name: vllm-container image: vllm/vllm-openai:v0.7.2 command: [&quot;/bin/bash&quot;] args: [&quot;-c&quot;, &quot;tail -f /dev/null&quot;] ports: - containerPort: 8000 volumeMounts: - name: model-volume mountPath: /root/models/maas-dev-bge-reranker-base - name: nvidia-smi-bin mountPath: /usr/bin/nvidia-smi readOnly: true resources: limits: nvidia.com/gpu: 1 nvidia.com/gpumem: 5120 volumes: - name: model-volume hostPath: path: /root/tmp/models/maas-dev-bge-reranker-base type: Directory - name: nvidia-smi-bin hostPath: path: /usr/bin/nvidia-smi type: File restartPolicy: Always #runtimeClassName: nvidia # 如有需要可以启用 123kubectl apply -f deploy.yaml kubectl -n prod get pods -l app=vllmkubectl -n prod exec -it pod/vllm-deployment-96d597cf8-gbbkw -- nvidia-smi web ui 离线安装下载 Helm Chart和相关镜像 12345678910111213141516# 添加 Helm 仓库helm repo add hami-webui https://project-hami.github.io/HAMi-WebUI# 下载 chart 到本地目录helm pull hami-webui/hami-webui --untar# 前端镜像docker pull --platform=linux/amd64 projecthami/hami-webui-fe-oss:main# 后端镜像docker pull --platform=linux/amd64 projecthami/hami-webui-be-oss:main# 保存为本地 tar 文件docker save -o hami-web-ui-images.tar \\projecthami/hami-webui-fe-oss:main \\projecthami/hami-webui-be-oss:main prometheus安装镜像下载 123456789101112131415161718192021#!/bin/bashimages=( &quot;quay.io/prometheus/alertmanager:v0.27.0&quot; &quot;quay.io/prometheus-operator/admission-webhook:v0.76.0&quot; &quot;registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6&quot; &quot;quay.io/prometheus-operator/prometheus-operator:v0.76.0&quot; &quot;quay.io/prometheus-operator/prometheus-config-reloader:v0.76.0&quot; &quot;quay.io/thanos/thanos:v0.36.1&quot; &quot;quay.io/prometheus/prometheus:v2.54.1&quot; &quot;docker.io/grafana/grafana:11.2.0&quot; &quot;registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0&quot;)for img in &quot;$&#123;images[@]&#125;&quot;; do echo &quot;Pulling $img...&quot; docker pull --platform linux/amd64 &quot;$img&quot; if [ $? -eq 0 ]; then echo &quot;Successfully pulled $img&quot; else echo &quot;Failed to pull $img&quot; fidone 12345678910docker save -o kube-prometheus-stack-images.tar \\ quay.io/prometheus/alertmanager:v0.27.0 \\ quay.io/prometheus-operator/admission-webhook:v0.76.0 \\ registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6 \\ quay.io/prometheus-operator/prometheus-operator:v0.76.0 \\ quay.io/prometheus-operator/prometheus-config-reloader:v0.76.0 \\ quay.io/thanos/thanos:v0.36.1 \\ quay.io/prometheus/prometheus:v2.54.1 \\ &quot;docker.io/grafana/grafana:11.2.0&quot; \\ &quot;registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0&quot; \\ 安装 123helm install prometheus ./hami-webui/charts/kube-prometheus-stack -n prometheus --create-namespace --set crds.enabled=truehelm uninstall prometheus -n prometheushelm show values ./kube-prometheus-stack &gt; values.yaml dcgm-exporter安装镜像下载 12docker pull --platform linux/amd64 nvcr.io/nvidia/k8s/dcgm-exporter:3.3.7-3.5.0-ubuntu22.04docker save -o dcgm.tar nvcr.io/nvidia/k8s/dcgm-exporter:3.3.7-3.5.0-ubuntu22.04 安装 1helm install dcgm ./hami-webui/charts/dcgm-exporter -n dcgm --create-namespace hami-webui安装123456helm install my-hami-webui ./hami-webui \\ --set externalPrometheus.enabled=true \\ --set externalPrometheus.address=&quot;http://my-hami-webui-kube-prometh-prometheus.hami.svc.cluster.local:9090&quot; \\ -n hamihelm uninstall my-hami-webui ./hami-webui \\ -n hami","categories":[],"tags":[]},{"title":"deer-flow 项目详解","slug":"deer-flow-项目详解","date":"2025-05-30T09:27:59.000Z","updated":"2025-05-30T09:28:38.117Z","comments":true,"path":"2025/05/30/deer-flow-项目详解/","link":"","permalink":"http://peapod.top/2025/05/30/deer-flow-%E9%A1%B9%E7%9B%AE%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"deer-flow 介绍简介DeerFlow 是一个社区驱动的开源深度研究框架，旨在通过多智能体协作，将大型语言模型（LLM）与专业工具（如网络搜索、网页爬虫、Python 代码执行等）结合，提升自动化研究和内容创作的效率。它基于 LangChain 和 LangGraph 构建，支持模块化的多智能体架构，强调“人在回路”（human-in-the-loop）的人机协作体验，允许用户随时干预和调整研究计划。 核心功能多智能体架构： 系统基于 LangGraph 实现，通过有向图协调多个专门的 AI 智能体： 研究者（Researcher）：负责网络搜索、爬虫和信息收集，支持 Tavily、DuckDuckGo、Brave Search 和 Arxiv 等搜索工具。 编码者（Coder）：处理代码分析、执行和数据处理，使用 Python REPL 工具。 报告者（Reporter）：整合研究成果，生成报告、幻灯片、播客脚本等。 智能体通过消息传递系统协作，工作流灵活且可扩展。 工具集成： 网络搜索与爬虫：支持实时知识获取和数据聚合，特别适合学术研究（例如 Arxiv 搜索）。 Python REPL：支持数据处理、统计分析和代码生成。 MCP 集成：与 ByteDance 的内部模型控制平台（Model Control Platform）无缝协作，提升企业级自动化。 文本转语音（TTS）：通过 volcengine TTS API 将研究报告转为高质量音频，支持语速、音量和音调定制。 多模态输出：生成文本报告、幻灯片、播客脚本甚至可视化内容。 技术架构 LangGraph：用于工作流编排，确保智能体间的协作高效且可控。 LangChain：支持 LLM 的推理和记忆管理，增强智能体的交互能力。 模块化设计：各智能体和工具可独立扩展，适合定制化开发。 Web 界面：使用 Next.js 和 Zustand 管理状态，通过流式 API 与后端实时交互。 项目结构介绍main.py基于 Python，用于启动项目的命令行界面（CLI）或交互式模式。使用 argparse 处理命令行参数，InquirerPy 提供交互式用户界面，asyncio 支持异步运行智能体工作流。 运行模式： 命令行模式：用户通过命令行直接输入查询（如 python entry.py “我的问题”）。 交互模式：通过 –interactive 标志启动，用户可选择语言（英文&#x2F;中文）、预定义问题或自定义问题。 核心功能 解析命令行参数，设置运行配置（如调试模式、最大计划迭代次数等）。 提供交互式界面，引导用户选择或输入问题。 调用异步工作流函数 run_agent_workflow_async，执行多智能体协作任务。 ask 函数1234567891011121314151617def ask( question, debug=False, max_plan_iterations=1, max_step_num=3, enable_background_investigation=True,): &quot;&quot;&quot;Run the agent workflow with the given question.&quot;&quot;&quot; asyncio.run( run_agent_workflow_async( user_input=question, debug=debug, max_plan_iterations=max_plan_iterations, max_step_num=max_step_num, enable_background_investigation=enable_background_investigation, ) ) 作用：核心执行函数，将用户的问题传递给异步工作流 run_agent_workflow_async。 server.py用于运行一个基于 FastAPI 的 Web 服务。它使用 uvicorn 作为 ASGI 服务器，处理 HTTP 请求，并通过命令行参数配置服务器行为。 核心功能： 配置日志系统，记录服务器运行信息。 解析命令行参数，设置服务器的主机、端口、日志级别和自动重载等。 使用 uvicorn 启动 FastAPI 应用（src.server:app），运行 DeerFlow 的 API 服务。 运行方式：通过命令行运行（如 python server.py –host 0.0.0.0 –port 8080），支持开发和生产环境的灵活配置。 启动服务器 12345678logger.info(&quot;Starting DeerFlow API server&quot;)uvicorn.run( &quot;src.server:app&quot;, host=args.host, port=args.port, reload=reload, log_level=args.log_level,) src.server:app：指定 FastAPI 应用，位于 src&#x2F;server.py 模块中的 app 对象（通常是 fastapi.FastAPI 实例）。 src&#x2F;server.py定义了一个基于 FastAPI 的 API 服务（src&#x2F;server.py 中的核心部分），用于处理客户端的聊天流请求。它通过 Server-Sent Events (SSE) 提供实时流式响应，支持多智能体工作流（如研究、编码、报告生成），并与 LangGraph 集成以管理状态和消息流。 核心功能： 初始化 FastAPI 应用，配置 CORS 中间件以支持跨域请求。 定义如&#x2F;api&#x2F;chat&#x2F;stream 的POST 路由端点，接收聊天请求，生成流式响应。 使用 LangGraph（graph）管理多智能体工作流，支持消息传递、工具调用和中断处理。 支持实时事件流（SSE），返回消息片段、工具调用结果或中断提示。 &#x2F;api&#x2F;chat&#x2F;stream 端点，处理客户端的聊天请求，触发多智能体工作流，并以流式方式返回响应。 &#x2F;api&#x2F;tts：将文本转换为语音，使用火山引擎（Volcengine）TTS API。 &#x2F;api&#x2F;podcast&#x2F;generate：生成播客音频，基于输入内容。 &#x2F;api&#x2F;ppt&#x2F;generate：生成 PPT 文件，基于输入内容。 &#x2F;api&#x2F;prose&#x2F;generate：生成散文内容，支持流式响应。 &#x2F;api&#x2F;mcp&#x2F;server&#x2F;metadata：查询 MCP 服务器的元数据，如工具列表。 Work Flow详解DeerFlow 中的 LangGraph 工作流由 8 个主要节点组成，每个节点在代码库中以函数形式实现。该函数处理当前状态并返回更新的状态或转换到另一个节点的命令。 1234567891011121314151617181920212223def _build_base_graph(): &quot;&quot;&quot;Build and return the base state graph with all nodes and edges.&quot;&quot;&quot; builder = StateGraph(State) builder.add_edge(START, &quot;coordinator&quot;) # 协调员，确定查询是否应由规划器直接处理或需要背景调查 builder.add_node(&quot;coordinator&quot;, coordinator_node) # 背景调查人员，进行初步的网络搜索，为规划师收集背景信息 builder.add_node(&quot;background_investigator&quot;, background_investigation_node) # 规划师，创建包含步骤的结构化研究计划，是否需要更多研究或现有背景是否足够 builder.add_node(&quot;planner&quot;, planner_node) builder.add_node(&quot;reporter&quot;, reporter_node) # 研究团队 builder.add_node(&quot;research_team&quot;, research_team_node) # 研究员 builder.add_node(&quot;researcher&quot;, researcher_node) # 编码 builder.add_node(&quot;coder&quot;, coder_node) # 人工反馈，允许用户审查和修改研究计划 builder.add_node(&quot;human_feedback&quot;, human_feedback_node) # 汇报 builder.add_edge(&quot;reporter&quot;, END) return builder 协调器节点coordinator_node是工作流的入口点，负责分析用户查询并确定下一步的操作。 协调器节点： 分析用户的查询 确定查询是否需要规划或是否具有足够的上下文 检测用户的语言区域 决定是否在规划前进行背景调查 背景调查节点background_investigation_node对用户的查询进行初步研究，为规划提供背景。 背景调查节点： 使用该LoggedTavilySearch工具搜索与用户查询相关的信息 处理并格式化搜索结果 更新背景调查结果 将工作流引导至规划器节点 12345678910111213141516171819202122232425262728293031def background_investigation_node(state: State) -&gt; Command[Literal[&quot;planner&quot;]]: logger.info(&quot;background investigation node is running.&quot;) # 列表中最后一条消息的内容作为用户的查询字符串。 query = state[&quot;messages&quot;][-1].content # 搜索引擎选择执行搜索 if SELECTED_SEARCH_ENGINE == SearchEngine.TAVILY: searched_content = LoggedTavilySearch(max_results=SEARCH_MAX_RESULTS).invoke( &#123;&quot;query&quot;: query&#125; ) background_investigation_results = None if isinstance(searched_content, list): background_investigation_results = [ &#123;&quot;title&quot;: elem[&quot;title&quot;], &quot;content&quot;: elem[&quot;content&quot;]&#125; for elem in searched_content ] else: logger.error( f&quot;Tavily search returned malformed response: &#123;searched_content&#125;&quot; ) else: background_investigation_results = web_search_tool.invoke(query) # 搜索结果（转成 JSON 字符串）保存在 background_investigation_results # 跳转到下一节点 &quot;planner&quot;，继续流程执行 return Command( update=&#123; &quot;background_investigation_results&quot;: json.dumps( background_investigation_results, ensure_ascii=False ) &#125;, goto=&quot;planner&quot;, ) 规划器节点planner_node根据用户查询和可用上下文生成结构化的研究计划。 规划器节点： 使用提示模板和 LLM 生成研究计划 将计划构建为一系列步骤 确定该计划是否需要人工审核或是否具有足够的背景信息 使用生成的计划更新状态 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677def planner_node( state: State, config: RunnableConfig) -&gt; Command[Literal[&quot;human_feedback&quot;, &quot;reporter&quot;]]: &quot;&quot;&quot;Planner node that generate the full plan.&quot;&quot;&quot; logger.info(&quot;Planner generating full plan&quot;) # 获取允许的最大 plan 次数 configurable = Configuration.from_runnable_config(config) plan_iterations = state[&quot;plan_iterations&quot;] if state.get(&quot;plan_iterations&quot;, 0) else 0 # 生成 prompt 模板 messages = apply_prompt_template(&quot;planner&quot;, state, configurable) # 加入背景调查结果 if ( plan_iterations == 0 and state.get(&quot;enable_background_investigation&quot;) and state.get(&quot;background_investigation_results&quot;) ): messages += [ &#123; &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: ( &quot;background investigation results of user query:\\n&quot; + state[&quot;background_investigation_results&quot;] + &quot;\\n&quot; ), &#125; ] # 初始化 Planner 使用的 LLM if AGENT_LLM_MAP[&quot;planner&quot;] == &quot;basic&quot;: llm = get_llm_by_type(AGENT_LLM_MAP[&quot;planner&quot;]).with_structured_output( Plan, method=&quot;json_mode&quot;, ) else: llm = get_llm_by_type(AGENT_LLM_MAP[&quot;planner&quot;]) # if the plan iterations is greater than the max plan iterations, return the reporter node # 超过最大计划迭代次数，直接跳转 reporter if plan_iterations &gt;= configurable.max_plan_iterations: return Command(goto=&quot;reporter&quot;) # 调用语言模型生成计划 full_response = &quot;&quot; if AGENT_LLM_MAP[&quot;planner&quot;] == &quot;basic&quot;: response = llm.invoke(messages) full_response = response.model_dump_json(indent=4, exclude_none=True) else: response = llm.stream(messages) for chunk in response: full_response += chunk.content logger.debug(f&quot;Current state messages: &#123;state[&#x27;messages&#x27;]&#125;&quot;) logger.info(f&quot;Planner response: &#123;full_response&#125;&quot;) # 尝试解析计划 JSON 内容 try: curr_plan = json.loads(repair_json_output(full_response)) except json.JSONDecodeError: logger.warning(&quot;Planner response is not a valid JSON&quot;) if plan_iterations &gt; 0: return Command(goto=&quot;reporter&quot;) else: return Command(goto=&quot;__end__&quot;) # 判断计划是否足够有上下文，决定下一步跳转 if curr_plan.get(&quot;has_enough_context&quot;): logger.info(&quot;Planner response has enough context.&quot;) new_plan = Plan.model_validate(curr_plan) return Command( update=&#123; &quot;messages&quot;: [AIMessage(content=full_response, name=&quot;planner&quot;)], &quot;current_plan&quot;: new_plan, &#125;, goto=&quot;reporter&quot;, ) return Command( update=&#123; &quot;messages&quot;: [AIMessage(content=full_response, name=&quot;planner&quot;)], &quot;current_plan&quot;: full_response, &#125;, goto=&quot;human_feedback&quot;, ) 人工反馈节点human_feedback_node允许人工审查和批准生成的研究计划。 人工反馈节点： 检查 auto_accepted_plan 是否启用 如果没有，则中断工作流程以提交计划以供审查 处理人工反馈以编辑计划或接受计划 根据反馈和计划质量，路由到合适的下一个节点 研究团队节点research_team_node充当研究执行的协调者，将任务委托给研究人员或编码员节点。 研究团队节点： 分析当前的研究计划 标识下一个未执行的步骤 确定该步骤是研究任务还是编码任务 前往相应专家节点的路线 研究员节点researcher_node使用网络搜索和爬网工具执行研究步骤。 研究员节点： 使用网络搜索和爬网工具收集信息 处理和格式化研究结果 通过研究观察更新状态 将控制权交还给研究团队节点 编码器节点coder_node使用 Python REPL 执行与代码相关的任务。 编码器节点： 使用 Python REPL 执行代码 分析代码执行结果 使用编码观察更新状态 将控制权交还给研究团队节点 报告节点reporter_node根据所有收集到的信息生成最终的研究报告。 汇编所有研究观察结果 用要点、概述和分析来格式化研究报告 包含所有来源的正确引用 使用最终报告更新状态 MCP 执行MCP服务器的调用发生在编码器节点和研究员节点的使用过程中，两者都调用函数_setup_and_execute_agent_step实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364async def _setup_and_execute_agent_step( state: State, config: RunnableConfig, agent_type: str, default_agent, default_tools: list,) -&gt; Command[Literal[&quot;research_team&quot;]]: &quot;&quot;&quot;Helper function to set up an agent with appropriate tools and execute a step. This function handles the common logic for both researcher_node and coder_node: 1. Configures MCP servers and tools based on agent type 2. Creates an agent with the appropriate tools or uses the default agent 3. Executes the agent on the current step Args: state: The current state config: The runnable config agent_type: The type of agent (&quot;researcher&quot; or &quot;coder&quot;) default_agent: The default agent to use if no MCP servers are configured default_tools: The default tools to add to the agent Returns: Command to update state and go to research_team &quot;&quot;&quot; configurable = Configuration.from_runnable_config(config) mcp_servers = &#123;&#125; enabled_tools = &#123;&#125; # Extract MCP server configuration for this agent type if configurable.mcp_settings: for server_name, server_config in configurable.mcp_settings[&quot;servers&quot;].items(): if ( server_config[&quot;enabled_tools&quot;] and agent_type in server_config[&quot;add_to_agents&quot;] ): mcp_servers[server_name] = &#123; k: v for k, v in server_config.items() if k in (&quot;transport&quot;, &quot;command&quot;, &quot;args&quot;, &quot;url&quot;, &quot;env&quot;) &#125; for tool_name in server_config[&quot;enabled_tools&quot;]: enabled_tools[tool_name] = server_name # Create and execute agent with MCP tools if available if mcp_servers: try: async with MultiServerMCPClient(mcp_servers) as client: loaded_tools = default_tools[:] for tool in client.get_tools(): if tool.name in enabled_tools: tool.description = ( f&quot;Powered by &#x27;&#123;enabled_tools[tool.name]&#125;&#x27;.\\n&#123;tool.description&#125;&quot; ) loaded_tools.append(tool) agent = create_agent(agent_type, agent_type, loaded_tools, agent_type) return await _execute_agent_step(state, agent, agent_type) except Exception as e: logger.exception(f&quot;[&#123;agent_type&#125;] MCP agent setup or execution failed: &#123;repr(e)&#125;&quot;) raise ToolException(f&quot;Error: &#123;str(e) or repr(e)&#125;\\nTraceback:\\n&#123;traceback.format_exc()&#125;&quot;) else: # Use default agent if no MCP servers are configured return await _execute_agent_step(state, default_agent, agent_type)","categories":[],"tags":[]},{"title":"kbebuilder CronJob","slug":"kbebuilder-CronJob","date":"2025-04-24T09:25:49.000Z","updated":"2025-04-24T09:26:58.148Z","comments":true,"path":"2025/04/24/kbebuilder-CronJob/","link":"","permalink":"http://peapod.top/2025/04/24/kbebuilder-CronJob/","excerpt":"","text":"kbebuilder CronJob简介CronJob controller 会控制 kubernetes 集群上的 job 每隔一段时间运行一次，它是基于 Job controller 实现的，Job controller 的 job 只会执行任务一次。 创建项目123mkdir projectcd projectkubebuilder init --domain tutorial.kubebuilder.io --repo tutorial.kubebuilder.io/project --domain tutorial.kubebuilder.io：指定 创建的 API 的组名后缀。 --repo tutorial.kubebuilder.io/project：指定 Go module 的路径，用于设置 go.mod 中的模块名。 apiVersion 决定了该资源属于哪个 API 组、使用哪个版本的 schema 来解析。完整的apiVersion： 1apiVersion: &lt;group&gt;.&lt;domain&gt;/&lt;version&gt; 项目结构go.mod： 包含最基本依赖关系的 go module 文件。 Makefile： 用于构建和部署 controller。 PROJECT： 用于创建新组件的 Kubebuilder 元数据。 config/目录：运行 operator 所需的所有配置文件。现在它只包含运行 controller 所需要的 Kustomize YAML 配置文件，后续编写 operator 时，这个目录还会包含 CustomResourceDefinitions(CRD)、RBAC 和 Webhook 等相关的配置文件。 config/default包含Kustomize base文件，用于以标准配置启动 controller。 config/manager: 包含在 k8s 集群中以 pod 形式运行 controller 的 YAML 配置文件 config/rbac: 包含运行 controller 所需最小权限的配置文件 main.go 解析每组 controller 都需要一个 Scheme， Scheme 会提供 Kinds 与 Go types 之间的映射关系。 main.go 的功能相对来说比较简单： 为 metrics 绑定一些基本的 flags。 实例化一个 manager，用于跟踪运行的所有 controllers， 并设置 shared caches 和可以连接到 API server 的 k8s clients 实例，并将 Scheme 配置传入 manager。 运行manager, 而 manager 又运行所有的 controllers 和 webhook。 manager 会一直处于运行状态，直到收到正常关闭信号为止。 // +kubebuilder:scaffold:builder：告诉 Kubebuilder 工具，在执行代码生成命令时，把新代码插入到这个位置。 当运行这些命令时： 123kubebuilder create api --group xxx --version v1 --kind MyKindmake generatemake manifests Kubebuilder 会自动把新生成的代码 插入到有 +kubebuilder:scaffold:\\* 的标记位置，比如： 注册 SchemeBuilder 添加 controller 添加 webhook 创建API1kubebuilder create api --group batch --version v1 --kind CronJob 创建api/v1/个目录， 对应的 group-version 是 batch.tutorial.kubebuilder.io/v1 创建 api/v1/cronjob_types.go 文件并添加 CronJob Kind cronjob_types.go 解析CronJobSpec和 CronJobStatusKubernetes 的功能是将期望状态(Spec)与集群实际状态(其他对象的Status)和外部状态进行协调。 然后记录下观察到的状态（Status）。 因此，每个具有功能的对象都包含 Spec 和 Status 。 但是 ConfigMap 之类的一些类型不遵循此模式，因为它们不会维护一种状态，但是大多数类型都需要。 12345678910type CronJobSpec struct &#123; // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster // Important: Run &quot;make&quot; to regenerate code after modifying this file&#125;// CronJobStatus defines the observed state of CronJobtype CronJobStatus struct &#123; // INSERT ADDITIONAL STATUS FIELD - define observed state of cluster // Important: Run &quot;make&quot; to regenerate code after modifying this file&#125; CronJob 和 CronJobList定义了 Kinds 对应的结构体类型， CronJob 是 root type，用来描述 CronJob Kind。和所有 Kubernetes 对象一样， 它包含 TypeMeta (用来定义 API version 和 Kind) 和 ObjectMeta (用来定义 name、namespace 和 labels等一些字段)。 CronJobList 包含了一个 CronJob 的切片，它是用来批量操作 Kind 的，比如 LIST 操作。通常不会修改它们所有的修改都是在 Spec 和 Status 上进行的。 1234567891011121314151617// +kubebuilder:object:root=true// CronJob is the Schema for the cronjobs APItype CronJob struct &#123; metav1.TypeMeta `json:&quot;,inline&quot;` metav1.ObjectMeta `json:&quot;metadata,omitempty&quot;` Spec CronJobSpec `json:&quot;spec,omitempty&quot;` Status CronJobStatus `json:&quot;status,omitempty&quot;`&#125;// +kubebuilder:object:root=true// CronJobList contains a list of CronJobtype CronJobList struct &#123; metav1.TypeMeta `json:&quot;,inline&quot;` metav1.ListMeta `json:&quot;metadata,omitempty&quot;` Items []CronJob `json:&quot;items&quot;`&#125; // +kubebuilder:object:root=true：这个注释告诉 object 这是一种 root type Kind。 然后，object 生成器会为生成 runtime.Object 接口的实现， 这是所有 Kinds 必须实现的接口。 Register123func init() &#123; SchemeBuilder.Register(&amp;CronJob&#123;&#125;, &amp;CronJobList&#123;&#125;)&#125; Kinds 注册到 API group 中。这将此 API group 中的 Kind 添加到任何 Scheme 中。 其他文件解析groupversion_info.go 包含和 group-version 有关的元数据: 定义一些全局变量帮助建立 Scheme。 由于需要在 controller 中使用此程序包中的所有 types， 因此需要一种方便的方法（或约定）可以将所有 types 添加到其他 Scheme 中。 123456789var ( // GroupVersion is group version used to register these objects GroupVersion = schema.GroupVersion&#123;Group: &quot;batch.tutorial.kubebuilder.io&quot;, Version: &quot;v1&quot;&#125; // SchemeBuilder is used to add go types to the GroupVersionKind scheme SchemeBuilder = &amp;scheme.Builder&#123;GroupVersion: GroupVersion&#125; // AddToScheme adds the types in this group-version to the given scheme. AddToScheme = SchemeBuilder.AddToScheme) zz_generated.deepcopy.go包含之前所说的由 +kubebuilder:object:root自动生成的 runtime.Object 接口的实现。 runtime.Object interface 的核心是一个 deep-copy 方法：DeepCopyObject。 controller-tools 中的 object 生成器也为每个 root type(CronJob) 和他的 sub-types(CronJobList,CronJobSpec,CronJob1Status) 都生成了两个方法：DeepCopy 和 DeepCopyInto。 编写APICronJobSpec schedule ：Cron 表达式，用来定义任务执行的时间，例如 *&#x2F;5 * * * * 表示每 5 分钟执行一次。 JobTemplate：每次执行会基于这个模板生成一个 Job。 StartingDeadlineSeconds：这个截止时间，将会等到下一个调度时间点调度。 ConcurrencyPolicy：并发策略 Suspend：暂停 SuccessfulJobsHistoryLimit：限制历史 Job 的数量 1234567891011121314151617181920212223242526type CronJobSpec struct &#123; Foo string `json:&quot;foo,omitempty&quot;` // +kubebuilder:validation:MinLength=0 // Cron 表达式，用来定义任务执行的时间，例如 */5 * * * * 表示每 5 分钟执行一次。 Schedule string `json:&quot;schedule&quot;` // +optional // 调度开始之后在这个时间内，就可以执行job // 如果任务错过了调度时间（比如因为 controller 崩溃、宕机），这个字段定义了一个“容忍窗口（秒）”， // 允许它在这个时间内仍然启动，否则就认为“错过”，并标记为失败。 StartingDeadlineSeconds *int64 `json:&quot;startingDeadlineSeconds,omitempty&quot;` // +optional // 并行策略 ConcurrencyPolicy ConcurrencyPolicy `json:&quot;concurrencyPolicy,omitempty&quot;` // +optional // 是否暂停该 CronJob 的调度。 Suspend *bool `json:&quot;suspend,omitempty&quot;` // CronJob 每次执行会基于这个模板生成一个 Job JobTemplate batchv1.JobTemplateSpec `json:&quot;jobTemplate&quot;` // +optional // 保留多少个成功完成的 Job。 SuccessfulJobsHistoryLimit *int32 `json:&quot;successfulJobsHistoryLimit,omitempty&quot;` // +kubebuilder:validation:Minimum=0 // +optional // 失败的job历史记录限制条数 FailedJobsHistoryLimit *int32 `json:&quot;failedJobsHistoryLimit,omitempty&quot;`&#125; 自定义了一个类型（ConcurrencyPolicy）来保存并发策略。 1234567891011121314// +kubebuilder:validation:Enum=Allow;Forbid;Replacetype ConcurrencyPolicy stringconst ( // AllowConcurrent allows CronJobs to run concurrently. AllowConcurrent ConcurrencyPolicy = &quot;Allow&quot; // ForbidConcurrent forbids concurrent runs, skipping next run if previous // hasn&#x27;t finished yet. ForbidConcurrent ConcurrencyPolicy = &quot;Forbid&quot; // ReplaceConcurrent cancels currently running job and replaces it with a new one. ReplaceConcurrent ConcurrencyPolicy = &quot;Replace&quot;) CronJobstatus它用来存储观察到的状态。它包含 controllers 能够获取的所有信息。 12345678type CronJobStatus struct &#123; // +optional Active []corev1.ObjectReference `json:&quot;active,omitempty&quot;` // Information when was the last time the job was successfully scheduled. // +optional LastScheduleTime *metav1.Time `json:&quot;lastScheduleTime,omitempty&quot;`&#125; 保留一份正在运行的 Job 列表，以及最后一次成功运行 Job 的时间。 CronJob123456789// +kubebuilder:object:root=true// +kubebuilder:subresource:statustype CronJob struct &#123; metav1.TypeMeta `json:&quot;,inline&quot;` metav1.ObjectMeta `json:&quot;metadata,omitempty&quot;` Spec CronJobSpec `json:&quot;spec,omitempty&quot;` Status CronJobStatus `json:&quot;status,omitempty&quot;`&#125; +kubebuilder:subresource:status 它的作用是： 告诉 Kubebuilder 为 CRD 启用 status 子资源支持。 在 Kubernetes 中，每个资源（包括 CRD）都可以有一个 status 字段，但： 默认情况下，status 只是资源的普通字段，用户可以随意修改。 如果希望 只有 Kubernetes 控制器能修改 status，用户不能手动改，需要开启它的 subresource 支持。 Controllers简介Controllers 是 operator 和 Kubernetes 的核心组件。 controller 的职责是确保实际的状态（包括群集状态，以及潜在的外部状态，例如正在运行的 Kubelet 容器和云提供商的 loadbalancers）与给定 object 期望的状态相匹配。 每个 controller 专注于一个 root Kind，但也可以与其他 Kinds 进行交互。 这种努力达到期望状态的过程，称之为 reconciling(调协）。 在 controller-runtime 库中，实现 Kind reconciling 的逻辑称为 Reconciler。 reconciler 获取对象的名称并返回是否需要重试。 reconciler 结构体每个 reconciler 都需要记录日志，并且需要能够获取对象，因此这个结构体是开箱即用的。 12345// CronJobReconciler reconciles a CronJob objecttype CronJobReconciler struct &#123; client.Client Scheme *runtime.Scheme&#125; Reconcile函数大多数 controllers 最终都会运行在 k8s 集群上，因此它们需要 RBAC 权限, 我们使用 controller-tools RBAC markers 指定了这些权限。 这是运行所需的最小权限。 12// +kubebuilder:rbac:groups=batch.tutorial.kubebuilder.io,resources=cronjobs,verbs=get;list;watch;create;update;patch;delete// +kubebuilder:rbac:groups=batch.tutorial.kubebuilder.io,resources=cronjobs/status,verbs=get;update;patch 1func (r *CronJobReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) Reconcile 方法对个某个单一的 object 执行 reconciling 动作，req内容是一个 NamespacedName，client 可以通过 NamespacedName 信息从 cache 中获取到对应的 object。 返回的 result 为空，且 error 为 nil， 这表明 controller-runtime 已经成功 reconciled 了这个 object，无需进行任何重试，直到这个 object 被更改。 SetupWithManager函数12345func (r *CronJobReconciler) SetupWithManager(mgr ctrl.Manager) error &#123; return ctrl.NewControllerManagedBy(mgr). For(&amp;batchv1.CronJob&#123;&#125;). Complete(r)&#125; 将此 reconciler 加到 manager，以便在启动 manager 时启动 reconciler。 编写ControllersCronJob controller 的基本逻辑是： 加载 CronJob 列出所有 active jobs，并更新状态 根据历史记录清理 old jobs 检查 Job 是否已被 suspended（如果被 suspended，请不要执行任何操作） 获取到下一次要 schedule 的 Job 运行新的 Job, 确定新 Job 没有超过 deadline 时间，且不会被我们 concurrency 规则 block 如果 Job 正在运行或者它应该下次运行，请重新排队 CronJobReconciler添加计时器模拟时钟：需要一个 Clock 字段，它在测试中伪装计时。 12345678910111213type CronJobReconciler struct &#123; client.Client Log logr.Logger Scheme *runtime.Scheme Clock&#125;type realClock struct&#123;&#125;func (_ realClock) Now() time.Time &#123; return time.Now() &#125;type Clock interface &#123; Now() time.Time&#125; reconciler 的逻辑按 namespace 加载 CronJob使用 client 获取 CronJob。使用 NamespacedName作为中间参数获取CronJob对象。 12345678var cronJob batch.CronJob if err := r.Get(ctx, req.NamespacedName, &amp;cronJob); err != nil &#123; log.Error(err, &quot;unable to fetch CronJob&quot;) // we&#x27;ll ignore not-found errors, since they can&#x27;t be fixed by an immediate // requeue (we&#x27;ll need to wait for a new notification), and we can get them // on deleted requests. return ctrl.Result&#123;&#125;, client.IgnoreNotFound(err) &#125; 列出所有 active jobs，并更新状态需要列出此 namespace 中属于此 CronJob 的所有 Job。 与 Get 方法类似，可以使用 List 方法列出 Job。 注意，使用可变参数选项来设置 client.InNamespace 和 client.MatchingFields。 client.InNamespace(req.Namespace)这个表示：只查找指定命名空间下的资源。 client.MatchingFields&#123;jobOwnerKey: req.Name&#125;它的意思是：只匹配 .metadata.ownerReferences.name == req.Name 的 Job，也就是属于当前 CronJob 的 Job jobOwnerKey 是自定义的 index key，后面介绍。 主要的步骤如下： 列出所有关联的 Job 遍历当前 CronJob 的所有子 Job，对它们进行分类 遍历的同时，从注解提取调度时间，并记录最后一次执行的调度时间 更新 CronJob 资源中的 Status的LastScheduleTime，就是记录的最后一次执行的调度时间 更新 CronJob 资源中的 Status的Active，就是分类出的activeJobs 更新 CronJob 的状态信息（Status）到 Kubernetes 集群中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192// 列出所有关联的 Job var childJobs kbatch.JobList if err := r.List(ctx, &amp;childJobs, client.InNamespace(req.Namespace), client.MatchingFields&#123;jobOwnerKey: req.Name&#125;); err != nil &#123; log.Error(err, &quot;unable to list child Jobs&quot;) return ctrl.Result&#123;&#125;, err &#125; // 分类 Job：成功、失败、运行中 var activeJobs []*kbatch.Job var successfulJobs []*kbatch.Job var failedJobs []*kbatch.Job var mostRecentTime *time.Time // find the last run so we can update the status // 判断一个 Job 是否已经“完成”，（成功或失败） isJobFinished := func(job *kbatch.Job) (bool, kbatch.JobConditionType) &#123; for _, c := range job.Status.Conditions &#123; if (c.Type == kbatch.JobComplete || c.Type == kbatch.JobFailed) &amp;&amp; c.Status == corev1.ConditionTrue &#123; // 找到符合条件的 Condition，就立即返回 (true, c.Type) return true, c.Type &#125; &#125; // 如果遍历完都没有找到符合条件的项 // 表示这个 Job 还没有完成，也就是仍在运行中或等待中。 return false, &quot;&quot; &#125; // 从 Job 的注解中提取调度时间（ScheduledTime）并返回一个 time.Time 类型的时间戳。 getScheduledTimeForJob := func(job *kbatch.Job) (*time.Time, error) &#123; timeRaw := job.Annotations[scheduledTimeAnnotation] if len(timeRaw) == 0 &#123; return nil, nil &#125; timeParsed, err := time.Parse(time.RFC3339, timeRaw) if err != nil &#123; return nil, err &#125; return &amp;timeParsed, nil &#125; // 遍历当前 CronJob 的所有子 Job，对它们进行分类， // 并提取每个 Job 的调度时间（从 annotation 中拿），以便控制器后续判断和处理。 for i, job := range childJobs.Items &#123; // 判断这个 Job 是否完成，并获取它的完成类型 _, finishedType := isJobFinished(&amp;job) switch finishedType &#123; // 还在运行的放入 activeJobs case &quot;&quot;: // ongoing activeJobs = append(activeJobs, &amp;childJobs.Items[i]) case kbatch.JobFailed: failedJobs = append(failedJobs, &amp;childJobs.Items[i]) case kbatch.JobComplete: successfulJobs = append(successfulJobs, &amp;childJobs.Items[i]) &#125; // We&#x27;ll store the launch time in an annotation, so we&#x27;ll reconstitute that from // the active jobs themselves. // 从 Job 的 annotation 中获取调度时间 scheduledTimeForJob, err := getScheduledTimeForJob(&amp;job) // 解析失败，打印日志并跳过这个 Job if err != nil &#123; log.Error(err, &quot;unable to parse schedule time for child job&quot;, &quot;job&quot;, &amp;job) continue &#125; // mostRecentTime 会记录该 CronJob 最近一次实际执行 Job 的时间 if scheduledTimeForJob != nil &#123; if mostRecentTime == nil || mostRecentTime.Before(*scheduledTimeForJob) &#123; mostRecentTime = scheduledTimeForJob &#125; &#125; &#125; // 更新 CronJob 资源中的 Status.LastScheduleTime 字段，用来记录 CronJob 最后一次成功调度时间。 if mostRecentTime != nil &#123; cronJob.Status.LastScheduleTime = &amp;metav1.Time&#123;Time: *mostRecentTime&#125; &#125; else &#123; cronJob.Status.LastScheduleTime = nil &#125; cronJob.Status.Active = nil // 将 当前活跃的 Job（即正在执行中的 Job）更新到 CronJob 的 Status.Active 字段。 for _, activeJob := range activeJobs &#123; // 将 activeJob 转换为 Kubernetes 对象引用（ObjectReference）。 jobRef, err := ref.GetReference(r.Scheme, activeJob) // 生成 ObjectReference 时发生错误，则记录错误并跳过当前的 activeJob if err != nil &#123; log.Error(err, &quot;unable to make reference to active job&quot;, &quot;job&quot;, activeJob) continue &#125; cronJob.Status.Active = append(cronJob.Status.Active, *jobRef) &#125; // 帮助开发人员或者运维人员监控 CronJob 的执行状态，查看当前系统中各个 Job 的情况。 log.V(1).Info(&quot;job count&quot;, &quot;active jobs&quot;, len(activeJobs), &quot;successful jobs&quot;, len(successfulJobs), &quot;failed jobs&quot;, len(failedJobs)) // 更新 CronJob 的状态信息到 Kubernetes 集群中 if err := r.Status().Update(ctx, &amp;cronJob); err != nil &#123; log.Error(err, &quot;unable to update CronJob status&quot;) return ctrl.Result&#123;&#125;, err &#125; 根据历史记录清理过期 jobs清理过期的失败作业（failed jobs），并根据 CronJob 中的 FailedJobsHistoryLimit 配置删除历史失败的 Job 成功的作业同理。 123456789101112131415161718192021222324252627282930313233343536373839404142// 清理过期的失败作业（failed jobs），并根据 CronJob 中的 FailedJobsHistoryLimit 配置删除历史失败的 Job if cronJob.Spec.FailedJobsHistoryLimit != nil &#123; // 按失败时间对失败作业排序， 最旧的失败作业排在前面。 sort.Slice(failedJobs, func(i, j int) bool &#123; if failedJobs[i].Status.StartTime == nil &#123; return failedJobs[j].Status.StartTime != nil &#125; return failedJobs[i].Status.StartTime.Before(failedJobs[j].Status.StartTime) &#125;) // 删除超出历史保留限制的失败作业 for i, job := range failedJobs &#123; // 检查当前遍历的失败作业是否超过了保留的最大历史失败作业数。 if int32(i) &gt;= int32(len(failedJobs))-*cronJob.Spec.FailedJobsHistoryLimit &#123; break &#125; // 删除作业 if err := r.Delete(ctx, job, client.PropagationPolicy(metav1.DeletePropagationBackground)); client.IgnoreNotFound(err) != nil &#123; log.Error(err, &quot;unable to delete old failed job&quot;, &quot;job&quot;, job) &#125; else &#123; log.V(0).Info(&quot;deleted old failed job&quot;, &quot;job&quot;, job) &#125; &#125; &#125; if cronJob.Spec.SuccessfulJobsHistoryLimit != nil &#123; sort.Slice(successfulJobs, func(i, j int) bool &#123; if successfulJobs[i].Status.StartTime == nil &#123; return successfulJobs[j].Status.StartTime != nil &#125; return successfulJobs[i].Status.StartTime.Before(successfulJobs[j].Status.StartTime) &#125;) for i, job := range successfulJobs &#123; if int32(i) &gt;= int32(len(successfulJobs))-*cronJob.Spec.SuccessfulJobsHistoryLimit &#123; break &#125; if err := r.Delete(ctx, job, client.PropagationPolicy(metav1.DeletePropagationBackground)); err != nil &#123; log.Error(err, &quot;unable to delete old successful job&quot;, &quot;job&quot;, job) &#125; else &#123; log.V(0).Info(&quot;deleted old successful job&quot;, &quot;job&quot;, job) &#125; &#125; &#125; 检查 Job 是否已被 suspended如果这个 object 已被 suspended，会立即 return。 1234if cronJob.Spec.Suspend != nil &amp;&amp; *cronJob.Spec.Suspend &#123; log.V(1).Info(&quot;cronjob suspended, skipping&quot;) return ctrl.Result&#123;&#125;, nil &#125; 获取到下一次要 schedule 的 Job的时间如果 Job 没有被暂停，则需要计算错过但仍然在允许范围内的执行时间（missedRun）和下一次调度的时间（nextRun）。 在这里需要StartingDeadlineSeconds来实现missedRun的计算。 [!NOTE] 假设上一次调度时间是12:00，调度规则是每小时调度 ，StartingDeadlineSeconds是30分钟。 当前时间是13:00，设置earliestTime为上一次调度时间12:00。当前时间13:00-30分钟（StartingDeadlineSeconds）&#x3D;12:30，12:30在earliestTime之后，设置earliestTime为12:30。 earliestTime（12:30）在当前时间（13:00）之前，此时说明存在可以调度的时间，根据earliestTime和调度规则计算出调度时间为13:00。后续就会在13:00时调度。missedRun为13:00。 假设上一次调度时间是12:00，调度规则是每小时调度 ，StartingDeadlineSeconds是30分钟。 当前时间是13:28，假设调度出现问题，在13:00时没有调度，因此上一次调度时间是12:00。 设置earliestTime为上一次调度时间12:00。当前时间13:28-30分钟（StartingDeadlineSeconds）&#x3D;12:58，12:58在earliestTime（12:00）之后，设置earliestTime为12:58。 earliestTime（12:58）在在当前时间（13:28）之前，此时说明存在可以调度的时间，根据earliestTime和调度规则计算出调度时间为13:00。后续就会在13:00时调度。missedRun为13:00。 这两项说明：当调度出现问题，在13:00时没有调度，一直到13:30这个范围内，都是可以调度的，这就是StartingDeadlineSeconds的作用。 假设上一次调度时间是12:00，调度规则是每小时调度 ，StartingDeadlineSeconds是3小时。 当前时间是18:11，假设调度出现问题，在到当前时间的范围内没有调度，因此上一次调度时间是12:00。 设置earliestTime为上一次调度时间12:00。当前时间18:11-3小时（StartingDeadlineSeconds）&#x3D;15:11， 15:11在earliestTime（12:00）之后，设置earliestTime为15:11。 earliestTime（15:11）在在当前时间（18:11）之前，此时说明存在可以调度的时间，根据earliestTime和调度规则计算出调度时间为16:00、17:00和18:00，由于StartingDeadlineSeconds的过大，存在多个未调度的时间点的时候，遍历这些事件点找到离当前时间最近的时间点，该时间点为18:00。missedRun为18:00。 根据earliestTime和调度规则计算出调度时间 12t := sched.Next(earliestTime)// 假设earliestTime为11:10，规则为每小时调度，第一次调用t为12:00，依次分别为13:00、14:00..... 完整代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455getNextSchedule := func(cronJob *batchv1.CronJob, now time.Time) (lastMissed time.Time, next time.Time, err error) &#123; // 将 Cron 表达式字符串 (cronJob.Spec.Schedule) 解析成一个 Cron 表达式调度器 sched。 sched, err := cron.ParseStandard(cronJob.Spec.Schedule) if err != nil &#123; return time.Time&#123;&#125;, time.Time&#123;&#125;, fmt.Errorf(&quot;Unparseable schedule %q: %v&quot;, cronJob.Spec.Schedule, err) &#125; // for optimization purposes, cheat a bit and start from our last observed run time // we could reconstitute this here, but there&#x27;s not much point, since we&#x27;ve // just updated it. // earliestTime 是开始计算下一个调度时间的基础时间 var earliestTime time.Time // 如果 CronJob 已经有 LastScheduleTime（上次成功调度的时间），则使用该时间。 if cronJob.Status.LastScheduleTime != nil &#123; earliestTime = cronJob.Status.LastScheduleTime.Time &#125; else &#123; // 如果没有 LastScheduleTime，则使用 CronJob 的创建时间作为开始时间 earliestTime = cronJob.ObjectMeta.CreationTimestamp.Time &#125; // 限制我们调度“过去的漏掉的任务”的范围，避免太老的调度点被浪费资源去执行。 // 设置了 StartingDeadlineSeconds，表示在某个时间点之后的调度将被忽略 if cronJob.Spec.StartingDeadlineSeconds != nil &#123; // controller is not going to schedule anything below this point schedulingDeadline := now.Add(-time.Second * time.Duration(*cronJob.Spec.StartingDeadlineSeconds)) // 如果 earliestTime 晚于 schedulingDeadline，则将 earliestTime 更新为 schedulingDeadline。 if schedulingDeadline.After(earliestTime) &#123; earliestTime = schedulingDeadline &#125; &#125; if earliestTime.After(now) &#123; return time.Time&#123;&#125;, sched.Next(now), nil &#125; starts := 0 for t := sched.Next(earliestTime); !t.After(now); t = sched.Next(t) &#123; // 最终记录的是最近一次错过的时间 lastMissed = t // 一共发现了多少个错过的时间点 starts++ if starts &gt; 100 &#123; // We can&#x27;t get the most recent times so just return an empty slice return time.Time&#123;&#125;, time.Time&#123;&#125;, fmt.Errorf(&quot;Too many missed start times (&gt; 100). Set or decrease .spec.startingDeadlineSeconds or check clock skew.&quot;) &#125; &#125; return lastMissed, sched.Next(now), nil &#125; // 错过的 Cron 执行时间， nextRun 下一次执行的时间 missedRun, nextRun, err := getNextSchedule(&amp;cronJob, r.Now()) if err != nil &#123; log.Error(err, &quot;unable to figure out CronJob schedule&quot;) // we don&#x27;t really care about requeuing until we get an update that // fixes the schedule, so don&#x27;t return an error return ctrl.Result&#123;&#125;, nil &#125; 如果missedRun为0，说明没有需要调度的时间点，直接返回下一次调度的时间。 12345678scheduledResult := ctrl.Result&#123;RequeueAfter: nextRun.Sub(r.Now())&#125; // save this so we can re-use it elsewhere // 日志添加当前时间（now）和下一次运行时间（next run）两个字段。 log = log.WithValues(&quot;now&quot;, r.Now(), &quot;next run&quot;, nextRun) // 没有错过任何调度。 if missedRun.IsZero() &#123; log.V(1).Info(&quot;no upcoming scheduled times, sleeping until next&quot;) return scheduledResult, nil &#125; 运行新的 Job, 确定新 Job 没有超过 deadline 时间，且不会被 concurrency 规则 block检查 Job运行的时间点是否还在 deadline 时间内，没有直接返回scheduledResult12345678910111213log = log.WithValues(&quot;current run&quot;, missedRun) // 定义一个标志变量，表示“是否已经太迟不能补救” tooLate := false if cronJob.Spec.StartingDeadlineSeconds != nil &#123; // 当前时间是否已经超过了 missedRun + startingDeadlineSeconds tooLate = missedRun.Add(time.Duration(*cronJob.Spec.StartingDeadlineSeconds) * time.Second).Before(r.Now()) &#125; if tooLate &#123; // “太迟”，就打印日志，什么都不做，等待下次调度 log.V(1).Info(&quot;missed starting deadline for last run, sleeping till next&quot;) // TODO(directxman12): events return scheduledResult, nil &#125; [!NOTE] 个人理解：检查是否还在 deadline 时间内 missedRun在上一步骤是通过sched.Next（当前时间-StartingDeadlineSeconds）计算得出，若missedRun存在，那么条件missedRun.Add(time.Duration(*cronJob.Spec.StartingDeadlineSeconds) * time.Second).Before(r.Now())，一定是可以满足的，所以这一步骤做了冗余检查。 controller 有延迟（reconcile 不是实时触发），从上次计算r.Now()和这次调用的r.Now()计算的时间不同，所以不能 100% 保证 missedRun 一定还在“合法的执行时间窗口”内。因此要做一次检查。 执行并发规则123456789101112131415161718// 如果当前 CronJob 的策略是禁止并发（ForbidConcurrent），并且还有未完成的 Job, 直接跳过本次调度 if cronJob.Spec.ConcurrencyPolicy == batchv1.ForbidConcurrent &amp;&amp; len(activeJobs) &gt; 0 &#123; log.V(1).Info(&quot;concurrency policy blocks concurrent runs, skipping&quot;, &quot;num active&quot;, len(activeJobs)) return scheduledResult, nil &#125; // ...or instruct us to replace existing ones... // 替换运行中的 Job if cronJob.Spec.ConcurrencyPolicy == batchv1.ReplaceConcurrent &#123; // 当前所有还在运行的 Job 全部删除 for _, activeJob := range activeJobs &#123; // we don&#x27;t care if the job was already deleted if err := r.Delete(ctx, activeJob, client.PropagationPolicy(metav1.DeletePropagationBackground)); client.IgnoreNotFound(err) != nil &#123; log.Error(err, &quot;unable to delete active job&quot;, &quot;job&quot;, activeJob) return ctrl.Result&#123;&#125;, err &#125; &#125; &#125; 创建job123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 创建实际 Job 的核心逻辑 constructJobForCronJob := func(cronJob *batchv1.CronJob, scheduledTime time.Time) (*kbatch.Job, error) &#123; // We want job names for a given nominal start time to have a deterministic name to avoid the same job being created twice name := fmt.Sprintf(&quot;%s-%d&quot;, cronJob.Name, scheduledTime.Unix()) job := &amp;kbatch.Job&#123; ObjectMeta: metav1.ObjectMeta&#123; Labels: make(map[string]string), Annotations: make(map[string]string), Name: name, Namespace: cronJob.Namespace, &#125;, Spec: *cronJob.Spec.JobTemplate.Spec.DeepCopy(), &#125; for k, v := range cronJob.Spec.JobTemplate.Annotations &#123; job.Annotations[k] = v &#125; // 注解添加执行的时间 job.Annotations[scheduledTimeAnnotation] = scheduledTime.Format(time.RFC3339) for k, v := range cronJob.Spec.JobTemplate.Labels &#123; job.Labels[k] = v &#125; // 表示这个 Job 是由哪个 CronJob 控制的 if err := ctrl.SetControllerReference(cronJob, job, r.Scheme); err != nil &#123; return nil, err &#125; return job, nil &#125; // actually make the job... // 构造 Job job, err := constructJobForCronJob(&amp;cronJob, missedRun) if err != nil &#123; log.Error(err, &quot;unable to construct job from template&quot;) // don&#x27;t bother requeuing until we get a change to the spec return scheduledResult, nil &#125; // ...and create it on the cluster // 集群创建job if err := r.Create(ctx, job); err != nil &#123; log.Error(err, &quot;unable to create Job for CronJob&quot;, &quot;job&quot;, job) return ctrl.Result&#123;&#125;, err &#125; log.V(1).Info(&quot;created Job for CronJob run&quot;, &quot;job&quot;, job) return scheduledResult, nil SetupWithManager 逻辑初始化r.Clock给 Reconciler 设置一个默认的“时钟实现”。 在 CronJob Controller 里，需要获取“当前时间”来决定下一次调度时间是否到了，比如在这个调用中： 1missedRun, nextRun, err := getNextSchedule(&amp;cronJob, r.Now()) 看到的 r.Now()，其实就是： 123456789type Clock interface &#123; Now() time.Time&#125;type realClock struct&#123;&#125;func (realClock) Now() time.Time &#123; return time.Now()&#125; 添加索引还记得查找job时的函数吗？ 1r.List(ctx, &amp;childJobs, client.InNamespace(req.Namespace), client.MatchingFields&#123;jobOwnerKey: req.Name&#125;) r.List：用来列出某种类型的 Kubernetes 对象。在这里是列出所有 Job 类型的对象，并将它们填充到 childJobs。 client.MatchingFields&#123;jobOwnerKey: req.Name&#125;：字段选择器（field selector），表示只匹配jobOwnerKey 字段等于 req.Name 的 Job。 jobOwnerKey 是哪里来的？ 在 controller 初始化时，手动为 Job 设置的一个索引字段 key。 1234var ( jobOwnerKey = &quot;.metadata.controller&quot; apiGVStr = batchv1.GroupVersion.String()) 12345678910111213141516171819if err := mgr.GetFieldIndexer().IndexField(context.Background(), &amp;kbatch.Job&#123;&#125;, jobOwnerKey, func(rawObj client.Object) []string &#123; // grab the job object, extract the owner... // 首先将原始对象转换为 kbatch.Job 类型 job := rawObj.(*kbatch.Job) owner := metav1.GetControllerOf(job) if owner == nil &#123; return nil &#125; // ...make sure it&#x27;s a CronJob... if owner.APIVersion != apiGVStr || owner.Kind != &quot;CronJob&quot; &#123; return nil &#125; // ...and if so, return it return []string&#123;owner.Name&#125; &#125;); err != nil &#123; return err &#125; mgrmgr.GetFieldIndexer().IndexField(...) 这是 controller-runtime 提供的方法，用来给某种资源（这里是 Job）建立字段索引。 jobOwnerKey 是索引字段的名字，通常是个字符串（比如 &quot;metadata.owner&quot; 或者自定义的名字）。 后面那个函数是如何从 Job 中提取这个字段值的逻辑。 12345return ctrl.NewControllerManagedBy(mgr). For(&amp;batchv1.CronJob&#123;&#125;). Owns(&amp;kbatch.Job&#123;&#125;). Named(&quot;cronjob&quot;). Complete(r) “告诉 Controller Manager：要管理 CronJob 对象（主资源），并且也需要关注由它控制的 Job 对象（子资源）。” main.go使用任何其他 CRD，则必须以相同的方式添加其 scheme。 1234567891011var ( scheme = runtime.NewScheme() setupLog = ctrl.Log.WithName(&quot;setup&quot;))func init() &#123; _ = clientgoscheme.AddToScheme(scheme) _ = batchv1.AddToScheme(scheme) // +kubebuilder:scaffold:scheme&#125; 更改是 kubebuilder 添加了一个块代码， 该代码调用了我们的 CronJob controller 的 SetupWithManager 方法。 1234567if err = (&amp;controller.CronJobReconciler&#123; Client: mgr.GetClient(), Scheme: mgr.GetScheme(), &#125;).SetupWithManager(mgr); err != nil &#123; setupLog.Error(err, &quot;unable to create controller&quot;, &quot;controller&quot;, &quot;CronJob&quot;) os.Exit(1) &#125; 设置 webhook，只需要将它们添加到管理器中即可。可能希望单独运行 webhook，或者在本地测试控制器时不运行它们，因此将它们放在环境变量后面。 123456if os.Getenv(&quot;ENABLE_WEBHOOKS&quot;) != &quot;false&quot; &#123; if err = webhookbatchv1.SetupCronJobWebhookWithManager(mgr); err != nil &#123; setupLog.Error(err, &quot;unable to create webhook&quot;, &quot;webhook&quot;, &quot;CronJob&quot;) os.Exit(1) &#125; &#125; 其他详解Reconcile返回值Reconcile() 的签名是这样的： 1Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) 返回值 含义 ctrl.Result&#123;&#125; 不需要立即重新调度 ctrl.Result&#123;Requeue: true&#125; 立刻重新调度 ctrl.Result&#123;RequeueAfter: time.Duration&#125; 过一段时间后自动调度 error != nil 表示出错，控制器会立即重试 controller-runtime 框架内部根据返回的 ctrl.Result 自动决定是否&#x2F;何时重新执行 Reconcile() 的。不需要自己管理这些调度行为。 框架源码示意（仅供理解） 在 controller-runtime 源码中（比如在 pkg/internal/controller/controller.go 里）有类似的逻辑： 12345if result.Requeue &#123; queue.AddRateLimited(req)&#125; else if result.RequeueAfter &gt; 0 &#123; queue.AddAfter(req, result.RequeueAfter)&#125; controller 会把 req（也就是那个 CronJob 的名字）重新塞到队列里，等时间到了就再次调用 Reconcile。 执行流程SetupWithManager 先执行，Reconcile 只有在资源变更或手动触发后才执行。 启动流程详细解释在 main.go 中写了这样的代码： 123456if err := (&amp;controllers.CronJobReconciler&#123; Client: mgr.GetClient(), // ...&#125;).SetupWithManager(mgr); err != nil &#123; // handle error&#125; 这段代码注册了自定义的 Reconcile 逻辑到控制器运行框架中（controller-runtime 的 manager），这个 SetupWithManager() 的作用是：告诉 controller-runtime：这个控制器要 watch 哪些资源、怎么处理它们。 1234if err := mgr.Start(ctrl.SetupSignalHandler()); err != nil &#123; setupLog.Error(err, &quot;problem running manager&quot;) os.Exit(1) &#125; 这是一个阻塞操作，一旦调用： 所有注册的 controller 都会启动控制循环。 各 controller 会开始监听它们所关心的 Kubernetes 资源变更（通过 informer）。 SetupWithManager 什么时候执行？ SetupWithManager它在 mgr.Start() 之前执行，仅执行 一次。做的事情包括： 通过 .For()、.Owns() 设置要 watch 的 GVK（资源类型） 构造 controller 对象，并注入 Reconcile 逻辑 注册到 manager 中的控制器队列里 它是注册阶段的配置函数，而不是控制循环的一部分。 Reconcile 什么时候执行？ manager 启动后 当 Kubernetes 中的资源（例如 CronJob、Job）发生变化时（增删改） 或你手动设置了 .Result&#123;Requeue: true&#125; 或 .RequeueAfter 或用 event recorder 或 channel 明确触发它 123456789main() 开始 ↓SetupWithManager() 执行（注册控制器） ↓mgr.Start() 启动 manager，控制循环开始 ↓监听资源变更（informer） ↓当有资源变化 -&gt; 调用 Reconcile() webhook只需要实现 Defaulter 和 (或) Validator 接口 其余的东西 Kubebuilder 会自动实现，比如： 创建一个 webhook server 确保这个 server 被添加到 manager 中 为你的 webhooks 创建一个 handlers 将每个 handler 以 path 形式注册到你的 server 中 首先，让我们为 CRD（CronJob）创建 webhooks 12kubebuilder create webhook --group batch --version v1 --kind CronJob --defaulting --programmatic-validation 这将创建 Webhook 功能相关的方法，并在 main.go 中注册 Webhook 到你的 manager 中。","categories":[],"tags":[]},{"title":"Llama-factory LoRA 微调","slug":"Llama-factory微调","date":"2024-11-04T08:34:38.000Z","updated":"2025-04-24T08:47:11.386Z","comments":true,"path":"2024/11/04/Llama-factory微调/","link":"","permalink":"http://peapod.top/2024/11/04/Llama-factory%E5%BE%AE%E8%B0%83/","excerpt":"","text":"Llama-factory LoRA 微调简介LLaMA-Factory 是一个开源的、简单易用且高效的大型语言模型（LLM）训练与微调框架，旨在帮助用户以低代码或无代码的方式对超过 100 种预训练模型进行高效微调。它支持多种模型（如 LLaMA、Mistral、Qwen、Gemma、Phi 等）以及多种训练任务，包括预训练、监督微调（SFT）、奖励模型训练、PPO、DPO、KTO、ORPO 等。 核心特点 广泛的模型支持：支持 LLaMA、LLaVA、Mistral、Qwen、Gemma、ChatGLM 等 100+ 种语言模型和视觉-语言模型（VLMs）。 高效微调技术： 支持全参数微调、冻结微调、LoRA（低秩适配）和 QLoRA（量化 LoRA，2&#x2F;3&#x2F;4&#x2F;5&#x2F;6&#x2F;8 位）。 集成优化算法，如 GaLore、BAdam、DoRA、LongLoRA、LoRA+、PiSSA 等。 使用加速技术，如 FlashAttention-2、Unsloth 和 Liger Kernel，显著提升训练速度和降低 GPU 内存占用（相比 ChatGLM 的 P-Tuning，LoRA 微调速度快 3.7 倍）。 用户友好界面： 提供 LlamaBoard WebUI，允许通过图形界面调整模型、数据集和超参数，无需编码。 支持命令行接口（CLI）用于更灵活的配置。 多样化的数据集支持： 内置多种数据集（如 Alpaca、ShareGPT 格式），并支持自定义数据集（JSON 格式）。 可从 Hugging Face、ModelScope 或本地加载数据集。 灵活的部署与推理： 支持 vLLM、SGLang 等推理后端，加速推理过程。 可将微调模型导出到 Hugging Face 或以 GGUF 格式用于本地部署。 实验监控：集成 LlamaBoard、TensorBoard、Wandb、MLflow、SwanLab 等工具，实时监控训练进度和损失曲线。 多设备兼容：支持 GPU（CUDA）、NPU（Ascend）等计算设备，兼容多节点分布式训练。 [!NOTE] 文档地址：https://llamafactory.readthedocs.io/zh-cn/latest/ Nvidia 环境构建镜像编辑Dockerfile文件： 12345678910111213141516171819202122232425FROM ljxha471758/llama-factory# 设置工作目录WORKDIR /app# 安装必要的软件包RUN apt-get update &amp;&amp; apt-get install -y \\ git \\ vim \\ libaio-dev &amp;&amp; \\ apt-get clean &amp;&amp; \\ rm -rf /var/lib/apt/lists/*# 克隆 LLaMA-Factory 项目，深度为 1 以减少克隆大小RUN git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git# 进入 LLaMA-Factory 目录WORKDIR /app/LLaMA-Factory# 安装 Python 依赖RUN pip install --upgrade pip &amp;&amp; \\ pip install -e &quot;.[torch,metrics]&quot;# 设置默认的启动命令（可选）CMD [&quot;/bin/bash&quot;] 构建镜像： 1docker build --platform linux/amd64 -t llama-factory-image -f Dockerfile . 启动镜像1sudo docker run -it --privileged --gpus all --shm-size=50g -v /mnt/data/model/Qwen2.5-0.5B-Instruct:/app/models/Qwen2.5-0.5B-Instruct llama-factory **--privileged**：以特权模式运行容器，允许容器访问主机的所有设备。 **--gpus all**：启用容器对所有可用 GPU 的访问。通常用于深度学习的训练或推理任务，使得容器中的应用可以使用主机的 GPU 资源。 **--shm-size=50g**：将共享内存（/dev/shm）大小设置为 50 GB。 许多深度学习框架在处理大批量数据时需要较大的共享内存。 增加共享内存的大小可以减少因内存不足导致的错误，特别是使用大模型或大数据集时。 **-v /mnt/data/model/Qwen2.5-0.5B-Instruct:/app/models/Qwen2.5-0.5B-Instruct**：将主机的 /mnt/data/model/Qwen2.5-0.5B-Instruct 目录挂载到容器内的 /app/models/Qwen2.5-0.5B-Instruct 目录下。 执行命令微调1234567891011121314151617181920212223242526272829FORCE_TORCHRUN=1 CUDA_VISIBLE_DEVICES=0,1,3,4 llamafactory-cli train \\ --stage sft \\ --do_train \\ --model_name_or_path /app/models/Qwen2.5-0.5B-Instruct \\ --dataset alpaca_zh_demo \\ --dataset_dir ./data \\ --template qwen \\ --finetuning_type lora \\ --output_dir ./saves/qwen/lora/sft \\ --overwrite_cache \\ --overwrite_output_dir \\ --cutoff_len 1024 \\ --preprocessing_num_workers 16 \\ --per_device_train_batch_size 1 \\ --per_device_eval_batch_size 1 \\ --gradient_accumulation_steps 4 \\ --lr_scheduler_type cosine \\ --logging_steps 50 \\ --warmup_steps 20 \\ --save_steps 100 \\ --eval_steps 50 \\ --evaluation_strategy steps \\ --load_best_model_at_end \\ --learning_rate 5e-5 \\ --num_train_epochs 5.0 \\ --max_samples 1000 \\ --val_size 0.1 \\ --plot_loss \\ --fp16 合并123456789llamafactory-cli export \\ --model_name_or_path /app/models/Qwen2.5-0.5B-Instruct \\ --adapter_name_or_path ./saves/LLaMA3-8B/lora/sft \\ --template qwen \\ --finetuning_type lora \\ --export_dir models/llama3_lora_sft \\ --export_size 2 \\ --export_device cpu \\ --export_legacy_format false 华为 NPU 环境构建镜像使用官方文件构建镜像：https://github.com/hiyouga/LLaMA-Factory/tree/main/docker 使用NPU版本的文件构建镜像。 容器启动1234567891011121314151617181920docker run -it --rm \\--privileged \\-v /root/llama/hf_cache:/root/.cache/huggingface \\-v /root/llama/ms_cache:/root/.cache/modelscope \\-v /root/llama/output:/app/output \\-v /usr/local/dcmi:/usr/local/dcmi \\-v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \\-v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\-v /etc/ascend_install.info:/etc/ascend_install.info \\-v /data/model/Qwen2.5-0.5B-Instruct:/app/models/Qwen2.5-0.5B-Instruct \\-v /data/model/data:/app/data \\-p 7860:7860 \\-p 8000:8000 \\--device /dev/davinci2 \\--device /dev/davinci_manager \\--device /dev/devmm_svm \\--device /dev/hisi_hdc \\--shm-size 50g \\--name llamafactory1 \\llama-factory-npu:v1 /bin/bash 需要将主机的相关显卡的插件挂在到容器中。 执行命令微调123456789101112131415161718192021222324252627FORCE_TORCHRUN=1 ASCEND_RT_VISIBLE_DEVICES=1 llamafactory-cli train \\ --stage sft \\ --do_train \\ --model_name_or_path /app/models/Qwen2.5-0.5B-Instruct \\ --dataset alpaca_zh_demo \\ --dataset_dir ./data \\ --template qwen \\ --finetuning_type lora \\ --output_dir ./saves/qwen/lora/sft \\ --overwrite_cache \\ --overwrite_output_dir \\ --cutoff_len 1024 \\ --preprocessing_num_workers 16 \\ --per_device_train_batch_size 1 \\ --per_device_eval_batch_size 1 \\ --gradient_accumulation_steps 4 \\ --lr_scheduler_type cosine \\ --logging_steps 50 \\ --warmup_steps 20 \\ --save_steps 100 \\ --eval_steps 50 \\ --learning_rate 5e-5 \\ --num_train_epochs 5.0 \\ --max_samples 1000 \\ --val_size 0.1 \\ --plot_loss \\ --fp16 合并123456789llamafactory-cli export \\ --model_name_or_path /app/models/Qwen2.5-0.5B-Instruct \\ --adapter_name_or_path ./saves/qwen/lora/sft \\ --template qwen \\ --finetuning_type lora \\ --export_dir models/Qwen2.5 \\ --export_size 2 \\ --export_device cpu \\ --export_legacy_format false 1docker cp d2448a59c136b3f04:/app/saves/qwen/lora/sft ./saves/qwen/lora/sft","categories":[],"tags":[{"name":"LLM","slug":"LLM","permalink":"http://peapod.top/tags/LLM/"}]},{"title":"OpenAI-Gateway设计与实现","slug":"gateway实现","date":"2024-10-18T07:25:42.000Z","updated":"2025-04-24T09:24:46.434Z","comments":true,"path":"2024/10/18/gateway实现/","link":"","permalink":"http://peapod.top/2024/10/18/gateway%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"OpenAI-Gateway设计与实现项目背景微服务API网关通常可以反向代理系统内部的服务，保证内部服务对外不可见和安全。网关作为统一的流量入口，还可以实现负载均衡等、流量限制、消峰平谷、节点路由等功能，与Prometheus结合时还可以提供所有请求的监控统计功能。 在maas（模型即服务）系统的构建过程中，底层使用Ollamm和VLLM等框架推理模型并提供服务。使用K8s实现推理Pod和Server的管理，方便挂载模型文件、与推理日志的采集。在启用多个模型服务之后，需要对外提供统一的模型接口，统计每个模型调用的token使用情况。网关需要实现以下功能： 支持OpenAI的标准接口调用，如chat 通过请求中模型名称转发到后端的推理服务 相同模型推理服务的后端节点的自动选择 校验apikey的正确性 记录首token、单对话token数量等的统计 每个模型的调用统计 项目实现相关技术web框架：fiber fiber基于fasthttp实现，fasthttp引入协程池，对比net&#x2F;http具有更高的性能。但截至当前暂不支持http2,需要配合其他包实现。 中间件：PostgresqlDb、Kafka、Influxdb、Redis、Prometheus、Grafana 部署方式：docker镜像、K8s、kubevela CI 请求流程 执行步骤： 用户使用标准OpenAI接口调用模型，向网关发送请求 网关获取请求之后，校验apikey并根据请求参数找到真实的模型地址 网关创建一个客户端，使用客户端请求模型 客户端得到响应之后，根据需求分析响应的内容（计算token） 客户端将响应赋值给网关的响应 网关返回响应给用户 项目架构客户端架构 上图是项目gateway中client的实现，具体实现可以参考在项目中的内容。 重点分析：大模型的调用一般返回的都是流式响应，客户端获取的响应和网关返回给用户的响应都是流式数据，在fasthttp的实现中，响应的读取使用io read实现，读取客户端的响应就会将响应读取完，不能赋值给网关的响应。具体的请求转发逻辑的实现，在那个过程实现。可以封装fasthttp client在其之上实现，也可以直接在网关层实现。 问题解决流式返回的内容在网关读取的同时，也需要返回给用户。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182func (c *client) Do(ctx *fiber.Ctx) error &#123; //to do //选择器 n := c.applier.nodes[0] apikey := ctx.Get(&quot;Authorization&quot;)[7:] modelName := ctx.Locals(&quot;modelName&quot;).(string) reqBody := tools.Analysis(ctx) clientReq := fasthttp.AcquireRequest() clientRes := fasthttp.AcquireResponse() resp := ctx.Response() req := ctx.Request() resp.StreamBody = true clientRes.StreamBody = true clientReq = ctx.Request() originalURL := utils.CopyString(string(req.RequestURI())) defer clientReq.SetRequestURI(originalURL) copiedURL := utils.CopyString(n.address) clientReq.SetRequestURI(copiedURL) if scheme := getScheme(utils.UnsafeBytes(copiedURL)); len(scheme) &gt; 0 &#123; clientReq.URI().SetSchemeBytes(scheme) &#125; err := n.client.Do(clientReq, clientRes) if err != nil &#123; GatewayLog.Error().Str(&quot;ERROR_CODE&quot;, e.GetMsg(e.ERROR)).Msg(err.Error()) return err &#125; bodyStream := clientRes.BodyStream() if bodyStream == nil &#123; return errors.New(&quot;response body stream is nil&quot;) &#125; pr, pw := io.Pipe() startTime := time.Now() EndMessage := &quot;&quot; CompletionTokens := 0 go func() &#123; defer func() &#123; err := pw.Close() if err != nil &#123; GatewayLog.Error().Str(&quot;ERROR_CODE&quot;, e.GetMsg(e.ERROR)).Msg(err.Error()) &#125; err = clientRes.CloseBodyStream() if err != nil &#123; GatewayLog.Error().Str(&quot;ERROR_CODE&quot;, e.GetMsg(e.ERROR)).Msg(err.Error()) &#125; &#125;() buf := make([]byte, 1024) for &#123; n, readErr := bodyStream.Read(buf) if readErr != nil &amp;&amp; readErr != io.EOF &#123; GatewayLog.Error().Str(&quot;ERROR_CODE&quot;, e.GetMsg(e.ERROR)).Msg(readErr.Error()) return &#125; _, writeErr := pw.Write(buf[:n]) if writeErr != nil &#123; GatewayLog.Error().Str(&quot;ERROR_CODE&quot;, e.GetMsg(e.ERROR)).Msg(writeErr.Error()) return &#125; //fmt.Printf(&quot;%s&quot;, string(buf[:n])) CompletionTokens += 1 if readErr == io.EOF &#123; EndMessage = string(buf[:n]) break &#125; &#125; endTime := time.Now() go Handler(apikey, modelName, endTime.Sub(startTime), EndMessage, CompletionTokens, reqBody, clientRes.StatusCode(), ) &#125;() ctx.Set(&quot;Content-Type&quot;, &quot;text/event-stream&quot;) resp.SetBodyStream(pr, -1) return nil&#125; 在代码中使用pr, pw := io.Pipe()管道从clientRes.BodyStream中读取流式数据并做相关的处理，同时将读到的内容写到 pw.Write(buf[:n])，网关从管道中读到网关的响应resp.SetBodyStream(pr, -1)。","categories":[],"tags":[]},{"title":"Doker 教程","slug":"Doker-教程","date":"2024-08-27T03:33:07.000Z","updated":"2024-08-27T06:42:33.715Z","comments":true,"path":"2024/08/27/Doker-教程/","link":"","permalink":"http://peapod.top/2024/08/27/Doker-%E6%95%99%E7%A8%8B/","excerpt":"","text":"Docker 实践简介Docker 使用 Google 公司推出的 Go 语言进行开发实现，基于 Linux 内核的 cgroup ，namespace ，以及 OverlayFS类的 Union FS等技术，对进程进行封装隔离，属于 操作系统层面的虚拟化技术 。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 版本开始，则进一步演进为使用 runC和。 runc 是一个 Linux 命令行工具，用于根据 OCI容器运行时规范创建和运行容器。 containerd 是一个守护程序，它管理容器生命周期，提供了在一个节点上执行容器和管理镜像的最小功能集。 基本概念Docker 包括三个基本概念 镜像（Image） 容器（Container） 仓库（Repository） 镜像Docker 镜像 是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 不包含 任何动态数据，其内容在构建之后也不会被改变。 分层存储在 Docker 设计时，就充分利用 Union FS的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。 在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 容器容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。 容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。 每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为 容器存储层。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 仓库一个 Docker Registry 中可以包含多个 仓库（Repository）；每个仓库可以包含多个 标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 镜像基础命令获取镜像1docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] 运行镜像1docker run -it --rm ubuntu:18.04 bash 参数： -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。交互式终端。 --rm：这个参数是说容器退出后随之将其删除。因此使用 --rm 可以避免浪费空间。 ubuntu:18.04：这是指用 ubuntu:18.04 镜像为基础来启动容器。 bash：放在镜像名后的是 命令，有个交互式 Shell，用的是 bash。 列出镜像123456789docker image ls# 显示中间层镜像docker image ls -a# 根据仓库名列出镜像docker image ls ubuntu# 过滤器参数 --filter，或者简写 -fdocker image ls -f since=mongo:3.2# 格式化显示docker image ls --format &quot;&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;&quot; 列表包含了 仓库名、标签、镜像 ID、创建时间 以及 所占用的空间。 1docker system df 查看镜像、容器、数据卷所占用的空间 删除镜像1docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 镜像的唯一标识是其 ID 和摘要，而一个镜像可以有多个标签。 删除行为分为两类，一类是 Untagged，另一类是 Deleted。删除镜像的时候，实际上是在要求删除某个标签的镜像。当该镜像所有的标签都被取消了，该镜像很可能会失去了存在的意义，因此会触发删除行为。 有用这个镜像启动的容器存在（即使容器没有运行），那么同样不可以删除这个镜像。 1docker image rm $(docker image ls -q redis) commitdocker commit 命令有一些特殊的应用场合，比如被入侵后保存现场等。不要使用 docker commit 定制镜像，定制镜像应该使用 Dockerfile 来完成。 修改了容器的文件，也就是改动了容器的存储层。可以通过 docker diff 命令看到具体的改动。 1docker diff webserver 运行一个容器的时候（如果不使用卷的话），做的任何文件修改都会被记录于容器存储层。 docker commit 命令，可以将容器的存储层保存下来成为镜像。换句话说，就是在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像。 1234567docker commit [选项] &lt;容器ID或容器名&gt; [&lt;仓库名&gt;[:&lt;标签&gt;]]docker commit \\ --author &quot;Tao Wang &lt;twang2218@gmail.com&gt;&quot; \\ --message &quot;修改了默认网页&quot; \\ webserver \\ nginx:v2 使用 docker commit 意味着所有对镜像的操作都是黑箱操作，生成的镜像也被称为 黑箱镜像。 导入和导出 docker save 和 docker load 命令，用以将镜像保存为一个文件，然后传输到另一个位置上，再加载进来。 12345678# 将镜像保存为归档文件docker save alpine -o filename# 使用 gzip 压缩docker save alpine | gzip &gt; alpine-latest.tar.gz# 加载镜像docker load -i alpine-latest.tar.gz# 镜像迁移docker save &lt;镜像名&gt; | bzip2 | pv | ssh &lt;用户名&gt;@&lt;主机名&gt; &#x27;cat | docker load&#x27; 容器操作启动容器启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止状态（exited）的容器重新启动。 命令主要为 docker run。 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从 registry 下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 利用 docker container start 命令，直接将一个已经终止（exited）的容器启动运行。 后台运行需要让 Docker 在后台运行而不是直接把执行命令的结果输出在当前宿主机下。此时，可以通过添加 -d 参数来实现。 容器会在后台运行并不会把输出的结果 (STDOUT) 打印到宿主机上面(输出结果可以用 docker logs 查看)。 要获取容器的输出信息，可以通过 docker container logs 命令。 终止容器可以使用 docker container stop 来终止一个运行中的容器。 终止状态的容器可以用 docker container ls -a 命令看到。 docker container restart 命令会将一个运行态的容器终止，然后再重新启动它。 进入容器docker exec 后边可以跟多个参数，这里主要说明 -i -t 参数。当 -i -t 参数一起使用时，则可以看到 Linux 命令提示符。 删除容器可以使用 docker container rm 来删除一个处于终止状态的容器。 清理所有处于终止状态的容器。 1$ docker container prune 数据管理在容器中管理数据主要有两种方式： 数据卷（Volumes） 挂载主机目录 (Bind mounts) 数据卷数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性： 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 数据卷操作123456# 创建docker volume create my-vol# 查看docker volume ls# 查看指定 数据卷 的信息docker volume inspect my-vol 用 docker run 命令的时候，使用 --mount 标记来将 数据卷 挂载到容器里。 下面创建一个名为 web 的容器，并加载一个 数据卷 到容器的 /usr/share/nginx/html 目录。 12345$ docker run -d -P \\ --name web \\ # -v my-vol:/usr/share/nginx/html \\ --mount source=my-vol,target=/usr/share/nginx/html \\ nginx:alpine 查看 web 容器的信息 123456789101112131415$ docker inspect web&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125;], 删除数据卷 1docker volume rm my-vol 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。 挂载主机目录使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。 12345$ docker run -d -P \\ --name web \\ # -v /src/webapp:/usr/share/nginx/html \\ --mount type=bind,source=/src/webapp,target=/usr/share/nginx/html \\ nginx:alpine 上面的命令加载主机的 /src/webapp 目录到容器的 /usr/share/nginx/html目录。 以前使用 -v 参数时如果本地目录不存在 Docker 会自动为你创建一个文件夹，现在使用 --mount 参数时如果本地目录不存在，Docker 会报错。 查看 web 容器的信息 123456789101112docker inspect web&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/src/webapp&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125;], 挂载一个本地主机文件作为数据卷记录在容器输入过的命令 123456789$ docker run --rm -it \\ # -v $HOME/.bash_history:/root/.bash_history \\ --mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history \\ ubuntu:18.04 \\ bashroot@2affd44b4667:/# history1 ls2 diskutil list 网络管理Docker 允许通过外部访问容器或容器互联的方式来提供网络服务。 外部访问容器容器中可以运行一些网络应用，要让外部也可以访问这些应用，可以通过 -P 或 -p 参数来指定端口映射。 当使用 -P 标记时，Docker 会随机映射一个端口到内部容器开放的网络端口。 -p 则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort。 1$ docker run -d -p 80:80 nginx:alpine 查看映射端口配置1docker port fa 80 注意： 容器有自己的内部网络和 ip 地址（使用 docker inspect 查看，Docker 还可以有一个可变的网络配置。） -p 标记可以多次使用来绑定多个端口 容器互联建议将容器加入自定义的 Docker 网络来连接多个容器，而不是使用 --link 参数。 创建Docker 网络1docker network create -d bridge my-net -d 参数指定 Docker 网络类型，有 bridge overlay。其中 overlay 网络类型用于 Swarm mode 连接容器12docker run -it --rm --name busybox1 --network my-net busybox shdocker run -it --rm --name busybox2 --network my-net busybox sh 如果你有多个容器之间需要互相连接，推荐使用 Docker Compose。 配置 DNS如何自定义配置容器的主机名和 DNS ，Docker 利用虚拟文件来挂载容器的 3 个相关配置文件。 使用 mount 命令可以看到挂载信息： 1234mount/dev/disk/by-uuid/1fec...ebdf on /etc/hostname type ext4 .../dev/disk/by-uuid/1fec...ebdf on /etc/hosts type ext4 ...tmpfs on /etc/resolv.conf type tmpfs ... 这种机制可以让宿主主机 DNS 信息发生更新后，所有 Docker 容器的 DNS 配置通过 /etc/resolv.conf 文件立刻得到更新。 使用 docker run 命令启动容器时加入如下参数： -h HOSTNAME 或者 --hostname=HOSTNAME 设定容器的主机名，它会被写到容器内的 /etc/hostname 和 /etc/hosts。 --dns=IP_ADDRESS 添加 DNS 服务器到容器的 /etc/resolv.conf 中，让容器用这个服务器来解析所有不在 /etc/hosts 中的主机名。 --dns-search=DOMAIN 设定容器的搜索域，当设定搜索域为 .example.com 时，在搜索一个名为 host 的主机时，DNS 不仅搜索 host，还会搜索 host.example.com。","categories":[],"tags":[]},{"title":"DokerFile","slug":"DokerFile","date":"2024-08-27T03:32:29.000Z","updated":"2024-08-27T03:32:45.125Z","comments":true,"path":"2024/08/27/DokerFile/","link":"","permalink":"http://peapod.top/2024/08/27/DokerFile/","excerpt":"","text":"Docker 实践简介Docker 使用 Google 公司推出的 Go 语言进行开发实现，基于 Linux 内核的 cgroup ，namespace ，以及 OverlayFS类的 Union FS等技术，对进程进行封装隔离，属于 操作系统层面的虚拟化技术 。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 版本开始，则进一步演进为使用 runC和。 runc 是一个 Linux 命令行工具，用于根据 OCI容器运行时规范创建和运行容器。 containerd 是一个守护程序，它管理容器生命周期，提供了在一个节点上执行容器和管理镜像的最小功能集。 基本概念Docker 包括三个基本概念 镜像（Image） 容器（Container） 仓库（Repository） 镜像Docker 镜像 是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 不包含 任何动态数据，其内容在构建之后也不会被改变。 分层存储在 Docker 设计时，就充分利用 Union FS的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。 在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 容器容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。 容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。 每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为 容器存储层。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 仓库一个 Docker Registry 中可以包含多个 仓库（Repository）；每个仓库可以包含多个 标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 镜像基础命令获取镜像1docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] 运行镜像1docker run -it --rm ubuntu:18.04 bash 参数： -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。交互式终端。 --rm：这个参数是说容器退出后随之将其删除。因此使用 --rm 可以避免浪费空间。 ubuntu:18.04：这是指用 ubuntu:18.04 镜像为基础来启动容器。 bash：放在镜像名后的是 命令，有个交互式 Shell，用的是 bash。 列出镜像123456789docker image ls# 显示中间层镜像docker image ls -a# 根据仓库名列出镜像docker image ls ubuntu# 过滤器参数 --filter，或者简写 -fdocker image ls -f since=mongo:3.2# 格式化显示docker image ls --format &quot;&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;&quot; 列表包含了 仓库名、标签、镜像 ID、创建时间 以及 所占用的空间。 1docker system df 查看镜像、容器、数据卷所占用的空间 删除镜像1docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 镜像的唯一标识是其 ID 和摘要，而一个镜像可以有多个标签。 删除行为分为两类，一类是 Untagged，另一类是 Deleted。删除镜像的时候，实际上是在要求删除某个标签的镜像。当该镜像所有的标签都被取消了，该镜像很可能会失去了存在的意义，因此会触发删除行为。 有用这个镜像启动的容器存在（即使容器没有运行），那么同样不可以删除这个镜像。 1docker image rm $(docker image ls -q redis) commitdocker commit 命令有一些特殊的应用场合，比如被入侵后保存现场等。不要使用 docker commit 定制镜像，定制镜像应该使用 Dockerfile 来完成。 修改了容器的文件，也就是改动了容器的存储层。可以通过 docker diff 命令看到具体的改动。 1docker diff webserver 运行一个容器的时候（如果不使用卷的话），做的任何文件修改都会被记录于容器存储层。 docker commit 命令，可以将容器的存储层保存下来成为镜像。换句话说，就是在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像。 1234567docker commit [选项] &lt;容器ID或容器名&gt; [&lt;仓库名&gt;[:&lt;标签&gt;]]docker commit \\ --author &quot;Tao Wang &lt;twang2218@gmail.com&gt;&quot; \\ --message &quot;修改了默认网页&quot; \\ webserver \\ nginx:v2 使用 docker commit 意味着所有对镜像的操作都是黑箱操作，生成的镜像也被称为 黑箱镜像。 导入和导出 docker save 和 docker load 命令，用以将镜像保存为一个文件，然后传输到另一个位置上，再加载进来。 12345678# 将镜像保存为归档文件docker save alpine -o filename# 使用 gzip 压缩docker save alpine | gzip &gt; alpine-latest.tar.gz# 加载镜像docker load -i alpine-latest.tar.gz# 镜像迁移docker save &lt;镜像名&gt; | bzip2 | pv | ssh &lt;用户名&gt;@&lt;主机名&gt; &#x27;cat | docker load&#x27;","categories":[],"tags":[]},{"title":"fyne 入门指南","slug":"fyne-入门指南","date":"2024-08-27T01:35:18.000Z","updated":"2024-08-27T01:35:51.909Z","comments":true,"path":"2024/08/27/fyne-入门指南/","link":"","permalink":"http://peapod.top/2024/08/27/fyne-%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/","excerpt":"","text":"Fyne 入门 指南简介Fyne是一个使用Go语言开发的跨平台GUI框架，它通过简单的API为开发现代桌面和移动应用提供了强大的工具。利用矢量图形和 Material Design，Fyne旨在构建美观、高性能的应用程序，支持自动缩放以适应不同屏幕尺寸和分辨率。 快速开始安装教程Fyne需要3个基本元素：Go工具（至少版本1.12）、一个C编译器（用于与系统图形驱动连接）和一个系统图形驱动。 Mac安装教程已经安装xcode 使用Go模块 下载Fyne模块和辅助工具 1234go mod init MODULE_NAMEgo get fyne.io/fyne/v2@latestgo install fyne.io/fyne/v2/cmd/fyne@latest 创建应用1234567891011121314package mainimport ( &quot;fyne.io/fyne/v2/app&quot; &quot;fyne.io/fyne/v2/widget&quot;)func main() &#123; a := app.New() // 创建一个应用实例 w := a.NewWindow(&quot;Hello World&quot;) // 打开一个窗口 w.SetContent(widget.NewLabel(&quot;Hello World!&quot;))// 设置为主内容 w.ShowAndRun() // 显示应用UI&#125; 应用与主循环图形用户界面（GUI）应用程序，需要运行一个事件循环（有时被称为运行循环），来处理用户交互和绘图事件。在Fyne中，通过使用App.Run()或Window.ShowAndRun()函数启动。这些函数中必须有一个在你的main()函数代码末尾被调用。 一个应用程序应该只有一个运行循环，在代码中只调用Run()一次。 一个应用程序可以通过调用App.Quit()直接退出（移动应用不支持此功能）。一旦所有窗口都被关闭，应用程序也将退出。 在应用程序退出之前，执行Run()之后的函数将不会被调用。 更新GUI内容1234567891011121314151617181920212223242526272829package mainimport ( &quot;time&quot; &quot;fyne.io/fyne/v2/app&quot; &quot;fyne.io/fyne/v2/widget&quot;)func updateTime(clock *widget.Label) &#123; formatted := time.Now().Format(&quot;Time: 03:04:05&quot;) clock.SetText(formatted)&#125;func main() &#123; a := app.New() w := a.NewWindow(&quot;Clock&quot;) clock := widget.NewLabel(&quot;&quot;) updateTime(clock) w.SetContent(clock) go func() &#123; for range time.Tick(time.Second) &#123; updateTime(clock) &#125; &#125;() w.ShowAndRun()&#125; window窗口窗口是使用App.NewWindow()创建的，并需要使用Show()函数来显示。 调用Window.Resize()方法来设置更大的尺寸。这个方法接受一个fyne.Size，其中包含使用设备独立像素的宽度和高度。 1w.Resize(fyne.NewSize(100, 100)) 设置一个窗口为“主窗口”，这样如果该窗口关闭，应用程序就会退出。要做到这一点，使用Window上的SetMaster()函数。 测试main.go 1234567891011121314151617181920212223242526package mainimport ( &quot;fyne.io/fyne/v2/app&quot; &quot;fyne.io/fyne/v2/container&quot; &quot;fyne.io/fyne/v2/widget&quot;)func SetUI() (*widget.Label, *widget.Entry) &#123; out := widget.NewLabel(&quot;hello world&quot;) in := widget.NewEntry() in.OnChanged = func(s string) &#123; out.SetText(&quot;hello &quot; + s) &#125; return out, in&#125;func main() &#123; app := app.New() window := app.NewWindow(&quot;test&quot;) window.SetContent(container.NewVBox(SetUI())) window.ShowAndRun()&#125; ui_test.go 12345678910111213141516package mainimport ( &quot;fyne.io/fyne/v2/test&quot; &quot;testing&quot;)func TestSetUI(t *testing.T) &#123; out, in := SetUI() test.Type(in, &quot;Andy&quot;) if out.Text != &quot;hello Andy&quot; &#123; t.Error(&quot;Incorrect user greeting&quot;) &#125;&#125; 打包“fyne”应用有一个“package”命令可以自动处理这一切。只需指定目标操作系统和任何所需的元数据（如图标），就会生成适当的包。对于.icns或.ico图标转换将自动完成，所以只需提供.png文件 :)。 要在 macOS 上为 Windows 或liunx目标系统构建应用程序，需要进行交叉编译。 设置环境变量Window123export GOOS=windowsexport GOARCH=amd64export CC=x86_64-w64-mingw32-gcc liunx12export GOOS=linuxexport GOARCH=amd64 命令执行12345fyne package -os darwin -icon myapp.pngfyne package -os linux -icon myapp.pngfyne package -os windows -icon myapp.png// 安装fyne install -icon myapp.png 从Fyne 2.1开始，使用 元数据文件，为项目设置默认选项。 元数据文件支持一个元数据文件，允许在仓库中存储有关应用的信息。这个文件是可选的，但可以帮助避免在每个包和发布命令中记住特定的构建参数。 文件应该命名为FyneApp.toml，位于你运行fyne命令的目录中（通常是main包）。 12345678Website = &quot;https://example.com&quot;[Details]Icon = &quot;Icon.png&quot;Name = &quot;My App&quot;ID = &quot;com.example.app&quot;Version = &quot;1.0.0&quot;Build = 1 文件的顶部部分是元数据，如果你将你的应用上传到https://apps.fyne.io列表页面时会使用，因此它是可选的。 [Details]部分包含了其他应用商店和操作系统在发布过程中使用的有关应用的数据。 如果找到了这个文件，fyne工具将会使用它，仍然可以使用命令行参数覆盖这些值。","categories":[],"tags":[]},{"title":"K8s 生产环境安装","slug":"K8s-生产环境安装","date":"2024-08-26T00:37:08.000Z","updated":"2024-08-26T00:38:30.139Z","comments":true,"path":"2024/08/26/K8s-生产环境安装/","link":"","permalink":"http://peapod.top/2024/08/26/K8s-%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/","excerpt":"","text":"K8s 生产环境安装容器运行时 说明： 自 1.24 版起，Dockershim 已从 Kubernetes 项目中移除。 在集群内每个节点上安装一个 容器运行时 以使 Pod 可以运行在上面。 Kubernetes 1.31 要求你使用符合容器运行时接口（CRI）的运行时。 在 Kubernetes 中几个常见的容器运行时的用法。 containerd CRI-O Docker Engine Mirantis Container Runtime 这里仅说明containerd的使用。Docker Engine 没有实现 CRI， 而这是容器运行时在 Kubernetes 中工作所需要的。 为此，必须安装一个额外的服务 cri-dockerd。 containerd使用 containerd 作为 CRI 运行时的必要步骤。 containerd 内置了对 Kubernetes 容器运行时接口 (CRI) 的支持。 https://github.com/containerd/containerd/blob/main/docs/getting-started.md 12345# 下载wget https://github.com/containerd/containerd/releases/download/v1.7.5/cri-containerd-1.7.5-linux-amd64.tar.gz# 安装# 可以安装到/usr/localtar xf cri-containerd-1.7.5-linux-amd64.tar.gz -C / 自定义containerd生成默认配置containerd config default &gt; /etc/containerd/config.toml。 在 Linux 上，containerd 的默认 CRI 套接字是 /run/containerd/containerd.sock。 配置 systemd cgroup 驱动在 /etc/containerd/config.toml 中 1SystemdCgroup = true 应用此更改，请确保重新启动 containerd： 1sudo systemctl restart containerd 当使用 kubeadm 时，请手动配置 kubelet 的 cgroup 驱动。 沙箱（pause）镜像在 /etc/containerd/config.toml 中， 可以通过设置以下选项重载沙箱镜像： 12[plugins.&quot;io.containerd.grpc.v1.cri&quot;] sandbox_image = &quot;registry.k8s.io/pause:3.2&quot; 需要重启 containerd：systemctl restart containerd。 先决条件默认情况下，Linux 内核不允许 IPv4 数据包在接口之间路由。 大多数 Kubernetes 集群网络实现都会更改此设置。 启用IPv4数据包转发123456789# 设置所需的 sysctl 参数，参数在重新启动后保持不变cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.confnet.ipv4.ip_forward = 1EOF# 应用 sysctl 参数而不重新启动sudo sysctl --system# 验证sysctl net.ipv4.ip_forward cgroup 驱动在 Linux 上，控制组（CGroup）用于限制分配给进程的资源。 kubelet 和底层容器运行时都需要对接控制组来强制执行 为 Pod 和容器管理资源 并为诸如 CPU、内存这类资源设置请求和限制。若要对接控制组，kubelet 和容器运行时需要使用一个 cgroup 驱动。 关键的一点是 kubelet 和容器运行时需使用相同的 cgroup 驱动并且采用相同的配置。 可用的 cgroup 驱动有两个： cgroupfs systemd 当 systemd 是选定的初始化系统时， kubelet 和容器运行时将 systemd 用作 cgroup 驱动。 使用部署工具安装 Kubernetes搭建 Kubernetes 生产集群有工具，例如： kubeadm kops kubespray 这里仅说明kubeadm。 使用 kubeadm 引导集群准备条件： 一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令。 每台机器 2 GB 或更多的 RAM（如果少于这个数字将会影响你应用的运行内存）。 CPU 2 核心及以上。 集群中的所有机器的网络彼此均能相互连接（公网和内网都可以）。 节点之中不可以有重复的主机名、MAC 地址或 product_uuid。请参见这里了解更多详细信息。 开启机器上的某些端口。请参见这里了解更多详细信息。 交换分区的配置。kubelet 的默认行为是在节点上检测到交换内存时无法启动。 如果 kubelet 未被正确配置使用交换分区，则你必须禁用交换分区。 例如，sudo swapoff -a 将暂时禁用交换分区。要使此更改在重启后保持不变，请确保在如 /etc/fstab、systemd.swap 等配置文件中禁用交换分区，具体取决于你的系统如何配置。 12vim /etc/fstab# 找到 /swap.img none swap sw 0 0 这一行，给注释掉 安装 kubeadm、kubelet 和 kubectl在每台机器上安装以下的软件包： kubeadm：用来初始化集群的指令。 kubelet：在集群中的每个节点上用来启动 Pod 和容器等。 kubectl：用来与集群通信的命令行工具。 kubeadm 不能安装或者管理 kubelet 或 kubectl， 所以需要确保它们与通过 kubeadm 安装的控制平面的版本相匹配。 1.更新 apt 包索引并安装使用 Kubernetes apt 仓库所需要的包： 123sudo apt-get update# apt-transport-https 可能是一个虚拟包（dummy package）；如果是的话，你可以跳过安装这个包sudo apt-get install -y apt-transport-https ca-certificates curl gpg 2.下载用于 Kubernetes 软件包仓库的公共签名密钥。所有仓库都使用相同的签名密钥，因此你可以忽略URL中的版本： 123# 如果 `/etc/apt/keyrings` 目录不存在，则应在 curl 命令之前创建它，请阅读下面的注释。# sudo mkdir -p -m 755 /etc/apt/keyringscurl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg 3.添加 Kubernetes apt 仓库。 请注意，此仓库仅包含适用于 Kubernetes 1.31 的软件包 12# 此操作会覆盖 /etc/apt/sources.list.d/kubernetes.list 中现存的所有配置。echo &#x27;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /&#x27; | sudo tee /etc/apt/sources.list.d/kubernetes.list 4.更新 apt 包索引，安装 kubelet、kubeadm 和 kubectl，并锁定其版本 123sudo apt-get updatesudo apt-get install -y kubelet kubeadm kubectlsudo apt-mark hold kubelet kubeadm kubectl 配置 cgroup 驱动程序要将 systemd 设置为 cgroup 驱动，需编辑 KubeletConfiguration 的 cgroupDriver 选项，并将其设置为 systemd。 1kubeadm config print init-defaults &gt; kubeadm-config.yaml 在kubeadm-config.yaml中修改，添加如下的内容 1234---kind: KubeletConfigurationapiVersion: kubelet.config.k8s.io/v1beta1cgroupDriver: systemd 使用 kubeadm 创建集群前提条件：在所有主机上安装容器运行时和 kubeadm。 kubeadm 与其他 Kubernetes 组件类似，会尝试在与主机默认网关关联的网络接口上找到可用的 IP 地址。 这个 IP 地址随 1ip route show # 查找以 &quot;default via&quot; 开头的行 后用于由某组件执行的公告和&#x2F;或监听。 初始化控制平面节点控制平面节点是运行控制平面组件的机器， 包括 etcd（集群数据库） 和 API 服务器 （命令行工具 kubectl 与之通信）。 初始化控制平面节点，请运行： 12# kubeadm init &lt;args&gt;kubeadm init --config kubeadm-config.yaml 要再次运行 kubeadm init，你必须首先卸载集群。 kubeadm init 首先运行一系列预检查以确保机器为运行 Kubernetes 准备就绪。 这些预检查会显示警告并在错误时退出。然后 kubeadm init 下载并安装集群控制平面组件。这可能会需要几分钟。完成之后应该看到： 12345678910111213141516Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a Pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: /docs/concepts/cluster-administration/addons/You can now join any number of machines by running the following on each nodeas root: kubeadm join &lt;control-plane-host&gt;:&lt;control-plane-port&gt; --token &lt;token&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt; 要使非 root 用户可以运行 kubectl，运行以下命令， 它们也是 kubeadm init 输出的一部分： 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 警告：kubeadm init 生成的 kubeconfig 文件 admin.conf 包含一个带有 Subject: O = kubeadm:cluster-admins, CN = kubernetes-admin 的证书。 kubeadm:cluster-admins 组被绑定到内置的 cluster-admin ClusterRole 上。 不要与任何人共享 admin.conf 文件。 kubeadm init 生成另一个 kubeconfig 文件 super-admin.conf， 其中包含带有 Subject: O = system:masters, CN = kubernetes-super-admin 的证书。 system:masters 是一个紧急访问、超级用户组，可以绕过授权层（例如 RBAC）。 不要与任何人共享 super-admin.conf 文件，建议将其移动到安全位置。 记录 kubeadm init 输出的 kubeadm join 命令。 你需要此命令将节点加入集群。 令牌用于控制平面节点和加入节点之间的相互身份验证。 这里包含的令牌是密钥。 安装 Pod 网络附加组件必须部署一个基于 Pod 网络插件的容器网络接口（CNI）， 它由一个规范和库组成，用于编写插件来配置 Linux 容器中的网络接口，以及许多受支持的插件。以便 Pod 可以相互通信。在安装网络之前，集群 DNS (CoreDNS) 将不会启动。每个集群只能安装一个 Pod 网络。 这里仅说明 Calico 。官方安装教程 Calico 是一个联网和网络策略供应商。 Calico 支持一套灵活的网络选项，因此你可以根据自己的情况选择最有效的选项，包括非覆盖和覆盖网络，带或不带 BGP。 Calico 使用相同的引擎为主机、Pod 和（如果使用 Istio 和 Envoy）应用程序在服务网格层执行网络策略。 1.安装 Tigera Calico 操作器 12345kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml# 查看命名空间tigera-operatorkubectl get ns# 查看命名空间tigera-operator中的podkubectl get pods -n tigera-operator 2.创建必要的自定义资源来安装 Calico 123456# 获取配置文件wget https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml# 编辑vim custom-resources.yaml# 修改网段cidr: 10.244.0.0/16 3.应用自定义配置 12345kubectl create -f custom-resources.yaml# 查看命名空间calico-systemkubectl get ns# 查看命名空间calico-system中的podkubectl get pods -n calico-system 控制平面节点隔离默认情况下，出于安全原因，你的集群不会在控制平面节点上调度 Pod。 能够在单机 Kubernetes 集群等控制平面节点上调度 Pod，请运行： 1kubectl taint nodes --all node-role.kubernetes.io/control-plane- （可选）从控制平面节点以外的计算机控制集群将管理员 kubeconfig 文件从控制平面节点复制到工作站，如下所示： 12scp root@&lt;control-plane-host&gt;:/etc/kubernetes/admin.conf .kubectl --kubeconfig ./admin.conf get nodes","categories":[],"tags":[]},{"title":"fyne-编译指南","slug":"fyne-编译指南","date":"2024-08-19T08:58:16.000Z","updated":"2024-08-21T00:35:24.318Z","comments":true,"path":"2024/08/19/fyne-编译指南/","link":"","permalink":"http://peapod.top/2024/08/19/fyne-%E7%BC%96%E8%AF%91%E6%8C%87%E5%8D%97/","excerpt":"","text":"fyne-其他系统编译要在 macOS 上为 Windows 或liunx目标系统构建应用程序，需要进行交叉编译。 设置环境变量Window123export GOOS=windowsexport GOARCH=amd64export CC=x86_64-w64-mingw32-gcc liunx12345export CC=x86_64-linux-musl-gccexport CXX=x86_64-linux-musl-g++export CGO_ENABLED=1export GOOS=linuxexport GOARCH=amd64 命令执行1fyne package -os windows -icon icon.jpeg 1fyne package -os linux -icon icon.jpeg 1fyne package -os darwin -icon myapp.png","categories":[],"tags":[]},{"title":"C++ 多态","slug":"C-多态","date":"2024-04-05T11:23:12.000Z","updated":"2025-04-18T09:20:49.666Z","comments":true,"path":"2024/04/05/C-多态/","link":"","permalink":"http://peapod.top/2024/04/05/C-%E5%A4%9A%E6%80%81/","excerpt":"","text":"C++ 多态简介编译时的多态：函数的重载（包括运算符的重载）、对重载函数的调用，在编译时就能根据实参确定应该调用哪个函数，因此叫编译时的多态。 运行时多态：继承、虚函数等概念有关。 虚函数通过基类指针只能访问派生类的成员变量，但是不能访问派生类的成员函数。 让基类指针能够访问派生类的成员函数，C++ 增加了虚函数（Virtual Function）。 123456789//基类Peopleclass People&#123;public: People(char *name, int age); virtual void display(); //声明为虚函数protected: char *m_name; int m_age;&#125;; 有了虚函数，基类指针指向基类对象时就使用基类的成员（包括成员函数和成员变量），指向派生类对象时就使用派生类的成员。换句话说，基类指针可以按照基类的方式来做事，也可以按照派生类的方式来做事，它有多种形态，或者说有多种表现方式，我们将这种现象称为多态（Polymorphism）。 C++中虚函数的唯一用处就是构成多态。 C++提供多态的目的是：可以通过基类指针对所有派生类（包括直接派生和间接派生）的成员变量和成员函数进行“全方位”的访问，尤其是成员函数。如果没有多态，我们只能访问成员变量。 虚函数是根据指针的指向来调用的，指针指向哪个类的对象就调用哪个类的虚函数。 构成多态的条件虚函数使用条件： 只需要在虚函数的声明处加上 virtual 关键字，函数定义处可以加也可以不加。 可以只将基类中的函数声明为虚函数，这样所有派生类中具有遮蔽关系的同名函数都将自动成为虚函数。 当在基类中定义了虚函数时，如果派生类没有定义新的函数来遮蔽此函数，那么将使用基类的虚函数。 只有派生类的虚函数覆盖基类的虚函数（函数原型相同）才能构成多态（通过基类指针访问派生类函数）。 派生类不继承基类的构造函数，将构造函数声明为虚函数没有什么意义。 析构函数可以声明为虚函数，而且有时候必须要声明为虚函数。 构成多态的条件： 必须存在继承关系； 继承关系中必须有同名的虚函数，并且它们是覆盖关系（函数原型相同）。 存在基类的指针，通过该指针调用虚函数。 虚析构函数析构函数用于在销毁对象时进行清理工作，可以声明为虚函数，而且有时候必须要声明为虚函数。 12345678910111213141516171819202122232425262728293031323334353637383940//基类class Base&#123;public: Base(); ~Base();protected: char *str;&#125;;Base::Base()&#123; str = new char[100]; cout&lt;&lt;&quot;Base constructor&quot;&lt;&lt;endl;&#125;Base::~Base()&#123; delete[] str; cout&lt;&lt;&quot;Base destructor&quot;&lt;&lt;endl;&#125;//派生类class Derived: public Base&#123;public: Derived(); ~Derived();private: char *name;&#125;;Derived::Derived()&#123; name = new char[100]; cout&lt;&lt;&quot;Derived constructor&quot;&lt;&lt;endl;&#125;Derived::~Derived()&#123; delete[] name; cout&lt;&lt;&quot;Derived destructor&quot;&lt;&lt;endl;&#125;int main()&#123; Base *pb = new Derived(); delete pb; cout&lt;&lt;&quot;-------------------&quot;&lt;&lt;endl; Derived *pd = new Derived(); delete pd; return 0;&#125; 第一条语句delete pb;只调用了基类的析构函数（上转型对象）。 第二条语句delete pd;同时调用了派生类和基类的析构函数（先调用派生类的析构函数，后调用基类的析构函数）。 将基类的析构函数声明为虚函数后，派生类的析构函数也会自动成为虚函数。这个时候编译器会忽略指针的类型，而根据指针的指向来选择函数。 就是说，大部分情况下都应该将基类的析构函数声明为虚函数。 纯虚函数和抽象类（接口）将虚函数声明为纯虚函数，语法格式为： 1virtual 返回值类型 函数名 (函数参数) = 0; 包含纯虚函数的类称为抽象类（Abstract Class）。之所以说它抽象，是因为它无法实例化，也就是无法创建对象。原因很明显，纯虚函数没有函数体，不是完整的函数，无法调用，也无法为其分配内存空间。 抽象类通常是作为基类，让派生类去实现纯虚函数。派生类必须实现纯虚函数才能被实例化。 纯虚函数说明： 一个纯虚函数就可以使类成为抽象基类，抽象基类中除了包含纯虚函数外，还可以包含其它的成员函数和成员变量。 只有类中的虚函数才能被声明为纯虚函数，普通成员函数和顶层函数均不能声明为纯虚函数。 虚函数表当通过指针访问类的成员函数时： 如果该函数是非虚函数，那么编译器会根据指针的类型找到该函数；指针是哪个类的类型就调用哪个类的函数。 如果该函数是虚函数，并且派生类有同名的函数遮蔽它，那么编译器会根据指针的指向找到该函数；指针指向的对象属于哪个类就调用哪个类的函数。这就是多态。 编译器之所以能通过指针指向的对象找到虚函数，是因为在创建对象时额外地增加了虚函数表。 如果一个类包含了虚函数，那么在创建该类的对象时就会额外地增加一个数组，数组中的每一个元素都是虚函数的入口地址。不过数组和对象是分开存储的，为了将对象和数组关联起来，编译器还要在对象中安插一个指针，指向数组的起始位置。这里的数组就是虚函数表（Virtual function table），简写为vtable。 图中左半部分是对象占用的内存，右半部分是虚函数表 vtable。在对象的开头位置有一个指针 vfptr，指向虚函数表，并且这个指针始终位于对象的开头位置。 基类的虚函数在 vtable 中的索引（下标）是固定的，不会随着继承层次的增加而改变，派生类新增的虚函数放在 vtable 的最后。如果派生类有同名的虚函数遮蔽（覆盖）了基类的虚函数，那么将使用派生类的虚函数替换基类的虚函数，这样具有遮蔽关系的虚函数在 vtable 中只会出现一次。","categories":[{"name":"后端","slug":"后端","permalink":"http://peapod.top/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://peapod.top/tags/C/"}],"author":"taweizhong"},{"title":"C++ 继承","slug":"C-继承","date":"2024-04-05T11:23:04.000Z","updated":"2025-04-18T09:20:33.119Z","comments":true,"path":"2024/04/05/C-继承/","link":"","permalink":"http://peapod.top/2024/04/05/C-%E7%BB%A7%E6%89%BF/","excerpt":"","text":"C++ 继承继承（Inherice）可以理解为一个类从另一个类获取成员变量和成员函数的过程。例如类 B 继承于类 A，那么 B 就拥有 A 的成员变量和成员函数。 被继承的类称为父类或基类，继承的类称为子类或派生类。 继承的一般语法为： 123class 派生类名:［继承方式］ 基类名&#123; 派生类新增加的成员&#125;; 继承方式继承方式限定了基类成员在派生类中的访问权限，包括 public（公有的）、private（私有的）和 protected（受保护的）。默认为 private（成员变量和成员函数默认也是 private）。 protected 成员和 private 成员类似，也不能通过对象访问。但是当存在继承关系时，基类中的 protected 成员可以在派生类中使用。 继承方式中的 public、protected、private 是用来指明基类成员在派生类中的最高访问权限的。 基类中的 private 成员在派生类中始终不能使用（不能在派生类的成员函数中访问或调用）。 希望基类的成员既不向外暴露（不能通过对象访问），还能在派生类中使用，那么只能声明为 protected。 基类的 private 成员是能够被继承的，并且（成员变量）会占用派生类对象的内存，它只是在派生类中不可见，导致无法使用罢了。private 成员的这种特性，能够很好的对派生类隐藏基类的实现，以体现面向对象的封装性。 在派生类中访问基类 private 成员的唯一方法就是借助基类的非 private 成员函数，如果基类没有非 private 成员函数，那么该成员在派生类中将无法访问。 using 只能改变基类中 public 和 protected 成员的访问权限，不能改变 private 成员的访问权限，因为基类中 private 成员在派生类中是不可见的，根本不能使用，所以基类中的 private 成员在派生类中无论如何都不能访问。 12345678910111213141516171819202122//基类Peopleclass People &#123;public: void show();protected: char *m_name; int m_age;&#125;;void People::show() &#123; cout &lt;&lt; m_name &lt;&lt; &quot;的年龄是&quot; &lt;&lt; m_age &lt;&lt; endl;&#125;//派生类Studentclass Student : public People &#123;public: void learning();public: using People::m_name; //将protected改为public using People::m_age; //将protected改为public float m_score;private: using People::show; //将public改为private&#125;; 名字遮蔽派生类中的成员（包括成员变量和成员函数）和基类中的成员重名，那么就会遮蔽从基类继承过来的成员。 基类 People 中的被遮蔽的函数仍然可以访问，不过要加上类名和域解析符。 12//使用的是从基类继承来的成员函数stu.People::show(); 12345678910111213141516171819//基类Baseclass Base&#123;public: void func(); void func(int);&#125;;void Base::func()&#123; cout&lt;&lt;&quot;Base::func()&quot;&lt;&lt;endl; &#125;void Base::func(int a)&#123; cout&lt;&lt;&quot;Base::func(int)&quot;&lt;&lt;endl; &#125;//派生类Derivedclass Derived: public Base&#123;public: void func(char *); void func(bool);&#125;;void Derived::func(char *str)&#123; cout&lt;&lt;&quot;Derived::func(char *)&quot;&lt;&lt;endl; &#125;void Derived::func(bool is)&#123; cout&lt;&lt;&quot;Derived::func(bool)&quot;&lt;&lt;endl; &#125;d.func(); //compile errord.func(10); //compile error Base 类的两个 func 构成重载，而 Derive 类的两个 func 构成另外的重载。 名字查找（name lookup），也就是在作用域链中寻找与所用名字最匹配的声明（或定义）的过程。 只有一个作用域内的同名函数才具有重载关系，不同作用域内的同名函数是会造成遮蔽，使得外层函数无效。派生类和基类拥有不同的作用域，所以它们的同名函数不具有重载关系。 单继承，对象内存模型没有继承时对象内存的分布情况。成员变量和成员函数会分开存储： 对象的内存中只包含成员变量，存储在栈区或堆区（使用 new 创建对象）； 成员函数与对象内存分离，存储在代码区。 有继承关系时，派生类的内存模型可以看成是基类成员变量和新增成员变量的总和，而所有成员函数仍然存储在另外一个区域——代码区，由所有对象共享。 基类的成员变量排在前面，派生类的排在后面。成员变量按照派生的层级依次排列，新增成员变量始终在最后。 有成员变量遮蔽时的内存分布： 当基类 A、B 的成员变量被遮蔽时，仍然会留在派生类对象 obj_c 的内存中，C 类新增的成员变量始终排在基类 A、B 的后面。 单继承，构造函数 对继承过来的成员变量的初始化工作也要由派生类的构造函数完成，但是大部分基类都有 private 属性的成员变量，它们在派生类中无法访问，更不能使用派生类的构造函数来初始化。 解决这个问题的思路是：在派生类的构造函数中调用基类的构造函数。 123456789101112//派生类Studentclass Student: public People&#123;private: float m_score;public: Student(char *name, int age, float score); void display();&#125;;//People(name, age)就是调用基类的构造函数Student::Student(char *name, int age, float score): People(name, age), m_score(score)&#123; &#125;Student stu(&quot;小明&quot;, 16, 90.5); 派生类构造函数总是先调用基类构造函数再执行其他代码（包括参数初始化表以及函数体中的代码）。 函数头部是对基类构造函数的调用，而不是声明，所以括号里的参数是实参，它们不但可以是派生类构造函数参数列表中的参数，还可以是局部变量、常量等，例如： 1Student::Student(char *name, int age, float score): People(&quot;小明&quot;, 16), m_score(score)&#123; &#125; 构造函数的调用顺序是按照继承的层次自顶向下、从基类再到派生类的。 派生类构造函数中只能调用直接基类的构造函数，不能调用间接基类的。 定义派生类构造函数时最好指明基类构造函数；如果不指明，就调用基类的默认构造函数（不带参数的构造函数）；如果没有默认构造函数，那么编译失败。 1234567891011121314151617181920212223//基类Peopleclass People&#123;public: People(); //基类默认构造函数 People(char *name, int age);protected: char *m_name; int m_age;&#125;;People::People(): m_name(&quot;xxx&quot;), m_age(0)&#123; &#125;People::People(char *name, int age): m_name(name), m_age(age)&#123;&#125;//派生类Studentclass Student: public People&#123;public: Student(); Student(char*, int, float);public: void display();private: float m_score;&#125;;Student::Student(): m_score(0.0)&#123; &#125; //派生类默认构造函数Student::Student(char *name, int age, float score): People(name, age), m_score(score)&#123; &#125; 单继承，析构函数析构函数也不能被继承。与构造函数不同的是，在派生类的析构函数中不用显式地调用基类的析构函数，因为每个类只有一个析构函数，编译器知道如何选择，无需程序员干涉。 析构函数的执行顺序和构造函数的执行顺序也刚好相反： 创建派生类对象时，构造函数的执行顺序和继承顺序相同，即先执行基类构造函数，再执行派生类构造函数。 而销毁派生类对象时，析构函数的执行顺序和继承顺序相反，即先执行派生类析构函数，再执行基类析构函数。 多继承多继承的语法： 123class D: public A, private B, protected C&#123; //类D新增加的成员&#125; D 是多继承形式的派生类，它以公有的方式继承 A 类，以私有的方式继承 B 类，以保护的方式继承 C 类。 多继承，构造函数在派生类的构造函数中调用多个基类的构造函数。 123D(形参列表): A(实参列表), B(实参列表), C(实参列表)&#123; //其他操作&#125; 基类构造函数的调用顺序和和它们在派生类构造函数中出现的顺序无关，而是和声明派生类时基类出现的顺序相同。 多继承，命名冲突当两个或多个基类中有同名的成员时，如果直接访问该成员，就会产生命名冲突，编译器不知道使用哪个基类的成员。这个时候需要在成员名字前面加上类名和域解析符::，以显式地指明到底使用哪个类的成员，消除二义性。 多继承，对象内存模型A、B 是基类，C 是派生类，假设 obj_c 的起始地址是 0X1000，那么 obj_c 的内存分布如下图所示： 基类对象的排列顺序和继承时声明的顺序相同。 虚继承为了解决多继承时的命名冲突和冗余数据问题，C++ 提出了虚继承，使得在派生类中只保留一份间接基类的成员。 在继承方式前面加上 virtual 关键字就是虚继承： 12345678910111213141516171819202122232425//间接基类Aclass A&#123;protected: int m_a;&#125;;//直接基类Bclass B: virtual public A&#123; //虚继承protected: int m_b;&#125;;//直接基类Cclass C: virtual public A&#123; //虚继承protected: int m_c;&#125;;//派生类Dclass D: public B, public C&#123;public: void seta(int a)&#123; m_a = a; &#125; //正确 void setb(int b)&#123; m_b = b; &#125; //正确 void setc(int c)&#123; m_c = c; &#125; //正确 void setd(int d)&#123; m_d = d; &#125; //正确private: int m_d;&#125;; 虚基类虚继承的目的是让某个类做出声明，承诺愿意共享它的基类。其中，这个被共享的基类就称为虚基类（Virtual Base Class）。 必须在虚派生的真实需求出现前就已经完成虚派生的操作。虚派生只影响从指定了虚基类的派生类中进一步派生出来的类，它不会影响派生类本身。 在虚继承的最终派生类中只保留了一份虚基类的成员，所以该成员可以被直接访问，不会产生二义性。 不提倡在程序中使用多继承，只有在比较简单和不易出现二义性的情况或实在必要时才使用多继承，能用单一继承解决的问题就不要使用多继承。 虚继承，构造函数最终派生类的构造函数必须要调用虚基类的构造函数。对最终的派生类来说，虚基类是间接基类，而不是直接基类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344//虚基类Aclass A&#123;public: A(int a);protected: int m_a;&#125;;A::A(int a): m_a(a)&#123; &#125;//直接派生类Bclass B: virtual public A&#123;public: B(int a, int b);public: void display();protected: int m_b;&#125;;B::B(int a, int b): A(a), m_b(b)&#123; &#125;void B::display()&#123; cout&lt;&lt;&quot;m_a=&quot;&lt;&lt;m_a&lt;&lt;&quot;, m_b=&quot;&lt;&lt;m_b&lt;&lt;endl;&#125;//直接派生类Cclass C: virtual public A&#123;public: C(int a, int c);public: void display();protected: int m_c;&#125;;C::C(int a, int c): A(a), m_c(c)&#123; &#125;void C::display()&#123; cout&lt;&lt;&quot;m_a=&quot;&lt;&lt;m_a&lt;&lt;&quot;, m_c=&quot;&lt;&lt;m_c&lt;&lt;endl;&#125;//间接派生类Dclass D: public B, public C&#123;public: D(int a, int b, int c, int d);public: void display();private: int m_d;&#125;;D::D(int a, int b, int c, int d): A(a), B(90, b), C(100, c), m_d(d)&#123; &#125; 在最终派生类 D 的构造函数中，除了调用 B 和 C 的构造函数，还调用了 A 的构造函数，这说明 D 不但要负责初始化直接基类 B 和 C，还要负责初始化间接基类 A。而在以往的普通继承中，派生类的构造函数只负责初始化它的直接基类，再由直接基类的构造函数初始化间接基类，用户尝试调用间接基类的构造函数将导致错误。 C++ 规定必须由最终的派生类 D 来初始化虚基类 A，直接派生类 B 和 C 对 A 的构造函数的调用是无效的。 虚继承时构造函数的执行顺序与普通继承时不同：在最终派生类的构造函数调用列表中，不管各个构造函数出现的顺序如何，编译器总是先调用虚基类的构造函数，再按照出现的顺序调用其他的构造函数；而对于普通继承，就是按照构造函数出现的顺序依次调用的。 虚继承，对象内存模型对于普通继承，基类子对象始终位于派生类对象的前面： A 是最顶层的基类，在派生类 B、C、D 的对象中，A 类子对象始终位于最前面，偏移量是固定的，为 0。b1、b2 是派生类 B 的新增成员变量，它们的偏移量也是固定的，分别为 8 和 12。c1、c2、d1、d2 也是同样的道理。 对于虚继承，恰恰和普通继承相反，大部分编译器会把基类成员变量放在派生类成员变量的后面，这样随着继承层级的增加，基类成员变量的偏移就会改变，就得通过其他方案来计算偏移量。 A 是 B 的虚基类，B 又是 C 的虚基类，那么各个对象的内存模型如下图所示： 虚继承时的派生类对象被分成了两部分： 不带阴影的一部分偏移量固定，不会随着继承层次的增加而改变，称为固定部分； 带有阴影的一部分是虚基类的子对象，偏移量会随着继承层次的增加而改变，称为共享部分。 不同的编译器设计了不同的方案来计算共享部分的偏移。 虚基类表如果某个派生类有一个或多个虚基类，编译器就会在派生类对象中安插一个指针，指向虚基类表。虚基类表其实就是一个数组，数组中的元素存放的是各个虚基类的偏移。 A 是 B 的虚基类，同时 B 又是 C 的虚基类，那么各对象的内存模型如下图所示： 向上转型类其实也是一种数据类型，也可以发生数据类型转换，不过这种转换只有在基类和派生类之间才有意义，并且只能将派生类赋值给基类，包括将派生类对象赋值给基类对象、将派生类指针赋值给基类指针、将派生类引用赋值给基类引用，这在 C++ 中称为向上转型（Upcasting）。相应地，将基类赋值给派生类称为向下转型（Downcasting）。 将派生类对象赋值给基类对象赋值的本质是将现有的数据写入已分配好的内存中，对象的内存只包含了成员变量，所以对象之间的赋值是成员变量的赋值，成员函数不存在赋值问题。 这种转换关系是不可逆的，只能用派生类对象给基类对象赋值，而不能用基类对象给派生类对象赋值。理由很简单，基类不包含派生类的成员变量，无法对派生类的成员变量赋值。同理，同一基类的不同派生类对象之间也不能赋值。 将派生类指针赋值给基类指针将派生类指针赋值给基类指针（对象指针之间的赋值）。 多继承的例子，继承关系为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//基类Aclass A&#123;public: A(int a);public: void display();protected: int m_a;&#125;;A::A(int a): m_a(a)&#123; &#125;void A::display()&#123; cout&lt;&lt;&quot;Class A: m_a=&quot;&lt;&lt;m_a&lt;&lt;endl;&#125;//中间派生类Bclass B: public A&#123;public: B(int a, int b);public: void display();protected: int m_b;&#125;;B::B(int a, int b): A(a), m_b(b)&#123; &#125;void B::display()&#123; cout&lt;&lt;&quot;Class B: m_a=&quot;&lt;&lt;m_a&lt;&lt;&quot;, m_b=&quot;&lt;&lt;m_b&lt;&lt;endl;&#125;//基类Cclass C&#123;public: C(int c);public: void display();protected: int m_c;&#125;;C::C(int c): m_c(c)&#123; &#125;void C::display()&#123; cout&lt;&lt;&quot;Class C: m_c=&quot;&lt;&lt;m_c&lt;&lt;endl;&#125;//最终派生类Dclass D: public B, public C&#123;public: D(int a, int b, int c, int d);public: void display();private: int m_d;&#125;;D::D(int a, int b, int c, int d): B(a, b), C(c), m_d(d)&#123; &#125;void D::display()&#123; cout&lt;&lt;&quot;Class D: m_a=&quot;&lt;&lt;m_a&lt;&lt;&quot;, m_b=&quot;&lt;&lt;m_b&lt;&lt;&quot;, m_c=&quot;&lt;&lt;m_c&lt;&lt;&quot;, m_d=&quot;&lt;&lt;m_d&lt;&lt;endl;&#125; A *pa = new A(1); B *pb = new B(2, 20); C *pc = new C(3); D *pd = new D(4, 40, 400, 4000); pa = pd; pa -&gt; display(); pb = pd; pb -&gt; display(); pc = pd; pc -&gt; display(); 将派生类指针 pd 赋值给了基类指针 pa，调用 display() 函数时虽然使用了派生类的成员变量，但是 display() 函数本身却是基类的。 将派生类指针赋值给基类指针时，通过基类指针只能使用派生类的成员变量，但不能使用派生类的成员函数。","categories":[{"name":"后端","slug":"后端","permalink":"http://peapod.top/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://peapod.top/tags/C/"}],"author":"taweizhong"},{"title":"C++ 引用","slug":"C-引用","date":"2024-04-05T11:22:54.000Z","updated":"2025-04-18T09:20:19.480Z","comments":true,"path":"2024/04/05/C-引用/","link":"","permalink":"http://peapod.top/2024/04/05/C-%E5%BC%95%E7%94%A8/","excerpt":"","text":"C++ 引用引用简介比指针更加便捷的传递聚合类型数据的方式，那就是引用（Reference）。 引用可以看做是数据的一个别名，通过这个别名和原来的名字都能够找到这份数据。 引用的定义方式类似于指针，只是用&amp;取代了*，语法格式为： 1type &amp;name = data; 引用在定义时需要添加&amp;，在使用时不能添加&amp;，使用时添加&amp;表示取地址。 不希望通过引用来修改原始的数据，那么可以在定义时添加 const 限制，形式为： 12const type &amp;name = value;type const &amp;name = value; 将函数的形参指定为引用的形式，这样在调用函数时就会将实参和形参绑定在一起，让它们都指代同一份数据。如此一来，如果在函数体中修改了形参的数据，那么实参的数据也会被修改，从而拥有“在函数内部影响函数外部数据”的效果。 引用除了可以作为函数形参，还可以作为函数返回值。 123456789101112#include &lt;iostream&gt;using namespace std;int &amp;plus10(int &amp;r) &#123; r += 10; return r;&#125;int main() &#123; int num1 = 10; int num2 = plus10(num1); cout &lt;&lt; num1 &lt;&lt; &quot; &quot; &lt;&lt; num2 &lt;&lt; endl; return 0;&#125; 不能返回局部数据（例如局部变量、局部对象、局部数组等）的引用，因为当函数调用完成后局部数据就会被销毁，有可能在下次使用时数据就不存在了。 引用与指针引用只是对指针进行了简单的封装，它的底层依然是通过指针实现的，引用占用的内存和指针占用的内存长度一样，在 32 位环境下是 4 个字节，在 64 位环境下是 8 个字节，之所以不能获取引用的地址，是因为编译器进行了内部转换。 区别： 引用必须在定义时初始化，并且以后也要从一而终，不能再指向其他数据 可以有 const 指针，但是没有 const 引用 指针可以有多级，但是引用只能有一级 指针和引用的自增（++）自减（–）运算意义不一样 引用与临时数据在内存中的，例如定义的变量、创建的对象、字符串常量、函数形参、函数体本身、new或malloc()分配的内存等，这些内容都可以用&amp;来获取地址，进而用指针指向它们。 临时数据，例如表达式的结果、函数的返回值等，它们可能会放在内存中，也可能会放在寄存器中。一旦它们被放到了寄存器中，就没法用&amp;获取它们的地址了，也就没法用指针指向它们了。 只能将较小的临时数据放在寄存器中。int、double、bool、char 等基本类型的数据往往不超过 8 个字节，用一两个寄存器就能存储，所以这些类型的临时数据通常会放到寄存器中；而对象、结构体变量是自定义类型的数据，大小不可预测，所以这些类型的临时数据通常会放到内存中。 常量表达式由于不包含变量，没有不稳定因素，所以在编译阶段就能求值。编译器不会分配单独的内存来存储常量表达式的值，而是将常量表达式的值和代码合并到一起，放到虚拟地址空间中的代码区。从汇编的角度看，常量表达式的值就是一个立即数，会被“硬编码”到指令中，不能寻址。 常量表达式的值虽然在内存中，但是没有办法寻址，所以也不能使用&amp;来获取它的地址，更不能用指针指向它。 123456789101112131415bool isOdd(int &amp;n)&#123; if(n%2 == 0)&#123; return false; &#125;else&#123; return true; &#125;&#125;int main()&#123; int a = 100; isOdd(a); //正确 isOdd(a + 9); //错误 isOdd(27); //错误 isOdd(23 + 55); //错误 return 0;&#125; 它的参数是引用类型，只能传递变量，不能传递常量或者表达式。 绑定临时数据当使用 const 关键字对引用加以限定后，引用就可以绑定到临时数据了。 将常引用绑定到临时数据时，编译器采取了一种妥协机制：编译器会为临时数据创建一个新的、无名的临时变量，并将临时数据放入该临时变量中，然后再将引用绑定到该临时变量。注意，临时变量也是变量，所有的变量都会被分配内存。 123456S operator+(const S &amp;A, const S &amp;B)&#123; S C; C.a = A.a + B.a; C.b = A.b + B.b; return C;&#125; const 引用和普通引用不一样，只能通过 const 引用读取数据的值，而不能修改它的值，所以不用考虑同步更新的问题，也不会产生两份不同的数据，为 const 引用创建临时变量反而会使得引用更加灵活和通用。 12345678910111213int a = 100;isOdd(a); //正确isOdd(a + 9); //正确isOdd(27); //正确isOdd(23 + 55); //正确bool isOdd(const int &amp;n)&#123; //改为常引用 if(n/2 == 0)&#123; return false; &#125;else&#123; return true; &#125;&#125; 对于第 2 行代码，编译器不会创建临时变量，会直接绑定到变量 a；对于第 3~5 行代码，编译器会创建临时变量来存储临时数据。也就是说，编译器只有在必要时才会创建临时变量。 引用与转换类型编译器禁止指针指向不同类型的数据。 123456int n = 100;int *p1 = &amp;n; //正确float *p2 = &amp;n; //错误char c = &#x27;@&#x27;;char *p3 = &amp;c; //正确int *p4 = &amp;c; //错误 float *类型的指针不能指向 int 类型的数据，int *类型的指针也不能指向 char 类型的数据。 当对引用添加 const 限定后，编译器允许引用绑定到类型不一致的数据。 123456int n = 100;int &amp;r1 = n; //正确const float &amp;r2 = n; //正确char c = &#x27;@&#x27;;char &amp;r3 = c; //正确const int &amp;r4 = c; //正确 当引用的类型和数据的类型不一致时，如果它们的类型是相近的，并且遵守「数据类型的自动转换」规则，那么编译器就会创建一个临时变量，并将数据赋值给这个临时变量（这时候会发生自动类型转换），然后再将引用绑定到这个临时的变量，这与「将 const 引用绑定到临时数据时」采用的方案是一样的。 总结给引用添加 const 限定后，不但可以将引用绑定到临时数据，还可以将引用绑定到类型相近的数据，这使得引用更加灵活和通用，它们背后的机制都是临时变量。 当引用作为函数参数时，如果在函数体内部不会修改引用所绑定的数据，那么请尽量为该引用添加 const 限制。","categories":[{"name":"后端","slug":"后端","permalink":"http://peapod.top/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://peapod.top/tags/C/"}],"author":"taweizhong"},{"title":"Go 并发原理","slug":"Go-并发原理","date":"2024-04-04T07:33:22.000Z","updated":"2024-04-04T07:35:07.000Z","comments":true,"path":"2024/04/04/Go-并发原理/","link":"","permalink":"http://peapod.top/2024/04/04/Go-%E5%B9%B6%E5%8F%91%E5%8E%9F%E7%90%86/","excerpt":"","text":"并发并行和并发有什么区别？ 并发（concurrency）：把任务在不同的时间点交给处理器进行处理。在同一时间点，任务并不会同时运行。 并行（parallelism）：把每一个任务分配给每一个处理器独立完成。在同一时间点，任务一定是同时运行。 goroutine 可能发生并行执行； 但 coroutine(协程) 始终顺序执行。 并发的三大特性:有序性 ,原子性,可见性 有序性：即程序执行的顺序按照代码的先后顺序执行。原子性：一个或多个操作,要么全部执行且在执行过程中不被任何因素打断,要么全部不执行。可见性：当一个线程修改了共享变量的值，其他线程能够看到修改的值。 并发控制手段Go是一门天生支持并发编程的语言，提供了丰富的原生并发控制手段，以下是其中的几个常用的并发控制手段： goroutine：goroutine是Go中的轻量级线程，可以通过关键字go快速启动一个goroutine，使其在后台执行任务。在一个程序中可以同时运行数千甚至数百万个goroutine，有效地提高了程序的并发性和性能。 channel：channel是Go语言中的一种通信机制，用于在goroutine之间传递数据。通过使用channel，可以在不使用锁的情况下实现不同goroutine之间的同步和协调。 sync.Mutex：互斥锁是最常用的同步原语之一，用于保护临界区。在Go语言中，通过sync包提供的Mutex类型可以实现互斥锁。 sync.WaitGroup：sync包还提供了WaitGroup类型，用于等待一组goroutine的完成。通过在WaitGroup中添加计数器，可以在主goroutine中等待所有goroutine完成后再继续执行。 sync.Cond：条件变量是一种高级的同步原语，用于在不同的goroutine之间传递信号。通过使用sync.Cond，可以实现复杂的同步和协调操作。 atomic：atomic包提供了原子操作，用于在不加锁的情况下进行并发访问。例如，通过原子操作可以实现无锁的计数器。 context：context包提供了一种机制，用于在goroutine之间传递上下文信息。通过使用context，可以实现在不同goroutine之间安全地取消操作、超时控制等。 这些并发控制手段在不同的场景下有着不同的应用，程序员需要根据实际情况选择合适的手段来实现并发控制，以提高程序的性能和可靠性。 如何确保高并发场景下一些事情只执行一次加载文件，关闭管道等使用sync.Once，或双检锁 如：单例模式 123456789type Singleton struct &#123;&#125;var singleton *Singletonvar singletonOnce sync.Oncefunc GetSingletonInstance() *Singleton &#123; singletonOnce.Do(func()&#123; singleton = &amp;Singleton&#123;&#125; &#125;) return singleton&#125; once.Do 源码 123456789101112func (o *Once) Do(f func()) &#123;//判断是否执行过该方法，如果执行过则不执行 if atomic.LoadUint32(&amp;o.done) == 1 &#123; return &#125; // Slow-path. o.m.Lock() defer o.m.Unlock() if o.done == 0 &#123; defer atomic.StoreUint32(&amp;o.done, 1) f() &#125;&#125; 容器的并发安全性数组，slice，struct允许并发修改（可能会脏写），并发修改map有时会发生panic 如果需要并发修改map，使用sync.Map n++ 可能会出现脏写，n &#x3D; a, a &#x3D; a + 1, n &#x3D; a解决：把n++封装成原子操作，解除资源竞争，避免脏写 123func atomic.AddInt32(addr *int32, delta int32) (new int32)func atomic.LoadInt32(addr *int32) (val int32) 读写锁1234567var lock sync.RWMutex // 声明读写锁，无需初始化// 写锁lock.Lock()lock.Unlock()// 读锁lock.Rlock()lock.RUnlock() 任意时刻只能加一把写锁，且不能加读锁每加写锁时，可以同时加多把读锁，读锁加上后不能加写锁 临界区如果一部分程序会被并发访问或修改，那么，为了避免并发访问导致的意向不到的结果，这部分程序需要被保护起来，这部分程序就是临界区。 如果多个线程同时访问或操作临界区，会造成访问错误，可以使用互斥锁，限定临界区同一时间只能有1个线程持有。 当临界区由一个线程持有的时候，其它线程如果想进入这个临界区，就会返回失败，或者是等待。 直到持有的线程退出临界区，这些等待线程中的某一个才有机会接着持有这个临界区。 Goroutinegoroutine介绍Goroutine，经 Golang 优化后的特殊协程，协程是一种更细粒度的调度，可以满足多个不同处理逻辑的协程共享一个线程资源，它的创建销毁和调度的成本都非常的小。它与线程存在映射关系，为 M：N，可以利用多个线程实现并行，并且go实现了GMP调度模型，可以通过调度器的调度来实现线程间的动态绑定和灵活调度。 GMP：M 是操作系统线程的抽象，P 则是用于管理 G的调度器。P 结构负责管理 G的调度，包括创建、销毁、挂起和唤醒等，而 M 结构则负责将 G 绑定到操作系统线程上并执行它们。 调度流程：M如果想要运行G就需要与P绑定，调度时执行p.runnext先找p的本地队列，再找全局队列，最后找准备就绪的网络协程，这样的好处是取本地队列时可以接近于无锁化减少锁的竞争。其中每61次调度会直接从全局队列中取G执行，并且把一个G放入本地队列，避免全局队列的G被饿死。如果都没有的话就会触发work stealing机制，会尝试从其他P的本地队列中偷取一半的G来执行。当M执行G时遇到了系统调用或其他阻塞行为，M会阻塞，此时runtime会通过handoff机制将M与P解绑，P与空闲的M或新建一个M绑定执行后续的G。当M结束阻塞后，G会尝试获取一个空闲的P，如果获取不到则这个M会变成休眠状态 （1）M 是线程的抽象；G 是 goroutine；P 是承上启下的调度器；（2）M调度G前，需要和P绑定；（3）全局有多个M和多个P，但同时并行的G的最大数量等于P的数量；（4）G的存放队列有三类：P的本地队列；全局队列；和wait队列；（5）M调度G时，优先取P本地队列，其次取全局队列，最后取wait队列；这样的好处是，取本地队列时，可以接近于无锁化，减少全局锁竞争；（6）为防止不同P的闲忙差异过大，设立work-stealing机制，本地队列为空的P可以尝试从其他P本地队列偷取一半的G补充到自身队列. goroutine特点： （1）与线程存在映射关系，为 M：N；（2）创建、销毁、调度在用户态完成，对内核透明，足够轻便；（3）可利用多个线程，实现并行；（4）通过调度器的斡旋，实现和线程间的动态绑定和灵活调度；（5）栈空间大小可动态扩缩，因地制宜. 调度假设当前正在执行G1，G1阻塞（如系统调用），此时P与G1，M1解绑，P被挂载到M2上继续执行G队列中其他任务。G1解除阻塞后，如果有空闲的P就加入到P队列中，如果没有就放到全局可运行队列runqueue中。P会周期性扫描全局（61次）可运行队列，执行里面的G；如果全局runqueue为空，就会从其他的P的执行队列中取一半G来执行。 在 GPM 模型，有一个全局队列（Global Queue）：存放等待运行的 G，还有一个 P 的本地队列：也是存放等待运行的 G，但数量有限，不超过 256 个。 GPM 的调度流程从 go func()开始创建一个 goroutine，新建的 goroutine 优先保存在 P 的本地队列中，如果 P 的本地队列已经满了，则会保存到全局队列中。 M 会从 P 的队列中取一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会从其他的 MP 组合偷取一个可执行的 G 来执行， 当 M 执行某一个 G 时候发生系统调用或者阻塞，M 阻塞， 如果这个时候 G 在执行，runtime 会把这个线程 M 从 P 中摘除，然后创建一个新的操作系统线程来服务于这个 P，当 M 系统调用结束时，这个 G 会尝试获取一个空闲的 P 来执行，并放入到这个 P 的本地队列，如果这个线程 M 变成休眠状态，加入到空闲线程中，然后整个 G 就会被放入到全局队列中。 work stealing（工作量窃取） 机制：会优先从全局队列里进行窃取，之后会从其它的P队列里窃取一半的G，放入到本地P队列里。hand off （移交）机制：当前线程的G进行阻塞调用时，例如睡眠，则当前线程就会释放P，然后把P转交给其它空闲的线程执行，如果没有闲置的线程，则创建新的线程。 线程VS协程：创建销毁： 协程goroutine由Go runtime负责管理，创建和销毁的销毁都非常小，是用户级 线程创建和销毁开销巨大，因为是内核级的，通常的解决方法是线程池 创建数量： 协程：轻松创建上百万个 线程：通常最多不超过1w个 内存占用： 协程：2kb，初始分配4k堆栈，随着程序的执行自动增长删除 线程：1M，创建线程是必须指定堆栈且固定，通常M为单位 切换成本： 协程：协程切换只需保存3个寄存器，耗时约200纳秒 线程：线程切换需要保存几十个寄存器，耗时约1000纳秒 调度方式： 协程：非抢占式，由Go runtime主动交出控制权 线程：在时间片用完后，由CPU中断任务强行将其调度走，此时需要保存很多信息 gorountine的优势 Go程序会智能地将 goroutine 中的任务合理地分配给每个CPU，最大限度的使用cpu的性能 开启一个goroutine消耗是非常小的（大概是2kb），所以可以轻松的创建数以百计的goroutine。 速度快，还可以用channel进行通信 协程什么时候会发生切换？协程可以主动让渡自己的执行权利（用户调用强制让渡），也可以在发生锁或者通道堵塞时被动让渡自己的执行权利。除此之外，为了让每个协程都有执行的机会，并且最大化利用CPU 资源，在Go 语言初始化时会启动一个特殊的线程来执行系统监控服务。系统监控会判断协程是否需要执行垃圾回收或者当前协程是否运行时间过长或处于系统调用阶段，在这些情况下，调度器将借助操作系统信号机制或者抢占逻辑处理器实现抢占调度。 GMP组成及原理GMP：M 是操作系统线程的抽象，P 则是用于管理 G的调度器。 P 结构负责管理 G的调度，包括创建、销毁、挂起和唤醒等，而 M 结构则负责将 G 绑定到操作系统线程上并执行它们。 调度流程：M如果想要运行G就需要与P绑定，调度时调用p.runnext先找p的本地队列，再找全局队列，最后找网络轮询器 Net Poller 上有一个陷入异步网络调用的准备就绪的G，这样的好处是取本地队列时可以接近于无锁化减少锁的竞争。其中每61次调度会直接从全局队列中取1个G执行，避免全局队列的G被饿死。如果都没有的话就会触发work stealing机制，会尝试从其他P的本地队列中偷取一半的G来执行。 当M执行G时遇到了系统调用或其他阻塞行为，M会阻塞，此时runtime会通过handoff（移交）机制将M与P解绑，P与空闲的M或新建一个M绑定执行后续的G。当M结束阻塞后，G会尝试优先绑定oldP，失败后从全局P队列中获取一个P，如果获取不到则这个M会变成休眠状态G放入全局队列。 抢占如果有G一直占用资源，go在运行时有sysmon进行监控，如果G独占P超过10ms就会被抢占。 为什么使用p？ 每个P有本地队列可以近乎无锁化执行，减少全局队列的锁竞争 当本地队列为空时，通过workstealing机制减少空转，提高资源利用率。 当M阻塞时会绑定到其他M上执行，提高并发性能，如果将队列实现在M上会使得阻塞时队列等待。 G0负责调度与创建g，分配defer，stw，扫描栈，栈分配 GMP 组成及数量关系 G(Goroutine)，表示一个 goroutine，即我需要分担出去的任务； M(Machine)，对应一个内核线程，用于将一个 G 搬到线程上执行； P(Processor)，一个装满 G 的队列，用于维护一些任务； G：Groutine协程，拥有运行函数的指针、栈、上下文（指的是sp、bp、pc等寄存器上下文以及垃圾回收的标记上下文），在整个程序运行过程中可以有无数个，代表一个用户级代码执行流（用户轻量级线程）； P：Processor，调度逻辑处理器，同样也是Go中代表资源的分配主体（内存资源、协程队列等），默认为机器核数，可以通过GOMAXPROCS环境变量调整 M：Machine，代表实际工作的执行者，对应到操作系统级别的线程；M的数量会比P多，但不会太多，最大为1w个。 G: 表示 Goroutine，每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数，可重用。G 并非执行体，每个 G 需要绑定到 P 才能被调度执行。 P: Processor，表示逻辑处理器， 对 G 来说，P 相当于 CPU 核，G 只有绑定到 P(在 P 的 local runq 中)才能被调度。对 M 来说，P 提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等，P 的数量决定了系统内最大可并行的 G 的数量（前提：物理 CPU 核数 &gt;&#x3D; P 的数量），P 的数量由用户设置的 GOMAXPROCS 决定，但是不论 GOMAXPROCS 设置为多大，P 的数量最大为 256。 M: Machine，OS 线程抽象，代表着真正执行计算的资源，在绑定有效的 P 后，进入 schedule 循环；而 schedule 循环的机制大致是从 Global 队列、P 的 Local 队列以及 wait 队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 goexit 做清理工作并回到 M，如此反复。M 并不保留 G 状态，这是 G 可以跨 M 调度的基础，M 的数量是不定的，由 Go Runtime 调整，为了防止创建过多 OS 线程导致系统调度不过来，目前默认最大限制为 10000 个。 在 Golang 中，为了提高并发性能，一个 M 可以绑定多个 P，并且一个 P 也可以被多个 M 共享。这种设计可以在多核 CPU 上更好地利用硬件资源，从而提高并发性能。 特殊的M0和G0在 Go 中创建的所有 Goroutine 都会被一个内部的调度器所管理。Go 调度器尝试为所有的 Goroutine 分配运行时间，并且在当前的 Goroutine 阻塞或者终止的时候，Go 调度器会通过运行 Goroutine 的方式使所有 CPU 保持忙碌状态。这个调度器实际上是作为一个特殊的 Goroutine 运行的。 M0 M0是启动程序后的编号为0的主线程，这个M对应的实例会在全局变量runtime.m0中，不需要在heap上分配，M0&#x3D;&#x3D;负责执行初始化操作和启动第一个G&#x3D;&#x3D;， 在之后M0就和其他的M一样了。 G0 G0是每次启动一个M都会第一个创建的gourtine，G0仅用于负责调度的G，G0不指向任何可执行的函数, 每个M都会有一个自己的G0。在调度或系统调用时会使用G0的栈空间, 全局变量的G0是M0的G0。 职责： Goroutine 创建与调度 defer 函数分配。 垃圾收集操作，比如 STW（ stopping the world ），扫描 Goroutine 的栈，以及一些标记清理操作。 栈增长。当需要的时候，Go 会增加 Goroutine 的大小。这个操作是由 g0 的 prolog 函数完成的。 m 通过 p 调度执行的 goroutine 永远在普通 g 和 g0 之间进行切换，当 g0 找到可执行的 g 时，会调用 gogo 方法，调度 g 执行用户定义的任务；当 g 需要主动让渡或被动调度时，会触发 mcall 方法，将执行权重新交还给 g0. goroutine什么时候会发生阻塞？ 由于原子、互斥量或通道操作调用导致 Goroutine 阻塞，调度器将把当前阻塞的 Goroutine 切换出去，重新调度 LRQ 上的其他 Goroutine； 由于网络请求和 IO 操作导致 Goroutine 阻塞。 当调用一些系统方法的时候（如文件 I&#x2F;O），如果系统方法调用的时候发生阻塞， 如果在 Goroutine 去执行一个 sleep 操作，导致 M 被阻塞了 在GPM调度模型，goroutine 有哪几种状态？g有9种状态 _Gidle：刚刚被分配并且还没有被初始化 _Grunnable：没有执行代码，没有栈的所有权，存储在运行队列中 _Grunning：可以执行代码，拥有栈的所有权，被赋予了内核线程 M 和处理器 P _Gsyscall：正在执行系统调用，拥有栈的所有权，没有执行用户代码，被赋予了内核线程 M 但是不在运行队列上 _Gwaiting：由于运行时而被阻塞，没有执行用户代码并且不在运行队列上，但是可能存在于 Channel 的等待队列上 _Gdead：没有被使用，没有执行代码，可能有分配的栈 _Gcopystack：栈正在被拷贝，没有执行代码，不在运行队列上 _Gpreempted：由于抢占而被阻塞，没有执行用户代码并且不在运行队列上，等待唤醒 _Gscan：GC 正在扫描栈空间，没有执行代码，可以与其他状态同时存在 如果goroutine一直占用资源怎么办，PMG模型怎么解决这个问题如果有一个goroutine一直占用资源的话，GMP模型会从正常模式转为饥饿模式，通过信号协作强制处理在最前的 goroutine 去分配使用 基于信号的抢占式调度在1.14中加入了基于信号的协程调度抢占。原理是这样的，首先注册绑定 SIGURG 信号及处理方法runtime.doSigPreempt，sysmon会间隔性检测超时的p，然后发送信号，m收到信号后休眠执行的goroutine并且进行重新调度。sysmon启动后会间隔性的进行监控，最长间隔10ms，最短间隔20us。如果某协程独占P超过10ms，那么就会被抢占！ 如果若干个线程中有一个发生OOM会发生什么？如果goroutine发生呢？当一个线程抛出OOM异常后，它所占据的内存资源会全部被释放掉，从而不会影响其他线程的运行 go中的内存泄漏一般都是goroutine泄露，就是goroutine没有被关闭，或者没有添加超时控制，让goroutine一只处于阻塞状态，不能被GC。 当一个线程发生OOM（内存溢出）时，通常会导致整个进程崩溃，因为线程共享进程的地址空间。然而，当一个Goroutine发生OOM时，情况可能会有所不同。由于Goroutine的堆栈是动态扩展的，当一个Goroutine的堆栈无法扩展时，Go运行时会尝试回收其他Goroutine的内存，以便为当前Goroutine分配更多的内存。如果回收失败，Go运行时会抛出一个运行时错误（如runtime: out of memory），但不会导致整个进程崩溃。 什么是协程泄露协程泄露指的是在 Go 语言程序中，由于某种原因而导致协程无法正常结束，从而造成内存泄露的情况。这种情况通常发生在使用协程时处理异步任务时，如果没有正确地处理协程的终止条件，它们将一直保持活动状态，不断占用内存，最终导致内存泄露。为了避免协程泄露，应该确保在程序结束时关闭所有协程，并释放其占用的内存。 可以通过leaktest库来检测 使用 golang 自带的pprof监控工具，可以发现内存上涨情况 常见的协程泄漏： channel缺少消费者，导致发送阻塞；没有生产者，读取阻塞 死锁 同一个goroutine中，使用同一个chnnel读写； 2个 以上的goroutine中， 使用同一个 channel 通信。 读写channel 先于 go程创建； channel 和 读写锁、互斥锁混用； select 所有的case都阻塞 无限死循环 主协程如何等待所有协程都完成 sync.WaitGroup Add：WaitGroup 类型有一个计数器，默认值是 0，通常通过个方法来标记需要等待的子协程数量 Done：当某个子协程执行完毕后，可以通过 Done 方法标记已完成，常用 defer 语句来调用 Wait 阻塞当前协程，直到对应 WaitGroup 类型实例的计数器值归零 使用channel 声明一个和子协程数量一致的通道数组，然后为每个子协程分配一个通道元素，在子协程执行完毕时向对应的通道发送数据；然后在主协程中，依次读取这些通道接收子协程发送的数据，只有所有通道都接收到数据才会退出主协程。 使用context 使用 context.WithCancel在子协程退出: 起多个协程，怎么控制他们的退出channel通知，select监控，ctx中Done退出，waitGroup等待 调用 runtime.Goexit() 来手动终止协程 使用select监控：监控chan或ctx.Done waitGroup等待 避免多线程竞争的方法Go语言提供了传统的同步 goroutine 的机制，就是对共享资源加锁。atomic 和 sync 包里的一些函数就可以对共享的资源进行加锁操作。 原子函数原子函数能够以很底层的加锁机制来同步访问整型变量和指针。 n++ 可能会出现脏写，n &#x3D; a, a &#x3D; a + 1, n &#x3D; a解决：把n++封装成原子操作，解除资源竞争，避免脏写 123func atomic.AddInt32(addr *int32, delta int32) (new int32)func atomic.LoadInt32(addr *int32) (val int32) 12345var isInit uint32if atomic.LoadUint32(&amp;isInit) == 1 &#123; return&#125;atomic.StoreUint32(&amp;isInit, 1) 互斥锁另一种同步访问共享资源的方式是使用互斥锁，互斥锁这个名字来自互斥的概念。互斥锁用于在代码上创建一个临界区，保证同一时间只有一个 goroutine 可以执行这个临界代码。","categories":[],"tags":[]},{"title":"Go 内存模型","slug":"Go-内存模型","date":"2024-04-04T07:32:57.000Z","updated":"2024-04-04T07:34:43.000Z","comments":true,"path":"2024/04/04/Go-内存模型/","link":"","permalink":"http://peapod.top/2024/04/04/Go-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"Go 内存管理go 管理内存Go语言的内存分配器的核心设计思想是：多级内存分配模块，减少内存分配时锁的使用与系统调用；多尺度内存单元，减少内存分配产生碎片。 Golang的内存管理实现主要涉及以下几个方面： 内存分配器(malloc)和释放器(free):Golang使用tcmalloc作为其默认的内存分配器，它是一个高效的内存分配器，可以减少内存碎片。在Go语言中，可以使用内置函数malloc和free来分配和释放内存。 垃圾回收机制：Golang使用并发标记清除算法(Concurrent Mark Sweep,CMS)作为其默认的垃圾回收机制。CMS是一种高效的垃圾回收算法，可以在不阻塞用户线程的情况下进行垃圾回收。 内存池技术：Golang使用内存池技术来提高内存分配和释放的效率。内存池是一种预先分配一定数量内存的技术，可以避免频繁地调用系统函数分配和释放内存，从而提高程序的性能。 大对象支持：Golang支持大对象，即超过1MB的对象。为了支持大对象，Golang使用了一种称为“可变大小数组”的数据结构，它可以在运行时动态调整数组的大小。 内存模型 以空间换时间，一次缓存，多次复用 由于每次向操作系统申请内存的操作很重，那么不妨一次多申请一些，以备后用. 多级缓存，实现无&#x2F;细锁化 Golang 在堆 mheap 之上，依次细化粒度，建立了 mcentral、mcache 的模型 mheap：全局的内存起源，访问要加全局锁 mcentral：每种对象大小规格（全局共划分为 68 种）对应的缓存，锁的粒度也仅限于同一种规格以内 mcache：每个 P（正是 GMP 中的 P）持有一份的内存缓存，访问时无锁 多级规格，提高利用率 123- Golang 借鉴操作系统分页管理的思想，每个最小的存储单元也称之为页 page，但大小为 8 KB。- mspan：最小的管理单元。mspan 大小为 page 的整数倍，且根据空间大小和面向分配对象的大小，从 8B 到 80 KB 被划分为 67 种不同的规格（实际上还有一种隐藏的 0 级，用于处理更大的对象，上不封顶）- 分配对象时，会根据大小映射到不同规格的 mspan，从中获取空间. 根据规格大小，产生了等级的制度 消除了外部碎片，但不可避免会有内部碎片 宏观上能提高整体空间利用率 正是因为有了规格等级的概念，才支持 mcentral 实现细锁化 堆是 Go 运行时中最大的临界共享资源，这意味着每次存取都要加锁，在性能层面是一件很可怕的事情. 在解决这个问题，Golang 在堆 mheap 之上，依次细化粒度，建立了 mcentral、mcache 的模型，下面对三者作个梳理： mheap：全局的内存起源，访问要加全局锁 mcentral：每种对象大小规格（全局共划分为 68 种）对应的缓存，锁的粒度也仅限于同一种规格以内 mcache：每个 P（正是 GMP 中的 P）持有一份的内存缓存，访问时无锁 mcache 是每个 P 独有的缓存，因此交互无锁 mcache 将每种 spanClass 等级的 mspan 各缓存了一个，总数为 2（nocan 维度） * 68（大小维度）&#x3D; 136 mcache 中还有一个为对象分配器 tiny allocator，用于处理小于 16B 对象的内存分配. 对于微对象的分配流程： （1）从 P 专属 mcache 的 tiny 分配器取内存（无锁）（2）根据所属的 spanClass，从 P 专属 mcache 缓存的 mspan 中取内存（无锁）（3）根据所属的 spanClass 从对应的 mcentral 中取 mspan 填充到 mcache，然后从 mspan 中取内存（spanClass 粒度锁）（4）根据所属的 spanClass，从 mheap 的页分配器 pageAlloc 取得足够数量空闲页组装成 mspan 填充到 mcache，然后从 mspan 中取内存（全局锁）（5）mheap 向操作系统申请内存，更新页分配器的索引信息，然后重复（4）. 对于小对象的分配流程是跳过（1）步，执行上述流程的（2）-（5）步；对于大对象的分配流程是跳过（1）-（3）步，执行上述流程的（4）-（5）步. object size &gt; 32K，则使用 mheap 直接分配。 object size &lt; 16 byte，不包含指针使用 mcache 的小对象分配器 tiny 直接分配；包含指针分配策略与[16 B, 32 K]类似。 object size &gt;&#x3D; 16 byte &amp;&amp; size &lt;&#x3D;32K byte 时，先使用 mcache 中对应的 size class 分配。 如果 mcache 对应的 size class 的 span 已经没有可用的块，则向 mcentral 请求。 如果 mcentral 也没有可用的块，则向 mheap 申请，并切分。 如果 mheap 也没有合适的 span，则向操作系统申请。 为什么分微对象，小对象，大对象16B以上是小对象，32KB以上是大对象，16B一下是微对象 因为程序中的绝大多数对象的大小都在 32KB 以下，而申请的内存大小影响 Go 语言运行时分配内存的过程和开销，所以分别处理大对象和小对象有利于提高内存分配器的性能。 内存逃逸go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做逃逸分析(escape analysis)，当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆。 所谓逃逸，就是指变量的生命周期不仅限于函数栈帧，而是超出了函数的范围，需要在堆上分配内存。如果变量x没有发生逃逸，那么它会被分配在函数栈帧中，随着函数的返回而被自动销毁。 一般我们给一个引用类对象中的引用类成员进行赋值，可能出现逃逸现象。可以理解为访问一个引用对象实际上底层就是通过一个指针来间接的访问了，但如果再访问里面的引用成员就会有第二次间接访问，这样操作这部分对象的话，极大可能会出现逃逸的现象。 在方法内把局部变量指针返回 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。 发送指针或带有指针的值到 channel 中。 在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。 在 interface 类型上调用方法。 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。 我们得出了指针必然发生逃逸的三种情况： 在某个函数中new或字面量创建出的变量，将其指针作为函数返回值，则该变量一定发生逃逸（构造函数返回的指针变量一定逃逸）； 被已经逃逸的变量引用的指针，一定发生逃逸； 被指针类型的slice、map和chan引用的指针，一定发生逃逸； 同时我们也得出一些必然不会逃逸的情况： 指针被未发生逃逸的变量引用； 仅仅在函数内对变量做取址操作，而未将指针传出； 逃逸分析好处通过逃逸分析，那些不需要分配到堆上的变量直接分配到栈上，堆上的变量少了不但同时减少 GC 的压力，还减轻了内存分配的开销。 go build -gcflags=-m main.go 如何避免内存逃逸 尽量减少外部指针引用，必要的时候可以使用值传递； 对于自己定义的数据大小，有一个基本的预判，尽量不要出现栈空间溢出的情况； Golang中的接口类型的方法调用是动态调度，如果对于性能要求比较高且访问频次比较高的函数调用，应该尽量避免使用接口类型； 尽量不要写闭包函数，可读性差且发生逃逸。 当指针类型作为返回时，会发生内存逃逸 内存泄露 临时性泄露，指的是该释放的内存资源没有及时释放，对应的内存资源仍然有机会在更晚些时候被释放，即便如此在内存资源紧张情况下，也会是个问题。这类主要是 string、slice 底层 buffer 的错误共享，导致无用数据对象无法及时释放，或者 defer 函数导致的资源没有及时释放。 永久性泄露，指的是在进程后续生命周期内，泄露的内存都没有机会回收，如 goroutine 内部预期之外的for-loop或者chan select-case导致的无法退出的情况，导致协程栈及引用内存永久泄露问题。 Goroutine泄漏：实际开发中更多的还是Goroutine引起的内存泄漏，因为Goroutine的创建非常简单，通过关键字go即可创建，由于开发的进度大部分程序猿只会关心代码的功能是否实现，很少会关心Goroutine何时退出。如果Goroutine在执行时被阻塞而无法退出，就会导致Goroutine的内存泄漏，一个Goroutine的最低栈大小为2KB，在高并发的场景下，对内存的消耗也是非常恐怖的！ 互斥锁未释放：协程拿到锁未释放，其他协程获取锁会阻塞 死锁 chan阻塞 定时器使用 time.Ticker是每隔指定的时间就会向通道内写数据。作为循环触发器，必须调用stop方法才会停止，从而被GC掉，否则会一直占用内存空间。 排查 pprof hook 库函数 代码审查：仔细检查代码，特别关注goroutine的创建和终止逻辑，确保没有未释放的资源，没有未关闭的通道，以及没有无限循环。 调试工具：使用Go语言提供的调试工具，如goroutine分析器（go tool pprof）和内存分析器（go tool pprof -alloc_space），来检查运行时的goroutine数量和内存使用情况。这些工具可以帮助定位泄露的goroutine以及相关的资源。 监控和日志：在应用程序中添加监控和日志记录，以便及时发现异常的goroutine数量和行为。记录重要的事件和错误信息，以便追踪和分析泄露的原因。 单元测试和性能测试：编写单元测试来验证goroutine的创建和终止逻辑，并进行性能测试以模拟高并发和负载情况，以确定是否存在泄露问题。 垃圾回收机制垃圾回收就是对程序中不再使用的内存资源进行自动回收的操作。 GoV1.3- 普通标记清除法，整体过程需要启动STW，效率极低。GoV1.5- 三色标记法， 堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要STW)，效率普通GoV1.8-三色标记法，混合写屏障机制， 栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高。 三色标记法 初始化状态下所有对象都是白色的。 从根节点开始遍历所有对象，把遍历到的对象变成灰色对象 遍历灰色对象，将灰色对象引用的对象也变成灰色对象，然后将遍历过的灰色对象变成黑色对象 循环步骤3，直到灰色对象全部变黑色。 通过写屏障检测对象有变化。重复以上操作 收集所有的白色对象（垃圾） 根节点根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括： 全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。 执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。 stop the world为了防止在GC处理过程中对象依赖树被篡改，比如一个黑节点指向一个白节点，会导致白节点错误的被清理，所以需要在整个GC过程停止用户的代码执行，即STW(stop the word), 早期的go就是这样做的，带来的后果也是非常严重的，STW时间长达数百毫秒，对时延敏感的程序造成巨大的影响。 a.第一次是Mark阶段的开始。第一次STW会准备根对象的扫描, 启动写屏障(Write Barrier)和辅助GC(mutator assist). b.第二次是Mark Termination（标记结束）阶段. re-scan过程，如果这个时候没有stw，那么mark将无休止。第二次STW会重新扫描部分根对象, 禁用写屏障(Write Barrier)和辅助GC(mutator assist). 需要注意的是, 不是所有根对象的扫描都需要STW, 例如扫描栈上的对象只需要停止拥有该栈的G. 从go 1.9开始, 写屏障的实现使用了Hybrid Write Barrier, 大幅减少了第二次STW的时间. 这里的写屏障(write barrier)是因为在GC的时候用户代码可以同时运行，这样在扫描的时候，对象的依赖树可能被改变了，为了避免这个问题，Golang在GC中标记阶段会启用写屏障。 写屏障:当标记和程序是并发执行的，这就会造成一个问题. 在标记过程中，有新的引用产生，可能会导致误清扫. 清扫开始前，标记为黑色的对象引用了一个新申请的对象，它肯定是白色的，而黑色对象不会被再次扫描，那么这个白色对象无法被扫描变成灰色、黑色，它就会最终被清扫，而实际它不应该被清扫. 这就需要用到屏障技术，golang采用了写屏障，其作用就是为了避免这类误清扫问题. 写屏障即在&#x3D;&#x3D;内存写操作前，维护一个约束，从而确保清扫开始前，黑色的对象不能引用白色对象&#x3D;&#x3D;. 插入写屏障：当一个对象指向另一个对象时，被指向的对象被置灰，所以黑节点指向灰节点，不会错误清理对象。删除写屏障：当删除一个对象对另一个对象的引用时，旧的被指向者被置灰。 强三色不变性不存在黑色对象引用到白色对象的指针。 弱三色不变性所有被黑色对象引用的白色对象都处于灰色保护状态. 黑色对象可以引用白色对象，当前仅当白色对象存在其他灰色对象引用，或者可达它的链路上游存在黑色对象强制性不允许黑色对象引用白色对象 插入写屏障具体操作: 在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)满足强三色不变性 我们知道,黑色对象的内存槽有两种位置, 栈和堆. 栈空间的特点是容量小,但是要求相应速度快,因为函数调用弹出频繁使用, 所以“插入屏障”机制,在栈空间的对象操作中不使用. 而仅仅使用在堆空间对象的操作中. &#x3D;&#x3D;为了防止栈空间内黑色对象引用白色对象，此时会在准备清扫白色对象时，进行STW再次扫描一遍栈空间。&#x3D;&#x3D; 缺点：结束时需要STW重新扫描栈，10~100ms 删除写屏障具体操作: 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。满足弱三色不变性 缺点：回收精度低，一个对象即时被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一次GC中才被清理。GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。 混合写屏障 GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)， GC期间，任何在栈上创建的新对象，均为黑色。 被删除的对象标记为灰色。 被添加的对象标记为灰色。 满足: 变形的弱三色不变式（结合了插入、删除写屏障的优点）.只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持，这个过程不需要STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行re-scan操作了，减少了STW的时间。 GC触发时机 主动触发，通过调用 runtime.GC 来触发 GC，此调用阻塞式地等待当前 GC 运行完毕。 被动触发，分为两种方式： 使用系统监控，当超过两分钟没有产生任何 GC 时，强制触发 GC。 当程序分配了一定数量的内存后，GC 也会被触发。当所分配的堆大小达到阈值（由控制器计算的触发堆的大小）时，将会触发。使用步调（Pacing）算法，其核心思想是控制内存增长的比例。第一次触发 GC 时强制设置触发第一次 GC 为 4MB 当系统内存空间不足时，GC 会被触发来释放内存 缺点stop the world是gc的最大性能问题，对于gc而言，需要停止所有的内存变化，即停止所有的goroutine，等待gc结束之后才恢复。 从1.8以后的golang将第一步的stop the world 也取消了，这又是一次优化； 1.9开始, 写屏障的实现使用了Hybrid Write Barrier, 大幅减少了第二次STW的时间.","categories":[],"tags":[]},{"title":"Go 基础","slug":"Go-基础指南","date":"2024-04-04T07:32:45.000Z","updated":"2024-04-10T07:31:57.000Z","comments":true,"path":"2024/04/04/Go-基础指南/","link":"","permalink":"http://peapod.top/2024/04/04/Go-%E5%9F%BA%E7%A1%80%E6%8C%87%E5%8D%97/","excerpt":"","text":"Go 基础数据类型占用空间 类型 空间 int8 1 int16 2 int32 4 int64 8 int 4(32位)&#x2F;8(64位) float32 4 float64 8 string 1(英文)&#x2F;2~4(中文取决于字符集) bool 1 byte 1 funcGo语言中，函数被认为是一等公民（First-class citizens），这意味着函数在语言中具有与其他类型（如整数、字符串等）相同的权利和地位。以下是函数在Go语言中被视为一等公民的原因： 函数可以作为值进行传递：在Go语言中，函数可以像其他类型的值一样被传递给其他函数或赋值给变量。这意味着可以将函数作为参数传递给其他函数，也可以将函数作为返回值返回。 函数可以赋值给变量：在Go语言中，可以将函数赋值给变量，然后通过变量来调用函数。这种能力使得函数可以像其他数据类型一样被操作和处理。 函数可以匿名定义：Go语言支持匿名函数的定义，也称为闭包。这意味着可以在不给函数命名的情况下直接定义和使用函数，更加灵活和便捷。 函数可以作为数据结构的成员：在Go语言中，函数可以作为结构体的成员，从而使得函数与其他数据一起存储在结构体中。这种特性使得函数能够更好地与数据相关联，实现更复杂的功能。 Init()函数golang程序初始化先于main函数执行，由runtime进行初始化，初始化顺序如下： 初始化导入的包（包的初始化顺序并不是按导入顺序（“从上到下”）执行的，runtime需要解析包依赖关系，&#x3D;&#x3D;没有依赖的包最先初始化&#x3D;&#x3D;，与变量初始化依赖关系类似） 初始化包作用域的变量（该作用域的变量的初始化也并非按照“从上到下、从左到右”的顺序，runtime解析变量依赖关系，没有依赖的变量最先初始化） 执行包的init函数； init函数先于main函数自动执行，不能被其他函数调用； init函数没有输入参数、返回值； 每个包可以有多个init函数； 包的每个源文件也可以有多个init函数，这点比较特殊； 同一个包的init执行顺序，golang没有明确定义，编程时要注意程序不要依赖这个执行顺序。 不同包的init函数按照包导入的依赖关系决定执行顺序。 init 函数没有输入参数、返回值，也未声明，所以无法被显示的调用，不能被引用（赋值给函数变量），否则会出现编译错误 一个go文件可以拥有多个init函数，执行顺序按定义顺序执行 初始化常量&#x2F;变量优于 init 函数执行，init函数先于main函数自动执行。执行顺序先后为： const常量 &gt; var 变量 &gt; init函数 &gt; main函数 只想调用包的init函数，不需要其他方法1import _ &quot;net/http/pprof&quot; golang对没有使用的导入包会编译报错，但是有时我们只想调用该包的init函数，不使用包导出的变量或者方法，这时就采用上面的导入方案。 结构体Go 语言中没有类的概念，因此在 Go 中结构体有着更为重要的地位。结构体是复合类型(composite types)，当需要定义一个类型，它由一系列属性组成，每个属性都有自己的类型和值的时候，就应该使用结构体，它把数据聚集在一起。然后可以访问这些数据，就好像它是一个独立实体的一部分。结构体也是值类型，因此可以通过 new 函数来创建。 初始化因为Go语言结构体是一个值类型，也就是说当你声明了一个结构体类型的变量时，实际上是在内存中分配了一块连续的内存空间的，这个空间里面包含这个结构体中定义的所有字段。字段均为默认零值 go的结构体能不能比较golang中 Slice，Map，Func 这三种数据类型是不可以直接比较的。 同一个struct的两个实例可比较也不可比较，当结构不包含不可直接比较成员变量时可直接比较，否则不可直接比较 对struct{}{}的理解结构体常用于抽象表示一类事物，可以拥有行为或者状态。 struct{ } ：表示struct类型struct{}{}是一种普通数据类型，一个无元素的结构体类型，通常在没有信息存储时使用。&#x3D;&#x3D;优点是大小为0，不需要内存来存储struct {}类型的值&#x3D;&#x3D;。 空结构体是一种特殊的结构体，没有任何字段，不会进行内存对齐，也不占用内存，但是有固定的地址 zerobase。 struct {} {}：表示struct类型的值，该值也是空。struct {} {}是一个复合字面量，它构造了一个struct {}类型的值，该值也是空。 应用场景 struct{}类型的chan，用于传递信号，用于流转各类状态或是控制并发情况。 map[type]struct{}，实现set 实现方法接收者，不占空间，也便于未来针对该类型进行公共字段等的增加 实现方法接收者： 在业务场景下，我们需要将方法组合起来，代表其是一个 ”分组“ 的，便于后续拓展和维护。但是如果我们使用： 12type T stringfunc (s *T) Call() 又似乎有点不大友好，因为作为一个字符串类型，其本身会占据定的空间。这种时候我们会采用空结构体的方式，这样&#x3D;&#x3D;也便于未来针对该类型进行公共字段等的增加&#x3D;&#x3D;。如下： 123456789type T struct&#123;&#125;func (s *T) Call() &#123;&#125;func main() &#123; var s T s.Call()&#125; 在该场景下，使用空结构体从多维度来考量是最合适的，易拓展，省空间，最结构化。 函数传值go都是值传递只是传的参数是值类型还是引用类型golang中所有函数参数传递都是传值，slice、map和chan看上去像引用只是因为他们内部有指针或本身就是指针而已。由于它们本身就是引用类型，因此使用引用传递可以避免复制数据和额外的内存开销。 string在底层实现上是引用类型，但是因为string不允许修改，只能生成新的对象，在逻辑上和值类型无差别。 值传递或者指针传递都有可能发生逃逸，关键是有没有外部引用！！！，不是传指针就一定会逃逸！！！ 当结构体很小且拷贝成本很低时，例如结构体中只包含几个基本类型的字段，可以直接传递结构体的值，这样可以避免创建指针的额外开销，而且较小的结构体会在栈上分配内存更加高效，减少GC压力。 当结构体很大时或者需要修改结构体中的字段时，传递指向结构体的指针会更加高效。因为在 Go 中，函数传递结构体时会进行一次值拷贝，如果结构体很大，则拷贝的成本也很高。而如果传递结构体的指针，函数就可以直接操作原始数据，避免了值拷贝的开销。 所以得出结论，当我们需要修改结构体的变量内容的时候，方法传入的结构体变量参数需要使用指针，也就是结构体的地址。 需要修改map中的架构体的变量的时候也需要使用结构体地址作为map的value。如果仅仅是读取结构体变量，可以不使用指针，直接传递引用即可。*type 这里的type这个变量存放的东西是地址，这点需要明确，需要使用&amp;type获取到地址。 引用类型引用类型 变量存储的是一个地址，这个地址存储最终的值。内存通常在堆上分配。通过 GC 回收。 包括 指针、slice 切片、管道 channel、接口 interface、map、函数等。 &#x3D;&#x3D;struct是值类型&#x3D;&#x3D; 值类型 直接存放值，内存通常在栈中分配 应用类型变量存储的地址（也就是通过指针访问类型里面的数据），通常真正的值在堆上分配。当没有变量引用这个地址的时候，该值会被gc回收。 make和new和var的区别？引用类型 变量存储的是一个地址，这个地址存储最终的值。内存通常在堆上分配。通过 GC 回收。包括 指针、slice 切片、管道 channel、接口 interface、map、函数等。值类型是基本数据类型，int,float,bool,string, 以及数组和 struct 特点：变量直接存储值，内存通常在栈中分配，栈在函数调用后会被释放对于引用类型的变量，我们不光要声明它，还要为它分配内存空间对于值类型的则不需要显示分配内存空间，是因为go会默认帮我们分配好 简单的说，new只分配内存，make用于slice，map，和channel的初始化。 make和new都是golang用来分配内存的內建函数，且在堆上分配内存，&#x3D;&#x3D;make 即分配内存，也初始化内存。new只是将内存清零(赋零值)，并没有初始化内存。&#x3D;&#x3D; make返回的还是&#x3D;&#x3D;引用类型本身&#x3D;&#x3D;；而new返回的是&#x3D;&#x3D;指向类型的指针&#x3D;&#x3D;。 make只能用来分配及初始化类型为&#x3D;&#x3D;slice，map，channel&#x3D;&#x3D;的数据；&#x3D;&#x3D;new可以分配任意类型的数据&#x3D;&#x3D;。 使用make()，来初始化slice，map 和channel 。 大多数场合，类型明确的场合下，使用短变量声明方式:&#x3D;。 当使用文字方式初始化一个变量，并且需要指明类型时，使用var变量声明方式。 避免使用new()，除非你需要一个指针变量。 对于值类型的变量，var 声明(包括结构体)，系统会默认为他分配内存空间，并赋该类型的零值。 new 和 make都是Go语言的两个内建函数，用于分配内存 new 一般用来返回指针类型（一般不用），make返回引用类型（map, slice,chan 这三个引用) var 声明的 基本类型和struct这种已经分配了内存，并且赋零值了。 make的参数1make(Type, len, cap) Type：数据类型，必要参数，Type 的值只能是 slice、 map、 channel 这三种数据类型。len：数据类型实际占用的内存空间长度，map、 channel 是可选参数，slice 是必要参数。cap：为数据类型提前预留的内存空间长度，可选参数。所谓的提前预留是当前为数据类型申请内存空间的时候，提前申请好额外的内存空间，这样可以避免二次分配内存带来的开销，大大提高程序的性能。 深拷贝和浅拷贝 深拷贝: 拷贝的是数据本身，创造一个新对象，新创建的对象与原对象不共享内存，新创建的对象在内存中开辟一个新的内存地址，新对象值修改时不会影响原对象值。 实现深拷贝的方式: copy(slice2, slice1)； 遍历slice进行append赋值 浅拷贝∶拷贝的是数据地址，只复制指向的对象的指针，此时新对象和老对象指向的内存地址是一样的，新对象值修改时老对象也会变化。 实现浅拷贝的方式：引用类型的变量,默认赋值操作就是浅拷贝 如slice2 := slice1 go中的uint无符号整型是否可以相减（uint类型溢出 ）不可以，如果相减会进行类型的自动推导c为uint32位，所以系统会把负数的1的正负位当做最高进制来算，造成数值很大 涉及到原码补码反码，计算机存储，减去一个数，相当于加上这个数的相反数的补码，负数的补码是符号位不变，其他位取反，相加变成一个很大的数，因为是无符号位，首位也会再变。 string 的底层go底层系列-string底层实现原理与使用 - 掘金 (juejin.cn) string我们看起来是一个整体，但是本质上是一片连续的内存空间，我们也可以将它理解成一个由字符组成的数组，相比于切片仅仅少了一个Cap属性。 相比于切片少了一个容量的cap字段，就意味着string是不能发生地址空间扩容； 可以把string当成一个只读的byte切片类型； string本身的切片是只读的，所以不会直接向字符串直接追加元素改变其本身的内存空间，所有在字符串上的写入操作都是通过拷贝实现的。 12345678910type stringStruct struct &#123; str unsafe.Pointer //字符串首地址，指向底层字节数组的指针 len int //字符串长度 &#125;// 实例化func gostringnocopy(str *byte) string &#123; ss := stringStruct&#123;str: unsafe.Pointer(str), len: findnull(str)&#125; s := *(*string)(unsafe.Pointer(&amp;ss)) return s &#125; string的元素不能取地址，s[i] 代表第i个元素，但是&amp;s[i]是违法的。 如果一个string很大1G，值传递的时候也是复制一遍吗？可以修改吗？传递指针的复制，不可以修改 string在底层实现上是引用类型，但是因为string不允许修改，只能生成新的对象，在逻辑上和值类型无差别。 string vs []byte既然string就是一系列字节，而[]byte也可以表达一系列字节，那么实际运用中应当如何取舍？ string可以直接比较，而[]byte不可以，所以[]byte不可以当map的key值。 因为无法修改string中的某个字符，需要粒度小到操作一个字符时，用[]byte。 string值不可为nil，所以如果你想要通过返回nil表达额外的含义，就用[]byte。 []byte切片这么灵活，想要用切片的特性就用[]byte。 需要大量字符串处理的时候用[]byte，性能好很多。 string转成byte数组会发生内存拷贝吗？会字符串转成切片，会产生拷贝。严格来说，只要是发生类型强转都会发生内存拷贝。那么问题来了。频繁的内存拷贝操作听起来对性能不大友好。有没有什么办法可以在字符串转成切片的时候不用发生拷贝呢？ 123a :=&quot;aaa&quot; addr := *(*reflect.StringHeader)(unsafe.Pointer(&amp;a)) b := *(*[]byte)(unsafe.Pointer(&amp;addr)) 那么如果想要在底层转换二者，只需要把 StringHeader 的地址强转成 SliceHeader 就行。那么go有个很强的包叫 unsafe 。 unsafe.Pointer(&amp;a)方法可以得到变量a的地址。 (*reflect.StringHeader)(unsafe.Pointer(&amp;a)) 可以把字符串a转成底层结构的形式。 (*[]byte)(unsafe.Pointer(&amp;ssh)) 可以把ssh底层结构体转成byte的切片的指针。 再通过 *转为指针指向的实际内容。 两个string合并，用“+”，fmt，strings，哪个效率高Go 字符串拼接6种，最快的方式 – strings.builder - 技术颜良 - 博客园 (cnblogs.com) 通过两次benchmark对比，我们可以看到 当进行少量字符串拼接时，直接使用+操作符进行拼接字符串，效率还是挺高的，但是当要拼接的字符串数量上来时，+操作符的性能就比较低了； 函数fmt.Sprintf还是不适合进行字符串拼接，无论拼接字符串数量多少，性能损耗都很大，还是老老实实做他的字符串格式化就好了； strings.Builder无论是少量字符串的拼接还是大量的字符串拼接，性能一直都能稳定，这也是为什么Go语言官方推荐使用strings.builder进行字符串拼接的原因，在使用strings.builder时最好使用Grow方法进行初步的容量分配，观察strings.join方法的benchmark就可以发现，因为使用了grow方法，提前分配好内存，在字符串拼接的过程中，不需要进行字符串的拷贝，也不需要分配新的内存，这样使用strings.builder性能最好，且内存消耗最小。 bytes.Buffer方法性能是低于strings.builder的，bytes.Buffer 转化为字符串时重新申请了一块空间，存放生成的字符串变量，不像strings.buidler这样直接将底层的 []byte 转换成了字符串类型返回，这就占用了更多的空间。 同步最后分析的结论： 无论什么情况下使用strings.builder进行字符串拼接都是最高效的，不过要主要使用方法，记得调用grow进行容量分配，才会高效。strings.join的性能约等于strings.builder，在已经字符串slice的时候可以使用，未知时不建议使用，构造切片也是有性能损耗的；如果进行少量的字符串拼接时，直接使用+操作符是最方便也是性能最高的，可以放弃strings.builder的使用。 综合对比性能排序： 1strings.join` ≈ `strings.builder` &gt; `bytes.buffer` &gt; `[]byte`转换`string` &gt; &quot;+&quot; &gt; `fmt.sprintf strings.builder避免内存拷贝的问题，使用了强制转换来避免内存拷贝 123func (b *Builder) String() string &#123; return *(*string)(unsafe.Pointer(&amp;b.buf)) &#125; strings.join也是基于strings.builder来实现的，唯一不同在于在join方法内调用了b.Grow(n)方法，这个是进行初步的容量分配，而前面计算的n的长度就是我们要拼接的slice的长度，因为我们传入切片长度固定，所以提前进行容量分配可以减少内存分配，很高效。 rune 和 byterunerune是int32的别名，代表字符的Unicode编码，采用4个字节存储，将string转成rune就意味着任何一个字符都用4个字节来存储其unicode值，这样每次遍历的时候返回的就是unicode值，而不再是字节了，这样就可以解决乱码问题了。&#x3D;&#x3D;中文、特殊字符&#x3D;&#x3D; bytebytes操作的对象也是字节切片，与string的不可变不同，byte是可变的，因此string按增量方式构建字符串会导致多次内存分配和复制，使用bytes就不会，因而更高效一点 区别：byte 表示一个字节，rune 表示四个字节 123first := &quot;社区&quot; fmt.Println([]rune(first)) // 输出[31038 21306]fmt.Println([]byte(first)) // [231 164 190 229 140 186] Slice切片切片（Slice）是一个动态数组，它不需要指定长度，可以动态增长。切片是对底层数组的一层封装，支持对底层数组进行动态增删改操作。切片的定义方式为 var s []int，其中 s 为切片名，int 为元素类型。切片可以使用 append() 函数对其进行动态增长，例如 s &#x3D; append(s, 1)。切片在内存中不是连续的存储空间，而是由一个指向底层数组的指针、长度和容量组成。 1.19源码：切片一定会分配在堆上 go&#x2F;complit.go at master · golang&#x2F;go · GitHub截取规则左闭右开 12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; 使用var声名的切片其实是一个nil切片，它与nil比较返回true而使用语法糖或者make声名的切片是一个空切片，他们与ni比较返回false arr[low:high:max]len &#x3D; high-lowcap &#x3D; max-low max不指定时max&#x3D;high max不允许超过cap 1panic: runtime error: slice bounds out of range [::6] with capacity 5 切片cap的值在被切时会改变 slice和数组的区别数组（Array）是一种固定长度的数据结构，元素的类型都是相同的。数组的长度在创建时就已经确定，并且不可更改。数组的定义方式为 var a [5]int，其中 a 为数组名，5 为数组的长度，int 为元素类型。数组可以使用下标进行访问和修改，例如 a[0] &#x3D; 1。数组在内存中是连续的存储空间。在Golang中数组是一个长度固定的数据类型，数组的长度是类型的一部分，也就是说[5]int和[10]int是两个不同的类型。 长度不同：数组的长度是固定的，而切片的长度可以动态增长。 内存分配方式不同：数组在定义时就已经分配好了内存空间，而切片需要使用 make() 函数进行初始化分配内存。 数据类型不同：数组中的元素类型必须相同，而切片可以是不同类型的元素的序列。 传递方式不同：数组是值类型，传递时会复制一份，而切片是引用类型，传递时会传递指向底层数组的指针，多个切片可能会共享底层数组。 访问方式不同：数组使用下标访问元素，而切片支持切片操作和下标访问元素。 为什么append()需要在传入一个切片后还需要再赋值因为append之后可能会生成新的slice对象，赋值操作是用来接受可能会产生的新对象，确保期望使用的silce对象始终符合预期append这种写法看起来有点奇怪而且重复，为什么需要将append函数返回的值再赋值给传入的值，而不是直接append(x,value)呢？这涉及到go语言的设计哲学，即参数传递是值拷贝。传入到函数中的参数x会建立一个新的副本。因此需要将添加元素后返回的新副本赋值给原始的变量。 nil slice切片的零值是nil，所以只声明变量时，其缺省值为零值nil，这时也就是我们所说的nil slice。nil切片不能直接访问元素值，但可通过append()追加元素。 append 内部append 会初始化 nil slice，与此类似的函数还有 copy 。这两个函数内部都进行 make 初始化。每次对 slice 的操作内部是会产生一个新的数组，然后返回 拷贝大切片一定比小切片代价大吗？并不是，所有切片的大小相同；三个字段（一个 uintptr，两个int）。切片中的第一个字是指向切片底层数组的指针，这是切片的存储空间，第二个字段是切片的长度，第三个字段是容量。将一个 slice 变量分配给另一个变量只会复制三个机器字。所以 拷贝大切片跟小切片的代价应该是一样的。 函数传参修改会影响原值吗？如果没有扩容则会影响，如果扩容此时函数的哪个就会变成独立的一个切片 注意： 12345678910func main() &#123; x := []int&#123;1, 2, 3&#125; y := x[:2] y = append(y, 50) y = append(y, 60) fmt.Println(x) // [1 2 50] y[0] = 10 fmt.Println(x) // [1 2 50] fmt.Println(y) // [10 2 50 60]&#125; x的大小为3，当y扩容后其大小超过3此时xy就变成了两个独立的切片 Slice扩容规则1.18 前当原 slice 容量小于 1024 的时候，新 slice 容量变成原来的 2 倍；原 slice 容量超过 1024，新 slice 容量变成原来的1.25倍。 1.18 后如果新切片的容量大于原切片的两倍，则直接将切片扩容到新切片的容量当原slice容量(oldcap)小于256的时候，新slice(newcap)容量为原来的2倍；原slice容量超过256，新slice容量$newcap &#x3D; oldcap+(oldcap+3*256)&#x2F;4$ 原来 newcap只是一个我们的预期容量，实际的容量需要根据切片中的元素大小对齐内存最后，会根据切片元素的大小和新容量计算内存，将超出切片长度的内存清空，并拷贝旧切片的内存数据到新申请的内存中,最后返回 defer在 Go 中，defer 语句用于注册一个函数，这个函数会在当前函数返回前执行，即使函数发生错误或者 panic。 defer 语句的实现原理是，Go 编译器会把 defer 语句转换为一个栈。在函数调用时，每遇到一个 defer 语句，就将其函数推入栈中。在函数返回时，栈中的函数会按照后进先出（LIFO）的顺序执行。这意味着最后注册的函数会最先执行。 return之后的语句先执行，defer后的语句后执行，return 不是原子级操作的，执行过程是: 保存返回值—&gt;执行 defer —&gt;执行 ret 底层defer 语句后面是要跟一个函数的，所以 defer 的数据结构跟一般的函数类似，不同之处是 defer 结构含有一个指针，用于指向另一个 defer ，每个 goroutine 数据结构中实际上也有一个 defer 指针指向一个 defer 的单链表，每次声明一个 defer 时就将 defer 插入单链表的表头，每次执行 defer 时就从单链表的表头取出一个 defer 执行。保证 defer 是按 LIFO 方式执行的。 123456789101112131415type _defer struct &#123; started bool heap bool openDefer bool sp uintptr // sp at time of defer pc uintptr // pc at time of defer fn func() // can be nil for open-coded defers _panic *_panic // panic that is running defer link *_defer // next defer on G; can point to either heap or stack! fd unsafe.Pointer // funcdata for the function associated with the frame varp uintptr // value of varp for the stack frame framepc uintptr&#125; 在Go语言的运行时环境中，_defer 结构体的实现可以通过一个链表来维护多个 defer 语句的执行顺序。具体来说，每个_defer 结构体都有指向下一个_defer 结构体的指针，从而可以形成一个链表。 当一个函数执行结束时，runtime 会自动遍历这个链表，按照 defer 语句的执行顺序依次执行这些被延迟的函数。同时，runtime 也会对这些 _defer 结构体进行释放，回收内存。 defer遇到panic时遇到panic时，遍历本协程的defer链表，并执行defer。在执行defer过程中:遇到recover则停止panic，返回recover处继续往下执行。如果没有遇到recover，遍历完本协程的defer链表后，向stderr抛出panic信息。 panic仅有最后一个可以被revover捕获。 panic 和 recoverPanic ：在 Go 语言中，出现 Panic 是代表一个严重问题，意味着程序结束并退出。在 Go 中 Panic 关键字用于抛出异常的。类似 Java 中的 throw。 recover：在 Go 语言中，用于将程序状态出现严重错误恢复到正常状态。当 发生 Panic 后，你需要使用recover 捕获，不捕获程序会退出。类似 Java 的 try catch 捕获异常。 panic 能够改变程序的控制流，调用 panic 后会立刻停止执行当前函数的剩余代码，并在当前 Goroutine 中递归执行调用方的 defer； recover 可以中止 panic 造成的程序崩溃。它是一个只能在 defer 中发挥作用的函数，在其他作用域中调用不会发挥作用； 如果有若干个goroutine，其中有一个panic，会发生什么有一个panic，那么剩余goroutine也会退出，程序退出。如果不想程序退出，那么必须通过调用 recover() 方法来捕获 panic 并恢复将要崩掉的程序。 defer可以捕获到其goroutine中的子goroutine的panic吗？不能,它们处于不同的调度器P中。对于子goroutine，必须通过 recover() 机制来进行恢复，然后结合日志进行打印（或者通过channel传递error），下面是一个例子 123456789101112131415161718func main() &#123; defer func() &#123; defer func() &#123; if err := recover(); err != nil &#123; panic(&quot;3&quot;) &#125; &#125;() if err := recover(); err != nil &#123; panic(&quot;2&quot;) &#125; &#125;() panic(&quot;1&quot;)&#125;// 结果panic: 1 [recovered] panic: 2 [recovered] panic: 3 接口inteface在Golang中接口（interface）是一种类型，一种抽象的类型。接口（interface）是一组函数method的集合，Golang中的接口不能包含任何变量。 在 Golang 中，interface 是一组 method 的集合，是 duck-type programming 的一种体现。不关心属性（数据），只关心行为（方法）。具体使用中你可以自定义自己的 struct，并提供特定的 interface 里面的 method 就可以把它当成 interface 来使用。 1234type 接口名 interface &#123; 方法名1 (参数列表1) 返回值列表1 方法名2 (参数列表2) 返回值列表2&#125; interface 是方法声明的集合 任何类型的对象实现了在interface 接口中声明的全部方法，则表明该类型实现了该接口。 interface 可以作为一种数据类型，实现了该接口的任何对象都可以给对应的接口类型变量赋值 注意： interface 可以被任意对象实现，一个类型&#x2F;对象也可以实现多个 interface 方法不能重载，如 eat() eat(s string) 不能同时存在 空接口空接口可以作为函数的参数，使用空接口可以接收任意类型的函数参数 1234567891011121314151617// 空接口表示没有任何约束，任意的类型都可以实现空接口type EmptyA interface &#123;&#125;func main() &#123; var a EmptyA var str = &quot;你好golang&quot; // 让字符串实现A接口 a = str fmt.Println(a) var a interface&#123;&#125; a = 20 a = &quot;hello&quot; a = true&#125; 两个接口可以比较吗？DeepEqual 函数的参数是两个 interface，实际上也就是可以输入任意类型，输出 true 或者 flase 表示输入的两个变量是否是“深度”相等。 123456// 判断类型是否一样reflect.TypeOf(a).Kind() == reflect.TypeOf(b).Kind()// 判断两个interface&#123;&#125;是否相等reflect.DeepEqual(a, b interface&#123;&#125;)// 将一个interface&#123;&#125;赋值给另一个interface&#123;&#125;reflect.ValueOf(a).Elem().Set(reflect.ValueOf(b)) 类型断言前面说过，因为空接口 interface&#123;&#125; 没有定义任何函数，因此 Go 中所有类型都实现了空接口。当一个函数的形参是 interface&#123;&#125;，那么在函数中，需要对形参进行断言，从而得到它的真实类型。 类型断言的本质，跟类型转换类似，都是类型之间进行转换，不同之处在于，类型断言实在接口之间进行 123&lt;目标类型的值&gt;，&lt;布尔参数&gt; := &lt;表达式&gt;.( 目标类型 ) // 安全类型断言&lt;目标类型的值&gt; := &lt;表达式&gt;.( 目标类型 ) //非安全类型断言 123456789func test6() &#123; var i interface&#123;&#125; = &quot;TT&quot; j, b := i.(int) if b &#123; fmt.Printf(&quot;%T-&gt;%d\\n&quot;, j, j) &#125; else &#123; fmt.Println(&quot;类型不匹配&quot;) &#125;&#125; 空接口类型断言实现流程：空接口类型断言实质是将eface中_type与要匹配的类型进行对比，匹配成功在内存中组装返回值，匹配失败直接清空寄存器，返回默认值。 小结：非空接口类型断言的实质是 iface 中 *itab 的对比。*itab 匹配成功会在内存中组装返回值。匹配失败直接清空寄存器，返回默认值。 作用 空接口 通用类型：实现可以接收任意类型的函数参数，保存任意值的字典。 类型断言：当我们需要在运行时确定一个值的类型时，可以使用类型断言将空接口转换为其他类型。 泛型编程：可以使用空接口将不同的类型转换为通用的类型，在函数或方法中进行处理，然后再将其转换为原来的类型。 接口可以定义通用的行为，提高代码复用性。例如，如果你编写了一个可以排序的数据结构，你可以定义一个名为Sort的接口，它定义了一个排序方法，然后任何实现了Sort接口的类型都可以使用这个排序方法。 接口可以实现多态性，让一个变量可以持有多种类型的值。这使得你可以写出更灵活的代码，可以在运行时根据具体情况选择使用哪个具体类型的方法。这对于实现插件系统、扩展性很高的应用程序或者抽象底层实现等场景非常有用。 抽象底层实现，接口可以降低模块之间的耦合度，增强代码的灵活性和可扩展性。通过面向接口编程，不同的模块之间可以更容易地协作，可以实现组件化的架构，让系统更加易于维护和扩展。使得上层代码只关注接口定义的行为特征，而不需要关心底层的实现细节。这使得代码更加易于维护和扩展 多态 怎么去复用一个接口的方法?在Go语言中，实现接口只需要实现接口中所有的方法即可。也就是说，当一个类型定义了接口所包含的全部方法时，该类型就自动地实现了该接口。由于Go语言中不存在显示实现的语法，一个类型实现的接口的集合是由该类型自动地决定的。 在Go语言中，接口的嵌套是一种用于组合接口类型的机制。嵌套接口就是将多个接口的方法组合在一起，以便某个类型可以同时满足这些接口的方法要求。 123456789101112131415161718192021222324252627282930package mainimport &quot;fmt&quot;type Phone interface &#123; call()&#125;type NokiaPhone struct &#123;&#125;func (nokiaPhone NokiaPhone) call() &#123; fmt.Println(&quot;I am Nokia, I can call you!&quot;)&#125;type ApplePhone struct &#123;&#125;func (iPhone ApplePhone) call() &#123; fmt.Println(&quot;I am Apple Phone, I can call you!&quot;)&#125;func main() &#123; var phone Phone phone = new(NokiaPhone) phone.call() phone = new(ApplePhone) phone.call()&#125; 上述中体现了interface接口的语法，在main函数中，也体现了多态的特性。同样一个phone的抽象接口，分别指向不同的实体对象，调用的call()方法，打印的效果不同，那么就是体现出了多态的特性。 底层【golang】interface原理 - 个人文章 - SegmentFault 思否 iface 和 eface 都是 Go 中描述interface{}的底层结构体，区别在于 iface 描述的接口包含方法，而 eface 则是不包含任何方法的空接口：interface&#123;&#125;。 efaceeface表示不含 method 的 interface 结构，或者叫 empty interface。对于 Golang 中的大部分数据类型都可以抽象出来 _type 结构，同时针对不同的类型还会有一些其他信息。 eface结构体是golang中实现interface的一种方式。在语言中，interface是一种类型，代表了一组方法的签名，也就是说实现一个interface的类型必须拥有该interface定义的一组方法。而在golang中，使用interface时，由于interface的底层实现是复合类型，需要保存类型信息和值信息等，在实现中就要使用到eface结构体。 123456789101112131415161718type eface struct &#123; _type *_type data unsafe.Pointer &#125; type _type struct &#123; size uintptr // type size ptrdata uintptr // size of memory prefix holding all pointers hash uint32 // hash of type; avoids computation in hash tables tflag tflag // extra type information flags align uint8 // alignment of variable with this type fieldalign uint8 // alignment of struct field with this type kind uint8 // enumeration for C alg *typeAlg // algorithm table gcdata *byte // garbage collection data str nameOff // string form ptrToThis typeOff // type for pointer to this type, may be zero &#125; 其中_type指向类型信息(type information)，data指向该类型的值(value of type)。因此，eface结构体可以保存任何类型的值，而不需要提前知道其类型。 当程序使用interface来定义变量时，这个变量实际上是一个eface结构体。程序在使用该变量时，可以通过类型信息对其进行断言，并调用具体的方法。 ifaceiface 表示 non-empty interface 的底层实现。相比于 empty interface，non-empty 要包含一些 method。method 的具体实现存放在 itab.fun 变量里。如果 interface 包含多个 method，这里只有一个 fun 变量怎么存呢？这个下面再细说。 12345678910111213141516171819202122232425262728type iface struct &#123; tab *itab // 方法表 data unsafe.Pointer // 具体的值&#125; // layout of Itab known to compilers // allocated in non-garbage-collected memory // Needs to be in sync with // ../cmd/compile/internal/gc/reflect.go:/^func.dumptypestructs. type itab struct &#123; inter *interfacetype _type *_type link *itab bad int32 inhash int32 // has this itab been added to hash? fun [1]uintptr // variable sized &#125; // 包含了一些关于 interface 本身的信息type interfacetype struct &#123; typ _type pkgpath name mhdr []imethod &#125; type imethod struct &#123; //这里的 method 只是一种函数声明的抽象，比如 func Print() error name nameOff ityp typeOff &#125; iface 结构体有两个字段： tab，指向该接口类型变量的方法表指针，其中 itab 是一个包含了该接口类型的方法集的结构体。 data，指向该接口类型变量具体的值的指针，其中 data 具体指向实现该接口的具体类型的值。 通过 iface 结构体的方法表指针，可以在运行时动态分派实际调用的具体实现方法。 使用 iface 结构体，可以在运行时实现接口类型的多态，这些多态的接口类型变量指向的具体类型也会在运行时动态确定。因此，iface 结构体在 Go 中的作用非常重要。 注意 nil !&#x3D; nil 接口是一种引用类型的数据结构，它的值可以为nil。 实现接口的类型必须实现接口中所有的方法，否则会编译错误。 接口的值可以赋给实现接口的类型的变量，反之亦然。 在实现接口的类型的方法中，可以通过类型断言来判断接口值的实际类型和值。 12345678910111213var i interface&#123;&#125; = nilvar j interface&#123;&#125; = (*int)(nil)var k interface&#123;&#125;var a chan intvar b chan intvar c chan boolfmt.Println(i, j, k, a, b, c)fmt.Println(i == nil, j == nil, a == nil, b == nil, c == nil)fmt.Println(i == j, i == k, i == a, a == b)// a == c invalid operation: a == c (mismatched types chan int and chan bool)// 输出&lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; // true false true true true// false true false true nil特点 nil 不是关键字或保留字:var nil = errors.New(&quot;my god&quot;) 不会报错 nil没有默认类型：&#96;fmt.Printf(“%T”, nil) &#x2F;&#x2F; .&#x2F;hello.go:9:7: use of untyped nil 不同类型 nil 的指针是一样的 123var arr []int var num *int fmt.Printf(&quot;%p %p&quot;, arr, num) // 0x0 0x0 1234567891011121314- nil 是 map、slice、pointer、channel、func、interface 的零值- 不同类型的 nil 是不能比较的- 不同类型的 nil 值占用的内存大小可能是不一样的#### 不能和nil比较的情况 1. nil 标识符是不能比较的: `invalid operation: nil == nil (operator == not defined on nil)`2. 不同类型的 nil 是不能比较的3. `map` 、 `slice` 和 `function` 类型的 `nil` 值不能比较，比较两个无法比较类型的值是非法的 ```go var s1 []int var s2 []int fmt.Printf(s1 == s2) // invalid operation: s1 == s2 (slice can only be compared to nil) mapGo 语言map采用的是哈希查找表，并且使用链表解决哈希冲突。 哈希查找表用一个哈希函数将 key 分配到不同的桶（bucket，也就是数组的不同 index）。这样，开销主要在哈希函数的计算以及数组的常数访问时间。在很多场景下，哈希查找表的性能很高。 不能做为map的keyslice、map、func以及包含这些类型的struct why？因为这些类型不可以用==比较 nil map 和空map的区别根据官方定义，nil是预定义标识，代表了指针pointer、通道channel、函数func、接口interface、map、切片slice类型变量的零值。 只声明一个map类型变量时，为nil map 此时为只读map，无法进行写操作，否则会触发panic nil map和empty map区别： nil map：只声明未初始化，此时为只读map，不能写入操作，示例：var m map[t]v empty map：空map，已初始化，可写入，示例：m := map[t]v&#123;&#125;或m := make(map[string]string, 0) 删除外层的循环就是在遍历整个 map，删除的核心就在那个empty。它修改了当前 key 的标记，而不是直接删除了内存里面的数据。 内存没有释放。清空只是修改了一个标记，底层内存还是被占用了只有将整个map置为nil时才会被GC map = nil08794我觉得这样不算是内存泄漏。如果继续给这个map写入值，如果这个值命中了之前被删除的bucket，那么会覆盖之前的empty数据。 哈希冲突当两个不同的 key 落在同一个桶中，就是发生了哈希冲突。冲突的解决手段是采用链表法：在 桶 中，从前往后找到第一个空位进行插入。如果8个kv满了，那么当前桶就会连接到下一个溢出桶（bmap） 如何有序遍历map当我们在遍历 map 时，并不是固定地从 0 号 bucket 开始遍历，每次都是从一个随机值序号的 bucket 开始遍历，并且是从这个 bucket 的一个随机序号的 cell 开始遍历。 将 Map 中的 key 拿出来，放入 slice 中做排序 利用官方库里的 list(链表) 封装一个结构体，实现一个有序的 K-V 存储结构，在里面维护一个 keys 的 list。 123456type OrderedMap struct &#123; //存储 k-v,使用 *list.Element 当做 value 是利用 map O(1) 的性能找到 list 中的 element kv map[interface&#123;&#125;]*list.Element //按顺序存储 k-v，保证插入、删除的时间复杂度O(1) ll *list.List&#125; 可以对key&#x2F;value取地址吗？不可以，因为没必要，扩容会改变 如果通过其他 hack 的方式，例如 unsafe.Pointer 等获取到了 key 或 value 的地址，也不能长期持有，因为一旦发生扩容，key 和 value 的位置就会改变，之前保存的地址也就失效了。 注意 map的key是无序的，不会通过key保持data的顺序。 map中的data不是按插入顺序存储的。 每次迭代循环map时，key的输出都是无序的 在迭代期间对map进行添加的新元素有可能被输出，也有可能被跳过。 在使用make函数初始化map时，指定元素个数，在操作中可以降低内存分配次数，提高性能。 map是非并发安全的，不能同时对同一个map进行读和写。想满足并发安全的场景，需要通过sync.RWMutex进行加锁同步。 可作为map的key的类型必须是能够是用 &#x3D;&#x3D; 操作符进行可比较的类型。 当从map访问一个不存在的键时，他会返回该类型的零值 两个map不能判断相等，只能判断深度相等 底层Golang | 由浅入深理解哈希表Map - 掘金 (juejin.cn) 哈希查找表用一个哈希函数将 key 分配到不同的桶（bucket，也就是数组的不同 index）。这样，开销主要在哈希函数的计算以及数组的常数访问时间。在很多场景下，哈希查找表的性能很高。 在go的map实现中，它的底层结构体是hmap，hmap里维护着若干个bucket数组 (即桶数组)。 Bucket数组中每个元素都是bmap结构，也即每个bucket（桶）都是bmap结构，【ps：后文为了语义一致，和方便理解，就不再提bmap了，统一叫作桶】 每个桶中保存了8个kv对，如果8个满了，又来了一个key落在了这个桶里，会使用overflow连接下一个桶(溢出桶)。 123456789101112131415161718192021222324252627type hmap struct &#123; count int // 元素的个数 flags uint8 // 标识 map 是否被 goroutine 并发读写 B uint8 // buckets 数组的长度就是 2^B 个 overflow uint16 // 溢出桶的数量 buckets unsafe.Pointer // 2^B个桶对应的数组指针 oldbuckets unsafe.Pointer // 发生扩容时，记录扩容前的buckets数组指针 nevacuate unsafe.Pointer // 扩容时的进度标识,index 小于 nevacuate 的桶都已经由老桶转移到新桶中 extra *mapextra //用于保存溢出桶的地址&#125;type mapextra struct &#123; overflow *[]*bmap // 供桶数组 buckets 使用的溢出桶 oldoverflow *[]*bmap // 扩容流程中，供老桶数组 oldBuckets 使用的溢出桶； nextOverflow *bmap // 下一个可用的溢出桶.&#125;const bucketCnt = 8type bmap struct &#123; // bmap 就是 map 中的桶，可以存储 8 组 key-value 对的数据，以及一个指向下一个溢出桶的指针；//每组 key-value 对数据包含 key 高 8 位 hash 值 tophash，key 和 val 三部分； tophash [bucketCnt]uint8&#125; //在编译期间会产生新的结构体type bmap struct &#123; tophash [8]uint8 //存储哈希值的高8位 data byte[1] //key value数据:key/key/key/.../value/value/value... overflow *bmap //溢出bucket的地址&#125; 核心流程写： 根据 key 取 hash 值； 根据 hash 值对桶数组取模，确定所在的桶； 倘若 map 处于扩容，则迁移命中的桶，帮助推进渐进式扩容； 沿着桶链表依次遍历各个桶内的 key-value 对； 倘若命中相同的 key，则对 value 中进行更新； 倘若 key 不存在，则插入 key-value 对； 倘若发现 map 达成扩容条件，则会开启扩容模式，并重新返回第2步. 读： 根据 key 取 hash 值； 根据 hash 值对桶数组取模，确定所在的桶； 沿着桶链表依次遍历各个桶内的 key-value 对； 命中相同的 key，则返回 value；倘若 key 不存在，则返回零值. 删： 根据 key 取 hash 值； 根据 hash 值对桶数组取模，确定所在的桶； 倘若 map 处于扩容，则迁移命中的桶，帮助推进渐进式扩容； 沿着桶链表依次遍历各个桶内的 key-value 对； 倘若命中相同的 key，删除对应的 key-value 对；并将当前位置的 tophash 置为 emptyOne，表示为空； 倘若当前位置为末位，或者下一个位置的 tophash 为 emptyRest，则沿当前位置向前遍历，将毗邻的 emptyOne 统一更新为 emptyRest. 桶数组map 中，会通过长度为 2 的整数次幂的桶数组进行 key-value 对的存储： 每个桶固定可以存放 8 个 key-value 对； 倘若超过 8 个 key-value 对打到桶数组的同一个索引当中，此时会通过创建桶链表的方式来化解这一问题. 解决哈希冲突在 map 解决 hash &#x2F;分桶 冲突问题时，实际上结合了拉链法和开放寻址法两种思路. 以 map 的插入写流程为例，进行思路阐述： 桶数组中的每个桶，严格意义上是一个单向桶链表，以桶为节点进行串联； 每个桶固定可以存放 8 个 key-value 对； 当 key 命中一个桶时，首先根据开放寻址法，在桶的 8 个位置中寻找空位进行插入； 倘若桶的 8 个位置都已被占满，则基于桶的溢出桶指针，找到下一个桶，重复第3步； 倘若遍历到链表尾部，仍未找到空位，则基于拉链法，在桶链表尾部续接新桶，并插入 key-value 对. 哈希算法对于哈希算法的选择，程序会根据当前架构判断是否支持AES，如果支持就使用AES hash，其实现代码位于src&#x2F;runtime&#x2F;asm_{386,amd64,arm64}.s中；若不支持，其hash算法则根据xxhash算法（https://code.google.com/p/xxhash/）和cityhash算法（https://code.google.com/p/cityhash/）启发而来，代码分别对应于32位（src&#x2F;runtime&#x2F;hash32.go）和64位机器（src&#x2F;runtime&#x2F;hash64.go）中，对这部分内容感兴趣的读者可以深入研究。 map扩容机制[[go源码#map#扩容]] 在赋值过程中，会判断是否需要扩容，主要有两个函数：overLoadFactory和tooManyOverflowBuckets （1）扩容分为增量扩容和等量扩容；（2）当桶内 key-value 总数&#x2F;桶数组长度 &gt; 6.5 时发生增量扩容，桶数组长度增长为原值的两倍；（3）当桶内溢出桶数量大于等于 2^B 时( B 为桶数组长度的指数，B 最大取 15)，发生等量扩容，桶的长度保持为原值；（4）采用渐进扩容的方式，当桶被实际操作到时，由使用者负责完成数据迁移，避免因为一次性的全量数据迁移引发性能抖动. 小结一下：map扩容有两种情况，一&#x3D;&#x3D;种是map的负载因子超过了6.5，一种是溢出桶（数组）太多了&#x3D;&#x3D; 扩容方式： 相同容量扩容：因为有添加和删除操作，所以桶中会出现一些空位，这种扩容实际上是进行了元素重排，不会换桶。 2倍容量扩容：由于当前桶数组确实不够用了，发生这种扩容时，元素会重排，可能会发生桶迁移。 扩容迁移规则：只有写操作会触发扩容 （1）在等量扩容中，新桶数组长度与原桶数组相同；（2）key-value 对在新桶数组和老桶数组的中的索引号保持一致；（3）在增量扩容中，新桶数组长度为原桶数组的两倍；（4）把新桶数组中桶号对应于老桶数组的区域称为 x 区域，新扩展的区域称为 y 区域.（5）实际上，一个 key 属于哪个桶，取决于其 hash 值对桶数组长度取模得到的结果，因此依赖于其低位的 hash 值结果.；（6）在增量扩容流程中，新桶数组的长度会扩展一位，假定 key 原本从属的桶号为 i，则在新桶数组中从属的桶号只可能是 i （x 区域）或者 i + 老桶数组长度（y 区域）；（7）当 key 低位 hash 值向左扩展一位的 bit 位为 0，则应该迁往 x 区域的 i 位置；倘若该 bit 位为 1，应该迁往 y 区域对应的 i + 老桶数组长度的位置. 扩容过程：&#x3D;&#x3D;类似redis的渐进式rehash&#x3D;&#x3D;由于 map 扩容需要将原有的 key&#x2F;value 重新搬迁到新的内存地址，如果有大量的 key&#x2F;value 需要搬迁，会非常影响性能。因此 Go map 的扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。当每次触发写、删操作时，会为处于扩容流程中的 map 完成两组桶的数据迁移： 一组桶是当前写、删操作所命中的桶； 另一组桶是，当前未迁移的桶中，索引最小的那个桶. 上面说的 hashGrow() 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 growWork() 函数中，而调用 growWork() 函数的动作是在 mapassign 和 mapdelete 函数中。&#x3D;&#x3D;也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作&#x3D;&#x3D;。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。 如何保证并发安全？（1）并发读没有问题；（2）并发读写中的“写”是广义上的，包含写入、更新、删除等操作；（3）读的时候发现其他 goroutine 在并发写，抛出 fatal error；（4）写的时候发现其他 goroutine 在并发写，抛出 fatal error. 需要关注，此处并发读写会引发 fatal error，是一种比 panic 更严重的错误，无法使用 recover 操作捕获. 如果对map进行并发读写会报fatal error，是不能被recover捕获的 使用时加锁或使用sync.Map 倘若发现存在其他 goroutine 在写 map，直接抛出并发读写的 fatal error；其中，并发写标记，位于 hmap.flags 的第 3 个 bit 位；&#x3D;&#x3D;在读写前，和读写后都会判断&#x3D;&#x3D; 12345// 检测 hmap 中的 flags uint8 // 标识 map 是否被 goroutine 并发读写const hashWriting = 4 if h.flags&amp;hashWriting != 0 &#123; fatal(&quot;concurrent map read and map write&quot;) &#125; sync.Map底层是两个map , 一个read map 一个dirty map , 一开始读read map ,没有数据则加锁穿透去读dirty map 并且记录一个计数 ,计数满的时候read map被用dirty map进行覆盖 123456789101112131415type Map struct &#123; mu sync.Mutex read atomic.Value // readOnly dirty map[interface&#123;&#125;]*entry misses int &#125;type entry struct &#123; p unsafe.Pointer // *interface&#123;&#125; &#125;type readOnly struct &#123; m map[interface&#123;&#125;]*entry amended bool // true if the dirty map contains some key not in m. &#125; 通过 read 和 dirty 两个字段将读写分离，读的数据存在只读字段 read 上，将最新写入的数据则存在 dirty 字段上 读取时会先查询 read，不存在再查询 dirty，写入时则只写入 dirty 读取 read 并不需要加锁，而读或写 dirty 都需要加锁 另外有 misses 字段来统计 read 被穿透的次数（被穿透只需要读 dirty 的情况），超过一定次数则将 dirty 数据同步到 read 上 对于删除数据则直接通过标记来延迟删除 sync.Map 由两个 map 构成： • read map：访问时全程无锁； • dirty map：是兜底的读写 map，访问时需要加锁. 之所以这样处理，是希望能根据对读、删、更新、写操作频次的探测，来实时动态地调整操作方式，希望在读、更新、删频次较高时，更多地采用 CAS 的方式无锁化地完成操作；在写操作频次较高时，则直接了当地采用加锁操作完成. • sync.Map 适用于读多、更新多、删多、写少的场景； • 倘若写操作过多，sync.Map 基本等价于互斥锁 + map； • sync.Map 可能存在性能抖动问题，主要发生于在读&#x2F;删流程 miss 只读 map 次数过多时（触发 missLocked 流程），下一次插入操作的过程当中（dirtyLocked 流程）. 读流程 • 查看 read map 中是否存在 key-entry 对，若存在，则直接读取 entry 返回； • 倘若第一轮 read map 查询 miss，且 read map 不全，则需要加锁 double check； • 第二轮 read map 查询仍 miss（加锁后），且 read map 不全，则查询 dirty map 兜底； • 查询操作涉及到与 dirty map 的交互，misses 加一； • 解锁，返回查得的结果. • 在读流程中，倘若未命中 read map，且由于 read map 内容存在缺失需要和 dirty map 交互时，会走进 missLocked 流程； • 在 missLocked 流程中，首先 misses 计数器累加 1； • 倘若 miss 次数小于 dirty map 中存在的 key-entry 对数量，直接返回即可； • 倘若 miss 次数大于等于 dirty map 中存在的 key-entry 对数量，则使用 dirty map 覆盖 read map，并将 read map 的 amended flag 置为 false； • 新的 dirty map 置为 nil，misses 计数器清零. 写流程（1）倘若 read map 存在拟写入的 key，且 entry 不为 expunged 状态，说明这次操作属于更新而非插入，直接基于 CAS 操作进行 entry 值的更新，并直接返回（存活态或者软删除，直接覆盖更新）；（2）倘若未命中（1）的分支，则需要加锁 double check；（3）倘若第二轮检查中发现 read map 或者 dirty map 中存在 key-entry 对，则直接将 entry 更新为新值即可（存活态或者软删除，直接覆盖更新）；（4）在第（3）步中，如果发现 read map 中该 key-entry 为 expunged 态，需要在 dirty map 先补齐 key-entry 对，再更新 entry 值（从硬删除中恢复，然后覆盖更新）；（5）倘若 read map 和 dirty map 均不存在，则在 dirty map 中插入新 key-entry 对，并且保证 read map 的 amended flag 为 true.（插入）（6）第（5）步的分支中，倘若发现 dirty map 未初始化，需要前置执行 dirtyLocked 流程；（7）解锁返回. 删流程（1）倘若 read map 中存在 key，则直接基于 cas 操作将其删除；（2）倘若read map 不存在 key，且 read map 有缺失（amended flag 为 true），则加锁 dou check；（3）倘若加锁 double check 时，read map 仍不存在 key 且 read map 有缺失，则从 dirty map 中取元素，并且将 key-entry 对从 dirty map 中物理删除；（4）走入步骤（3），删操作需要和 dirty map 交互，需要走进 3.3 小节介绍的 missLocked 流程；（5）解锁；（6）倘若从 read map 或 dirty map 中获取到了 key 对应的 entry，则走入 entry.delete() 方法逻辑删除 entry；（7）倘若 read map 和 dirty map 中均不存在 key，返回 false 标识删除失败. Contextcontext包定义了Context类型，该类型包含了截止日期、取消信号以及跨API的进程间的其他用户级别范围的变量。 作用一句话：context 用来解决 goroutine 之间退出通知、元数据传递的功能。 传递共享数据、取消goroutine、 Go语言中的context包提供了一种在程序中传递请求范围内的上下文信息的方式。这个上下文信息可以包括请求相关的元数据、取消信号以及其他请求范围内的数据。context 主要用来在 goroutine 之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v 等。 取消 goroutine（ctx怎么通知子节点取消的）Done() 返回一个 channel，&#x3D;&#x3D;标识ctx是否结束&#x3D;&#x3D;，可以表示 context 被取消的信号：当这个 channel 被关闭时，说明 context 被取消了。注意，这是一个只读的channel。 我们又知道，读一个关闭的 channel 会读出相应类型的零值。并且源码里没有地方会向这个 channel 里面塞入值。换句话说，这是一个 receive-only 的 channel。因此在子协程里读这个 channel，除非被关闭，否则读不出来任何东西。也正是利用了这一点，子协程从 channel 里读出了值（零值）后，就可以做一些收尾工作，尽快退出。 1234567891011121314func Perform(ctx context.Context) &#123; for &#123; calculatePos() sendResult() select &#123; case &lt;-ctx.Done(): // 被取消，直接返回 return case &lt;-time.After(time.Second): // block 1 秒钟 &#125; &#125;&#125; 底层12345678910111213type Context interface &#123; // 当 context 被取消或者到了 deadline，返回一个被关闭的 channel Done() &lt;-chan struct&#123;&#125; // 在 channel Done 关闭后，返回 context 取消原因 Err() error // 返回 context 是否会被取消以及自动取消时间（即 deadline） Deadline() (deadline time.Time, ok bool) // 获取 key 对应的 value Value(key interface&#123;&#125;) interface&#123;&#125;&#125; Context 是一个接口，定义了 4 个方法，它们都是幂等的。也就是说连续多次调用同一个方法，得到的结果都是相同的。 Done() 返回一个 channel，&#x3D;&#x3D;标识ctx是否结束&#x3D;&#x3D;，可以表示 context 被取消的信号：当这个 channel 被关闭时，说明 context 被取消了。注意，这是一个只读的channel。 我们又知道，读一个关闭的 channel 会读出相应类型的零值。并且源码里没有地方会向这个 channel 里面塞入值。换句话说，这是一个 receive-only 的 channel。因此在子协程里读这个 channel，除非被关闭，否则读不出来任何东西。也正是利用了这一点，子协程从 channel 里读出了值（零值）后，就可以做一些收尾工作，尽快退出。 Err() 返回一个&#x3D;&#x3D;错误&#x3D;&#x3D;，表示 context 被关闭的原因。例如是被取消，还是超时。 Deadline() 返回 context 的截止时间，&#x3D;&#x3D;过期时间&#x3D;&#x3D;，通过此时间，函数就可以决定是否进行接下来的操作，如果时间太短，就可以不往下做了，否则浪费系统资源。当然，也可以用这个 deadline 来设置一个 I&#x2F;O 操作的超时时间。 Value() 获取之前设置的 key 对应的 value。&#x3D;&#x3D;返回ctx存放的对应key的value&#x3D;&#x3D; context有几种类型WithCancelcontext.WithCancel(parent Context) (ctx Context, cancel CancelFunc)返回派生 context 和取消函数。只有创建它的函数才能调用取消函数来取消此 context。如果您愿意，可以传递取消函数，但是，强烈建议不要这样做。这可能导致取消函数的调用者没有意识到取消 context 的下游影响。 1ctx, cancel := context.WithCancel(context.Background()) WithDeadlinecontext.WithDeadline(parent Context, d time.Time) (ctx Context, cancel CancelFunc)此函数返回其父项的派生 context，当截止日期超过或取消函数被调用时，该 context 将被取消。例如，您可以创建一个将在以后的某个时间自动取消的 context，并在子函数中传递它。当因为截止日期耗尽而取消该 context 时，获此 context 的所有函数都会收到通知去停止运行并返回。 1ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(2 * time.Second)) WithTimeoutcontext.WithTimeout(parent Context, timeout time.Duration) (ctx Context, cancel CancelFunc) 此函数类似于 context.WithDeadline。不同之处在于它将持续时间作为参数输入而不是时间对象。此函数返回派生 context，如果调用取消函数或超出超时持续时间，则会取消该派生 context。 1ctx, cancel := context.WithTimeout(context.Background(), 2 * time.Second) WithValuecontext.WithValue(parent Context, key, val interface&#123;&#125;) (ctx Context, cancel CancelFunc) 此函数接收 context 并返回派生 context，其中值 val 与 key 关联，并通过 context 树与 context 一起传递。这意味着一旦获得带有值的 context，从中派生的任何 context 都会获得此值。 闭包在函数内部引用了函数内部变量的函数 &#x3D;&#x3D;一个函数内引用了外部的局部变量，这种现象，就称之为闭包。&#x3D;&#x3D; 一般来说，一个函数返回另外一个函数，这个被返回的函数可以引用外层函数的局部变量，这形成了一个闭包。通常，闭包通过一个结构体来实现，它存储一个函数和一个关联的上下文环境。但 Go 语言中，匿名函数就是一个闭包，它可以直接引用外部函数的局部变量 在函数外部访问函数内部变量成为可能 函数内部变量离开其作用域后始终保持在内存中而不被销毁 闭包环境中引用的变量是不能够在栈上分配的，而是在堆上分配。因为如果引用的变量在栈上分配，那么该变量会跟随函数f返回之后回收，那么闭包函数就不可能访问未分配的一个变量，即未声明的变量，之所以能够再堆上分配，而不是在栈上分配，是Go的一个语言特性—-escape analyze（能够自动分析出变量的作用范围，是否将变量分配堆上）。 应用场景 数据隔离 defer延迟调用与闭包 中间件在闭包中，除了动态创建函数，还可以通过参数传递的方式，将函数穿进去，实现闭包。典型应用计算函数执行时间 访问到原本访问不到的数据 二分查找，排序时实现排序函数 注意 闭包对自由变量的修改是引用的方式。 闭包中，自由变量的生命周期等同于闭包函数的生命周期，和局部环境的周期无关。","categories":[],"tags":[]},{"title":"Kafka","slug":"Kafka","date":"2024-04-04T07:31:49.000Z","updated":"2024-04-04T07:32:07.000Z","comments":true,"path":"2024/04/04/Kafka/","link":"","permalink":"http://peapod.top/2024/04/04/Kafka/","excerpt":"","text":"kafkaMQMQ(message queue)，从字面意思上看，本质是个队列，FIFO 先入先出，只不过队列中存放的内容是 message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ 是一种非常常 见的上下游「逻辑解耦 + 物理解耦」的消息通信服务。使用了 MQ 之后，消息发送上游只需要依赖 MQ，不用依赖其他服务。 MQ优势 异步处理 - 相比于传统的串行、并行方式，提高了系统吞吐量。 应用解耦 - 系统间通过消息通信，不用关心其他系统的处理。 流量削锋 - 可以通过消息队列长度控制请求量；可以缓解短时间内的高并发请求。 日志处理 - 解决大量日志传输。 消息通讯 - 消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。 解耦、异步、削峰流量消峰 先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。 应用解耦 生产者（客户端）发送消息到消息队列中去，接受者（服务端）处理消息，需要消费的系统直接去消息队列取消息进行消费即可而不需要和其他系统有耦合，这显然也提高了系统的扩展性。 异步 允许用户把一个消息放入队列，但并不立即处理它，然后在需要的时候再去处理它们。将用户的请求数据存储到消息队列之后就立即返回结果。随后，系统再对消息进行消费。使用消息队列进行异步处理之后，需要适当修改业务流程进行配合。 Kafka基础Kafka传统定义：Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 Kafka 最 新 定 义 ： Kafka 是 一 个 开 源 的 分 布 式 事 件 流 平 台 （ Event Streaming Platform），被用于高性能数据管道、流分析、数据集成和关键任务应用。 模型将消息以 topic 为单位进行归纳。 向 Kafka topic 发布消息的程序成为 producers. 将预订 topics 并消费消息的程序成为 consumer. Kafka 以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个 broker. 发布订阅模型（Pub-Sub） 使用主题（Topic） 作为消息通信载体，类似于广播模式；发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息广播之后才订阅的用户则是收不到该条消息的。 Producer（生产者） : 产生消息的一方。 Consumer（消费者） : 消费消息的一方。 Broker（代理） : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。 ack取值1（默认） 数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。 0 生产者将数据发送出去就不管了，不去等待任何返回。 -1producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。 消息接发模式生产者使用push模式将消息发布到Broker，消费者使用pull模式从Broker订阅消息。 Kafka 有个参数可以让 consumer 阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发） Kafka优势 Cache Filesystem Cache PageCache缓存 顺序写：由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。 Zero-copy：零拷技术减少拷贝次数 Batching of Messages：批量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。 Pull 拉模式：使用拉模式进行消息的获取消费，与消费端处理能力相符。 顺序写Kafka 用的是顺序写，追加数据是追加到末尾，磁盘顺序写的性能极高，在磁盘个数一定，转数达到一定的情况下，基本和内存速度一致。 随机写是在文件的某个位置修改数据，性能会较低。 零拷贝Zero Copy使用场景的地方有两处：基于mmap的索引和日志文件读写所用的TransportLayer。 索引都是基于MappedByteBuffer的，也就是让用户态和内核态共享内核态的数据缓冲区，此时，数据不需要复制到用户态空间。 TransportLayer是Kafka传输层的接口。它的某个实现类使用了FileChannel的transferTo方法。该方法底层使用sendfile实现了Zero Copy。对Kafka而言，如果I&#x2F;O通道使用普通的PLAINTEXT，那么，Kafka就可以利用Zero Copy特性，直接将页缓存中的数据发送到网卡的Buffer中，避免中间的多次拷贝。相反，如果I&#x2F;O通道启用了SSL，那么，Kafka便无法利用Zero Copy特性了。 Kafka消费消费顺序主要需要考虑如下两点： 如何保证消息在 Kafka 中顺序性； 如何保证消费者处理消费的顺序性。 使用**Partition(分区) **保证消息的顺序。在订单 topic 中我们可以指定订单 id 作为 key，那么相同订单 id 的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。消费者从 partition 中取出来数据的时候，也一定是有顺序的。通过制定 key 的方式首先可以保证在 kafka 内部消息是有序的。 每次添加消息到 Partition(分区) 的时候都会采用尾加法。 消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。在Kafka中，每个主题分区下的每条消息都被赋予了一个唯一的ID数值，用于标识它在分区中的位置。这个ID数值，就被称为位移，或者叫偏移量。一旦消息被写入到分区日志，它的位移值将不能被修改。 保证消息在 Kafka 中顺序性，两种方法： 1 个 Topic 只对应一个 Partition。 （推荐）发送消息的时候指定 key&#x2F;Partition。 对于多线程消费我们可以预先设置 N 个内存 Queue，具有相同 key 的数据都放到同一个内存 Queue 中；然后开启 N 个线程，每个线程分别消费一个内存 Queue 的数据即可，这样就能保证顺序性。 消息丢失 Consumer消费端消息丢失 手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset，比如消费者刚处理完，还没提交 offset，这时自己宕机了，此时这条消息肯定会被重复消费一次，这就需要消费者根据实际情况保证幂等性。 Producer生产端消息丢失 正确处理返回值或者捕获异常，就可以保证这个阶段消息不会丢失。通过在 producer 端设置 acks&#x3D;-1&#x2F;all 来处理，这个参数是要求 leader 接收到消息后，需要等到所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试。 Broker存储端消息丢失 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本； 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个参数的含义是一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 节点。 在 producer 端设置 acks=all，这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了； 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个参数的含义是一旦写入失败，就无限重试，卡在这里了。 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。生产者和消费者只与 leader 副本交互。 重复消费重复消费的原因： 服务端侧已经消费的数据没有成功提交 offset（根本原因）。 Kafka 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。 解决方案： 消费消息服务做幂等校验，比如 Redis 的 set、MySQL 的主键等天然的幂等功能。这种方法最有效。 将enable.auto.commit参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。 幂等性：多次调用方法或者接口不会改变业务状态，可以保证重复调用的结果和单次调用的结果一致。 消息积压主要原因是，对于绝大多数使用消息队列的业务来说，消息队列本身的处理能力要远大于业务系统的处理能力。 发送端：检查发送端发送消息前业务逻辑耗时。 消费端：保证消费端的消费性能要高于生产端的发送性能。增加消费端的并发数，在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。原因因为对于消费者来说，在每个分区上实际上只能支持单线程消费。 处理方法： 如果是单位时间发送的消息增多，短时间内不太可能优化消费端的代码来提升消费性能，唯一的方法是通过扩容消费端的实例数来提升总体的消费能力。 将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。 消费失败导致的一条消息反复消费，这种情况也会拖慢整个系统的消费速度。 不支持读写分离在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从而实现的是一种主写主读的生产消费模型。 主写从读有 2 个很明显的缺点: 数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间窗口会导致主从节点之间的数据不一致。 延时问题。数据从写入主节点到同步至从节点中的过程需要经历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，它需要经历网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。","categories":[],"tags":[]},{"title":"Mysql","slug":"Mysql","date":"2024-04-04T07:31:01.000Z","updated":"2024-04-04T07:31:25.000Z","comments":true,"path":"2024/04/04/Mysql/","link":"","permalink":"http://peapod.top/2024/04/04/Mysql/","excerpt":"","text":"mysql三大范式数据库在表设计的方法论，为了尽可能的降低表之间的耦合度，提高表的可读性。 第一范式(**确保每列保持原子性)**：强调的是列的原子性，即数据库表的每一列都是不可分割的原子数据项。&#x3D;&#x3D;数据库表中的任何字段都是单一属性的，不可再分&#x3D;&#x3D;。&#x3D;&#x3D;单表（字段）拆分到不可拆分为止&#x3D;&#x3D; 第二范式(**确保表中的每列都和主键相关)**：要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性。&#x3D;&#x3D;每一行数据唯一性&#x3D;&#x3D;，比如地址重复就在写一个地址表，也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。 第三范式(**确保每列都和主键列直接相关,而不是间接相关)**：任何非主属性不依赖于其它非主属性。&#x3D;&#x3D;表和表之间关联主键依赖&#x3D;&#x3D; 鲍依斯-科得范式（BCNF）：在3NF的基础上，库表中任何字段对任一候选关键字段的传递函数依赖都不存在。 3NF很简单就是2NF之上再消除传递函数依赖 DDL和DML的区别DDL（Data Definition Languages）：数据定义语言，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象的定义。常用的语句关键字主要包括 create、drop、alter等。 DML（Data Manipulation Language）：数据操纵语句，用于添加、删除、更新和查询数据库记录，并检查数据完整性，常用的语句关键字主要包括 insert、delete、udpate 和select 等。(增添改查） DCL（Data Control Language）：数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的语句关键字包括 grant、revoke 等。 DDL 是数据定义语言的缩写，简单来说，就是对数据库内部的对象进行创建、删除、修改的操作语言。它和 DML 语言的最大区别是 DML 只是对表内部数据的操作，而不涉及到表的定义、结构的修改，更不会涉及到其他对象。DDL 语句更多的被数据库管理员（DBA）所使用，一般开发人员很少使用。 非关系型数据库和关系型数据库的区别，谈谈优势比较？关系型数据库MySql，Oracle 关系型数据库指的是使用关系模型（二维表格模型）来组织数据的数据库。关系型数据库是基于表格的结构，使用 SQL 语言进行查询和操作，适用于处理结构化数据。 优势 采用二维表结构非常贴近正常开发逻辑（关系型数据模型相对层次型数据模型和网状型数据模型等其他模型来说更容易理解）； 支持通用的SQL（结构化查询语言）语句； 丰富的完整性大大减少了数据冗余和数据不一致的问题。并且全部由表结构组成，文件格式一致； 可以用SQL句子多个表之间做非常繁杂的查询； 关系型数据库提供对事务的支持，能保证系统中事务的正确执行，同时提供事务的恢复、回滚、并发控制和死锁问题的解决。 数据存储在磁盘中，安全可靠。 不足： 高并发读写能力差：网站类用户的并发性访问非常高，而一台数据库的最大连接数有限，且硬盘 I&#x2F;O 有限，不能满足很多人同时连接。 海量数据情况下读写效率低：对大数据量的表进行读写操作时，需要等待较长的时间等待响应。 可扩展性不足：不像web server和app server那样简单的添加硬件和服务节点来拓展性能和负荷工作能力。 数据模型灵活度低：关系型数据库的数据模型定义严格，无法快速容纳新的数据类型（需要提前知道需要存储什么样类型的数据）。 非关系型数据库Redis、Memcached、MongoDB 非关系型数据库则是以键值对、文档、图形等形式存储数据，不需要预定义表格结构，适用于处理半结构化和非结构化数据。非关系型数据库的优势在于具有更高的可扩展性、更好的性能和更灵活的数据模型，但相对于关系型数据库，缺乏事务支持和复杂查询能力。 优势： 非关系型数据库存储数据的格式可以是 key-value 形式、文档形式、图片形式等。使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。 速度快，效率高。 NoSQL 可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘。 海量数据的维护和处理非常轻松，成本低。 非关系型数据库具有扩展简单、高并发、高稳定性、成本低廉的优势。 可以实现数据的分布式处理。 不足: 非关系型数据库暂时不提供 SQL 支持，学习和使用成本较高。 非关系数据库没有事务处理，无法保证数据的完整性和安全性。适合处理海量数据，但是不一定安全。 功能没有关系型数据库完善。 复杂表关联查询不容易实现。 基础Limitlimit x, y 两个参数是什么 x ：offset：指定第一个返回记录行的偏移量（即从哪一行开始返回），注意：初始行的偏移量为0。y : rows：返回具体行数。 在查询中，经常要返回前几条或者中间某几行数据时，用到limit 客户端通过传递start(页码)，pageSize(每页显示的条数)两个参数去分页查询数据库表中的数据，那我们知道MySql数据库提供了分页的函数limit m,n，但是该函数的用法和我们的需求不一样，所以就需要我们根据实际情况去改写适合我们自己的分页语句 12# start是页码，pageSize是每页显示的条数。select * from table limit (start-1)*pageSize,pageSize; 左连接和内连接 char 和 varchar的区别CHAR类型： &#x3D;&#x3D;固定长度&#x3D;&#x3D; CHAR(M) 类型一般需要预先定义字符串长度。如果不指定(M)，则表示长度默认是1个字符。 如果保存时，数据的实际长度比CHAR类型声明的长度小，则会在右侧填充空格以达到指定的长度。当MySQL检索CHAR类型的数据时，CHAR类型的字段会去除尾部的空格。 定义CHAR类型字段时，声明的字段长度即为CHAR类型字段所占的存储空间的字节数。 VARCHAR类型： &#x3D;&#x3D;可变长度&#x3D;&#x3D; VARCHAR(M) 定义时，必须指定长度M，否则报错。 MySQL4.0版本以下，varchar(20)：指的是20字节，如果存放UTF8汉字时，只能存6个（每个汉字3字 节） ；MySQL5.0版本以上，varchar(20)：指的是20字符。 检索VARCHAR类型的字段数据时，会保留数据尾部的空格。VARCHAR类型的字段所占用的存储空间为字符串实际长度加1个字节。 int(1)和int(10)的区别int(M) M : 表示显示宽度，M的取值范围是(0, 255)。例如，int(5)：当数据宽度小于5位的时候在数字前面需要用 字符填满宽度。该项功能需要配合ZEROFILL使用，表示用“0”填满宽度，否则指定显示宽度无效。 如果设置了显示宽度，那么插入的数据宽度超过显示宽度限制，会不会截断或插入失败？ 如果整 数值超过M位，就按照实际位数存储。只是无须再用字符 0 进行填充。 int(1)和int(11)在实际使用中，如果不使用 zerofill 是没有任何区别的，而且int型最大只能存储4294967295这个整数，也就是只有10位。 备份sql指令：备份select * from tb into outfile ‘&#x2F;tmp.txt’导入load data infile ‘&#x2F;tmp.txt’ into table tb; 索引，B+树讲讲索引索引是一种特殊的数据结构，通过建立索引可以加快数据搜索速度，它就像书的目录一样，MySQL默认使用innodb作为存储引擎，它的底层索引结果是B+树，查询效率是非常高的，但是不一定创建索引就是非常好的，索引的创建本身是非常消耗资源的，在数据量比较大的时候创建索引需要花费大量时间，而且索引本身是非常占用内存空间的；在后期新增数据的时候可能需要进行数据的移动，后期维护也是需要大量时间的；当数据量比较小的时候没有必要建立索引，MySQL底层在判断索引和整表查询时间差不多的时候是不会使用索引的；有时候建立索引过多或者建立不当可能起到相反的作用 关于优化器的逻辑，使用何种索引的判断标准有三点：（1） 扫描行数，并兼顾回表代价，（2）是否需要排序，（3）是否需要使用临时表 为什么要控制各个字段大小？控制单行数据大小表设计，严格控制字段的大小，B+树的高出扇性 假设主键是bigint（自增，或者snowflake生成），占8个字节 假设id为1，存储为80000001(256)，id为3，存储为80000003(256) 存储器每页16KB16KB &#x2F; (8B + 6B) &#x3D; 1170.29，以1100计算第一层，指向1100二层节点第二层，指向1100^2 三层节点，10^6，1百万第三层：假设一行数据占16KB，则存储1百万数据（16KB&#x2F;16KB * 1百万）；假设一行数据占1KB，则存储一千六百万数据（16KB&#x2F;1KB\\ * 1百万）；因此需要严格控制存储字段大小 每次加载16KB内存页，二分查找索引，Olog(N)，再找下一层，共三次I&#x2F;O索引 MySQL底层数据结构为什么采用B+树？为什么不用B树，二叉树，哈希表？ B 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。非叶子节点存放的是索引键值和页指针 B 树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。 B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。 B+树可以在内存有限的情况下存储更多的节点。B+树的内部节点不保存数据，只保存索引，而且内部节点的大小通常要比数据节点小得多，因此可以在内存中缓存更多的节点。B树非叶子节点和叶子节点都会存储数据和索引，这样导致一页中存储的键值减少，指针跟着减少，要保存大量数据只能增加树的高度，导致性能降低。假设参数规格不变，存储一半数据，一半索引，第三层550 + 550 ^ 2 + 550 ^2 * 16&#x3D; 480万，大概是B+树的1&#x2F;4；二叉树存储相同的节点树的深度更高，则需要更多的I&#x2F;O读取次数 哈希表，在没有冲突的情况下，时间复杂度为O(1)，桶位转换为链表&#x2F;红黑树，时间复杂度为O(logN)，比B+树快，但： **不支持模糊匹配%**，无法使用LIKE”%”，由于哈希计算没有局部特性，例如hash(皮卡丘)跟hash(皮卡)没有关系 不支持范围匹配， 不支持排序，没有顺序性，例如查询1~100，采用B+树查到1，再后遍历，直到大于100则结束，而且数据一般在连续内存页中 哈希冲突问题 不支持联合索引（最左匹配原则） 为什么B+树可以加快查询速度InnoDB中B+索引能提高查询速度的原因其实就是通过引进B+树的结构将页的定位过程进行了优化。因为索引使用了B+树数据结构来存储，利用二分查询的原理O(logN)，有效的减少了磁盘IO的次数，所以查询会变快 B+树的数据节点形成有序链表，方便范围查找和排序。B+树的数据节点之间是通过指针形成有序链表的，因此可以很方便地进行范围查找和排序，比如查询一个范围内的记录或者按照关键字排序。B树虽然也可以进行范围查找和排序，但是需要进行中序遍历，效率较低。B+树可以更好地利用磁盘预读。磁盘I&#x2F;O是非常耗时的操作，为了提高查询效率，需要尽量减少磁盘I&#x2F;O的次数。B+树的数据节点形成有序链表，因此可以很好地利用磁盘的预读特性，将多个相邻的数据块一次性读入缓存，减少磁盘I&#x2F;O的次数。 B+树的非叶子节点为什么是双向链表在MySQL中，B+树的非叶子节点被实现为一个双向链表，是为了加速索引的查找和维护。B+树是一种多叉树结构，每个节点中存储了多个关键字，它的节点分为两种类型：内部节点和叶子节点。内部节点存储了关键字的范围以及指向下一层子节点的指针，而叶子节点则存储了关键字以及指向数据记录的指针。 在MySQL中，B+树的双向链表设计使得节点间的访问更加高效。由于B+树的内部节点和叶子节点都可能会在查找的过程中被访问到，因此需要在内部节点和叶子节点之间建立连接，使得它们能够快速地互相查找。双向链表可以实现节点之间的双向遍历，因此可以在查找时快速定位到目标节点。 另外，MySQL的B+树中还有一个特殊的头节点和尾节点，它们分别指向B+树的第一个节点和最后一个节点，可以方便地进行范围查找和遍历操作。由于双向链表具有前驱和后继指针，因此可以通过头节点和尾节点进行快速的查找操作，这也是B+树采用双向链表的一个重要原因。 如何查看索引是否生效？如果需要查看索引是否生效，可以使用MySQL提供的 EXPLAIN 命令来查看查询计划。在查询语句前加上 EXPLAIN 关键字，即可查看查询计划的详细信息。在查询计划中，可以查看到MySQL优化器选择的执行计划、使用的索引以及索引的类型等信息。如果查询计划中显示使用了合适的索引，则说明索引生效；否则，就需要考虑优化查询语句或索引的设计。 最左前缀原则最左前缀原则是指在使用联合索引进行查询时，如果查询语句中使用了联合索引的一部分列，那么联合索引可以被用于优化查询。这个原则也可以称为“最左匹配原则”。最左前缀原则是指在数据库中创建联合索引时，索引可以覆盖查询语句中最左侧的前缀字段。也就是说，在联合索引中，如果查询语句只涉及到索引最左侧的若干个字段，则该查询语句可以使用该联合索引进行优化 面试中常被提到的最左前缀匹配原则 - 知乎 (zhihu.com)为什么可以模糊查询？在mysql建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配， 最左前缀匹配原则，非常重要的原则，建立一个索引，对于索引中的字段，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，&#x3D;&#x3D;a,b,d的顺序可以任意调整&#x3D;&#x3D;。&#x3D;和in可以乱序，比如a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 索引分类 主键索引 唯一索引（允许空值NULL，主键索引不允许） 普通索引 全文索引 联合索引（最左前缀原则） 根据物理存储的形式聚簇索引，每张表&#x3D;&#x3D;只有一个&#x3D;&#x3D;聚簇索引B+树，以primary key构建，非叶子节点存储主键（主键类型大小，bigint为8字节）和下级索引（6个字节），叶子节点存储整行数据。&#x3D;&#x3D;聚簇索引的叶节点存放表的的行记录数据。&#x3D;&#x3D;非聚簇索引也称辅助索引、二级索引，也是B+树，每张表可以有多个辅助索引，非叶子节点存储主键和索引，叶子节点存储主键和索引辅助属性（存储主键，用于回表查询）。&#x3D;&#x3D;而非聚簇索引叶节点存的是指针，指向对应的数据块。&#x3D;&#x3D; 聚簇索引的优点： 通过聚簇索引查找目标数据时理论上比非聚簇索引要快。因为聚簇索引能够在B+树索引的叶子节点上直接找到数据。而非聚簇索引查找目标数据需要多一次索引查询。 此外，由于定义了数据的逻辑顺序，聚簇索引能够特别快地访问一定范围内的数据。 聚簇索引的存储并不是物理上的连续，而是逻辑上的连续。数据页之间通过双向链表链接，按照主键的顺序排序。而数据页内的记录是通过单向链表进行维护的，物理存储上可以同样不按照主键的顺序存储。 如何定义索引？ 经常被用作查询条件的列。 参与表的连接的列。 用于排序和分组的列。 用于唯一性约束的列。 经常用于子查询的列。 尽量扩展索引，不要新建索引 需要看字段内容的随机性，随机度越高作为索引的效率越高。看离散度可以用show index，如果cardinality（随更新表实时变化）越接近1（离散度越高）越适合做索引，同时要结合实际开发的业务需求。 why？这个就要从索引的数据结构 B+TREE 来说了。如果索引列没有重复的值，那在索引树搜索的时候查询到目标之后不会再进行搜索。如果有大量相同值，那么很多叶子节点磁盘块里面都是相同值，那么在搜索到目标之后还需要继续搜索（继续查询其他磁盘块，进行 IO 操作） 唯一标识符：通常建立在主键上，以确保表中每个记录都具有唯一的标识符。例如，可以在 ID 列上建立唯一索引。 外键关联：在连接两个表时，应在外键列上建立索引，以便快速查找连接的行。 经常查询的列：如果某个列是经常被用作查询条件的列，应该在该列上建立索引，以加快查询速度。例如，在一个产品表中，经常按照产品名称查询，可以在产品名称列上建立索引。 排序和分组的列：如果某个列经常用于排序和分组操作，应该在该列上建立索引，以加快这些操作的速度。例如，在一个订单表中，经常按照下单时间排序，可以在下单时间列上建立索引。 经常用于子查询的列：如果某个列经常用于子查询操作，应该在该列上建立索引，以加快子查询的速度。 什么时候适用索引？ 字段有唯一性限制的，比如商品编码； 经常用于 WHERE 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。 经常用于 GROUP BY 和 ORDER BY 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。 什么时候不需要创建索引？ WHERE 条件，GROUP BY，ORDER BY 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。 字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。 表数据太少的时候，不需要创建索引； 经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。 为什么不每个字段都建立索引？哒咩，索引是一颗逻辑上的 B+TREE，需要维护，当对表中的数据进行增删改的时候，索引树也要动态维护（变化）。这样会降低数据增删改的速度，所以索引不能无脑建。建立索引可能会增加数据的存储空间，并且在插入、更新和删除操作时会有一定的开销。因此，在建立索引时，需要权衡查询速度和数据操作的开销。建议在需要优化查询性能的场景下，选择具有较高查询频率的列建立索引，同时避免过度使用索引，以避免影响数据操作的性能。 在哪些场景下索引会变得越来越慢 SELECT *，索引没有覆盖； InnoDB默认secondary找到primary，你这样很可能最后全部是随机IO； 当返回的结果较多时，非聚集索引效率可能比全表扫描还要低。因为非聚集索引必定会引发mark lookup操作。性能优化不可能做到每个字段的查询都能优化到最快，必须根据访问模式有针对的优化 单表可以建立多少索引？索引一般不明显影响插入性能（大量小数据例外），因为建立索引的时间开销是O(1)或者O(logN) 官方文档InnoDB Limits ：1个表最大只能创建64个2级索引，加上主键索引共65个。复合索引最多只能16列，超过就会报错。 索引失效 like未使用最左前缀，where A like “%China”，即以&#x3D;&#x3D;%开头会索引失效&#x3D;&#x3D; or会使索引失效，当&#x3D;&#x3D;or两端其中一个条件没有使用索引&#x3D;&#x3D;。如果查询字段相同，也可以使用索引。例如 where A &#x3D; a1 or A &#x3D; a2（生效），where A&#x3D;a or B &#x3D; b （失效） 联合查询未使用最左前缀，例如联合索引（A，B），例如：where A &#x3D; a and B &#x3D; b 会使用索引，where B &#x3D; b 不会使用索引。即&#x3D;&#x3D;当创建联合索引中where没有从联合索引的首个索引开始时&#x3D;&#x3D;索引失效 +-*&#x2F;运算，当&#x3D;&#x3D;索引字段被运算时&#x3D;&#x3D;索引失效 在索引列上的操作，or、!&#x3D; （&lt;&gt;）,not in，is not 等，即&#x3D;&#x3D;取非结果集&#x3D;&#x3D; is null、is not null；&#x3D;&#x3D;索引本身不对null值的数据做处理&#x3D;&#x3D;。理论上不要让字段为null，处理方法：字段强制不为null、字段默认值 使用&#x3D;&#x3D;内置函数&#x3D;&#x3D;upper()等，以及例如：使用索引时，数字和string&#x3D;&#x3D;类型不统一&#x3D;&#x3D;，varchar &#x3D; 12345没有加引号，内部实际使用了convert函数导致失效。 版本：不同版本 1SELECT * FROM tb WHERE a &gt; 3; // a 辅助索引 MySQL&lt;5.6：走全表扫描，不使用索引 **离散读**：a &gt; 3 4 5 6 7 8 随机查 5 7 4 8 3, 5 * 3 次ioMySQL&gt;&#x3D;5.6 ：走索引 搜索一个索引而在另一个索引上做 order by， where A &#x3D; a order by B，只会使用A上的索引，因为查询只使用一个索引。 like索引失效的原因 %号在右:由于B+树的索引顺序，是&#x3D;&#x3D;按照首字母的大小进行排序&#x3D;&#x3D;，%号在右的匹配又是匹配首字母。所以可以在B+树上进行有序的查找，查找首字母符合要求的数据。 %号在左:是匹配字符串尾部的数据，我们上面说了排序规则，尾部的字母是没有顺序的，所以不能按照索引顺序查询，就用不到索引. 两个%号:这个是查询任意位置的字母满足条件即可，只有首字母是进行索引排序的，其他位置的字母都是相对无序的，所以查找任意位置的字母是用不上索引的. 回表，如何避免回表？通俗的讲就是，如果索引的列在 select 所需获得的列中（因为在 mysql 中索引是根据索引列的值进行排序的，所以索引节点中存在该列中的部分值）或者根据一次索引查询就能获得记录就不需要回表，如果 select 所需获得列中有大量的非索引列，索引就需要到表中找到相应的列的信息，这就叫回表。 这就是所谓的回表查询，&#x3D;&#x3D;先定位主键值，再定位行记录，它的性能较扫一遍索引树更低。&#x3D;&#x3D; 避免回表：实现索引覆盖覆盖索引，&#x3D;&#x3D;不是索引，是一种效果&#x3D;&#x3D;。覆盖索引是select的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖 常见的方法是：&#x3D;&#x3D;将被查询的字段，建立到联合索引里去。&#x3D;&#x3D; 覆盖索引就是&#x3D;&#x3D;select的数据列只用从索引中就能够取得，不必从数据表中读取&#x3D;&#x3D;，换句话说查询列要被所使用的索引覆盖。避免回表的产生从而减少IO，提升性能 123# id 主键索引， age 普通索引select * from user where age = 3; # 产生回表select id from user where age = 3; # 直接再age索引中取到id 索引下推服务层把查询工作下推到引擎层去处理。是 MySQL 5.6 版本中提供的一项索引优化功能，可以在非聚簇索引遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表次数。 效果：减少回表查询次数，提高查询效率，节约IO开销。 1234# id 主键索引， （name，age）联合索引select id from user where name = &quot;张%&quot; and age = 3; # 5.6之前只会用到name索引，回表查询多次每个张%# 5.6之后，通过索引下推，也会对age进行索引查询，只有一次回表 可用用explain语句查看是否使用了索引下推，explain的Extra列值为Using index condition 合并索引 index merge通过索引合并机制，可以实现针对单表的一次查询中利用多个索引，好处是减少了回表查询的消耗。 一个表的多个索引的范围扫描可以对结果进行合并，合并方式分为三种：intersection，union , Sort-Union。 Index Merge Intersection 索引合并-取交集 采用多索引AND等值查询。 Index Merge Union 索引合并-取并集 采用多索引OR等值查询。 Index Merge Sort-Union 索引合并-取有序并集 当 WHERE 子句转换为 OR 组合的多个范围条件时，可以采用排序联合算法Sort-Union。但 Index Merge 联合算法不适用。排序联合算法Sort-Union和联合算法Union的区别在于，排序联合算法必须首先获取所有行的行 id，并在返回任何行之前对它们进行排序。 MRR多范围读取MRR，全称「Multi-Range Read Optimization」。我们知道二级索引是有回表的过程的，由于二级索引上引用的主键值不一定是有序的，因此就有可能造成大量的随机 IO，如果回表前把主键值给它排一下序，那么在回表的时候就可以用顺序 IO 取代原本的随机 IO。简单说：MRR 通过把「随机磁盘读」，转化为「顺序磁盘读」，从而提高了索引查询的性能。 顺序读带来了几个好处： 1、磁盘和磁头不再需要来回做机械运动；2、可以充分利用磁盘预读 比如在客户端请求一页的数据时，可以把后面几页的数据也一起返回，放到数据缓冲池中，这样如果下次刚好需要下一页的数据，就不再需要到磁盘读取。这样做的理论依据是计算机科学中著名的局部性原理–当一个数据被用到时，其附近的数据也通常会马上被使用。 主键索引和普通索引的区别主键索引是一种特殊的唯一索引，它要求被索引的列不允许有空值（NULL），并且每张表只能存在一个主键索引。主键索引的作用是保证表中每一行数据的唯一性，主键索引还能够优化表的查询性能。 普通索引是指对表中的某个列或多个列建立索引，它与主键索引的区别在于索引的字段不必是唯一的，而且可以有多个普通索引。普通索引的作用是加快查询速度，优化 SELECT 语句的执行效率。 主键索引也被称为聚簇索引,&#x3D;&#x3D;叶子节点存放的是整行数据&#x3D;&#x3D;; 而非主键索引被称为二级索引,&#x3D;&#x3D;叶子节点存放的是主键的值&#x3D;&#x3D;.如果根据主键查询, 只需要搜索ID这颗B+树而如果通过非主键索引查询, 需要先搜索k索引树, 找到对应的主键, 然后再到ID索引树搜索一次, 这个过程叫做回表.总结, 非主键索引的查询需要多扫描一颗索引树, 效率相对更低. 单索引与联合索引在存储在存储上的区别对于联合索引来说只不过比单值索引多了几列，而这些索引列全都出现在索引树上。 对于联合索引，存储引擎会首先根据第一个索引列排序，如果第一列相等则再根据第二列排序。这就是为什么要满足最左前缀的原因。 order by索引当order by 字段出现在where条件中时，才会利用索引而无需排序操作。其他情况，order by不会出现排序操作。 Order By处理数据（排序）看第一部执行计划是不是用到索引，如果用到了就可以直接获得索引的顺序，从而避免再次排序。如果没用到就做排序（using filessort）。 搜索一个索引而在另一个索引上做 order by， where A &#x3D; a order by B，只会使用A上的索引，因为查询只使用一个索引。 关于优化器的逻辑，使用何种索引的判断标准有三点：（1） 扫描行数，并兼顾回表代价，（2）是否需要排序，（3）是否需要使用临时表 前缀索引索引的长度限制MySQL 官方手册索引的章节提到了，前缀索引长度限制是和引擎相关的，如果用的是 InnoDB ，前缀上限是 767 字节，当启用 innodb_large_prefix 时，上限可以达到 3072 字节。如果用的是 MyISAM，前缀上限是 1000 字节 我们知道，MySQL 和 Oracle 在索引上最大的一个区别，就是索引存在长度的限制。&#x3D;&#x3D;如果是超长键值，可以支持创建前缀的索引，顾名思义，取这个字段的前多少个字符&#x2F;字节作为索引的键值。&#x3D;&#x3D; 之所以可以定义一个字段前缀作为键值，存储效率是考虑的一个因素，如果列名的前10个字符通常都是不同的，检索这10个字符创建的索引应该会比检索整个列作为索引的效率更高，使用列前缀作为索引会让索引树更小，不仅节省空间，还可能提高插入操作的速度。 前缀索引MySQL前缀索引是一种索引技术，它允许在索引列上只使用列值的前缀部分来创建索引，而不是使用整个列值。这可以在某些情况下提供性能优势，特别是当索引列的数据量很大或者列的数据类型较长时。 &#x3D;&#x3D;当索引是很长的字符序列（比如BLOB,TEXT,或者很长的VARCHAR）时，这个索引将会很占内存，而且会很慢，这时候就会用到前缀索引了。&#x3D;&#x3D;所谓的前缀索引就是去索引的前面几个字母作为索引，但是要降低索引的重复率，索引我们还必须要判断前缀索引的重复率 以下是关于MySQL前缀索引的一些重要信息： 创建前缀索引：在创建索引时，可以通过指定索引长度来创建前缀索引。例如，可以使用以下语法创建一个前缀长度为10的索引： 1CREATE INDEX index_name ON table_name (column_name(10)); 这将在索引列的前10个字符上创建一个前缀索引。 索引选择性：前缀索引的选择性通常比完整列索引要低，因为它只考虑了列值的一部分。选择性是指索引中不同值的数量与总行数的比率。较低的选择性可能导致查询优化器选择不使用索引，而是执行全表扫描。 索引覆盖：前缀索引可以在某些情况下作为覆盖索引使用。当查询只需要索引列的前缀部分时，可以使用前缀索引来满足查询需求，而无需回到原始数据行。这可以提高查询性能，减少磁盘I&#x2F;O。 索引长度选择：选择适当的前缀长度是使用前缀索引的关键。较小的前缀长度可以提高索引的选择性，但可能会导致索引范围较大，从而增加了索引的大小和存储需求。较大的前缀长度可以减小索引的大小，但可能会降低索引的选择性，导致性能下降。 查询限制：使用前缀索引时，需要注意查询中对索引列的条件限制。查询条件必须与索引的前缀匹配，否则索引将无法使用。如果查询需要使用索引列的后缀部分进行匹配，前缀索引将无法满足查询需求。 前缀索引在某些情况下可以提供性能优势，特别是在大型列或长文本列上。然而，它也存在一些限制和缺点，需要根据具体情况进行权衡和选择。在设计和使用前缀索引时，需要考虑数据的唯一性、查询模式、索引长度的选择以及与其他索引的比较等因素，以获得最佳的性能和存储效率。 mysql一次搜索的过程 客户端通过 TCP 连接发送连接请求到 MySQL 连接器，连接器会对该请求进行权限验证及连接资源分配 查缓存。（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。）&#x3D;&#x3D;8.0后缓存特性删除了&#x3D;&#x3D;。 语法分析（SQL 语法是否写错了）。 如何把语句给到预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义。 优化。是否使用索引，生成执行计划。 交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。 更新语句执行会复杂一点。需要检查表是否有排它锁，写 binlog，刷盘，是否执行 commit。 MVCC一句话总结： &#x3D;&#x3D;MVCC是mysql基于自己的回滚机制为并发场景下的读操作做的读取的优化。&#x3D;&#x3D; 1.MVCC概念：MVCC全称Multi-Version Concurrency Control,即多版本并发控制。MVCC是为MySQL并发场景下无锁生成读视图进行读操作来进行多版本控制。 2.MVCC实现依赖undo log 3.不同隔离级别下MVCC表现“读未提交”隔离级别：直接返回记录上的最新值，没有视图概念。“读已提交”隔离级别下，视图是在每次SELECT时生成的。（违背了事务ACID里的隔离性）“可重复读（默认）”隔离级别下：视图是在第一次SELECT时创建的，事务读取期间的SELECT都用这个视图。（此隔离级别下需要利用间隙锁来解决幻读问题）“串行化”隔离级别下：直接用加锁的方式来避免并行访问，没有视图概念。 隐藏字段在内部，InnoDB 存储引擎为每行数据添加了三个 隐藏字段： DB_TRX_ID（6字节）：表示最后一次插入或更新该行的事务 id。此外，delete 操作在内部被视为更新，只不过会在记录头 Record header 中的 deleted_flag 字段将其标记为已删除 DB_ROLL_PTR（7字节） 回滚指针，指向该行的 undo log 。如果该行未被更新，则为空 DB_ROW_ID（6字节）：如果没有设置主键且该表没有唯一非空索引时，InnoDB 会使用该 id 来生成聚簇索引 Read ViewRead View 主要是用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务” 主要有以下字段： m_low_limit_id：目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见 m_up_limit_id：活跃事务列表 m_ids 中最小的事务 ID，如果 m_ids 为空，则 m_up_limit_id 为 m_low_limit_id。小于这个 ID 的数据版本均可见 m_ids：Read View 创建时其他未提交的活跃事务 ID 列表。创建 Read View时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。m_ids 不包括当前事务自己和已提交的事务（正在内存中） m_creator_trx_id：创建该 Read View 的事务 ID undo logundo log 主要有两个作用： 当事务回滚时用于将数据恢复到修改前的样子 另一个作用是 MVCC ，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 undo log 读取之前的版本数据，以此实现非锁定读 数据可见性算法在 InnoDB 存储引擎中，创建一个新事务后，执行每个 select 语句前，都会创建一个快照（Read View），快照中保存了当前数据库系统中正处于活跃（没有 commit）的事务的 ID 号。其实简单的说保存的是系统中当前不应该被本事务看到的其他事务 ID 列表（即 m_ids）。当用户在这个事务中要读取某个记录行的时候，InnoDB 会将该记录行的 DB_TRX_ID 与 Read View 中的一些变量及当前事务 ID 进行比较，判断是否满足可见性条件 使用我们在使用MVCC的时候，一般是根据业务场景搭配使用MVCC和乐观锁悲观锁，通过MVCC来解决读写冲突，乐观锁或悲观锁用于解决写写冲突，从而最大程度的去提高数据库的并发性能。 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，从而提高数据库的并发读写的处理能力。 能实现读一致性，从而解决脏读、幻读、不可重复读等事务隔离问题，但是不能解决数据更新丢失的问题。 采用乐观锁或者悲观锁用来解决写和写的冲突，从而最大程度地去提高数据库的并发性能。 举例：假设ABC三个线程，读写同一条数据 C开启事务，然后睡觉A同时开启事务，修改提交 后B开启事务，修改提交 C醒来，读取，读到的是那条数据？ 此时MVCC一共有3个快照版本，A修改前，B修改前，B修改后 “可重复读（默认）”：读取到A修改前创建的快照，即最原始的数据 “读已提交”：读取到B修改后提交的版本，即最新的版本（违背了事务ACID里的I隔离性） “读未提交”：即时读取，MVCC几乎不起作用，会脏读 “串行化”：读写都会锁定，因此不需要MVCC，没有并发访问，所有情况都能避免，但&#x3D;&#x3D;速度慢、性能差&#x3D;&#x3D; 脏读&#x3D;&#x3D;现在我们几乎碰不到脏读的情况，除非将Mysql的事务隔离级别定义为“读未提交”&#x3D;&#x3D;，才会出现：当一个事务正在访问数据，并且对数据进行了修改，而这种数据还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据还没有提交那么另外一个事务读取到的这个数据我们称之为脏数据。 不可重复读读取同一条数据，第一次读取和第二次读取内容不一样对于两个事务Session A、Session B，Session A 读取 了一个字段，然后 Session B 更新 了该字段。 之后Session A 再次读取 同一个字段， 值就不同 了。那就意味着发生了不可重复读。 幻读第一次读取和第二次读取读取的结果数量不一样，插入了数据，变多了。对于两个事务Session A、Session B, Session A 从一个表中 读取 了一个字段, 然后 Session B 在该表中 插入 了一些新的行。 之后, 如果 Session A 再次读取 同一个表, 就会多出几行。那就意味着发生了幻读。 脏写（ Dirty Write ）对于两个事务 Session A、Session B，如果事务Session A修改了另一个未提交事务Session B修改过的数据，那就意味着发生了脏写 [[锁]]讲一下MySql的锁首先如果按照锁的粒度来分类有：行级锁，表级锁和页级锁。行锁是mysql中锁定粒度最低的锁，表示只针对当前操作的行进行加锁。因此对于并发冲突最少，但加锁的开销也最大，行级锁分为共享锁和排他锁也就是读锁和写锁。表锁是锁定粒度最大的锁，表示对当前操作的整张表进行加锁，它速度快但是造成的冲突多，并发度最低。页级锁是mysql中粒度介于行锁和表锁之间的锁，因为表级锁速度快，但冲突多，行级冲突少，但速度慢，所以有了页锁一次锁定相邻的一组记录。 按锁级别的分类有：共享锁、排他锁和意向锁。共享锁又称读锁，针对一份数据多个事务可以并发的去读取数据，但不能修改数据。如果数据已经有共享锁则其他事务只能再加共享锁不能加排他锁。排他锁又称写锁、独占锁，如果事务A对数据加排他锁后，其他事务不能对该数据加任何类型的锁。只有获得排他锁的事务可以对该数据进行读写操作。意向锁是表级锁，它的目的是为了在一个事务中揭示下一行要被请求锁的类型。意向锁分为意向共享锁（IS）、意向排他锁（IX）。意向锁是InnoDB自动添加的不需要用户去干预，对于insert、update、delete会自动给涉及的数据添加排他锁意向共享锁，表示事务准备给数据行加入共享锁，也就是事务想要给一个数据行添加共享锁时必须先取得该表的意向共享锁。意向排他锁，表示事务准备给数据行加入排他锁，也就是事务想要给一个数据行添加排他锁时必须先取得该表的意向排他锁。 InnoDB存储引擎实现了如下两种标准的行级锁： 共享锁（S Lock），允许事务读一行数据。 排他锁（X Lock），允许事务删除或更新一行数据。 12select ... for update;select ... lock in share mode; update是行锁还是表锁最后要看优化器选择走索引还是全表扫描 InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁。 从数据操作的粒度划分：表级锁、页级锁、行锁他们的加锁开销从大到小，并发能力也是从大到小。 在关系型数据库中，可以按照锁的粒度把数据库锁分为行级锁(INNODB引擎)、表级锁(MYISAM引擎 )和页级锁(BDB引擎 )。 行级锁 行级锁是MySQL中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。 &#x3D;&#x3D;开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。&#x3D;&#x3D; 表级锁 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。 &#x3D;&#x3D;开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。&#x3D;&#x3D; 意向共享锁（Intention Shared Lock，IS 锁）：事务有意向对表中的某些记录加共享锁（S 锁），加共享锁前必须先取得该表的 IS 锁。 意向排他锁（Intention Exclusive Lock，IX 锁）：事务有意向对表中的某些记录加排他锁（X 锁），加排他锁之前必须先取得该表的 IX 锁。 页级锁 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁 &#x3D;&#x3D;开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般&#x3D;&#x3D; MyISAM和InnoDB存储引擎使用的锁： MyISAM采用表级锁(table-level locking)。 InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁 乐观锁和悲观锁 悲观锁：在所有操作前都上锁 乐观锁：总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。&#x3D;&#x3D;共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程&#x3D;&#x3D;。实现方式：使用数据库中的锁机制 乐观锁：&#x3D;&#x3D;假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性&#x3D;&#x3D;。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。 乐观锁的版本号机制在表中设计一个 版本字段 version ，第一次读的时候，会获取 version 字段的取值。然后对数据进行更新或删除操作时，会执行 UPDATE … SET version&#x3D;version+1 WHERE version&#x3D;version 。此时如果已经有事务对这条数据进行了更改，修改就不会成功。 乐观锁的时间戳机制时间戳和版本号机制一样，也是在更新提交的时候，将当前数据的时间戳和更新之前取得的时间戳进行比较，如果两者一致则更新成功，否则就是版本冲突。你能看到乐观锁就是程序员自己控制数据并发操作的权限，基本是通过给数据行增加一个戳（版本号或者时间戳），从而证明当前拿到的数据是否最新。 使用场景 乐观锁 适合 读操作多 的场景，相对来说写的操作比较少。它的优点在于 程序实现 ， 不存在死锁问题，不过适用场景也会相对乐观，因为它阻止不了除了程序以外的数据库操作。 悲观锁 适合 写操作多 的场景，因为写的操作具有 排它性 。采用悲观锁的方式，可以在数据库层面阻止其他事务对该数据的操作权限，防止 读 - 写 和 写 - 写 的冲突。 间隙锁间隙锁基于非唯一索引，它锁定一段范围内的索引记录。使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙也加上了间隙锁。这样就确保了无法再插入新的记录。 什么时候不用间隙锁 使用唯一索引进行查询 临键锁间隙锁和行锁合称next-key lock临键锁，它的封锁范围，既包含索引记录，又包含索引区间，是一个左开右闭区间。临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。 每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列(包括主键列)上不存在临键锁。 优化锁方面的意见？防止死锁 使用较低的隔离级别 设计索引，尽量使用索引去访问数据，加锁更加精确，从而减少锁冲突 调整业务逻辑SQL执行顺序，避免update&#x2F;delete长时间持有锁的SQL在事务前面。 避免大事务，尽量将达大事务拆成多个小事务来处理，小事务缩短锁定资源的时间，发生锁冲突的几率也更小。 选择合理的事务大小，给记录显示加锁时，最好一次性请求足够级别的锁。如：修改数据的话，最好申请排他锁，而不是先申请共享锁，修改时在申请排他锁，这样会导致死锁 不同的程序访问一组表的时候，应尽量约定一个相同的顺序访问各表，对于一个表而言，尽可能的固定顺序的获取表中的行。这样大大的减少死锁的机会。 尽量使用相等条件访问数据，这样可以避免间隙锁对并发插入的影响 不要申请超过实际需要的锁级别 数据查询的时候不是必要，不要使用加锁。MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能：MVCC只在committed read（读提交）和 repeatable read （可重复读）两种隔离级别 对于特定的事务，可以使用表锁来提高处理速度活着减少死锁的可能。 出现死锁超时会怎么办？会一直等待吗？锁等待：MySQL有一个参数来控制获取锁的等待时间，默认是50秒。 死锁检测：在第一个事务中，检测到了死锁，马上退岀了，第二个事务获得了锁， 不需要等待50秒 为什么可以直接检测到呢？是因为死锁的发生需要满足一定的条件，所以在发生死锁时，InnoDB —般都能通过算法(wait-for graph)自动检测到。 死锁的产生条件（因为锁本身是互斥的）： 同一时刻只能有一个事务持有这把锁； 其他的事务需要在这个事务释放锁之后才能获取锁，而不可以强行剥夺； 当多个事务形成等待环路的时候，即发生死锁。 mysql死锁怎么排查死锁检测：在第一个事务中，检测到了死锁，马上退岀了，第二个事务获得了锁， 不需要等待50秒 为什么可以直接检测到呢？是因为死锁的发生需要满足一定的条件，所以在发生死锁时，InnoDB —般都能通过算法(wait-for graph)自动检测到。 SHOW ENGINE INNODB STATUS; 其中status保存着最近一次死锁记录MySQL 系统内部提供一个 innodb_print_all_deadlocks 参数，该参数默认是关闭的，开启后可以将死锁信息自动记录到 MySQL 的错误日志中。 线上错误日志报警发现死锁异常 查看错误日志的堆栈信息 查看 MySQL 死锁相关的日志 根据 binlog 查看死锁相关事务的执行内容 根据上述信息找出两个相互死锁的事务执行的 SQL 操作，根据本系列介绍的锁相关理论知识，进行分析推断死锁原因 修改业务代码 加锁分析 一条Update语句没有带where条件，加的是什么锁： 相当于表锁，锁住表格中的每一条记录和每个间隙，其它UPDATE、INSERT和DELETE语句都无法执行： 带了where条件没有命中索引，加的是什么锁： 相当于表锁，锁住表格中的每一条记录和每个间隙，其它UPDATE、INSERT和DELETE语句都无法执行： 两条更新语句更新同一条记录，加的是什么锁： 两条更新语句更新同一条记录的不同字段，加的是什么锁 MySQL的update语句在读的时候就直接加的X锁，会阻塞其它的DML语句的读(insert, update, delete等),所以不会发生死锁 通过索引更新： 如果当前有值，则只加当前行行锁如果当前无值，或更新的为一个范围的值，那么会加行锁+间隙锁即临键锁 日志系统MySQL事务日志介绍下？innodb 事务日志包括 redo log 和 undo log。 重做日志（Redo Log）：记录所有数据修改操作的重做操作，包括 INSERT、UPDATE 和 DELETE 等操作，以便在发生故障时能够重新执行这些操作，以恢复数据的一致性。 回滚日志（Undo Log）：记录所有数据修改操作的撤销操作，主要用于事务回滚和 MVCC 等功能。 事务日志的目的：实例或者介质失败，事务日志文件就能派上用场。 redo logInnoDB作为MySQL的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘IO，效率会很低。为此，InnoDB提供了缓存(Buffer Pool)，Buffer Pool中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool；当向数据库写入数据时，会首先写入Buffer Pool，Buffer Pool中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）。 Buffer Pool的使用大大提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。 于是，redo log被引入来解决这个问题：当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次操作；当事务提交时，会调用fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log采用的是WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。 重做日志（redo log）是InnoDB引擎层的日志，用来&#x3D;&#x3D;记录事务操作引起数据的变化，记录的是数据页的物理修改&#x3D;&#x3D;。InnoDB引擎对数据的更新，是先将更新记录写入redo log日志，然后会在系统空闲的时候或者是按照设定的更新策略再将日志中的内容更新到磁盘之中。这就是所谓的预写式技术（Write Ahead logging）。这种技术可以大大减少IO操作的频率，提升数据刷新的效率。 redo log包括两部分：一个是内存中的日志缓冲(redo log buffer)，另一个是磁盘上的日志文件(redo log file)。mysql每执行一条DML语句，先将记录写入redo log buffer，后续某个时间点再一次性将多个操作记录写到redo log file。这种先写日志，再写磁盘的技术就是MySQL里经常说到的WAL(Write-Ahead Logging) 技术。 好处： redo日志降低了刷盘频率 redo日志占用的空间非常小存储表空间ID、页号、偏移量以及需要更新的值，所需的存储空间是很小的，刷盘快。 特点： redo日志是顺序写入磁盘的 事务执行过程中，redo log不断记录 既然redo log也需要在事务提交时将日志写入磁盘，为什么它比直接将Buffer Pool中修改的数据写入磁盘(即刷脏)要快呢？（1）刷脏是随机IO，因为每次修改的数据位置随机，但写redo log是追加操作，属于顺序IO。 （2）刷脏是以数据页（Page）为单位的，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入；而redo log中只包含真正需要写入的部分，无效IO大大减少。 刷盘规则 开启事务，发出提交事务指令后是否刷新日志由变量innodb_flush_log_at_trx_commit 决定 0: 每次提交事务时，不会将 Log Buffer 中的日志写入 OS buffer, 而是通过一个单独的线程，每秒写入 OS buffer 并调用系统的 fsync() 函数写入磁盘的 Redo Log File, 这种方式不是实时写磁盘的， 而是每隔 1s 写一次日志，如果系统崩溃，可能会丢失 1s 的数据。 1: 每次提交事务都会将 Log Buffer 中的日志写入 OS buffer 中，并且会调用 fsync() 函数将日志写入 Redo Log File 中，这种方式虽然不会再崩溃时丢失数据，但是性能比较差。也是这个变量的默认值。 2: 每次提交事务时，都只是将数据写入 os buffer 中，之后每隔 1s ,通过 fsync() 函数将 os buffer 中的数据写入 Redo Log 文件中。 每秒刷新一次，刷新日志的频率由变量 innodb_flush_log_at_timeout 的值决定，默认是 1s, 刷新日志的频率和是否执行了 commit 操作无关 当 Log Buffer 中已经使用内存超过一半时，会触发刷盘操作 写入机制Redo Log 记录的是物理日志，其文件内容是以循环的方式写入的，一个文件写满了就写入另一个文件，最后一个文件写满了就会向第一个文件写入，并且是覆盖写。 Write Pos 是数据表中当前记录所在的位置，随着写入，这个位置逐渐向后移动，最后一个文件写满后，这个位置移动到第一个文件的开始处。 CheckPoint 是当前要擦除的位置，这个位置也是向后移动的，擦除之前要将数据更新到数据文件中。 Write Pos 和 CheckPoint 之间存在间隔，间隔表示还可以记录新的操作。如果 Write Pos 写入较快，追上了擦除的位置，则表示已经写满，不再向 Redo Log 文件中写数据了，此时需要停止写入，擦除一些数据。 怎么判断redolog是已提交的当一个事务提交时，MySQL 会将该事务的所有修改操作记录在 redo log 中。这些记录不会直接写入磁盘，而是先写入 redo log buffer，等到 redo log buffer 填满或事务提交时才会将记录写入磁盘。redo log 中的记录只有在事务提交之后才是有效的。如果事务没有提交，则 redo log 中的记录会被回滚，不会对数据库产生影响。 在MySQL中，InnoDB引擎会维护一个LSN（Log Sequence Number）值，表示当前redo log写入的位置。当一个事务的redo log写入到磁盘时，该事务的commit信息会写入redo log的末尾，并记录一个commit标记。当MySQL重启或者发生crash恢复时，会从磁盘读取redo log，并通过commit标记判断哪些事务已经提交。如果一个事务的redo log中没有commit标记，则认为该事务未提交，需要进行回滚操作。 undo log&#x3D;&#x3D;原子性底层就是通过undo log实现的&#x3D;&#x3D;。undo log主要记录了数据的逻辑变化，比如一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态。 undo log由两个作用，一是提供回滚，二是实现MVCC redolog两阶段提交过程 写入redo log，处于prepare状态 写binlog 修改redo log状态为commit 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交 如果 redo log 里面的事务处于 prepare 状态，则判断对应的事务 binlog 是否存在并完整，不完整则回滚 为什么redo log要分两步写，中间再穿插写binlog呢？因为*redo log影响主库的数据，binlog影响从库的数据，所以redo log和binlog必须保持一致才能保证主从数据一致。 binlog与redolog对比 redo log 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎层产生的。 而 binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID&#x3D;2 这一行的 c 字段加 1”，属于MySQL Server 层。在MySQL数据库的上层产生的，并且二进制日志不 仅仅针对于InnoDB存储引擎，MySQL数据库中的任何存储引擎对于数据库的更改都会产生二进制日志。 虽然他们都属于持久化的保证但侧重点不同： redolog 让部分InnoDB引擎有了崩溃恢复的能力 binlog保证了mysql主从架构的数据一致性，以及作为pit恢复数据 为什么binlog只能作为pit（时间恢复点）和主从同步，做不了持久化？redo log 记录的是mysql内存页的修改逻辑(物理修改)，binlog记录的是mysql上层执行语句的log日志。 优化，单次insert多条数据，然后在事务里做一次性提交 一个表超大数据 ，分页查询怎么才能尽可能的快，如何优化大分页查询？对于超大数据的分页查询，为了尽可能地快速和高效地查询数据，可以考虑以下优化措施： 使用合适的索引：确保使用正确的索引可以大大提高查询速度。在分页查询中，应该将索引按照分页查询的列进行优化，以便能够快速地找到要查询的数据。 使用LIMIT子句：使用LIMIT子句可以限制返回的行数，避免将整个表扫描，提高查询效率。同时，使用LIMIT子句的时候需要根据实际情况设置合适的偏移量和返回行数，以免查询过多的数据。 使用缓存：使用缓存可以避免每次查询都要重新从磁盘读取数据。在MySQL中，可以使用查询缓存和应用程序缓存等方式来实现数据的缓存。 分批次查询：将大分页查询拆分为多个小分页查询可以降低数据库负载和查询时间。在实现分批次查询时，需要根据实际情况合理设置每次查询的偏移量和返回行数。 记录下上次查询到的值，下次直接从该值后进行分页查询 避免使用子查询：尽量避免在分页查询中使用子查询，因为子查询会增加查询的复杂度和执行时间。 使用水平分表：如果数据表非常大，可以考虑将表水平分割成多个子表，每个子表存储一定数量的数据。这样可以将数据分布到多个表中，降低单个表的查询负担，提高查询效率。 使用分区表：MySQL提供了分区表的功能，将数据分区存储，可以显著提高查询效率。分区表将数据划分为多个区域，每个区域可以独立地进行查询和维护。 delete、drop和truncate区别delete是数据操纵语言（DML），其按行删除，支持where语句，执行操作采用行锁，执行操作时会将该操作记录在redo和undo中，因此支持回滚。 truncate是数据定义语言（DDL），其操作隐式提交，不支持回滚，不支持where，删除时采用表级锁进行删除 drop也是DDL，不支持回滚，从数据库中删除整张表，其所有数据行，索引和权限也会被删除。 事务事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。 四个特征ACID事务就是一组原子性的操作，这些操作要么全部发生，要么全部不发生。事务把数据库从一种一致性状态转换成另一种一致性状态。 原子性。事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做 一致性。事 务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态。 隔离性。一个事务的执行不能其它事务干扰。即一个事务内部的&#x2F;&#x2F;操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。 持续性。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。 实现原理原子性：InnoDB实现回滚，靠的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。 持久性：redo log被引入来解决这个问题：当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次操作；当事务提交时，会调用fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log采用的是WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。 隔离性：(一个事务)写操作对(另一个事务)写操作的影响：锁机制保证隔离性(一个事务)写操作对(另一个事务)读操作的影响：MVCC保证隔离性 一致性：保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致 隔离级别Read Uncommitted（读取未提交内容）在该隔离级别，&#x3D;&#x3D;所有事务都可以看到其他未提交事务的执行结果&#x3D;&#x3D;。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。 不能避免脏读、不可重复读、幻读。 Read Committed（读取提交内容）这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。 可以避免脏读，但不可重复读、幻读问题仍然存在。 Repeatable Read（可重读）这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。 可以避免脏读、不可重复读，但幻读问题仍然存在。 这是MySQL的默认隔离级别。 Serializable（可串行化）这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。 所有的并发问题都可以避免，但性能十分低下。能避免脏读、不可重复读和幻读。 分库分表分库分表是一种将数据分散到多个数据库或表中的技术，用于处理大规模数据存储和查询的问题。通常情况下，当单个数据库或表无法满足大量数据的存储和查询需求时，可以采用分库分表的方式来扩展数据库性能和容量。 优点： 提高性能：分库分表可以将负载分散到多个数据库或表中，提高数据存储和查询的性能。 扩展容量：分库分表可以将数据存储到多个数据库或表中，扩展数据库的容量。 增强可用性：当某个数据库或表发生故障时，可以将负载转移到其他数据库或表中，保证系统的可用性。 降低成本：通过分库分表可以采用廉价的硬件进行数据存储和查询，降低系统成本。 缺点 系统复杂性增加：分库分表需要考虑分片策略、数据一致性、跨库查询等问题，增加了系统的复杂性和开发难度。 数据一致性难以保证：当数据跨越多个数据库或表时，需要确保数据一致性，这可能会增加开发难度和系统复杂性。 查询复杂性增加：跨库查询需要将查询请求发送到多个数据库或表中，增加了查询复杂性和查询时间。 方式分库分表可以分为水平分片和垂直分片两种方式： 水平分片：将数据按照某个规则分散到多个数据库或表中，每个数据库或表存储一部分数据。水平分片通常基于数据的某个属性，如时间、地理位置等进行分片，以确保每个分片的数据量大致相同。 垂直分片：将数据库或表按照功能或属性进行分割，将不同的数据存储到不同的数据库或表中。例如，可以将用户信息、订单信息、商品信息等分别存储到不同的数据库或表中。 水平拆分水平拆分的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。 垂直拆分垂直拆分的意思，就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多··访问频率很低的字段放到另外一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。 两种分库分表的方式： 一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如时间范围来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。 或者是按照某个字段hash一下均匀分散，这个较为常用。 range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。 hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表 跨库查询如何做优化？ 对于常用字段可以做数据冗余 全局表，就是有可能系统中所有模块都可能会依赖到的一些表。 使用缓存 分库分表后如何保证全局唯一的主键idUUID：不适合作为主键，因为太⻓了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。数据库自增 id : 两台数据库分别&#x3D;&#x3D;设置不同步⻓&#x3D;&#x3D;，生成不重复 ID 的策略来实现高可用。这种方式生成的 id 有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。利用 redis 生成 id : 性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。雪花算法 uuid自增id 字符串做主键区别UUID：不适合作为主键，因为太⻓了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。 针对B+树叶子节点，如果主键是自增的，那它产生的id每次都比前一次要大，所以每次都会将数据加在B+树尾部，B+树的叶子节点本质上是双向链表，查找它的首部和尾部，时间复杂度O(1)。而如果此时最末尾的数据页满了，那创建个新的页就好。 如果主键不是自增的，比方说上次分配了id&#x3D;7，这次分配了id&#x3D;3，为了让新加入数据后B+树的叶子节点还能保持有序，它就需要往叶子结点的中间找，查找过程的时间复杂度是O(lgn)，如果这个页正好也满了，这时候就需要进行页分裂了。并且页分裂操作本身是需要加悲观锁的。总体看下来，&#x3D;&#x3D;自增的主键遇到页分裂的可能性更少，因此性能也会更高&#x3D;&#x3D;。 InnoDB和MyISAM的区别 InnoDB 支持行级别的锁粒度，MyISAM 不支持，只支持表级别的锁粒度。 MyISAM 不提供事务支持。InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别。 MyISAM 不支持外键，而 InnoDB 支持外键。 MyISAM 不支持 MVCC，而 InnoDB 支持MVCC。 虽然 MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。 MyISAM 不支持数据库异常崩溃后的安全恢复，而 InnoDB 支持,redo log。 InnoDB 的性能比 MyISAM 更强大。 何时使用myisam多读场景如果你的应用程序对查询性能要求较高，就要使用MYISAM了。MYISAM索引和数据是分开的，而且其索引是压缩的，可以更好地利用内存。所以它的查询性能明显优于INNODB。压缩后的索引也能节约一些磁盘空间。 mysql是如何解决幻读问题的快照读在默认隔离级别RR下，select 语句默认是快照读 当前读select 语句加锁是当前读， update 语句是当前读 当前读：select…lock in share mode，select…for update， update，delete，insert 幻读幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此， 幻读在“当前读”下才会出现（三个查询都是for update表示当前读）； 上面session B的修改update结果，被session A之后的select语句用“当前读”看到，不能称为幻读，幻读仅专指“新插入的行” 解决即使把所有的记录都加上锁，还是阻止不了新插入的记录，所以“幻读”问题要单独拿出来解决。没法依靠MVCC或者行锁机制来解决。这就引出“间隙锁”，是另外一种加锁机制。 产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。 在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙也加上了间隙锁。这样就确保了无法再插入新的记录。 间隙锁和行锁合称next-key lock临键锁，每个next-key lock是前开后闭区间（间隙锁开区间，next-key lock前开后闭区间）：它的封锁范围，既包含索引记录，又包含索引区间。每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。 为了解决幻读问题可以采用读可提交隔离级别，间隙锁是在可重复读隔离级别下才会生效的。所以如果把隔离级别设置为读提交的话， 就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把binlog格式设置为row，也就是说采用“RC隔离级别+日志格式binlog_format&#x3D;row”组合。 总结 RR隔离级别下间隙锁才有效，RC隔离级别下没有间隙锁； RR隔离级别下为了解决“幻读”问题：“快照读”依靠MVCC控制，“当前读”通过间隙锁解决； 间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间； 间隙锁的引入，可能会导致同样语句锁住更大的范围，影响并发度。 表结构优化进行表结构优化的目的是为了提高数据库查询效率、减少数据库存储空间的使用、降低数据库的锁竞争等。 提高效率角度： 使用缓存：将查询结果缓存到缓存中，以减少数据库的查询操作，提高查询效率。 使用索引：合理的索引可以极大地提高查询效率。 分库分表：有水平拆分和垂直拆分两种形式，可以按照时间、地区进行水平拆分，比如每个月一张表，每个地区一张表，通过业务层拆分拆卸请求可以将表中的频率较高的字段分成一张表，或者大文本字段分成一张表，提高查询的效率 适当合并表或者适当冗余：合并多个表减少表的联接操作，从而提高查询效率。 减少存储空间的角度： 合理定义数据类型，字段大小。比如区分开tinyint(1),int(4),bigint(8)，固定长度（或长度几乎相等）的字符串用char不用verchar(实际长度+1) 使用数据压缩算法，将数据压缩存储，以减少存储空间的使用。 字段优化 尽量使用TINYINT、SMALLINT、MEDIUM INT 作为整数类型而非INT，如果非负则加上UNSIGNED VARCHAR的长度只分配真正需要的空间 使用枚举或整数代替字符串类型 尽量使用TIMESTAMP 而DATETIME 单表不要有太多字段，建议在20以内 避免使用 NULL字段，很难查询优化且占用额外索引空间 用整型来存IP 分页优化对于有大数据量的mysql表来说，使用LIMIT分页存在很严重的性能问题。 一言以蔽之，就是越往后分页，LIMIT语句的偏移量就会越大，速度也会明显变慢。 优化： 123456# SQL代码1：平均用时6.6秒 SELECT * FROM `cdb_posts` ORDER BY pid LIMIT 1000000 , 30# SQL代码2：平均用时0.6秒 SELECT * FROM `cdb_posts` WHERE pid &gt;= (SELECT pid FROM `cdb_posts` ORDER BY pid LIMIT 1000000 , 1) LIMIT 30 因为要取出所有字段内容，第一种需要跨越大量数据块并取出，而第二种基本通过直接根据索引字段定位后，才取出相应内容，效率自然大大提升。对limit的优化，不是直接使用limit，而是首先获取到offset的id，然后直接使用limit size来获取数据。 为什么说mysql数据库单表最大行数不能超过2000万为什么说mysql数据库单表最大行数不能超过2000万_mysql表最大行数_CoreDump1024的博客-CSDN博客 IOMySQL一次IO的最小单位是页（page），也可以理解为一次原子操作都是以page为单位的，默认大小16k。刚刚列出的所有物理文件结构上都是以Page构成的，只是page内部的结构不同。mysql的IO是指数据库文件的读写，也就是检索数据和插入数据。 2kw B+树叶子和非叶子结点的数据页都是16k，且数据结构一致，区别在于叶子节点放的是真实的行数据，而非叶子结点放的是主键和下一个页的地址。 B+树一般有两到三层，由于其高扇出，三层就能支持2kw以上的数据，且一次查询最多1~3次磁盘IO，性能也还行。 存储同样量级的数据，B树比B+树层级更高，因此磁盘IO也更多，所以B+树更适合成为mysql索引。 索引结构不会影响单表最大行数，2kw也只是推荐值，超过了这个值可能会导致B+树层级更高，影响查询性能。 单表最大值还受主键大小和磁盘大小限制。 行数超一亿就慢了吗？上面假设单行数据用了1kb，所以一个数据页能放个15行数据。如果我单行数据用不了这么多，比如只用了250byte。那么单个数据页能放60行数据。那同样是三层B+树，单表支持的行数就是 (1280 ^ (3-1)) * 60 ≈ 1个亿。你看我一个亿的数据，其实也就三层B+树，在这个B+树里要查到某行数据，最多也是三次磁盘IO。所以并不慢。 总结 MySQL 的表数据是以页的形式存放的，页在磁盘中不一定是连续的。 页的空间是 16K, 并不是所有的空间都是用来存放数据的，会有一些固定的信息，如，页头，页尾，页码，校验码等等。 在 B+ 树中，叶子节点和非叶子节点的数据结构是一样的，区别在于，叶子节点存放的是实际的行数据，而非叶子节点存放的是主键和页号。 索引结构不会影响单表最大行数，2000W 也只是推荐值，超过了这个值可能会导致 B + 树层级更高，影响查询性能。 数据库的主键为什么是自增的 主键可以唯一标识这一行数据，从而保证在删除更新操作时，只是操作这一行数据。 索引需要，每个 InnoDB 表又有一个特殊的索引，即聚簇索引，用来存储行数据。通常，聚簇索引和主键同义。 针对B+树叶子节点，如果主键是自增的，那它产生的id每次都比前一次要大，所以每次都会将数据加在B+树尾部，B+树的叶子节点本质上是双向链表，查找它的首部和尾部，时间复杂度O(1)。而如果此时最末尾的数据页满了，那创建个新的页就好。 如果主键不是自增的，比方说上次分配了id&#x3D;7，这次分配了id&#x3D;3，为了让新加入数据后B+树的叶子节点还能保持有序，它就需要往叶子结点的中间找，查找过程的时间复杂度是O(lgn)，如果这个页正好也满了，这时候就需要进行页分裂了。并且页分裂操作本身是需要加悲观锁的。总体看下来，&#x3D;&#x3D;自增的主键遇到页分裂的可能性更少，因此性能也会更高&#x3D;&#x3D;。 声明主键，InnoDB 会将主键作为聚簇索引。 未声明时，会在 UNIQUE 所有键列所在位置找到第一个索引，NOT NULL 并将其作为聚簇索引 未声明且找不到合适的 UNIQUE 索引，则内部生成一个隐藏的聚簇索引 GEN_CLUST_INDEX，这个隐藏的行 ID 是 6 字节且单调增加。 数据页大小是固定16k 数据页内，以及数据页之间，数据主键id都是从小到大排序的由于数据页大小固定了是16k，当我们需要插入一条新的数据，数据页会被慢慢放满，当超过16k时，这个数据页就有可能会进行分裂。 总结 建表sql里主键边上的AUTO_INCREMENT，可以让主键自增，去掉它是可以的，但这就需要你在insert的时候自己设置主键的值。 建表sql里的 PRIMARY KEY 是用来声明主键的，如果去掉，那也能建表成功，但mysql内部会给你偷偷建一个 ROW_ID的隐藏列作为主键。 由于mysql使用B+树索引，叶子节点是从小到大排序的，如果使用自增id做主键，这样每次数据都加在B+树的最后，比起每次加在B+树中间的方式，加在最后可以有效减少页分裂的问题。 在分库分表的场景下，我们可以通过redis等第三方组件来获得严格自增的主键id。如果不想依赖redis，可以参考雪花算法进行魔改，既能保证数据趋势递增，也能很好的满足分库分表的动态扩容。 并不是所有数据库都建议使用自增id作为主键，比如tidb就推荐使用随机id，这样可以有效避免写热点的问题。而对于一些敏感数据，比如用户id，订单id等，如果使用自增id作为主键的话，外部通过抓包，很容易可以知道新进用户量，成单量这些信息，所以需要谨慎考虑是否继续使用自增主键。 如何保证自增插入操作会依据这个自增长的计数器值加1赋予自增长列。这个实现方式称做AUTO-INC Locking。这种锁其实是采用一种特殊的表锁机制，为了提高插入的性能，锁不是在一个事务完成后才释放，而是在完成对自增长值插入的SQL语句后立即释放。 MySQL中varchar最大长度是多少？导致实际应用中varchar长度限制的是一个行定义的长度。 MySQL要求一个行的定义长度不能超过65535。 varchar最多能存储65535个字节的数据。varchar 的最大长度受限于最大行长度（max row size，65535bytes）。 字符类型若为gbk，每个字符最多占2个字节，最大长度不能超过32766;字符类型若为utf8，每个字符最多占3个字节，最大长度不能超过21845。若定义的时候超过上述限制，则varchar字段会被强行转为text类型，并产生warning。 列数限制MySQL 对每个表有 4096 列的硬限制，但是对于给定的表，有效最大值可能会更少。确切的列限制取决于几个因素： 表的最大行大小限制了列的数量（可能还有大小），因为所有列的总长度不能超过该大小 个列的存储要求限制了给定最大行大小内的列数。某些数据类型的存储要求取决于存储引擎，存储格式和字符集等因素 存储引擎可能会施加其他限制表列计数的限制。例如， InnoDB每个表的限制为 1017 列 功能键部分被实现为隐藏的虚拟生成的存储列，因此表索引中的每个功能键部分都计入表的总列数限制。 数据库脑裂脑裂(split-brain)：指在一个高可用(HA)系统中，当联系着的两个节点断开联系时，本来为一个整体的系统，分裂为两个独立节点，这时两个节点开始争抢共享资源，结果会导致系统混乱，数据损坏。 裂脑通常用于描述集群中的两个或多个节点彼此失去连接但随后继续彼此独立运行（包括获取逻辑或物理资源）的场景，错误假设其他进程（es ) 不再运作或使用上述资源。简单来说，“大脑分裂”意味着有 2 个或更多不同的节点集或“队列”，两个队列之间没有通信。 为什么禁止使用count(列名)count(常量)：InnoDB会遍历整张表，但不取值，server层对返回的每一行放一个常量进去，包含值为NULL的行数，返回累加结果 count(字段)：返回SELECT语句检索的行中不为NULL的数量，和字段的类型无关 count(*)：统计所有的列，相当于行数，包含值为NULL的行数。并且count(*)是SQL92定义的标准统计行数的语法，mysql对于count(*)做了优化：MyISAM会直接把表的总行数单独记录返回给count(*)，InnoDB会选择最小的索引来降低成本。 分布式事务InnoDB存储引擎提供了对XA事务的支持，并通过XA事务来支持分布式事务的实现。分布式事务指的是允许多个独立的事务资源（transactional resources）参与到一个全局的事务中。事务资源通常是关系型数据库系统，但也可以是其他类型的资源。全局事务要求在其中的所有参与的事务要么都提交，要么都回滚，这对于事务原有的ACID要求又有了提高。另外，在使用分布式事务时，InnoDB存储引擎的事务隔离级别必须设置为SERIALIZABLE。 分布式事务使用两段式提交（two-phase commit）的方式。在第一阶段，所有参与全局事务的节点都开始准备（PREPARE），告诉事务管理器它们准备好提交了。在第二阶段，事务管理器告诉资源管理器执行ROLLBACK还是COMMIT。如果任何一个节点显示不能提交，则所有的节点都被告知需要回滚。可见与本地事务不同的是，分布式事务需要多一次的PREPARE操作，待收到所有节点的同意信息后，再进行COMMIT或是ROLLBACK操作。 主从复制原理：Slave 会从Master 读取binlog 来进行数据同步。作用：读写分离，数据备份，高可用性（性能、扩展），负载均衡缺点：存在瞬时数据不一致问题（网络延时） 流程MySQL 的主从复制是一个 异步 的复制过程（一般情况下感觉是实时的），数据将从一个 MySQL 数据库（Master）复制到另外一个 MySQL 数据库（Slave），在 Master 与 Slave 之间实现整个主从复制的过程是由三个线程参与完成的，其中有两个线程（SQL 线程和 I&#x2F;O 线程）在 Slave 端，另外一个线程（ I&#x2F;O 线程）在 Master 端。 Master 端：打开二进制日志（binlog ）记录功能 —— 记录下所有改变了数据库数据的语句，放进 Master 的 binlog 中； Slave 端：开启一个 I&#x2F;O 线程 —— 负责从 Master上拉取 binlog 内容，放进自己的中继日志（Relay log）中； Slave 端：SQL 执行线程 —— 读取 Relay log，并顺序执行该日志中的 SQL 事件。 redo log与binlog两份日志之间的逻辑不一致，会出现什么问题？由于binlog没写完就异常，这时候binlog里面没有对应的修改记录。为了解决两份日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案。prepare和commit阶段 使用两阶段提交后，写入binlog时发生异常也不会有影响，当mysql根据redolog恢复数据时，发现redolog还处于prepare阶段，并且没有对应的binlog日志，就会回滚该事务。 如何解决一致性问题 异步复制 半同步复制（一个从库收到了才返回） 组复制MGR（加了一层一致性协议层，判断从库响应的个数） 主库和从库出现比较严重的主从延迟如何处理原因： 网络延迟：如果主从之间的网络传输速度慢，或者出现丢包、抖动等问题，那么就会影响 binlog 的传输效率，导致从库延迟。解决方法是优化网络环境，比如提升带宽、降低延迟、增加稳定性等。 从库的压力较大，从库承受了大量的请求。从库需要执行主库的所有写操作，同时还要响应读请求，如果读请求过多，会占用从库的 CPU、内存、网络等资源，影响从库的复制效率（也就是 T2-T1 和 T3-T2 的值会较大，和前一种情况类似）。解决方法是引入缓存（推荐）、使用一主多从的架构，将读请求分散到不同的从库，或者使用其他系统来提供查询的能力，比如将 binlog 接入到 Hadoop、Elasticsearch 等系统中。 执行大事务。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。运行时间比较长，长时间未提交的事务就可以称为大事务。由于大事务执行时间长，并且从库上的大事务会比主库上的大事务花费更多的时间和资源，因此非常容易造成主从延迟。解决办法是避免大批量修改数据，尽量分批进行。类似的情况还有执行时间较长的慢 SQL ，实际项目遇到慢 SQL 应该进行优化。 从库机器性能比主库差：从库接收 binlog 并写入 relay log 以及执行 SQL 语句的速度会比较慢，进而导致延迟。解决方法是选择与主库一样规格或更高规格的机器作为从库，或者对从库进行性能优化，比如调整参数、增加缓存、使用 SSD 等。 从库太多：主库需要将 binlog 同步到所有的从库，如果从库数量太多，会增加同步的时间和开销（也就是 T2-T1 的值会比较大，但这里是因为主库同步压力大导致的）。解决方案是减少从库的数量，或者将从库分为不同的层级，让上层的从库再同步给下层的从库，减少主库的压力。 复制模式：MySQL 默认的复制是异步的，必然会存在延迟问题。全同步复制不存在延迟问题，但性能太差了。半同步复制是一种折中方案，相对于异步复制，半同步复制提高了数据的安全性，减少了主从延迟（还是有一定程度的延迟）。MySQL 5.5 开始，MySQL 以插件的形式支持 semi-sync 半同步复制。并且，MySQL 5.7 引入了 增强半同步复制 。 半同步复制、实时性操作强制走主库、并行复制。 半同步复制「异步复制」：MySQL 默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给客户端，并不关心从库是否已经接收并处理。这样就会有一个问题，一旦主库宕机，此时主库上已经提交的事务可能因为网络原因并没有传到从库上，如果此时执行故障转移，强行将从提升为主，可能导致新主上的数据不完整。 「全同步复制」：指当主库执行完一个事务，并且所有的从库都执行了该事务，主库才提交事务并返回结果给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。 「半同步复制」：是介于全同步复制与全异步复制之间的一种，主库只需要等待至少一个从库接收到并写到 Relay Log 文件即可，主库不需要等待所有从库给主库返回 ACK。主库收到这个 ACK 以后，才能给客户端返回 “事务完成” 的确认。 实时性操作强制走主库如果某些操作对数据的实时性要求比较苛刻，需要反映实时最新的数据，比如说涉及金钱的金融类系统、在线实时系统、又或者是写入之后马上又读的业务，这时我们就得放弃读写分离，让此类的读请求也走主库，这就不存延迟问题了。 为什么不建议使用外键外键(FK) 是用于在两个表中的数据之间建立和加强链接的一列或多列的组合，可控制可在外键表中存储的数据。 在外键引用中，当包含一个表的主键值的一个或多个列被另一个表中的一个或多个列引用时，就在这两个表之间创建了链接。 这个列就成为第二个表的外键。 首先我们明确一点，外键约束是一种约束，这个约束的存在，会保证表间数据的关系“始终完整”。因此，外键约束的存在，并非全然没有优点。 保证数据的完整性和一致性 级联操作方便 将数据完整性判断托付给了数据库完成，减少了程序的代码量 RESTRICT 外键会在更新和删除关系表中的数据时对外键约束的合法性进行检查，保证外键不会引用到不存在的记录； CASCADE 外键会在更新和删除关系表中的数据时触发对关联记录的更新和删除，在数据量较大的数据库中可能会有数量级的放大效果； 但是：每次做DELETE 或者UPDATE都必须考虑外键约束，会导致开发的时候很痛苦,测试数据极为不方便。 慢SQL定位首先GORM可以添加一个logger来打印慢SQL错误。mysql也可以打开慢查询日志explain命令可以查mysql具体执行语句时的顺序 一般通过“慢日志明细”功能进行分析，排在Top的SQL需要重点关注。根据执行次数、执行时间、返回行数、解析行数进行分析 set profiling = on通过show profiles查看性能记录，可以看到整个执行过程每个状态的耗时情况。然后定位到具体是哪个状态最耗时，然后针对性的排查原因。 慢查询日志慢查询日志记录了执行时间超过 long_query_time（默认是 10s，通常设置为1s）的所有查询语句，在解决 SQL 慢查询（SQL 执行时间过长）问题的时候经常会用到。找到慢 SQL 是优化 SQL 语句性能的第一步，然后再用 EXPLAIN 命令可以对慢 SQL 进行分析，获取执行计划的相关信息。 可以通过 show variables like &quot;slow_query_log&quot;;命令来查看慢查询日志是否开启，默认是关闭的。可以通过 SET GLOBAL slow_query_log=ON 命令将其开启。 long_query_time 参数定义了一个查询消耗多长时间才可以被定义为慢查询，默认是 10s，通过 SHOW VARIABLES LIKE &#39;%long_query_time%&#39;命令即可查看 可能的原因 SQL解析行数比返回行数多得多：很可能是SQL没有合理使用索引导致。 SQL执行次数比较多，而解析行数和返回行数都比较少：一般是并发太大导致SQL堆积，而使整个系统响应变慢 SQL解析行数和返回行数都比较多：一般SQL本身没有太大优化空间，需要业务层面进行优化。 业务流量太大导致系统响应变慢：写流量比较大，可考虑分库分表，利用分片扩展特性，提升整个集群的写能力和存储容量,读流量比较大，可考虑使用代理实例，利用代理实例的读写分离和负载均衡特性，分摊主库的读流量压力。 解决 首先查一下查询是否用到了索引，是否出现索引失效的情况 lol， +-*&#x2F;，not，null，函数，版本 不要使用select *。 排序请尽量使用升序。 or的查询尽量用union代替（Innodb）。 复合索引高选择性的字段排在前面。 order by&#x2F;group by字段包括在索引当中减少排序，效率会更高。 注意避免冗余索引，以及长期未使用的索引 用了索引还是慢什么原因，如何解决 避免使用select * 索引失效 查询不符合最左前缀匹配 查询字段特别多或进行了多表join：优化查询条件（用小表去驱动大表） 索引区分度不高：优化查询条件和索引 数据库自身的锁等待，cpu占用高，网络问题：偶发的，结合日志业务改 优化器选错了索引：force index 数据量太大：分库分表 explain字段[[#explain]]Explain 执行计划包含字段信息如下：分别是 id、select_type、table、partitions、type、possible_keys、key、key_len、ref、rows、filtered、Extra 12个字段。 &#x3D;&#x3D;关心type，和extra&#x3D;&#x3D; type：查询使用了何种类型，它在 SQL优化中是一个非常重要的指标，以下性能从好到坏依次是：system &gt; const &gt; eq_ref &gt; ref &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL extra里Using index 使用了覆盖索引；Using index condition索引下推 InnoDB三大特性自适应哈希、buffer pool、两次写 自适应哈希索引自适应即我们不需要自己处理，当lnnoDB引擎根据查询统计发现某一查询满足hash索引的数据结构特点，就会给其建立一个hash索引 InnodB存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引(Adaptive Hash Index,AHI)。AHI是通过缓冲池的B+树页构造而来，因此建立的速度很快，而且不需要对整张表构建哈希索引，只是对热点页建立hash索引。InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。 hash索引底层的数据结构是散列表(Hash表)，其数据特点就是比较适合在内存中使用，自适应Hash索引存在于InnoDB架构中的缓存中(不存在于磁盘架构中)，见下面的InnoDB架构图。 自适应hash索引&#x3D;&#x3D;只适合搜索等值的查询&#x3D;&#x3D;，如select * from table where index_col&#x3D;’xxx，而对于其他查找类型，如范围查找，是不能使用的; 优点 无序，没有树高； 降低对二级索引树的频繁访问资源，查询消耗 O(1)； 自适应，不用人为创建。 缺点 自适应hash索引会占用innodb buffer pool； 自适应hash索引只适合搜索等值的查询，而对于其他查找类型，如范围查找、模糊查询，是不能使用的； 自适应哈希索引无法对order by进行优化； 只有在某些负载情况下，通过哈希索引查找带来的性能提升才能远大于额外的监控索引搜索情况和保持这个哈希表结构所带来的开销，此时自适应hash索引才有比较大的意义，可以降低逻辑读。 Buffer PoolBufer Pool: 缓冲池，简称BP。其作用是用来缓存表数据与索引数据，减少磁盘I0操作，提升效率。 Buffer Pool由缓存数据页(Page)和对缓存数据页进行描述的控制块组成。控制块中存储着对应缓存页的所属的表空间、数据页的编号、以及对应缓存页在Buffer Pool中的地址等信息 Buffer Pool默认大小是128M,以Page页为单位，Page页默认大小16K，而控制块的大小约为数据页的5%，大概是800字节。 InnoDB作为MySQL的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘IO，效率会很低。为此，InnoDB提供了缓存(Buffer Pool)，Buffer Pool中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool；当向数据库写入数据时，会首先写入Buffer Pool，Buffer Pool中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）。 Buffer Pool的使用大大提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。 于是，redo log被引入来解决这个问题：当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次操作；当事务提交时，会调用fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log采用的是WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。 如何判断一个页是否在BufferPool中？MySQI中有一个哈希表数据结构，它使用表空间号+数据页号，作为一个key，然后缓冲页对应的控制块作为value。 当需要访问某个页的数据时，先从哈希表中根据表空间号+页号看看是否存在对应的缓冲页。 如果有，则直接使用。 如果没有，就从free链表中选出一个空闲的缓冲页，然后把磁盘中对应的页加载到该缓冲页的位置 Buffer pool的单位，frame的概念？在 MySQL 启动的时候，InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。 Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。 为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个控制块，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。 控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页 如何管理脏页设计 Buffer Pool 除了能提高读性能，还能提高写性能，也就是更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为脏页，然后再由后台线程将脏页写入到磁盘。 那为了能快速知道哪些缓存页是脏的，于是就设计出 Flush 链表，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。&#x3D;&#x3D;有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。&#x3D;&#x3D; 两次写（double write）提高innodb的可靠性，用来解决部分写失败(partial page write页断裂)。 redolog中存的是物理页的修改：如偏移量600，写’xxxx’记录。 脏刷时宕机：磁盘文件不完整因此redolog失效，从double write buffer里恢复数据 写double write buffer时宕机：直接从redolog恢复数据 写缓冲 Change Buffer非聚集索引也是一颗B+树，只是叶子节点存的是聚集索引的主键和name 的值。因为不能保证name列的数据是顺序的，所以非聚集索引这棵树的插入必然也不是顺序的了。 可以看出非聚集索引插入的离散性导致了插入性能的下降，因此InnoDB引擎设计了 Insert Buffer来提高插入性能 。 Insert Buffer 就是用于提升非聚集索引页的插入性能的，其数据结构类似于数据页的一个B+树，物理存储在共享表空间ibdata1中 。 首先对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中。 若在，则直接插入；若不在，则先放入到一个Change Buffer对象中。 给外部的感觉好像是树已经插入非聚集的索引的叶子节点，而其实是存放在其他位置了 以一定的频率和情况进行Insert Buffer和辅助索引页子节点的merge（合并）操作，通常会将多个插入操作一起进行merge，这就大大的提升了非聚集索引的插入性能。 Double write解决了什么问题当数据库正在从内存想磁盘写一个数据页是，数据库宕机，从而导致这个页只写了部分数据，这就是部分写失效，它会导致数据丢失。这时是无法通过重做日志恢复的，因为重做日志记录的是对页的物理修改，如果页本身已经损坏，重做日志也无能为力。 因为存储引擎缓冲池内的数据页大小默认为16KB，而文件系统一页大小为4KB，所以在进行刷盘操作时，就有可能发生如下场景：数据库准备刷新脏页时，需要四次IO才能将16KB的数据页刷入磁盘。但当执行完第二次IO时，数据库发生意外宕机，导致此时才刷了2个文件系统里的页，这种情况被称为写失效（partial page write）。此时重启后，磁盘上就是不完整的数据页，就算使用redo log也是无法进行恢复的。 redo log无法恢复数据页损坏的问题，恢复必须是数据页正常并且redo log正常。 这里要知道一点，redo log中记录的是对页的物理操作，如偏移量600，写’xxxx’记录。 如果这个页本身已经发生了损坏，再对其进行重做是没有意义的 过程其实就是在重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是double write。 doublewrite由两部分组成，一部分为内存中的doublewrite buffer，其大小为2MB，另一部分是磁盘上共享表空间(ibdata x)中连续的128个页，即2个区(extent)，大小也是2M。 当一系列机制触发数据缓冲池中的脏页刷新时，并不直接写入磁盘数据文件中，而是先拷贝至内存中的doublewrite buffer中； 接着从两次写缓冲区分两次写入磁盘共享表空间中(连续存储，顺序写，性能很高)，每次写1MB；然后马上调用fsync函数，同步磁盘，避免缓冲写带来的问题 待第二步完成后，再将doublewrite buffer中的脏页数据写入实际的各个表空间文件(离散写)；(脏页数据固化后，即进行标记对应doublewrite数据可覆盖) doublewrite的崩溃恢复如果操作系统在将页写入磁盘的过程中发生崩溃，在恢复过程中，innodb存储引擎可以从共享表空间的doublewrite中找到该页的一个最近的副本，将其复制到表空间文件，再应用redo log，就完成了恢复过程。 因为有副本所以也不担心表空间中数据页是否损坏。 存在问题Double write buffer 它是在物理文件上的一个buffer, 其实也就是file，所以它会导致系统有更多的fsync操作，而因为硬盘的fsync性能问题，所以也会影响到数据库的整体性能。 Double write页是连续的，因此这个过程是顺序写的，开销并不是很大。 在完成Double write页的写入后，再将Double write buffer中的页写入各个数据文件中，此时的写入则是离散的 为什么log write不需要doublewrite的支持？因为redolog写入的单位就是512字节，也就是磁盘IO的最小单位，所以无所谓数据损坏。 总结 当commit 一个修改语句时，如果redo log有空闲区域，直接写redo log，如果redo log没有空闲区域，那么需要把被覆盖的redo log对应的数据页刷新到data file 中，最后改pool buffer中的记录 innodb的redo log 不会记录完整的一页数据，因为这样日志太大，它只会记录那次（sequence）如何操作了（update,insert）哪页(page)的哪行(row) 因为数据库使用的页（page，默认16KB）大小和操作系统对磁盘的操作页（page，默认4KB）不一样，当提交了一个页需要刷新到磁盘，会有多次IO， 此时刷了前面的8k时异常发生宕机。在系统恢复正常后，如果没有double write机制，此时数据库磁盘内的数据页已损坏，无法使用redo log进行恢复。 如果有double write buffer，会检查double writer的数据的完整性，如果不完整直接丢弃double write buffer内容，重新执行那条redo log，如果double write buffer的数据是完整的，用double writer buffer的数据更新该数据页，跳过该redo log。 第一步，对数据页数据进行更新第二步，向redo log buffer中记录redo log第三步，将缓存中的redo log写入磁盘第四步，将脏页复制到double write buffer中第五步，将数据页写入到共享表空间（维护的是128个连续页，最小16KB）第六步，马上调用fsync函数同步磁盘第七步，当第六步执行一半时发生宕机，执行恢复操作，InnoDB存储引擎从共享表空间中doublewrite中找到该页的一个副本，将其复制到表空间文件。如果在执行第五步时，有些数据页还没写入共享表空间就宕机了，那么此时磁盘中就丢失了该数据页，这时就需要靠redo log来恢复数据了。第八步，重启服务，根据redo log文件向缓存池中加载数据页，以一个数据页LSN&#x3D;1000为例子，该数据页时更新之前的，在redo log中该数据页LSN&#x3D;1100。第九步，比较redo log与数据页的LSN大小 redo log lsn &gt; page lsn，需要更新数据页，更新完成后该数据页为脏页。此时重复第四步，将脏页复制到double write buffer中继续重复后面所有步骤。 100000条数据怎么插入比较快先说第一种方案，就是用 for 循环循环插入： 这种方案的优势在于，JDBC 中的 PreparedStatement 有预编译功能，预编译之后会缓存起来，后面的 SQL 执行会比较快并且 JDBC 可以开启批处理，这个批处理执行非常给力。 劣势在于，很多时候我们的 SQL 服务器和应用服务器可能并不是同一台，所以必须要考虑网络 IO，如果网络 IO 比较费时间的话，那么可能会拖慢 SQL 执行的速度。 再来说第二种方案，就是生成一条 SQL 插入： 这种方案的优势在于只有一次网络 IO，即使分片处理也只是数次网络 IO，所以这种方案不会在网络 IO 上花费太多时间。 当然这种方案有好几个劣势，一是 SQL 太长了，甚至可能需要分片后批量处理；二是无法充分发挥 PreparedStatement 预编译的优势，SQL 要重新解析且无法复用；三是最终生成的 SQL 太长了，数据库管理器解析这么长的 SQL 也需要时间。 所以我们最终要考虑的就是我们在网络 IO 上花费的时间，是否超过了 SQL 插入的时间？这是我们要考虑的核心问题。 从程序层面上看： 使用事务会比较快一些。 多连接插入会快很多，当读写成为瓶颈的时候，效果就不太明显。 一次插入多条数据也会快很多。 高并发大量插入请求，mysql服务的应对措施是宕机，而不是拒绝请求，mysql在高并发场景，如果承受不住会宕机，这点在设计上需要注意。 2、数据库插入优化基础1）插入无索引表会比插入有索引的表快，毕竟建立索引总是要增加一些额外操作2）插入小表比插入大表快，业务一般插入速度是以条数计算，大表一条记录比较大，需要IO的时间比较长。3）多个连接一起插入会比单连接快，因为mysql不是单线程。4）日志缓存增大可以加快插入速度，因为减少了IO访问次数。5）一次插入多条数据可以加快插入速度。 having和where的区别？都能实现同样的过滤结果？having是在分组后对数据进行过滤where是在分组前对数据进行过滤having后面可以使用聚合函数where后面不可以使用聚合 HAVING子句可以让我们直接筛选成组后的各组数据，也可以在聚合后对组记录进行筛选，而WHERE子句在聚合前先筛选记录，也就是说作用在GROUP BY 子句和HAVING子句前。 explain当Explain 与 SQL语句一起使用时，MySQL 会显示来自优化器关于SQL执行的信息。也就是说，MySQL解释了它将如何处理该语句，包括如何连接表以及什么顺序连接表等。 表的加载顺序 sql 的查询类型 可能用到哪些索引，哪些索引又被实际使用 表与表之间的引用关系 一个表中有多少行被优化器查询 具体字段Explain 执行计划包含字段信息如下：分别是 id、select_type、table、partitions、type、possible_keys、key、key_len、ref、rows、filtered、Extra 12个字段。 idid： ：表示查询中执行select子句或者操作表的顺序，**id的值越大，代表优先级越高，越先执行**。 select_type表示 select 查询的类型，主要是用于区分各种复杂的查询，例如：普通查询、联合查询、子查询等。 SIMPLE：表示最简单的 select 查询语句，也就是在查询中不包含子查询或者 union交并差集等操作。 PRIMARY：当查询语句中包含任何复杂的子部分，最外层查询则被标记为PRIMARY。 SUBQUERY：当 select 或 where 列表中包含了子查询，该子查询被标记为：SUBQUERY 。 DERIVED：表示包含在from子句中的子查询的select，在我们的 from 列表中包含的子查询会被标记为derived 。 UNION：如果union后边又出现的select 语句，则会被标记为union；若 union 包含在 from 子句的子查询中，外层 select 将被标记为 derived。 UNION RESULT：代表从union的临时表中读取数据，而table列的&lt;union1,4&gt;表示用第一个和第四个select的结果进行union操作。 table查询的表名，并不一定是真实存在的表，有别名显示别名，也可能为临时表 partitions查询时匹配到的分区信息，对于非分区表值为NULL，当查询的是分区表时，partitions显示分区表命中的分区情况。 type查询使用了何种类型，它在 SQL优化中是一个非常重要的指标，以下性能从好到坏依次是：system &gt; const &gt; eq_ref &gt; ref &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL system： 当表仅有一行记录时(系统表)，数据量很少，往往不需要进行磁盘IO，速度非常快。 const：表示查询时命中 primary key 主键或者 unique 唯一索引，或者被连接的部分是一个常量(const)值。这类扫描效率极高，返回数据量少，速度非常快。 eq_ref：查询时命中主键primary key 或者 unique key索引， type 就是 eq_ref。 ref：区别于eq_ref ，ref表示使用非唯一性索引，会找到很多个符合条件的行。 ref_or_null：这种连接类型类似于 ref，区别在于 MySQL会额外搜索包含NULL值的行。 index_merge：使用了索引合并优化方法，查询使用了两个以上的索引。 unique_subquery：替换下面的 IN子查询，子查询返回不重复的集合。 index_subquery：区别于unique_subquery，用于非唯一索引，可以返回重复值。 range：使用索引选择行，仅检索给定范围内的行。简单点说就是针对一个有索引的字段，给定范围检索数据。在where语句中使用 bettween...and、&lt;、&gt;、&lt;=、in 等条件查询 type 都是 range。只有对设置了索引的字段，做范围检索 type 才是 range。 index：Index 与ALL 其实都是读全表，区别在于index是遍历索引树读取，而ALL是从硬盘中读取。 ALL：将遍历全表以找到匹配的行，性能最差。 possible_keys表示在MySQL中通过哪些索引，能让我们在表中找到想要的记录，一旦查询涉及到的某个字段上存在索引，则索引将被列出，但这个索引并不定一会是最终查询数据时所被用到的索引。具体请参考上边的例子。 keykey：区别于possible_keys，key是查询中实际使用到的索引，若没有使用索引，显示为NULL。具体请参考上边的例子。 当 type 为 index_merge 时，可能会显示多个索引。 key_lenkey_len：表示查询用到的索引长度（字节数），原则上长度越短越好 。 单列索引，那么需要将整个索引长度算进去； 多列索引，不是所有列都能用到，需要计算查询中实际用到的列。 refref：常见的有：const，func，null，字段名。 当使用常量等值查询，显示const， 当关联查询时，会显示相应关联表的关联字段 如果查询条件使用了表达式、函数，或者条件列发生内部隐式转换，可能显示为func 其他情况null rowsrows：以表的统计信息和索引使用情况，估算要找到我们所需的记录，需要读取的行数。 这是评估SQL 性能的一个比较重要的数据，mysql需要扫描的行数，很直观的显示 SQL 性能的好坏，一般情况下 rows 值越小越好。 filteredfiltered 这个是一个百分比的值，表里符合条件的记录数的百分比。简单点说，这个字段表示存储引擎返回的数据在经过过滤后，剩下满足条件的记录数量的比例。 在MySQL.5.7版本以前想要显示filtered需要使用explain extended命令。MySQL.5.7后，默认explain直接显示partitions和filtered的信息。 ExtraExtra ：不适合在其他列中显示的信息，Explain 中的很多额外的信息会在 Extra 字段显示。 Using index：我们在相应的 select 操作中使用了覆盖索引，通俗一点讲就是查询的列被索引覆盖，使用到覆盖索引查询速度会非常快，SQl优化中理想的状态。 Using where：查询时未找到可用的索引，进而通过where条件过滤获取所需数据，但要注意的是并不是所有带where语句的查询都会显示Using where。 Using temporary：表示查询后结果需要使用临时表来存储，一般在排序或者分组查询时用到。 Using filesort：表示无法利用索引完成的排序操作，也就是ORDER BY的字段没有索引，通常这样的SQL都是需要优化的。 Using join buffer：在我们联表查询的时候，如果表的连接条件没有用到索引，需要有一个连接缓冲区来存储中间结果。 Impossible where：表示在我们用不太正确的where语句，导致没有符合条件的行。 No tables used：我们的查询语句中没有FROM子句，或者有 FROM DUAL子句。 mysql删除数据是真的删除了吗在内部，InnoDB 存储引擎为每行数据添加了三个 隐藏字段： DB_TRX_ID（6字节）：表示最后一次插入或更新该行的事务 id。&#x3D;&#x3D;此外，delete 操作在内部被视为更新，只不过会在记录头 Record header 中的 deleted_flag 字段将其标记为已删除&#x3D;&#x3D; DB_ROLL_PTR（7字节） 回滚指针，指向该行的 undo log 。如果该行未被更新，则为空 DB_ROW_ID（6字节）：如果没有设置主键且该表没有唯一非空索引时，InnoDB 会使用该 id 来生成聚簇索引 在 MySQL 中，当你执行 DELETE 命令删除一条数据时，默认情况下并不会真正地删除数据，而是将其标记为已删除。这是由于 MySQL 使用了一种称为 MVCC（多版本并发控制）的机制来处理并发访问和事务的一致性。 在 MVCC 中，每条记录都会包含一个被称为版本号或时间戳的字段。当你执行 DELETE 命令时，MySQL 会为该记录创建一个新的版本，并将其标记为已删除。这样，已删除的数据仍然存储在磁盘上，但对于普通查询操作，已删除的数据将被隐藏。这种方式称为逻辑删除。 逻辑删除的优点是可以轻松地进行数据恢复和回滚操作。如果有需要，你可以通过特定的查询条件找回已删除的数据。另外，逻辑删除可以更好地保护数据的完整性，并提供审计功能，因为你可以追踪删除操作的历史记录。 然而，逻辑删除也存在一些缺点。首先，已删除的数据仍然占用存储空间，特别是对于大型表来说，可能会导致存储资源的浪费。其次，当进行范围查询时，已删除的数据可能会干扰结果的正确性，因为它们仍然存在于表中。 如果你希望完全删除数据，可以使用 TRUNCATE TABLE 命令或执行物理删除（物理删除是指直接从磁盘上删除数据文件）。但在执行物理删除之前，请务必确保你不再需要这些数据，并且已经备份了必要的数据。此外，物理删除可能会导致性能开销，因为它需要更多的磁盘操作和资源消耗。","categories":[],"tags":[]},{"title":"二维切片使用","slug":"二维切片使用","date":"2024-04-04T07:29:58.000Z","updated":"2024-04-04T07:30:19.000Z","comments":true,"path":"2024/04/04/二维切片使用/","link":"","permalink":"http://peapod.top/2024/04/04/%E4%BA%8C%E7%BB%B4%E5%88%87%E7%89%87%E4%BD%BF%E7%94%A8/","excerpt":"","text":"GO 切片陷阱切片的复制问题，导致新切片和旧切片的底层数组一致，修改会导致底层数组改变。 二维切片的拷贝问题： 12345678// newArr是新切片// matrix是旧切片// copy(目标切片, 原切片)，需要保证目标切片有足够的容量可以容纳。newArr := make([][]int, len(matrix)) for i := range matrix &#123; newArr[i] = make([]int, len(matrix[i])) copy(newArr[i], matrix[i]) &#125;","categories":[],"tags":[]},{"title":"场景知识","slug":"场景知识","date":"2024-04-04T07:28:44.000Z","updated":"2024-04-04T07:29:10.000Z","comments":true,"path":"2024/04/04/场景知识/","link":"","permalink":"http://peapod.top/2024/04/04/%E5%9C%BA%E6%99%AF%E7%9F%A5%E8%AF%86/","excerpt":"","text":"场景知识限流漏桶和令牌桶都是常用的限流算法，用于控制系统的流量，防止系统被过度访问而崩溃。总的来说，漏桶算法适用于需要稳定处理请求的场景，而令牌桶算法适用于需要应对瞬时流量激增的场景。 固定窗口算法劣势：临界时间点产生突发流量，统计数量不准确。 滑动窗口算法滑动窗口算法把间隔时间划分成更小的粒度，当更小粒度的时间间隔过去后，把过去的间隔请求数减掉，再补充一个空的时间间隔。当滑动窗口的格子划分的越多，滑动窗口的滚动就越平滑，限流的统计就会越精确。但滑动窗口的时间间隔（小格子）多了，存储的空间也会增加。 漏桶漏桶算法是一种固定容量的算法，类似于水桶，它可以以恒定的速率流出请求，无论输入速率有多快，最终输出速率都不会超过指定的限制。实现方式是，在服务端维护一个固定容量的队列（即漏桶），并以恒定速率处理请求。如果请求速率过快，请求将被加入到漏桶中，等待服务端处理。当漏桶已满时，新的请求将被丢弃，从而控制了流量。 令牌桶原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。优点是可以应对瞬时流量激增的情况，因为它可以通过调整发放令牌的速率来控制请求的处理速度，但是实现相对漏桶算法更复杂一些。 使用Redis实现令牌桶算法： 首先判断当前令牌桶是否存在，可能是过期或刚启动 如果不存在就创建桶 存在就通过时间计算差计算当前剩余值减一放回，更新时间。 如果桶中剩余数量小于零，返回限流 鉴权JWTJWT( JSON-WEB-TOKEN ) 是比较新的一种登录方式，他利用时间换空间的方式，服务端将用户的信息相关信息进行加密并返回到客户端，即签发了 一个”令牌”，在令牌的有效期内，客户端可以通过传递令牌的方式与服务端通信。 JWT 登录整体流程： 用户输入用户名密码进行登录 服务端验证用户名密码，成功后，将用户的相关信息（通常是 user_id）及一些附加信息通过 JWT 方式进行加密，并返回给客户端。 客户端可以用任意方式储存服务器返回的 JWT ，之后只需在每次请求时，将 JWT 通过某种方式传递给后端。 服务器收到请求后，获取并验证 JWT，从而获取用户的信息（通常是 user_id 及一些附加信息），即服务器不需要储存每个用户的状态（即 session）， 只需要在每次请求时获取并解析 JWT，即可完成用户身份校验和用户基本信息的获取。 JWT默认的传递方式为: 123&quot;headers&quot;: &#123; &#x27;Authorization&#x27;: &#x27;Bearer &#x27; + token // JWT 规定的的表示形式&#125; 特点 JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。不加密的情况下，不要将秘密数据写入 JWT。 JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。 JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。 JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。 后端每次接口请求都需要进行 JWT 的加解密，计算压力增大。 refreshToken就是用来在accessToken过期以后来重新获取accessToken。 Cookie+SessionSession是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中。 Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。 cookie + session 是最传统的登录方式，利用浏览器默认行为，每次请求将登录后设置好的 cookie 发送给服务端， 服务端通过 cookie 中的信息（ session_id），获取用户的登录信息。 整体流程如下： 用户输入用户名密码进行登录 服务端验证用户名密码，成功后，生成唯一的 session_id 储存起来（可以是内存、数据库等，通常使用 redis ）。 通过设置 set-cookie，将 session_id 返回给前端并储存在浏览器 cookie 中。 cookie 过期前，对该系统的每次请求都将会带上 cookie（浏览器默认行为），后端通过 cookie 中的信息，获取用户的 session_id 信息。 并在后端（ redis ）查询出对应用户的信息。 优点 ：原理简单、实现方便 缺点: 服务器端需维护大量 session_id，有一定负担。（目前通常将 session_id 放在 redis中，也解决了服务器集群下 session_id 同步问题） 无法阻止跨站请求伪造CSRF 攻击。 这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。 异步写库实现异步写库可以帮助减轻数据库的压力，提高系统的吞吐量和响应速度。 为了解决这个问题，我把所有的更新、插入数据库的需求，放入一个独立的goroutine中，使用channel进行数据的异步传递，也避免了多个goroutine之间的竞争和锁的使用，使代码更加简洁易于维护。 数据一致性采用先更新数据库再删除缓存的方案。 回写redis先更新数据库再删除缓存，使用双检加锁机制锁住mysql，只让一个线程回写redis，完成数据一致性。 双检加锁双检加锁就是在加锁后再次查询reids缓存，二次查询无数据才去查询mysql。 更新频繁的热点key同一热点key保留2份，A有过期时间，B无 先查询A的，查询不到，则： 后端查询DB更新缓存 查询带后缀返回给调用方 延迟双删先删除缓存在写数据库再延迟一段时间再次删除缓存。 假设A删除完redis缓存，然后更新mysql， 此时B读取数据，redis找不到，读mysql然后回写到redis中 A再次回写redis出现问题，因此在A第一次删除缓存时，延迟一段时间再次删除。 删除缓存失败把要删除的缓存值或者要更新的数据库值暂存到消息队列中，从消息队列中读取这些值，然后再次进行删除或更新。 mysql有改动，立即同步redisMySQL binlog增量订阅消费+消息队列+增量数据更新到redis读Redis，一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。","categories":[],"tags":[]},{"title":"服务器架构演进","slug":"服务器架构演进","date":"2024-04-04T07:27:30.000Z","updated":"2024-04-04T07:28:24.000Z","comments":true,"path":"2024/04/04/服务器架构演进/","link":"","permalink":"http://peapod.top/2024/04/04/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/","excerpt":"","text":"服务架构演进分层架构分层架构模式（Layered Architecture Pattern）是架构模式中最常见的架构模式之一，也称为 n 层架构模式，分层架构模式中的组件被组织成水平层，每个层在应用程序中执行特定的角色（例如，表示逻辑或业务逻辑）。尽管分层架构模式没有指定模式中必须存在的层的数量和类型，但大多数分层架构都包含四个标准层：表示层、业务层、持久层和数据库层。 分层架构特征： 整体敏捷性低 部署成本低 可测试性高 性能低 扩展性低 开发成本低 事件驱动架构事件驱动架构模式（Event-Driven Architecture Pattern）是一种流行的分布式异步架构模式，用于生成高度可扩展的应用程序。它还具有很强的适应性，既可用于小型应用程序，也可用于大型、复杂的应用程序。事件驱动架构由高度分离的、单一用途的事件处理组件组成，这些组件异步接收和处理事件。 事件驱动架构模式由两个主要拓扑结构组成，中介者和代理。 事件驱动架构特征： 整体敏捷性高 部署升本高 可测试性低 性能高 可扩展性高 开发成本低 微服务架构微服务架构模式（Microservices Architecture Pattern）是一种软件架构风格，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent&#x2F;Language agnostic）的API集相互通信。 最重要概念可能是服务组件的概念。服务组件的粒度可以从单个模块到应用程序的大部分。服务组件包含一个或多个模块（例如 Java 类），这些模块代表单一用途功能（例如，提供特定城市或城镇的天气）或大型业务应用程序的独立部分（例如，股票交易配售或确定汽车保险费率）。设计正确级别的服务组件粒度是微服务架构中最大的挑战之一。 由于主要的应用程序组件被拆分成更小的、单独部署的单元，使用微服务架构模式构建的应用程序通常更健壮，提供更好的可扩展性，并且可以更轻松地支持持续交付。 特征： 整体敏捷性高 部署成本高 可测试性高 性能低 可扩展性高 开发成本高 微服务中最重要的就是每个服务的独立与自主，因此服务与服务之间也不应该有所沟通。倘若真有沟通，也应采用异步沟通的方式来避免紧密的相依性问题。","categories":[],"tags":[]},{"title":"GRPC 简介","slug":"GRPC-简介","date":"2024-03-27T08:53:09.000Z","updated":"2024-03-27T09:32:17.000Z","comments":true,"path":"2024/03/27/GRPC-简介/","link":"","permalink":"http://peapod.top/2024/03/27/GRPC-%E7%AE%80%E4%BB%8B/","excerpt":"","text":"GRPC 简介gRPC：gRPC是Google公布的开源项目，基于HTTP2.0协议，并支持常见的众多编程语言。HTTP 2.0协议是基于二进制的HTTP协议的升级版本，gRPC底层使用了Netty框架。 使用gRPC， 可以一次性的在一个.proto文件中定义服务并使用任何支持它的语言去实现客户端和服务端，它们可以应用在各种场景中， gRPC解决了不同语言及环境间通信的复杂性。使用protocol buffers提供高效的序列化、简单的IDL以及容易进行接口更新。总之一句话，使用gRPC可以更容易的编写跨语言的分布式代码。 rpc工作原理RPC（Remote Procedure Call，远程过程调用）是一种分布式计算模型，它允许程序在不同的计算机之间通过网络进行通信和交互，实现像本地调用一样的程序调用和数据传输。RPC通常用于构建分布式系统和微服务架构。 RPC的工作原理可以简单地分为以下几个步骤： 客户端调用远程服务：客户端程序调用本地接口，接口封装了需要执行的操作和参数，然后将请求通过网络发送到远程服务端。 服务端接收请求：远程服务端接收请求，解析请求的内容，根据请求的操作调用相应的方法，执行操作。 服务端返回结果：服务端将执行结果返回给客户端，客户端接收到结果后继续执行。 客户端接收结果：客户端接收到服务端返回的结果，进行处理并返回给调用者。 在这个过程中，RPC通常需要解决以下问题： 远程服务的定位：客户端需要知道远程服务的位置和地址，才能将请求发送到正确的服务端。解决这个问题可以使用命名服务（如DNS）、注册中心等技术。 数据传输和序列化：客户端和服务端之间需要进行数据传输和序列化。RPC框架通常使用网络协议（如HTTP、TCP等）进行数据传输，同时需要将数据序列化成二进制流或其他格式(Protobuf, json)。 异常处理和容错机制：由于网络和远程服务的不确定性，RPC框架需要提供异常处理和容错机制，例如超时重试、故障转移等技术，保证RPC调用的可靠性和稳定性。 rpc 调用基于 sdk 方式，调用方法和出入参协议固定，stub 文件本身还能起到接口文档的作用，很大程度上优化了通信双方约定协议达成共识的成本。 rpc 在传输层协议 tcp 基础之上，可以由实现框架自定义填充应用层协议细节，理论上存在着更高的上限。 gRPC优势RPC（远程过程调用）之所以被称为 “远程”，是因为在微服务架构下，当服务部署到不同的服务器时，它可以实现远程服务之间的通信。从用户的角度来看，它就像一个本地函数调用。 更高的性能：gRPC使用二进制协议，可以比HTTP传输更快地传输数据，可以提高系统的响应速度和吞吐量，特别是在大数据传输和高并发的场景下更为明显。 更小的带宽占用：gRPC使用Protocol Buffers作为数据序列化协议，与XML和JSON相比，它可以将数据更紧凑地编码，从而减少网络带宽的占用，降低系统的网络开销。 gRPC 基于 HTTP&#x2F;2 标准设计，要比传统的http1快 更严格的接口定义：gRPC使用IDL（Interface Definition Language）定义接口，可以清晰地定义每个服务的接口、参数和返回值，并生成相应的代码，降低开发者的开发难度和出错率，同时也增加了接口的可读性和可维护性。 更多的语言支持：gRPC支持多种编程语言，包括Java、C++、Python、Go等，可以让开发者根据自己的喜好和技能选择最适合的编程语言进行开发，提高了开发效率和灵活性。 更好的扩展性和互操作性：gRPC支持负载均衡、流控制和错误处理等功能，可以让开发者轻松地构建高可用的分布式系统，同时也可以与其他系统集成，实现跨平台、跨语言的服务调用。 gRPC工作流程gRPC流程分为四个步骤：定义服务、生成源代码、实现服务、启动服务。首先，需要定义要实现的服务及其接口，使用Protocol Buffers编写接口定义文件。其次，使用编译器生成客户端和服务器端的源代码。然后，实现生成的接口。最后，启动服务器并将其部署在适当的位置。 步骤 1：从客户端发出 REST 调用。请求体通常为 JSON 格式。步骤 2 - 4：订单服务（gRPC 客户端）接收 REST 调用，对其进行转换，然后向支付服务发出 RPC 调用。步骤 5：gRPC 通过 HTTP2 在网络上发送数据包。由于采用了二进制编码和网络优化，gRPC 据说比 JSON 快 5 倍。步骤 6 - 8：支付服务（gRPC 服务器）接收来自网络的数据包，解码后调用服务器应用程序。步骤 9 - 11：结果从服务器应用程序返回，经过编码后发送到传输层。步骤 12 - 14：订单服务接收数据包、解码并将结果发送给客户端应用程序。 http对比rpc 纯裸 TCP 是能收发数据，但它是个无边界的数据流，上层需要定义消息格式用于定义消息边界。于是就有了各种协议，HTTP 和各类 RPC 协议就是在 TCP 之上定义的应用层协议。 RPC 本质上不算是协议，而是一种调用方式，而像 gRPC 和 Thrift 这样的具体实现，才是协议，它们是实现了 RPC 调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时 RPC 有很多种实现方式，不一定非得基于 TCP 协议。 从发展历史来说，HTTP 主要用于 B&#x2F;S 架构，而 RPC 更多用于 C&#x2F;S 架构。但现在其实已经没分那么清了，B&#x2F;S 和 C&#x2F;S 在慢慢融合。很多软件同时支持多端，所以对外一般用 HTTP 协议，而内部集群的微服务之间则采用 RPC 协议进行通讯。 RPC 其实比 HTTP 出现的要早，且比目前主流的 HTTP&#x2F;1.1 性能要更好，所以大部分公司内部都还在使用 RPC。 HTTP&#x2F;2.0 在 HTTP&#x2F;1.1 的基础上做了优化，性能可能比很多 RPC 协议都要好，但由于是这几年才出来的，所以也不太可能取代掉 RPC。 检测 RPC 调用 健康检查和监控： 定期探活 在RPC调用的架构中，可以实现健康检查和监控机制，定期检测RPC服务的可用性和网络连接状态。通过监控系统的指标和警报，可以及时发现并解决网络问题。 日志记录和错误处理： 在RPC调用的代码中，可以添加日志记录功能，以捕获网络相关的错误和异常。通过检查日志，可以查看是否有网络连接失败、超时或其他网络相关的错误信息。 监控网络延迟、丢包、带宽。 grpc通信方式普通rpc：这就是一般的rpc调用，一个请求对象对应一个返回对象，&#x3D;&#x3D;传统的 即刻响应的 &#x3D;&#x3D;服务端流式rpc：一个请求对象，服务端可以传回多个结果对象，&#x3D;&#x3D;入参为流&#x3D;&#x3D;客户端流式rpc：客户端传入多个请求对象，服务端返回一个响应结果，&#x3D;&#x3D;出参为流&#x3D;&#x3D;双向流式rpc：结合客户端流式rpc和服务端流式rpc，可以传入多个对象，返回多个响应对象，&#x3D;&#x3D;出入参均为流&#x3D;&#x3D; grpc通过使用流式（关键字stream）的方式，返回&#x2F;接受多个实例可以用于类似不定长数组的入参和出参 protocol buffersProtobuf是由Google开发的二进制格式，用于在不同服务之间序列化数据。是一种IDL（interface description language）语言。 Protocol Buffers (protobuf) 是 除了 json 和 xml 之外的另一种 数据传输方式。 一条 数据，用 protobuf 序列化后的大小是 json 的 10分之一, 性能却是它的 5~100倍。 支持多种语言 缺点: 由于是 二进制格式 存储的，所以 可读性较差 体积小-无需分隔符 存储方式tag-value不需要分隔符 空白字段可以省略，若字段没有被设置字段值，那么该字段序列化时的数据是完全不存在的，即不需要进行编码，而json会传key和空值的value tag用二进制表示，tag是用字段的数字值然后转换成二进制进行表示的，比json的key用字符串表示更加省空间 编码快，tag的里面存储了字段的类型，可以直接知道value的长度，或者当value是字符串的时候，则用length存储了长度，可以直接从length后取n个字节就是value的值，而如果不知道value的长度，我们就必须要做字符串匹配。主要使用的两种编码方式就是varint和ZigZag 底层Protobuf 是一系列键值对。消息的二进制版本只使用字段的标签作为键，每个字段的名称和声明类型只能在解码结束时通过引用消息类型的定义来确定。 varint和ZigZag的编码方式； 隔断冗余信息的剔除； tag-value方式的存储，tag采用二进制进行存储。 Protobuf协议实现原理 | 学习笔记 (haohtml.com) 和json编码比较而言，protobuf首先就去除了{}””,等标点符号，其次完全没有字段名，而是仅保留了字段的编号。因此protobuf的编码结果会比json的编码结果更小 原始的json数据： 1&#123;&quot;name&quot;:&quot;personJson&quot;,&quot;id&quot;:15,&quot;email&quot;:&quot;personJson@google.com&quot;&#125; 按照之前定义的.proto文件，name编号为1，id编号为2，email编号为3，编码后的结果若翻译成可读的文字来说如下 11personJson2153personJson@google.com 即1号字段的值是personJson，2号字段的值是15，3号字段的值是personJson@google.com 数字编码Varint、数据长度在网络上传递编码成字节的数据时，由于网络传输半包、粘包等等各种因素的存在，如何确定整个数据的长度就是最首要的任务。因为数据大小的不确定性，无法约定固定的字节表示数据长度。例如有时候数据量小于255个字节，那么一个字节就能表示长度，若超过了65535，那么就需要3个字节才能表示数据长度了。 为了解决这个问题，采用了varint编码方式。它约定，每个表示数字字节的最高位若为1，则说明该数字还需要读取下一个字节。若字节的最高位位0，则表示数字的字节读取完毕。而剩下的7位则记录具体的数字。 Varint 是一种紧凑的表示数字的方法。它用一个或多个字节来表示一个数字，值越小的数字使用越少的字节数。这能减少用来表示数字的字节数。 比如对于 int32 类型的数字，一般需要 4 个 byte 来表示。但是采用 Varint，对于很小的 int32 类型的数字，则可以用 1 个 byte 来表示。当然凡事都有好的也有不好的一面，采用 Varint 表示法，大的数字则需要 5 个 byte 来表示。从统计的角度来说，一般不会所有的消息中的数字都是大数，因此大多数情况下，采用 Varint 后，可以用更少的字节数来表示数字信息 Varint 中的每个 byte 的最高位 bit 有特殊的含义，如果该位为 1，表示后续的 byte 也是该数字的一部分；如果该位为 0，则结束。其他的 7 个 bit 都用来表示数字。因此小于 128 的数字都可以用一个 byte 表示。大于 128 的数字，比如 300，会用两个字节来表示： 1010 1100 0000 0010。 另外如果从数据大小角度来看，这种表示方式比真正要代表的数据多了一个bit, 所以其实际传输大小就多14%（1&#x2F;7 &#x3D; 0.142857143），对于这一点我们需要有所了解。 数据编号Message Buffer消息经过序列化后会成为一个二进制数据流，该流中的数据为一系列的 Key-Value 对。如下图所示： 采用这种 Key-Pair 结构无需使用分隔符来分割不同的 Field。对于可选的 Field，如果消息中不存在该 field，那么在最终的 Message Buffer 中就没有该 field，这些特性都有助于节约消息本身的大小。Key 用来标识具体的 field，在解包的时候，客户端创建一个结构对象，Protocol Buffer 从数据流中读取并反序列化数据，并根据 Key 就可以知道相应的 Value 应该对应于结构体中的哪一个 field。 定义模型的.proto文件中，有看到每个字段后面会跟着一个数字。这不表示这个字段的默认值，而是表示这个字段的编号。当编码完成后的字节中，每一个字段的数据之前都会有几个字节表示该数据的编号。 而Key也是由以下两部分组成 Key 的定义如下： (field_number &lt;&lt; 3) | wire_type 可以看到 Key 由两部分组成。第一部分是 field_number。第二部分为 wire_type。表示 Value 的传输类型。 一个字节的低3位表示数据类型，其它位则表示字段序号。 Type Meaning Used For 0 Varint int32, int64, uint32, uint64, sint32, sint64, bool, enum 1 64-bit fixed64, sfixed64, double 2 Length-delimi string, bytes, embedded messages, packed repeated fields 3 Start group Groups (deprecated) 4 End group Groups (deprecated) 5 32-bit fixed32, sfixed32, float Protobuf fixed32类型和int32类型有什么区别?Protobuf 中的 fixed32 类型和 int32 类型之间有以下区别： 数据范围： fixed32 类型是一个无符号的 32 位整数，取值范围为 0 到 2^32-1。 int32 类型是一个带符号的 32 位整数，取值范围为 -2^31 到 2^31-1。 内存占用： fixed32 类型始终占用 4 个字节的内存空间，无论存储的值是多少。 int32 类型使用变长编码进行存储，根据存储的值的大小动态选择所需的字节数，通常情况下会占用更少的内存空间。 符号位处理： fixed32 类型是无符号的，不包含符号位。 int32 类型是带符号的，包含一个符号位，用于表示正数、负数或零。 选择使用 fixed32 还是 int32 取决于你的数据的性质和需求： 如果你的数据范围是非负数，并且需要精确表示 0 到 2^32-1 之间的整数，那么可以选择 fixed32 类型。 如果你的数据范围包括正数、负数和零，并且希望节省存储空间，可以选择 int32 类型。同时，使用变长编码可以在存储较小的值时节省空间。 解码 在消息流中每个Tag都是varint，编码方式为：field_num &lt;&lt; 3 | wire_type。即，Tag由 .proto文件中字段的编号(field_num) 和 **传输类型(wire_type)**两部分组成。 注：Tag也是Varints编码，其后三位是传输类型(wire_type)，之前的数值为是字段编号(field_num)。 注意并不是说Tag只能是一个字节，这里说了Tag也是用Varint编码，显然使用Varint编码方式几千&#x2F;几万的字段序号(field_num)都是可以被表示的。 在对一条消息(message)进行编码的时候是把该消息中所有的key-value对序列化成二进制字节流；key和value分别采用不同的编码方式。 消息的二进制格式只使用消息字段的字段编号(field_num)作为Tag(key&#x2F;键)的一部分，字段名和声名类型只能在解析端通过引用参考消息类型的定义(即.proto文件)才能确定。 解码的时候解码程序(解码器)读入二进制的字节流，解析出每一个key-value对； 如果解码过程中遇到识别不出来的filed_num就直接跳过。这样的机制保证了即使该消息(message)添加了新的字段，也不会影响旧的编&#x2F;解码程序正常工作。 序号的作用 每个字段有唯一编号，在二进制流中标识字段，可以看后面protobuf 编解码原理去了解字段的作用。 消息被使用了，字段就不能改了，改了会造成数据错乱（常见坑)，服务器和客户端很多bug，是proto buffer 文件更改，未使用更改后的协议导致。 1 到 15 范围内的字段编号需要一个字节进行编码，编码结果将同时包含编号和类型 16 到 2047 范围内的字段编号占用两个字节。因此，非常频繁出现的 message 元素保留字段编号 1 到 15。 字段最小数字为1，最大字段数为2^29 - 1。（原因在编码原理那章讲解过，字段数字会作为key，key最后三位是类型） 在 Protocol Buffers（protobuf）中，每个字段后面的序号（Field Number）用于标识和区分不同的字段。每个字段都必须有一个唯一的序号，它在定义消息结构时起到以下几个作用： 标识字段： 序号用于唯一标识消息结构中的每个字段。通过序号，可以清楚地指定消息中的特定字段，从而在序列化和反序列化过程中准确地读取和写入对应的值。 向后兼容性： 序号在 Protocol Buffers 的版本演进中起到重要作用。当你需要向现有的消息结构中添加新字段时，可以使用未使用的序号，这样旧版本的解析器仍然能够正确解析旧的消息，并忽略它们不了解的新字段。 优化编码： 序号还用于优化编码和消息的大小。Protocol Buffers 使用了一种紧凑的二进制编码格式，通过使用序号而不是字段名来进行编码，可以减少序列化后的消息大小，提高网络传输效率。 需要注意的是，序号的分配应该是有规划和稳定的。一旦为字段分配了序号，就应该保持稳定，不要更改或重复使用序号，以确保向后兼容性和正确的解析。 原始的json数据： 1&#123;&quot;name&quot;:&quot;personJson&quot;,&quot;id&quot;:15,&quot;email&quot;:&quot;personJson@google.com&quot;&#125; 按照之前定义的.proto文件，name编号为1，id编号为2，email编号为3，编码后的结果若翻译成可读的文字来说如下 11personJson2153personJson@google.com 即1号字段的值是personJson，2号字段的值是15，3号字段的值是personJson@google.com 拦截器Interceptor拦截器的作用，是在执行核心业务方法的前后，创造出一个统一的切片，来执行所有业务方法锁共有的通用逻辑. 此外，还能够通过这部分通用逻辑的执行结果，来判断是否需要熔断当前的执行链路，以起到所谓的”拦截“效果. 拦截器是gRPC生态中的中间件，可以对RPC的请求和响应进行拦截处理，而且既可以在客户端进行拦截，也可以对服务器端进行拦截。 拦截器可以做统一接口的认证工作，再也不需要每一个接口都做一次认证了，多个接口多次访问，只需要在统一个地方认证即可 分类： 按功能分： 一元拦截器UnaryInterceptor 流式拦截器StreamInterceptor 按端角度分： 客户端拦截器ClientInterceptor 服务端拦截器ServerInterceptor 常见：身份认证、日志框架 序列化和反序列化 序列化： 将数据结构或对象转换成二进制串的过程 反序列化：将在序列化过程中所生成的二进制串转换成数据结构或者对象的过程 性能性能包括两个方面，时间复杂度和空间复杂度： 第一、空间开销（Verbosity）， 序列化需要在原有的数据上加上描述字段，以为反序列化解析之用。如果序列化过程引入的额外开销过高，可能会导致过大的网络，磁盘等各方面的压力。对于海量分布式存储系统，数据量往往以TB为单位，巨大的的额外空间开销意味着高昂的成本。 第二、时间开销（Complexity），复杂的序列化协议会导致较长的解析时间，这可能会使得序列化和反序列化阶段成为整个系统的瓶颈。 JSON总的来说，采用JSON进行序列化的额外空间开销比较大，对于大数据量服务或持久化，这意味着巨大的内存和磁盘开销，这种场景不适合。没有统一可用的IDL降低了对参与方的约束，实际操作中往往只能采用文档方式来进行约定，这可能会给调试带来一些不便，延长开发周期。 由于JSON在一些语言中的序列化和反序列化需要采用反射机制，所以在性能要求为ms级别，不建议使用。 go中解析json就需要反射 ProtobufProtobuf具有广泛的用户基础，空间开销小以及高解析性能是其亮点，非常适合于公司内部的对性能要求高的RPC调用。由于Protobuf提供了标准的IDL以及对应的编译器，其IDL文件是参与各方的非常强的业务约束，另外，Protobuf与传输层无关，采用HTTP具有良好的跨防火墙的访问属性，所以Protobuf也适用于公司间对性能要求比较高的场景。由于其解析性能高，序列化后数据量相对少，非常适合应用层对象的持久化场景。 Protobuf 是一系列键值对。消息的二进制版本只使用字段的标签作为键，每个字段的名称和声明类型只能在解码结束时通过引用消息类型的定义来确定。","categories":[],"tags":[{"name":"GRPC","slug":"GRPC","permalink":"http://peapod.top/tags/GRPC/"}]},{"title":"Go http包详解","slug":"Go-http包详解","date":"2024-03-21T09:59:01.000Z","updated":"2024-04-06T06:39:30.000Z","comments":true,"path":"2024/03/21/Go-http包详解/","link":"","permalink":"http://peapod.top/2024/03/21/Go-http%E5%8C%85%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"http包详解http包运行机制基础概念： Request：用户请求的信息，用来解析用户的请求信息，包括post、get、cookie、url等信息 Response：服务器需要反馈给客户端的信息 Conn：用户的每次请求链接 Handler：处理请求和生成返回信息的处理逻辑 工作流程： 创建Listen Socket, 监听指定的端口, 等待客户端请求到来。 Listen Socket接受客户端的请求, 得到Client Socket, 接下来通过Client Socket与客户端通信。 处理客户端的请求, 首先从Client Socket读取HTTP请求的协议头, 如果是POST方法, 还可能要读取客户端提交的数据, 然后交给相应的handler处理请求, handler处理完毕准备好客户端需要的数据, 通过Client Socket写给客户端。 监听端口初始化一个server对象，然后调用了net.Listen(&quot;tcp&quot;, addr)，底层用TCP协议搭建服务，监控设置的端口。 1234567891011121314151617181920212223242526272829func (srv *Server) Serve(l net.Listener) error &#123; defer l.Close() var tempDelay time.Duration // how long to sleep on accept failure for &#123; rw, e := l.Accept() if e != nil &#123; if ne, ok := e.(net.Error); ok &amp;&amp; ne.Temporary() &#123; if tempDelay == 0 &#123; tempDelay = 5 * time.Millisecond &#125; else &#123; tempDelay *= 2 &#125; if max := 1 * time.Second; tempDelay &gt; max &#123; tempDelay = max &#125; log.Printf(&quot;http: Accept error: %v; retrying in %v&quot;, e, tempDelay) time.Sleep(tempDelay) continue &#125; return e &#125; tempDelay = 0 c, err := srv.newConn(rw) if err != nil &#123; continue &#125; go c.serve() &#125;&#125; 接收请求调用了srv.Serve(net.Listener)函数，这个函数就是处理接收客户端的请求信息。这个函数里面起了一个for&#123;&#125;，首先通过Listener接收请求，其次创建一个Conn，最后单独开了一个goroutine，把这个请求的数据当做参数扔给这个conn去服务：go c.serve()。 分配handlerconn首先会解析request:c.readRequest(),然后获取相应的handler:handler := c.server.Handler，也就是在调用函数ListenAndServe时候的第二个参数，传递的是nil，也就是为空，那么默认获取handler = DefaultServeMux,这个变量就是一个路由器，它用来匹配url跳转到其相应的handle函数，调用http.HandleFunc(&quot;/&quot;, sayhelloName)，这个作用就是注册了请求/的路由规则，当请求uri为”&#x2F;“，路由就会转到函数sayhelloName，DefaultServeMux会调用ServeHTTP方法，这个方法内部其实就是调用sayhelloName本身，最后通过写入response的信息反馈到客户端。 流程 客户端的每次请求都会创建一个Conn，这个Conn里面保存了该次请求的信息，然后再传递到对应的handler，该handler中便可以读取到相应的header信息，这样保证了每个请求的独立性。 路由器12345type ServeMux struct &#123; mu sync.RWMutex //锁，由于请求涉及到并发处理，因此这里需要一个锁机制 m map[string]muxEntry // 路由规则，一个string对应一个mux实体，这里的string就是注册的路由表达式 hosts bool // 是否在任意的规则中带有host信息&#125; muxEntry： 12345type muxEntry struct &#123; explicit bool // 是否精确匹配 h Handler // 这个路由表达式对应哪个handler pattern string //匹配字符串&#125; Handler的定义： 123type Handler interface &#123; ServeHTTP(ResponseWriter, *Request) // 路由实现器&#125; http包里面还定义了一个类型HandlerFunc,定义的函数sayhelloName就是这个HandlerFunc调用之后的结果，这个类型默认就实现了ServeHTTP这个接口，即调用HandlerFunc(f),强制类型转换f成为HandlerFunc类型，这样f就拥有了ServeHTTP方法。 123456type HandlerFunc func(ResponseWriter, *Request)// ServeHTTP calls f(w, r).func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) &#123; f(w, r)&#125; 请求分发默认的路由器实现了ServeHTTP： 123456789func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) &#123; if r.RequestURI == &quot;*&quot; &#123; w.Header().Set(&quot;Connection&quot;, &quot;close&quot;) w.WriteHeader(StatusBadRequest) return &#125; h, _ := mux.Handler(r) h.ServeHTTP(w, r)&#125; 调用mux.Handler(r)返回对应设置路由的处理Handler，然后执行h.ServeHTTP(w, r) 也就是调用对应路由的handler的ServerHTTP接口。 mux.Handler(r)返回过程： 1234567891011121314151617181920212223242526func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) &#123; if r.Method != &quot;CONNECT&quot; &#123; if p := cleanPath(r.URL.Path); p != r.URL.Path &#123; _, pattern = mux.handler(r.Host, p) return RedirectHandler(p, StatusMovedPermanently), pattern &#125; &#125; return mux.handler(r.Host, r.URL.Path)&#125;func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) &#123; mux.mu.RLock() defer mux.mu.RUnlock() // Host-specific pattern takes precedence over generic ones if mux.hosts &#123; h, pattern = mux.match(host + path) &#125; if h == nil &#123; h, pattern = mux.match(path) &#125; if h == nil &#123; h, pattern = NotFoundHandler(), &quot;&quot; &#125; return&#125; 根据用户请求的URL和路由器里面存储的map去匹配的，当匹配到之后返回存储的handler，调用这个handler的ServeHTTP接口就可以执行到相应的函数。 总结 首先调用Http.HandleFunc() 1 调用了DefaultServeMux的HandleFunc 2 调用了DefaultServeMux的Handle 3 往DefaultServeMux的map[string]muxEntry中增加对应的handler和路由规则 调用http.ListenAndServe() 1 实例化Server 2 调用Server的ListenAndServe() 3 调用net.Listen(“tcp”, addr)监听端口 4 启动一个for循环，在循环体中Accept请求 5 对每个请求实例化一个Conn，并且开启一个goroutine为这个请求进行服务go c.serve() 6 读取每个请求的内容w, err :&#x3D; c.readRequest() 7 判断handler是否为空，如果没有设置handler（这个例子就没有设置handler），handler就设置为DefaultServeMux 8 调用handler的ServeHttp","categories":[{"name":"golang标准库","slug":"golang标准库","permalink":"http://peapod.top/categories/golang%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Mysql事物与锁","slug":"Mysql事物与锁","date":"2024-03-19T02:32:46.000Z","updated":"2024-03-19T06:28:09.000Z","comments":true,"path":"2024/03/19/Mysql事物与锁/","link":"","permalink":"http://peapod.top/2024/03/19/Mysql%E4%BA%8B%E7%89%A9%E4%B8%8E%E9%94%81/","excerpt":"","text":"事物与锁事物当多个用户访问同一数据时，一个用户在更改数据的过程中可能有其它用户同时发起更改请求，为保证数据的一致性状态，MySQL 引入了事务。 事务可以将一系列的数据操作捆绑成一个整体进行统一管理，如果某一事务执行成功，则在该事务中进行的所有数据更改均会提交，成为数据库中的永久组成部分。如果事务执行时遇到错误，则就必须取消或回滚。取消或回滚后，数据将全部恢复到操作前的状态，所有数据的更改均被清除。 数据库的事务（Transaction）是一种机制、一个操作序列，包含了一组数据库操作命令。 事务具有 4 个特性，即原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。 支持事务的存储引擎有 InnoDB 和 BDB，其中，InnoDB 存储引擎事务主要通过 UNDO 日志和 REDO 日志实现，MyISAM 存储引擎不支持事务。 日志操作： UNDO 日志：复制事务执行前的数据，用于在事务发生异常时回滚数据。 REDO 日志：记录在事务执行中，每条对数据进行更新的操作，当事务提交时，该内容将被刷新到磁盘。 默认设置下，每条 SQL 语句就是一个事务，即执行 SQL 语句后自动提交。 用 BEGIN 或 START TRANSACTION 开启一个事务，或者禁止当前会话的自动提交。 事物执行语法123456// 显式地标记一个事务的起始点。BEGIN;// 将事务中所有对数据库的更新都写到磁盘上的物理数据库中，事务正常结束。COMMIT;// 回滚到事务开始时的状态。 ROLLBACK; BEGIN 或 START TRANSACTION 语句后面的 SQL 语句对数据库数据的更新操作都将记录在事务日志中，直至遇到 ROLLBACK 语句或 COMMIT 语句。 如果事务中某一操作失败且执行了 ROLLBACK 语句，那么在开启事务语句之后所有更新的数据都能回滚到事务开始前的状态。 如果事务中的所有操作都全部正确完成，并且使用了 COMMIT 语句向数据库提交更新数据，则此时的数据又处在新的一致状态。 注意： 事务尽可能简短 事务中访问的数据量尽量最少 查询数据时尽量不要使用事务 在事务处理过程中尽量不要出现等待用户输入的操作 MySQL 默认开启事务自动提交模式，每条 SOL 语句都会被当做一个单独的事务自动执行。 关闭自动提交后，该位置会作为一个事务起点，直到执行 COMMIT 语句和 ROLLBACK 语句后，该事务才结束。结束之后，这就是下一个事务的起点。 事物隔离事务的隔离性就是指当多个事务同时运行时，各事务之间相互隔离，不可互相干扰。 事务并发时就容易出现脏读、不可重复读和幻读等情况。 脏读是指一个事务正在访问数据，并且对数据进行了修改，但是这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 在这个事务还没有结束时，另外一个事务也访问了该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 幻读是指当事务不是独立执行时发生的一种现象。 事务隔离级别如下： 读未提交（READ UNCOMITTED） 读提交（READ COMMITTED） 可重复读（REPEATABLE READ） 串行化（SERIALIZABLE） 如果一个事务读取到了另一个未提交事务修改过的数据，那么这种隔离级别就称之为读未提交。 读提交就是只能读到已经提交了的内容。满足了隔离的简单定义：一个事务从开始到提交前所做的任何改变都是不可见的，事务只能读取到已经提交的事务所做的改变。 可重复读是 MySQL 的默认事务隔离级别，它能确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。在该隔离级别下，如果有事务正在读取数据，就不允许有其它事务进行修改操作，这样就解决了可重复读问题。 如果一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来。那么这种隔离级别就称之为串行化。 SERIALIZABLE 是最高的事务隔离级别，主要通过强制事务排序来解决幻读问题。简单来说，就是在每个读取的数据行上加上共享锁实现，这样就避免了脏读、不可重复读和幻读等问题。 锁机制锁机制是为了解决数据库的并发控制问题而产生的。 按锁级别分类，可分为共享锁、排他锁和意向锁。 按锁粒度分类，可分为行级锁、表级锁和页级锁。 共享锁的代号是 S，也可称为读锁。是一种可以查看但无法修改和删除的数据锁。共享锁的锁粒度是行或者元组（多个行）。一个事务获取了共享锁之后，可以对锁定范围内的数据执行读操作。会阻止其它事务获得相同数据集的排他锁。 排他锁的代号是 X，是 eXclusive 的缩写，也可称为写锁，是基本的锁类型。粒度与共享锁相同，也是行或者元组。一个事务获取了排他锁之后，可以对锁定范围内的数据执行写操作。允许获得排他锁的事务更新数据，阻止其它事务取得相同数据集的共享锁和排他锁。 意向锁是一种表锁，锁定的粒度是整张表，分为意向共享锁（IS）和意向排他锁（IX）两类。 “有意”表示事务想执行操作但还没有真正执行。 锁和锁之间的关系，要么是相容的，要么是互斥的。 锁 a 和锁 b 相容是指：操作同样一组数据时，如果事务 t1 获取了锁 a，另一个事务 t2 还可以获取锁 b； 锁 a 和锁 b 互斥是指：操作同样一组数据时，如果事务 t1 获取了锁 a，另一个事务 t2 在 t1 释放锁 a 之前无法释放锁 b。 如果一个事务请求的锁模式与当前的锁兼容，InnoDB 就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。 表锁、行锁和页锁MySQL 按锁的粒度可以细分为行级锁、页级锁和表级锁。 锁粒度表示锁范围。 表级锁为表级别的锁定，会锁定整张表，可以很好的避免死锁，是 MySQL 中最大颗粒度的锁定机制。 一个用户在对表进行写操作（插入、删除、更新等）时，需要先获得写锁，这会阻塞其它用户对该表的所有读写操作。没有写锁时，其它读取的用户才能获得读锁，读锁之间是不相互阻塞的。 使用表级锁的主要是 MyISAM，MEMORY，CSV 等一些非事务性存储引擎。 页级锁的颗粒度介于行级锁与表级锁之间，所以获取锁定所需要的资源开销，以及所能提供的并发处理能力同样也是介于上面二者之间。另外，页级锁和行级锁一样，会发生死锁。 页级锁主要应用于 BDB 存储引擎。 行级锁的锁定颗粒度在 MySQL 中是最小的，只针对操作的当前行进行加锁，所以行级锁发生锁定资源争用的概率也最小。行级锁也最容易发生死锁。 行级锁主要应用于 InnoDB 存储引擎。 表级锁适合以查询为主，只有少量按索引条件更新数据的应用，如 Web 应用。而行级锁更适合于有大量按索引条件，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。 表级锁 行级锁 页级锁 开销 小 大 介于表级锁和行级锁之间 加锁 快 慢 介于表级锁和行级锁之间 死锁 不会出现死锁 会出现死锁 会出现死锁 锁粒度 大 小 介于表级锁和行级锁之间 并发度 低 高 一般 InnoDB的3种行锁通过给索引上的索引项加锁来实现，如果没有索引，InnoDB 将通过隐藏的聚簇索引来对记录加锁。 支持 3 种行锁定方式： 行锁（Record Lock）：直接对索引项加锁。 间隙锁（Gap Lock）：锁加在索引项之间的间隙，也可以是第一条记录前的“间隙”或最后一条记录后的“间隙”。 Next-Key Lock：行锁与间隙锁组合起来用就叫做 Next-Key Lock。 默认情况下，InnoDB 工作在可重复读（默认隔离级别）下，并且以 Next-Key Lock 的方式对数据行进行加锁，这样可以有效防止幻读的发生。 Next-Key Lock 是行锁与间隙锁的组合，这样，当 InnoDB 扫描索引项的时候，会首先对选中的索引项加上行锁（Record Lock），再对索引项两边的间隙（向左扫描扫到第一个比给定参数小的值， 向右扫描扫到第一个比给定参数大的值， 然后以此为界，构建一个区间）加上间隙锁（Gap Lock）。如果一个间隙被事务 T1 加了锁，其它事务不能在这个间隙插入记录。 禁止间隙锁的话，可以把隔离级别降为读已提交（READ COMMITTED），或者开启参数 innodb_locks_unsafe_for_binlog。 开启一个事务时，InnoDB 存储引擎会在更新的记录上加行级锁，此时其它事务不可以更新被锁定的记录。 死锁是指两个或两个以上的事务在执行过程中，因争夺资源而造成的一种互相等待的现象。 几种避免死锁的方法： 如果不同程序会并发存取多个表，或者涉及多行记录时，尽量约定以相同的顺序访问表，这样可以大大降低死锁的发生。 业务中要及时提交或者回滚事务，可减少死锁产生的概率。 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率。 对于非常容易产生死锁的业务部分，可以尝试使用升级锁粒度，通过表锁定来减少死锁产生的概率（表级锁不会产生死锁）。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://peapod.top/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://peapod.top/tags/mysql/"}],"author":"taweizhong"},{"title":"redis 基础数据类型","slug":"redis-基础数据类型","date":"2024-03-17T09:18:14.000Z","updated":"2024-03-17T09:55:12.000Z","comments":true,"path":"2024/03/17/redis-基础数据类型/","link":"","permalink":"http://peapod.top/2024/03/17/redis-%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"redis 数据类型redis简介Remote Dictionary Server（即远程字典服务），它是一个基于内存实现的键值型非关系（NoSQL）数据库。 具有以下特点： Redis 不仅可以将数据完全保存在内存中，还可以通过磁盘实现数据的持久存储； Redis 支持丰富的数据类型，包括 string、list、set、zset、hash 等多种数据类型，因此它也被称为“数据结构服务器”； Redis 支持主从同步，即 master-slave 主从复制模式。数据可以从主服务器向任意数量的从服务器上同步，有效地保证数据的安全性； Redis 支持多种编程语言，包括 C、C++、Python、Java、PHP、Ruby、Lua 等语言。 Redis体系架构主要分为两个部分： Redis服务端：能够把数据存储到内存中，并且起到管理数据的作用。 Redis客户端：连接服务端。 启动redis服务端： 1redis-server 启动redis客户端： 12redis-cli -h [ip] -p [port] -a [password] redis-cli 数据类型是 Value（值） 的数据类型，而非 key。 key 的类型对应着 value 的类型，同样也有五种（string、list、hash、set、zset）。 在 key 的取值上，使用“见名知意”的字符串格式，便于理解 key 的含义。 定时策略：Redis 会把每个设置了过期时间的 key 存放到一个独立的字典中，并且会定时遍历这个字典来删除到期的 key。 惰性策略：当客户端访问这个 key 的时候，Redis 对 key 的过期时间进行检查，如果过期了就立即删除。 Redis 使用两种方式相结合的方法来处理过去的 key。 string 字符串string 结构String 是 Redis 最基本的数据类型。字符串是一组字节，一个字符串类型的值最多能够存储 512 MB 的内容。String 的实现属于特殊结构 SDS（Simple Dynamic String）即简单动态字符串） 结构定义： 12345678struct sdshdr&#123; //记录buf数组中已使用字符的数量，等于 SDS 保存字符串的长度 int len; //记录 buf 数组中未使用的字符数量 int free; //字符数组，用于保存字符串 char buf[];&#125; 将字符串存储到字符类型的buf[]中，并使用 len、free对buf[]数组的长度和未使用的字符数进行描述。 当字符串所占空间小于 1MB 时，Redis 对字符串存储空间的扩容是以成倍的方式增加的；而当所占空间超过 1MB 时，每次扩容只增加 1MB。Redis 字符串允许的最大值字节数是 512 MB。 string命令1SET key value [EX seconds|PX milliseconds] [NX|XX] 其含义如下所示： EX seconds：设置指定的过期时间，以秒为单位； PX milliseconds：设置指定的过期时间，以毫秒为单位； NX：先判断 key 是否存在，如果 key 不存在，则设置 key 与 value； XX：先判断 key 是否存在，如果 key 存在，则重新设置 value。 string 类型提供了一些专门操作数值的命令，比如 INCRBY（自增）、DECRBR（自减）、INCR（加1） 和 DECR（减1） 等命令。此时 key 对应的 value 值是必须是一个整数，或浮点数，使用命令对这个数值进行自增或自减操作。 INCRBYFLOAT该命令是 string 中唯一操作浮点数的命令，浮点数可以为正数或者负数，从而实现对数值的加减操作。 1INCRBYFLOAT fans:num -10.5 hash 散列hash 结构一个包含了多个键值对的集合。一般被用来存储对象。hash（哈希散列）是由字符类型的 field（字段）和 value 组成的哈希映射表结构（也称散列表），在 hash 类型中，field 与 value 一一对应，且不允许重复。 对 value 进行查询时，这个值只能以字符串的形式返回。 其底层存储结构有两种实现方式。 第一种，当存储的数据量较少的时，hash 采用 ziplist 作为底层存储结构，此时要求符合以下两个条件： 哈希对象保存的所有键值对（键和值）的字符串长度总和小于 64 个字节。 哈希对象保存的键值对数量要小于 512 个。 第二种，dict（字典结构）是一个无序的字典，并采用了数组和链表相结合的方式存储数据。dict 是基于哈希表算法实现的，因此其查找性能非常高效，其时间复杂度为 O(1)。 list列表list 结构List 中的元素是字符串类型，其中的元素按照插入顺序进行排列，允许重复插入。可以添加一个元素到列表的头部（左边）或者尾部（右边）。 是一个链表而非数组，其插入、删除元素的时间复杂度为 O(1)，但是查询速度欠佳，时间复杂度为 O(n)。 Redis 列表的底层存储结构，是一个快速链表（quicklist）的结构。当列表中存储的元素较少时，Redis 会使用一块连续的内存来存储这些元素，这个连续的结构被称为 ziplist（压缩列表），它将所有的元素紧挨着一起存储。当数据量较大时，Redis 列表就会是用 quicklist（快速链表）存储元素。 队列和栈实现右进左出（队列） 123Rpush book c python javalpop booklpop book 右进右出（栈） 123RPUSH book c python javarpop bookrpop book set集合set 结构Set 是一个字符串类型元素构成的无序集合。在 Redis 中，集合是通过哈希映射表实现的，所以无论是添加元素、删除元素，亦或是查找元素，它们的时间复杂度都为 O(1)。 当集合中最后一个成员被删除时，存储成员所用的数据结构也会被自动删除。 底层存储结构，分别是 intset（整型数组）与 hash table（哈希表），当 set 存储的数据满足以下要求时，使用 intset 结构： 集合内保存的所有成员都是整数值； 集合内保存的成员数量不超过 512 个。 当不满足上述要求时，则使用 hash table 结构。 intset 的结构体定义： 12345typedf struct inset&#123; uint32_t encoding;//指定编码方式，默认为INSET_ENC_INT16 uint32_t length;//集合内成员的总个数 int8_t contents[];//实际存储成员的数组，并且数组中的数值从小到大依次排列&#125;inset; zset有序集合zset 结构zset 是一个字符串类型元素构成的有序集合，集合中的元素不仅具有唯一性，而且每个元素还会关联一 个 double 类型的分数，该分数允许重复。Redis 通过这个分数来为集合中的成员排序。适用于排行榜类型的业务场景。 使用了两种不同的存储结构，分别是 zipList（压缩列表）和 skipList（跳跃列表），当 压缩列表： 成员的数量小于128 个； 每个 member （成员）的字符串长度都小于 64 个字节。 如下： zlbytes 是一个无符号整数，表示当前 ziplist 占用的总字节数； zltail 指的是压缩列表尾部元素相对于压缩列表起始元素的偏移量。 zllen 指 ziplist 中 entry 的数量。当 zllen 比2^16 - 2大时，需要完全遍历 entry 列表来获取 entry 的总数目。 entry 用来存放具体的数据项（score和member），长度不定，可以是字节数组或整数，entry 会根据成员的数量自动扩容。 zlend 是一个单字节的特殊值，等于 255，起到标识 ziplist 内存结束点的作用。 跳跃列表（skipList）又称“跳表”是一种基于链表实现的随机化数据结构，其插入、删除、查找的时间复杂度均为 O(logN)。 skipList 节点最高可以达到 64 层，一个“跳表”中最多可以存储 2^64 个元素，每个节点都是一个 skiplistNode（跳表节点）。 skipList 的结构体定义： 12345678910typedf struct zskiplist&#123; //头节点 struct zskiplistNode *header; //尾节点 struct zskiplistNode *tail; // 跳表中的元素个数 unsigned long length; //表内节点的最大层数 int level;&#125;zskiplist; header：指向 skiplist 的头节点指针，通过它可以直接找到跳表的头节点，时间复杂度为 O(1)； tail：指向 skiplist 的尾节点指针，通过它可以直接找到跳表的尾节点，时间复杂度为 O(1)； length：记录 skiplist 的长度，也就跳表中有多少个元素，但不包括头节点； level：记录当前跳表内所有节点中的最大层数（level）；","categories":[{"name":"数据库","slug":"数据库","permalink":"http://peapod.top/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://peapod.top/tags/redis/"}],"author":"taweizhong"},{"title":"blog标准化","slug":"blog标准化","date":"2024-03-17T07:43:56.000Z","updated":"2024-03-27T12:52:43.000Z","comments":true,"path":"2024/03/17/blog标准化/","link":"","permalink":"http://peapod.top/2024/03/17/blog%E6%A0%87%E5%87%86%E5%8C%96/","excerpt":"","text":"blog标准化标签标签使用已经生成的标签，每种相关框架作为单独标签使用。标签名字使用英文标识，简单、可以快速检索。 分类分类使用中文标识，分类应该精简，可以代表大部分的文章，不超过10种。","categories":[],"tags":[{"name":"blog","slug":"blog","permalink":"http://peapod.top/tags/blog/"}],"author":"taweizhong"},{"title":"io多路复用","slug":"io多路复用","date":"2024-03-17T06:44:15.000Z","updated":"2025-04-18T09:22:27.778Z","comments":true,"path":"2024/03/17/io多路复用/","link":"","permalink":"http://peapod.top/2024/03/17/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","excerpt":"","text":"I&#x2F;O 多路复用：select&#x2F;poll&#x2F;epollSocket 模型(基于 TCP 的 Socket 编程)服务端：服务端首先调用 socket() 函数，创建网络协议为 IPv4，以及传输协议为 TCP 的 Socket ，接着调用 bind() 函数，给这个 Socket 绑定一个 IP 地址和端口，绑定完 IP 地址和端口后，就可以调用 listen() 函数进行监听，进入了监听状态后，通过调用 accept() 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。 客户端：客户端在创建好 Socket 后，调用 connect() 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，开始TCP 三次握手建立连接。 服务端的 accept() 函数，从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket。 在内核中 Socket 是以「文件」的形式存在的，有对应的文件描述符。内核可以通过文件描述符找到对应打开的文件。在 Linux 下，单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024 TCP Socket 调用流程是最简单、最基本的，它基本只能一对一通信，因为使用的是同步阻塞的方式，当服务端在还没处理完一个客户端的网络 I&#x2F;O 时，或者读写操作发生阻塞时，其他客户端是无法与服务端连接的。 TCP 连接是由四元组唯一确认的，这个四元组就是：本机IP, 本机端口, 对端IP, 对端端口。 多进程模型服务器的主进程负责监听客户的连接，一旦与客户端连接完成，accept() 函数就会返回一个「已连接 Socket」，这时就通过 fork() 函数创建一个子进程，实际上就把父进程所有相关的东西都复制一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。 根据返回值来区分是父进程还是子进程，如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。 有两种方式可以在子进程退出后回收资源，分别是调用 wait() 和 waitpid() 函数。进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。 多线程模型线程是运行在进程中的一个“逻辑流”，单进程中可以运行多个线程，同进程里的线程可以共享进程的部分资源，比如文件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享些资源在上下文切换时不需要切换，而只需要切换线程的私有数据、寄存器等不共享的数据，因此同一个进程下的线程上下文切换的开销要比进程小得多。 当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。 使用线程池的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当由新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出「已连接 Socket 」进行处理。 了避免多线程竞争，线程在操作这个队列前要加锁。 I&#x2F;O 多路复用多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。 select&#x2F;poll&#x2F;epoll 这是三个多路复用接口。 select&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。 select&#x2F;poll&#x2F;epoll 获取网络事件：在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。 select&#x2F;pollselect 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。 需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 select 使用固定长度的 BitsMap，表示文件描述符集合。poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。 都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合。 epoll先用epoll_create 创建一个 epoll对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据。 12345678910111213int s = socket(AF_INET, SOCK_STREAM, 0);bind(s, ...);listen(s, ...)int epfd = epoll_create(...);epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中while(1) &#123; int n = epoll_wait(...); for(接收到数据的socket)&#123; //处理 &#125;&#125; 第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。减少了内核和用户空间大量的数据拷贝和内存分配。 第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。 边缘触发和水平触发epoll 支持两种事件触发模式，分别是**边缘触发（*edge-triggered，ET*）**和**水平触发（*level-triggered，LT*）**。 水平触发:只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户。边缘触发:只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。 原文：https://www.xiaolincoding.com/os/8_network_system/selete_poll_epoll.html#%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9A%84-socket-%E6%A8%A1%E5%9E%8B","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/tags/%E7%AC%94%E8%AE%B0/"}],"author":"taweizhong"},{"title":"GO缓存","slug":"GO缓存","date":"2024-03-16T02:49:46.000Z","updated":"2024-03-16T02:50:53.000Z","comments":true,"path":"2024/03/16/GO缓存/","link":"","permalink":"http://peapod.top/2024/03/16/GO%E7%BC%93%E5%AD%98/","excerpt":"","text":"本地缓存实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150package mainimport ( &quot;fmt&quot; &quot;strconv&quot; &quot;sync&quot; &quot;time&quot;)type Cache interface &#123;// 添加缓存项，并设置过期时间Set(key string, val interface&#123;&#125;, expire time.Duration) // 获取缓存项Get(key string) (interface&#123;&#125;, bool)// 删除缓存项Del(key string) bool// 判断是否存在Exists(key string) bool// 刷新缓存Flush() bool// 获取键Keys() int64&#125;type CacheItem struct &#123; value interface&#123;&#125; expAt time.Time creAt time.Time&#125;func (c CacheItem) Size() int64 &#123; // 计算存储的数据所占用的内存大小 var dataSize int64switch v := c.value.(type) &#123; case string: dataSize = int64(len(v)) case int: dataSize = int64(8) case bool: dataSize = int64(1) default: dataSize = 1024 &#125; return dataSize + int64(2*24)&#125;type MCache struct &#123; CItems map[string]CacheItem MaxM int64 CurM int64 mutex sync.Mutex&#125;func NewCache() *MCache &#123; return &amp;MCache&#123; CItems: make(map[string]CacheItem), &#125;&#125;func (m *MCache) Set(key string, value interface&#123;&#125;) &#123; m.SetDefault(key, value, 10*time.Minute)&#125;func (m *MCache) SetDefault(key string, value interface&#123;&#125;, exp time.Duration) &#123; m.mutex.Lock() defer m.mutex.Unlock() if _, ok := m.CItems[key]; ok &#123; m.CurM -= int64(len(key)) + m.CItems[key].Size() &#125; m.CItems[key] = CacheItem&#123; value: value, expAt: time.Now().Add(exp), creAt: time.Now(), &#125; m.CurM += int64(len(key)) + m.CItems[key].Size() m.overCache()&#125;func (m *MCache) Get(key string) (interface&#123;&#125;, bool) &#123; m.mutex.Lock() defer m.mutex.Unlock() item, ok := m.CItems[key] if !ok || time.Now().After(item.expAt) &#123; return nil, false &#125; return item.value, true&#125;func (m *MCache) Del(key string) bool &#123; m.mutex.Lock() defer m.mutex.Unlock() _, ok := m.CItems[key] if !ok &#123; return false &#125; m.CurM -= int64(len(key)) + m.CItems[key].Size() delete(m.CItems, key) return true&#125;func (m *MCache) Exists(key string) bool &#123; m.mutex.Lock() defer m.mutex.Unlock() _, ok := m.CItems[key]return ok &#125;func (m *MCache) Flush() bool &#123; m.mutex.Lock() defer m.mutex.Unlock() m.CItems = make(map[string]CacheItem) m.CurM = 0 return true&#125;func (m *MCache) Keys() int64 &#123; m.mutex.Lock() defer m.mutex.Unlock() return int64(len(m.CItems))&#125;// 100KB 1MB 2MB 1GBfunc (m *MCache) SetMaxMemory(size string) bool &#123; s1 := size[:2] num, _ := strconv.Atoi(s1) unit := size[len(size)-2:] switch unit &#123; case &quot;KB&quot;: m.MaxM = 1024 * int64(num) return true case &quot;MB&quot;: m.MaxM = 1024 * 1024 * int64(num) return true case &quot;GB&quot;: m.MaxM = 1024 * 1024 * 1024 * int64(num) return true default: return false &#125;&#125;func (m *MCache) overCache() &#123; for m.CurM &gt; m.MaxM &#123; oldKey := &quot;&quot; oldTime := time.Time&#123;&#125; for key, cacheItem := range m.CItems &#123; if cacheItem.creAt.Before(oldTime) &#123; oldKey = key oldTime = cacheItem.creAt&#125; &#125; m.CurM -= int64(len(oldKey)) + m.CItems[oldKey].Size() delete(m.CItems, oldKey) &#125;&#125; func main() &#123; cache := NewCache() cache.SetMaxMemory(&quot;100MB&quot;) cache.Set(&quot;int&quot;, 1) cache.Set(&quot;bool&quot;, false) cache.Set(&quot;data&quot;, map[string]interface&#123;&#125;&#123;&quot;a&quot;: 1&#125;) if val, ok := cache.Get(&quot;int&quot;); ok &#123; fmt.Printf(&quot;key:%s, value:%d \\n&quot;, &quot;int&quot;, val) &#125; cache.Del(&quot;int&quot;) fmt.Print(cache.Keys()) //cache.Flush()&#125;","categories":[],"tags":[]},{"title":"ECS框架","slug":"ECS框架","date":"2024-03-16T02:48:46.000Z","updated":"2024-03-16T02:52:00.000Z","comments":true,"path":"2024/03/16/ECS框架/","link":"","permalink":"http://peapod.top/2024/03/16/ECS%E6%A1%86%E6%9E%B6/","excerpt":"","text":"ECS框架简介ECS stands for Entity Component System，为“实体组件系统”。ECS是一种以数据为导向的编程方式。 提供给开发者一种方便的写出高性能代码的方式，同时代码的逻辑架构足够清晰，模块之间的耦合性足够小。 它的基本思想是： 将数据与行为分离，让数据在内存中紧凑排列，提高cpu的缓存命中率； 同时不使用引用类型，不使用继承，让多线程代码的编写更为简单，使各种batch技术的应用成为可能； ECS将数据和行为分离，在Component中仅储存数据，System中仅储存行为，System通过依赖注入的方式访问Component，这可以很大程度上解耦； 详细介绍https://johnyoung404.github.io/2019/06/27/ECS%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B/ Entitas简介Entitas 是最流行的开源实体组件系统框架 (ECS)，专为 C# 和 Unity 打造。","categories":[],"tags":[]},{"title":"查找表","slug":"查找表","date":"2024-03-10T05:59:22.000Z","updated":"2024-03-16T06:55:28.000Z","comments":true,"path":"2024/03/10/查找表/","link":"","permalink":"http://peapod.top/2024/03/10/%E6%9F%A5%E6%89%BE%E8%A1%A8/","excerpt":"","text":"查找表一般对于查找表有以下几种操作： 在查找表中查找某个具体的数据元素； 在查找表中插入数据元素； 从查找表中删除数据元素； 在查找表中只做查找操作，而不改动表中数据元素，称此类查找表为静态查找表；反之，在查找表中做查找操作的同时进行插入数据或者删除数据的操作，称此类表为动态查找表。 二分查找使用的前提是静态查找表中的数据必须是有序的。 折半查找的运行过程可以用二叉树来描述，这棵树通常称为“判定树”。 折半查找的平均查找长度为：ASL = log2(n+1) – 1。 折半查找算法只适用于有序表，同时仅限于查找表用顺序存储结构表示。 二叉排序树（二叉查找树）动态查找表中做查找操作时，若查找成功可以对其进行删除；如果查找失败，即表中无该关键字，可以将该关键字插入到表中。 具有如下特点： 二叉排序树中，如果其根结点有左子树，那么左子树上所有结点的值都小于根结点的值； 二叉排序树中，如果其根结点有右子树，那么右子树上所有结点的值都大小根结点的值； 二叉排序树的左右子树也要求都是二叉排序树； 一个无序序列可以通过构建一棵二叉排序树，从而变成一个有序序列。当使用中序遍历算法遍历二叉排序树时，得到的序列为有序序列。 使用二叉排序树实现动态查找操作的过程，实际上就是从二叉排序树的根结点到查找元素结点的过程，所以时间复杂度同被查找元素所在的树的深度（层次数）有关。 平衡二叉树（AVL树）遵循以下两个特点的二叉树： 每棵子树中的左子树和右子树的深度差不能超过 1； 二叉树中每棵子树都要求是平衡二叉树； 平衡因子：每个结点都有其各自的平衡因子，表示的就是其左子树深度同右子树深度的差。取值只可能是：0、1 和 -1。 使用平衡二叉树进行查找操作的时间复杂度为 O(logn)。 红黑树两个要求： 树中的每个结点增加了一个用于存储颜色的标志域； 树中没有一条路径比其他任何路径长出两倍，整棵树要接近于“平衡”的状态。 满足以下性质的二叉查找树才是红黑树： 树中的每个结点颜色不是红的，就是黑的； 根结点的颜色是黑的； 所有为 nil 的叶子结点的颜色是黑的；（注意：叶子结点说的只是为空（nil 或 NULL）的叶子结点！） 如果此结点是红的，那么它的两个孩子结点全部都是黑的； 对于每个结点，从该结点到到该结点的所有子孙结点的所有路径上包含有相同数目的黑结点； 每个结点附带一个整形数值，表示的是此结点的黑高度（从该结点到其子孙结点中包含的黑结点数，用 bh(x) 表示（x 表示此结点）），nil 的黑高度为 0，颜色为黑色。 整棵树也有自己的黑高度，即为根结点的黑高度。对于一棵具有 n 个结点的红黑树，树的高度至多为：2lg(n+1)。 红黑树进行查找操作时的时间复杂度为O(lgn) B-树一颗 m 阶的 B-树，或者本身是空树，否则必须满足以下特性： 树中每个结点至多有 m 棵子树； 若根结点不是叶子结点，则至少有两棵子树； 除根之外的所有非终端结点至少有 ⌈m&#x2F;2⌉ 棵子树； 所有的非终端结点中包含下列信息数据：（n，A0，K1，A1，K2，A2，…，Kn，An）； n 表示结点中包含的关键字的个数，取值范围是：⌈m/2⌉-1≤ n ≤m-1。Ki （i 从 1 到 n）为关键字，且 Ki &lt; Ki+1 ；Ai 代表指向子树根结点的指针，且指针 Ai-1 所指的子树中所有结点的关键字都小于 Ki，An 所指子树中所有的结点的关键字都大于 Kn。 对于 m 阶的 B-树来说，在定义中规定所有的非终端结点（终端结点即叶子结点，其关键字个数为 0）中包含关键字的个数的范围是[⌈m/2⌉-1,m-1]，所以在插入新的数据元素时，首先向最底层的某个非终端结点中添加，如果该结点中的关键字个数没有超过 m-1，则直接插入成功，否则还需要继续对该结点进行处理。 B+树B-树的变型树——B+树。 一颗 m 阶的 B+树和 m 阶的 B-树的差异在于： 有 n 棵子树的结点中含有 n 个关键字； 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 所有的非终端结点（非叶子结点）可以看成是索引部分，结点中仅含有其子树（根结点）中的最大（或最小）关键字。 可以进行两种查找运算：一种是利用 sqt 链表做顺序查找，另一种是从树的根结点开始，进行类似于二分查找的查找方式。 无论查找成功与否，每次查找操作都是走了一条从根结点到叶子结点的路径。 哈希表（散列表）哈希表可以通过关键字直接找到数据的存储位置，不需要进行任何的比较，其查找的效率相较于前面所介绍的查找算法是更高的。 哈希地址只是表示在查找表中的存储位置，而不是实际的物理存储位置。f（）是一个函数，通过这个函数可以快速求出该关键字对应的的数据的哈希地址，称之为“哈希函数”。 对于哈希表而言，冲突只能尽可能地少，无法完全避免。常用的哈希函数的构造方法有 6 种：直接定址法、数字分析法、平方取中法、折叠法、除留余数法和随机数法。 直接定址法：其哈希函数为一次函数，即以下两种形式： 1H（key）= key 或者 H（key）=a * key + b 对于无法避免的冲突，需要采取适当的措施去处理。 开放定址法 H（key）&#x3D;（H（key）+ d）MOD m（其中 m 为哈希表的表长，d 为一个增量） 当得出的哈希地址产生冲突时，选取以下 3 种方法中的一种获取 d 的值，然后继续计算，直到计算出的哈希地址不在冲突为止。 线性探测法：d&#x3D;1，2，3，…，m-1 哈希表的装填因子：在一般情况下，当处理冲突的方式相同的情况下，其平均查找长度取决于哈希表的装满程度：装的越满，插入数据时越有可能发生冲突；反之则越小。 装填因子&#x3D;哈希表中数据的个数&#x2F;哈希表的长度，用字符 α 表示（是数学符号，而不是字符 a）。装填因子越小，表示哈希表中空闲的位置就越多。 在假设查找表中的所有数据的查找概率相等的情况下，对于表长为 m，数据个数为 n 的哈希表： 其查找成功的平均查找长度约为：-1&#x2F;α * ln⁡(1-α) 其查找不成功的平均查找长度约为：1&#x2F;(1-α) 通过公式可以看到，哈希表的查找效率只同装填因子有关，而同哈希表中的数据的个数无关","categories":[],"tags":[]},{"title":"STL 容器简介","slug":"STL-容器简介","date":"2024-03-07T13:05:29.000Z","updated":"2024-03-10T05:58:24.000Z","comments":true,"path":"2024/03/07/STL-容器简介/","link":"","permalink":"http://peapod.top/2024/03/07/STL-%E5%AE%B9%E5%99%A8%E7%AE%80%E4%BB%8B/","excerpt":"","text":"STL 容器 简介STL 容器是一些模板类的集合，容器中封装的是组织数据的方法（也就是数据结构）。STL 提供有 3 类标准容器，分别是序列容器、排序容器和哈希容器，其中后两类容器有时也统称为关联容器。 vector 的底层为顺序表（数组），list 的底层为双向链表，deque 的底层为循环队列，set 的底层为红黑树，hash_set 的底层为哈希表。 容器种类 功能 序列容器 主要包括 vector 向量容器、list 列表容器以及 deque 双端队列容器。之所以被称为序列容器，是因为元素在容器中的位置同元素的值无关，即容器不是排序的。将元素插入容器时，指定在什么位置，元素就会位于什么位置。 排序容器 包括 set 集合容器、multiset多重集合容器、map映射容器以及 multimap 多重映射容器。排序容器中的元素默认是由小到大排序好的，即便是插入元素，元素也会插入到适当位置。所以关联容器在查找时具有非常好的性能。 哈希容器 C++11 新加入 4 种关联式容器，分别是 unordered_set 哈希集合、unordered_multiset 哈希多重集合、unordered_map 哈希映射以及 unordered_multimap 哈希多重映射。和排序容器不同，哈希容器中的元素是未排序的，元素的位置由哈希函数确定。 序列式容器序列式容器，其共同的特点是不会对存储的元素进行排序，元素排列的顺序取决于存储它们的顺序。以线性排列（类似普通数组的存储方式）来存储某一指定类型（例如 int、double 等）的数据，需要特殊说明的是，该类容器并不会自动对存储的元素按照值的大小进行排序。 序列容器大致包含以下几类容器： array&lt;T,N&gt;（数组容器）：表示可以存储 N 个 T 类型的元素，是 C++ 本身提供的一种容器。此类容器一旦建立，其长度就是固定不变的，这意味着不能增加或删除元素，只能改变某个元素的值； vector（向量容器）：用来存放 T 类型的元素，是一个长度可变的序列容器，即在存储空间不足时，会自动申请更多的内存。使用此容器，在尾部增加或删除元素的效率最高（时间复杂度为 O(1) 常数阶），在其它位置插入或删除元素效率较差（时间复杂度为 O(n) 线性阶，其中 n 为容器中元素的个数）； deque（双端队列容器）：和 vector 非常相似，区别在于使用该容器不仅尾部插入和删除元素高效，在头部插入或删除元素也同样高效，时间复杂度都是 O(1) 常数阶，但是在容器中某一位置处插入或删除元素，时间复杂度为 O(n) 线性阶； list（链表容器）：是一个长度可变的、由 T 类型元素组成的序列，它以双向链表的形式组织元素，在这个序列的任何地方都可以高效地增加或删除元素（时间复杂度都为常数阶 O(1)），但访问容器中任意元素的速度要比前三种容器慢，这是因为 list 必须从第一个元素或最后一个元素开始访问，需要沿着链表移动，直到到达想要的元素。 forward_list（正向链表容器）：和 list 容器非常类似，只不过它以单链表的形式组织元素，它内部的元素只能从第一个元素开始访问，是一类比链表容器快、更节省内存的容器。 关联式容器关联式容器在存储元素时还会为每个元素在配备一个键，整体以键值对的方式存储到容器中。相比前者，关联式容器可以通过键值直接找到对应的元素，而无需遍历整个容器。另外，关联式容器在存储元素，默认会根据各元素键值的大小做升序排序。 相比其它类型容器，关联式容器查找、访问、插入和删除指定元素的效率更高。 关联式容器所具备的这些特性，归咎于 STL 标准库在实现该类型容器时，底层选用了 「红黑树」。 关联式容器名称 特点 map 定义在 头文件中，使用该容器存储的数据，其各个元素的键必须是唯一的（即不能重复），该容器会根据各元素键的大小，默认进行升序排序（调用 std::less）。 set 定义在 头文件中，使用该容器存储的数据，各个元素键和值完全相同，且各个元素的值不能重复（保证了各元素键的唯一性）。该容器会自动根据各个元素的键（其实也就是元素值）的大小进行升序排序（调用 std::less）。 multimap 定义在 头文件中，和 map 容器唯一的不同在于，multimap 容器中存储元素的键可以重复。 multiset 定义在 头文件中，和 set 容器唯一的不同在于，multiset 容器中存储元素的值可以重复（一旦值重复，则意味着键也是重复的）。 C++ 11 还新增了 4 种哈希容器，即 unordered_map、unordered_multimap 以及 unordered_set、unordered_multiset。严格来说，它们也属于关联式容器，但由于哈希容器底层采用的是哈希表。 容器适配器容器适配器是一个封装了序列容器的类模板，它在一般序列容器的基础上提供了一些不同的功能。 stack、queue、priority_queue： stack：是一个封装了 deque 容器的适配器类模板，默认实现的是一个后入先出（Last-In-First-Out，LIFO）的压入栈。stack 模板定义在头文件 stack 中。 queue：是一个封装了 deque 容器的适配器类模板，默认实现的是一个先入先出（First-In-First-Out，LIFO）的队列。可以为它指定一个符合确定条件的基础容器。queue 模板定义在头文件 queue 中。 priority_queue：是一个封装了 vector 容器的适配器类模板，默认实现的是一个会对元素排序，从而保证最大元素总在队列最前面的队列。priority_queue 模板定义在头文件 queue 中。","categories":[],"tags":[]},{"title":"Go并发-下","slug":"Go并发-下","date":"2024-02-27T10:47:35.000Z","updated":"2024-02-27T11:00:39.000Z","comments":true,"path":"2024/02/27/Go并发-下/","link":"","permalink":"http://peapod.top/2024/02/27/Go%E5%B9%B6%E5%8F%91-%E4%B8%8B/","excerpt":"","text":"Go并发-下基础知识并发和并行之间的区别。 并发（concurrency）：把任务在不同的时间点交给处理器进行处理。在同一时间点，任务并不会同时运行。 并行（parallelism）：把每一个任务分配给每一个处理器独立完成。在同一时间点，任务一定是同时运行。 Go 语言的并发通过 goroutine 特性完成，由 Go 语言的运行时调度完成。 提供 channel 在多个 goroutine 间进行通信。goroutine 和 channel 是 Go 语言秉承的 CSP（Communicating Sequential Process）并发模式的重要实现基础。 goroutine使用 go 关键字就可以创建 goroutine，将 go 声明放到一个需调用的函数之前。 所有 goroutine 在 main() 函数结束时会一同结束。 channelGo语言在语言级别提供的 goroutine 间的通信方式。使用 channel 在两个或多个 goroutine 之间传递消息。 一个 channel 只能传递一种类型的值，类型需要在声明 channel 时指定。 死锁、活锁和饥饿死锁是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。 活锁是另一种形式的活跃性问题，该问题尽管不会阻塞线程，但也不能继续执行，因为线程将不断重复同样的操作，而且总会失败。 饥饿是指一个可运行的进程尽管能继续执行，但被调度器无限期地忽视，而不能被调度执行的情况。 并发通信最常见的并发通信模型：共享数据和消息。 传统的同步 goroutine 的机制，对共享资源加锁。atomic 和 sync 包可以对共享的资源进行加锁操作。 原子函数以底层的加锁机制来同步访问整型变量和指针。 12345678910111213141516171819202122232425package mainimport ( &quot;fmt&quot; &quot;runtime&quot; &quot;sync&quot; &quot;sync/atomic&quot;)var ( counter int64 wg sync.WaitGroup)func main() &#123; wg.Add(2) go incCounter(1) go incCounter(2) wg.Wait() //等待goroutine结束 fmt.Println(counter)&#125;func incCounter(id int) &#123; defer wg.Done() for count := 0; count &lt; 2; count++ &#123; atomic.AddInt64(&amp;counter, 1) //安全的对counter加1 runtime.Gosched() &#125;&#125; 互斥锁和读写锁sync 包提供了两种锁类型：sync.Mutex 和 sync.RWMutex。RWMutex 相对友好些，是经典的单写多读模型。 用于在代码上创建一个临界区，保证同一时间只有一个 goroutine 可以执行这个临界代码。 1234567891011121314151617181920212223242526272829303132package mainimport ( &quot;fmt&quot; &quot;runtime&quot; &quot;sync&quot;)var ( counter int64 wg sync.WaitGroup mutex sync.Mutex)func main() &#123; wg.Add(2) go incCounter(1) go incCounter(2) wg.Wait() fmt.Println(counter)&#125;func incCounter(id int) &#123; defer wg.Done() for count := 0; count &lt; 2; count++ &#123; //同一时刻只允许一个goroutine进入这个临界区 mutex.Lock() &#123; value := counter runtime.Gosched() value++ counter = value &#125; mutex.Unlock() //释放锁，允许其他正在等待的goroutine进入临界区 &#125;&#125; 12345678910111213var ( // 逻辑中使用的某个变量 count int // 与变量对应的使用互斥锁 countGuard sync.RWMutex)func GetCount() int &#123; // 锁定 countGuard.RLock() // 在函数退出时解除锁定 defer countGuard.RUnlock() return count&#125; 等待组使用等待组进行多个任务的同步，等待组可以保证在并发环境中完成指定数量的任务。 方法名 功能 (wg * WaitGroup) Add(delta int) 等待组的计数器 +1 (wg * WaitGroup) Done() 等待组的计数器 -1 (wg * WaitGroup) Wait() 当等待组计数器不等于 0 时阻塞直到变 0。 12345678910111213141516171819202122232425262728293031323334package mainimport ( &quot;fmt&quot; &quot;net/http&quot; &quot;sync&quot;)func main() &#123; // 声明一个等待组 var wg sync.WaitGroup // 准备一系列的网站地址 var urls = []string&#123; &quot;http://www.github.com/&quot;, &quot;https://www.qiniu.com/&quot;, &quot;https://www.golangtc.com/&quot;, &#125; // 遍历这些地址 for _, url := range urls &#123; // 每一个任务开始时, 将等待组增加1 wg.Add(1) // 开启一个并发 go func(url string) &#123; // 使用defer, 表示函数完成时将等待组值减1 defer wg.Done() // 使用http访问提供的地址 _, err := http.Get(url) // 访问完成后, 打印地址和可能发生的错误 fmt.Println(url, err) // 通过参数传递url地址 &#125;(url) &#125; // 等待所有的任务完成 wg.Wait() fmt.Println(&quot;over&quot;)&#125; 通道（chan）可以让一个 goroutine 通过它给另一个 goroutine 发送值信息。 提倡使用通信的方法代替共享内存，当一个资源需要在 goroutine 之间共享时，通道在 goroutine 之间架起了一个管道，并提供了确保同步交换数据的机制。 在任何时候，同时只能有一个 goroutine 访问通道进行发送和获取数据。goroutine 间通过通道就可以通信。 通道声明1var 通道变量 chan 通道类型 通道创建1通道实例 := make(chan 数据类型) 发送数据1234567// 通道变量 &lt;- 值// 创建一个空接口通道ch := make(chan interface&#123;&#125;)// 将0放入通道中ch &lt;- 0// 将hello字符串放入通道中ch &lt;- &quot;hello&quot; 接受数据123456789// 阻塞接收数据data := &lt;-ch// 非阻塞接收数据data, ok := &lt;-ch// 忽略接收的数据&lt;-ch// 循环接收for data := range ch &#123;&#125; 单向通道只能写入数据的通道类型为chan&lt;-，只能读取数据的通道类型为&lt;-chan 1234567ch := make(chan int)// 声明一个只能写入数据的通道类型, 并赋值为chvar chSendOnly chan&lt;- int = ch// 声明一个只能读取数据的通道类型, 并赋值为chvar chRecvOnly &lt;-chan int = ch// make 创建通道时，也可以创建一个只写入或只读取的通道ch := make(&lt;-chan int) 带缓冲的通道创建缓冲通道12// 创建一个3个元素缓冲大小的整型通道 ch := make(chan int, 3) 阻塞条件 带缓冲通道被填满时，尝试再次发送数据时发生阻塞。 带缓冲通道为空时，尝试接收数据时发生阻塞。 超时机制Go语言中提供了 select 关键字，可以同时响应多个通道的操作。每个 case 语句里必须是一个 IO 操作。 在一个 select 语句中，Go语言会按顺序从头至尾评估每一个发送和接收的语句。 如果其中的任意一语句可以继续执行（即没有被阻塞），那么就从那些可以执行的语句中任意选择一条来使用。 没有任意一条语句可以执行： 如果给出了 default 语句，那么就会执行 default 语句，同时程序的执行会从 select 语句后的语句中恢复； 如果没有 default 语句，那么 select 语句将被阻塞，直到至少有一个通信可以进行下去。 select 做的就是：选择处理列出的多个通信情况中的一个。 如果都阻塞了，会等待直到其中一个可以处理 如果多个可以处理，随机选择一个 如果没有通道操作可以处理并且写了 default 语句，它就会执行：default 永远是可运行的（这就是准备好了，可以执行）。 select 语句实现了一种监听模式，通常用在（无限）循环中；在某种情况下，通过 break 语句使循环退出。 123456789select&#123; case 操作1: 响应操作1 case 操作2: 响应操作2 … default: 没有操作情况&#125; 操 作 语句示例 接收任意数据 case &lt;- ch; 接收变量 case d :&#x3D; &lt;- ch; 发送数据 case ch &lt;- 100; 123456789101112131415161718192021222324252627package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() &#123; ch := make(chan int) quit := make(chan bool) //新开一个协程 go func() &#123; for &#123; select &#123; case num := &lt;-ch: fmt.Println(&quot;num = &quot;, num) case &lt;-time.After(3 * time.Second): fmt.Println(&quot;超时&quot;) quit &lt;- true &#125; &#125; &#125;() //别忘了() for i := 0; i &lt; 5; i++ &#123; ch &lt;- i time.Sleep(time.Second) &#125; &lt;-quit fmt.Println(&quot;程序结束&quot;)&#125; 从已经关闭的通道接收数据或者正在接收数据时，将会接收到通道类型的零值，然后停止阻塞并返回。 多核并行化通过设置环境变量 GOMAXPROCS 的值来控制使用多少个 CPU 核心。 12345678910package mainimport ( &quot;fmt&quot; &quot;runtime&quot;)func main() &#123; cpuNum := runtime.NumCPU() //获得当前设备的cpu核心数 fmt.Println(&quot;cpu核心数:&quot;, cpuNum) runtime.GOMAXPROCS(cpuNum) //设置需要用到的cpu数量&#125; CSP：通信顺序进程CSP（communicating sequential processes）并发模型。 Go语言并没有完全实现了 CSP 并发模型的所有理论，仅仅是实现了 process 和 channel 这两个概念。 process 就是Go语言中的 goroutine，每个 goroutine 之间是通过 channel 通讯来实现数据共享。 通道（channel）和 map、切片一样，也是由 Go 源码编写而成。为了保证两个 goroutine 并发访问的安全性，通道也需要做一些锁操作，因此通道其实并不比锁高效。","categories":[{"name":"golang标准库","slug":"golang标准库","permalink":"http://peapod.top/categories/golang%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"python对象","slug":"python对象","date":"2023-12-21T11:44:27.000Z","updated":"2023-12-21T13:00:46.000Z","comments":true,"path":"2023/12/21/python对象/","link":"","permalink":"http://peapod.top/2023/12/21/python%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"python对象class123class 类名： 多个（≥0）类属性... 多个（≥0）类方法... 类属性指的就是包含在类中的变量；而类方法指的是包含类中的函数。 1234567class TheFirstDemo: &#x27;&#x27;&#x27;这是一个学习Python定义的第一个类&#x27;&#x27;&#x27; # 下面定义了一个类属性 add = &#x27;http://c.biancheng.net&#x27; # 下面定义了一个say方法 def say(self, content): print(content) 构造方法构造方法用于创建对象时使用，创建一个类的实例对象时，解释器都会自动调用它。 12def __init__(self,...): 代码块 必须包含一个名为 self 的参数，且必须作为第一个参数。 12345678910class TheFirstDemo: &#x27;&#x27;&#x27;这是一个学习Python定义的第一个类&#x27;&#x27;&#x27; #构造方法 def __init__(self): print(&quot;调用构造方法&quot;) # 下面定义了一个类属性 add = &#x27;http://c.biancheng.net&#x27; # 下面定义了一个say方法 def say(self, content): print(content) 即便不手动为类添加任何构造方法，会自动为类添加一个仅包含 self 参数的构造方法。 在 __init__() 构造方法中，除了 self 参数外，还可以自定义一些参数，参数之间使用逗号“,”进行分割。 123456class CLanguage: &#x27;&#x27;&#x27;这是一个学习Python定义的一个类&#x27;&#x27;&#x27; def __init__(self,name,add): print(name,&quot;的网址为:&quot;,add)#创建 add 对象，并传递参数给构造函数add = CLanguage(&quot;C语言中文网&quot;,&quot;http://c.biancheng.net&quot;) 对象定义的类只有进行实例化，也就是使用该类创建对象之后，才能得到利用。 访问或修改类对象具有的实例变量，甚至可以添加新的实例变量或者删除已有的实例变量； 调用类对象的方法，包括调用现有的方法，以及给类对象动态添加方法。 给类对象动态添加方法为 对象动态增加的方法，不会自动将调用者自动绑定到第一个参数。 12345678# 先定义一个函数def info(self): print(&quot;---info函数---&quot;, self)# 使用info对clanguage的foo方法赋值（动态绑定方法）clanguage.foo = info# Python不会自动将调用者绑定到第一个参数，# 因此程序需要手动将调用者绑定为第一个参数clanguage.foo(clanguage) self 所表示的都是实际调用该方法的对象。","categories":[],"tags":[]},{"title":"python函数","slug":"python函数","date":"2023-12-21T10:43:51.000Z","updated":"2023-12-21T11:43:57.000Z","comments":true,"path":"2023/12/21/python函数/","link":"","permalink":"http://peapod.top/2023/12/21/python%E5%87%BD%E6%95%B0/","excerpt":"","text":"python函数函数简介将常用的代码以固定的格式封装（包装）成一个独立的模块，可以重复使用，这个模块就叫做函数（Function）。 定义函数。 1234567#定义个空函数，没有实际意义def pass_dis(): pass#定义一个比较字符串大小的函数def str_max(str1,str2): str = str1 if str1 &gt; str2 else str2 return str 调用函数。 123pass_dis()strmax = str_max(&quot;http://c.biancheng.net/python&quot;,&quot;http://c.biancheng.net/shell&quot;);print(strmax) 函数说明文档。 函数的说明文档通常位于函数内部、所有代码的最前面。 12345678910#定义一个比较字符串大小的函数def str_max(str1,str2): &#x27;&#x27;&#x27; 比较 2 个字符串的大小 &#x27;&#x27;&#x27; str = str1 if str1 &gt; str2 else str2 return strhelp(str_max)#__doc__ 属性来获取 str_max() 函数的说明文档print(str_max.__doc__) 值传递和引用传递形式参数：在定义函数时，函数名后面括号中的参数就是形式参数。 实际参数：在调用函数时，函数名后面括号中的参数称为实际参数。 值传递：适用于实参类型为不可变类型（字符串、数字、元组）； 引用（地址）传递：适用于实参类型为可变类型（列表，字典）； 函数参数进行值传递后，若形参的值发生改变，不会影响实参的值；而函数参数继续引用传递后，改变形参的值，实参的值也会一同改变。 值传递，其本质就是将实际参数值复制一份，将其副本传给形参。这意味着，采用值传递方式的函数中，无论其内部对参数值进行如何修改，都不会影响函数外部的实参。 传参解包当传入列表或元组时，其名称前要带一个 * 号，当传入字典时，其名称前要带有 2 个 * 号。 123456def dis_str(name,add) : print(&quot;name:&quot;,name) print(&quot;add&quot;,add)data = [&quot;Python教程&quot;,&quot;http://c.biancheng.net/python/&quot;]#使用逆向参数收集方式传值dis_str(*data) 函数返回多值2 种方式： 在函数中，提前将要返回的多个值存储到一个列表或元组中，然后函数返回该列表或元组； 函数直接返回多个值，之间用逗号（ , ）分隔，Python 会自动将多个值封装到一个元组中，其返回值仍是一个元组。 序列解包，使用对应数量的变量，直接接收函数返回列表或元组中的多个值。 123456def retu_list() : add = [&quot;http://c.biancheng.net/python/&quot;,\\ &quot;http://c.biancheng.net/shell/&quot;,\\ &quot;http://c.biancheng.net/golang/&quot;] return addpythonadd,shelladd,golangadd = retu_list() 变量作用域局部变量仅限于函数内部，出了函数就不能使用。 在函数执行完毕后，这块临时存储空间随即会被释放并回收，该空间中存储的变量无法再被使用。 全局变量在所有函数的外部定义变量，这样的变量称为全局变量（Global Variable）。 全局变量的默认作用域是整个程序，即全局变量既可以在各个函数的外部使用，也可以在各函数内部使用。 在函数体外定义的变量。 在函数体内使用 global 关键字对变量进行修饰。 函数高级赋值、作为其他函数的参数以及作为其他函数的返回值。 将函数赋值给其它变量。 123456def my_def (): print(&quot;正在执行 my_def 函数&quot;)#将函数赋值给其他变量 other = my_def#间接调用 my_def() 函数other() 将函数以参数的形式传入其他函数中。 123456789def multi(a,b): return a*bdef my_def(a,b,dis): return dis(a,b) #求 2 个数的和print(my_def(3,4,add))#求 2 个数的乘积print(my_def(3,4,multi)) 返回值为函数。 123456789def my_def (): #局部函数 def indef(): print(&quot;调用局部函数&quot;) #调用局部函数 return indefother_def = my_def()#调用局部的 indef() 函数other_def() 闭包外部函数返回的不是一个具体的值，而是一个函数。一般情况下，返回的函数会赋值给一个变量，这个变量可以在后面被继续执行调用。 123456789#闭包函数，其中 exponent 称为自由变量def nth_power(exponent): def exponent_of(base): return base ** exponent return exponent_of # 返回值是 exponent_of 函数square = nth_power(2) # 计算一个数的平方cube = nth_power(3) # 计算一个数的立方print(square(2)) # 计算 2 的平方print(cube(2)) # 计算 2 的立方 闭包比普通的函数多了一个 closure 属性，该属性记录着自由变量的地址。 匿名函数lambda 表达式，又称匿名函数，常用来表示内部仅包含 1 行表达式的函数。 对于单行函数，使用 lambda 表达式可以省去定义函数的过程，让代码更加简洁； 对于不需要多次复用的函数，使用 lambda 表达式可以在用完之后立即释放，提高程序执行的性能 12add = lambda x,y:x+yprint(add(3,4))","categories":[],"tags":[]},{"title":"python复杂类型详解","slug":"python复杂类型详解","date":"2023-12-18T03:07:22.000Z","updated":"2023-12-18T03:40:40.000Z","comments":true,"path":"2023/12/18/python复杂类型详解/","link":"","permalink":"http://peapod.top/2023/12/18/python%E5%A4%8D%E6%9D%82%E7%B1%BB%E5%9E%8B%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"复杂类型详解list列表实现栈和队列二者的区别在于对数据的存取顺序： 队列是，先存入的数据最先取出，即“先进先出”。 栈是，最后存入的数据最先取出，即“后进先出”。 list实现队列存入数据时使用 insert() 方法，设置其第一个参数为 0，即表示每次都从最前面插入数据； 读取数据时，使用 pop() 方法，即将队列的最后一个元素弹出。 12345678910#定义一个空列表，当做队列queue = []#向列表中插入元素queue.insert(0,1)queue.insert(0,2)queue.insert(0,&quot;hello&quot;)print(queue)print(&quot;取一个元素：&quot;,queue.pop())print(&quot;取一个元素：&quot;,queue.pop())print(&quot;取一个元素：&quot;,queue.pop()) list实现栈append() 方法存入数据；使用 pop() 方法读取数据。 123456789#定义一个空 list 当做栈stack = []stack.append(1)stack.append(2)stack.append(&quot;hello&quot;)print(stack)print(&quot;取一个元素：&quot;,stack.pop())print(&quot;取一个元素：&quot;,stack.pop())print(&quot;取一个元素：&quot;,stack.pop()) collections模块实现栈和队列标准库的 collections 模块中的 deque 结构体，它被设计成在两端存入和读取都很快的特殊 list，可以用来实现栈和队列的功能。 123456789101112import collectionsqueueAndStack = collections.deque()queueAndStack.append(1)queueAndStack.append(2)queueAndStack.append(&quot;hello&quot;)print(list(queueAndStack))#实现队列功能，从队列中取一个元素，根据先进先出原则，这里应输出 1print(queueAndStack.popleft())#实现栈功能，从栈里取一个元素，根据后进先出原则，这里应输出 helloprint(queueAndStack.pop())#再次打印列表print(list(queueAndStack)) 列表和元组的底层实现list 列表123456789101112131415161718typedef struct &#123; PyObject_VAR_HEAD /* Vector of pointers to list elements. list[0] is ob_item[0], etc. */ PyObject **ob_item; /* ob_item contains space for &#x27;allocated&#x27; elements. The number * currently in use is ob_size. * Invariants: * 0 &lt;= ob_size &lt;= allocated * len(list) == ob_size * ob_item == NULL implies ob_size == allocated == 0 * list.sort() temporarily sets allocated to -1 to detect mutations. * * Items must normally not be NULL, except during construction when * the list is not yet visible outside the function that builds it. */ Py_ssize_t allocated;&#125; PyListObject; 本质上是一个长度可变的连续数组。其中 ob_item 是一个指针列表，里边的每一个指针都指向列表中的元素，而 allocated 则用于存储该列表目前已被分配的空间大小。 当前列表分配的空间已满（即 allocated &#x3D;&#x3D; len(list)），则会向系统请求更大的内存空间，并把原来的元素全部拷贝过去。 tuple元组12345678typedef struct &#123; PyObject_VAR_HEAD PyObject *ob_item[1]; /* ob_item contains space for &#x27;ob_size&#x27; elements. * Items must normally not be NULL, except during construction when * the tuple is not yet visible outside the function that builds it. */&#125; PyTupleObject; 本质也是一个数组，但是空间大小固定。 字典和集合的底层实现字典和集合是进行过性能高度优化的数据结构，特别是对于查找、添加和删除操作。 原理字典和集合的内部结构都是一张哈希表： 对于字典而言，这张表存储了哈希值（hash）、键和值这 3 个元素。 而对集合来说，哈希表内只存储单一的元素。 为了提高存储空间的利用率，现在的哈希表除了字典本身的结构，会把索引和哈希值、键、值单独分开。 平均情况下，仍能保证插入、查找和删除的时间复杂度为 O(1)。 哈希表插入数据当向字典中插入数据时，Python 会首先根据键（key）计算出对应的哈希值（通过 hash(key) 函数），而向集合中插入数据时，Python会根据该元素本身计算对应的哈希值（通过 hash(valuse) 函数）。 得到哈希值（例如为 hash）之后，再结合字典或集合要存储数据的个数（例如 n），就可以得到该元素应该插入到哈希表中的位置（比如，可以用 hash%n 的方式）。 哈希表查找数据根据哈希值，找到该元素应该存储到哈希表中的位置，然后和该位置的元素比较其哈希值和键（集合直接比较元素值）： 如果相等，则证明找到； 反之，则证明当初存储该元素时，遇到了哈希冲突，需要继续使用当初解决哈希冲突的方法进行查找，直到找到该元素或者找到空位为止。 哈希表删除元素对这个位置的元素赋于一个特殊的值，等到重新调整哈希表的大小时，再将其删除。 哈希冲突的发生往往会降低字典和集合操作的速度。因此，为了保证其高效性，字典和集合内的哈希表，通常会保证其至少留有 1&#x2F;3 的剩余空间。随着元素的不停插入，当剩余空间小于 1&#x2F;3 时，Python 会重新获取更大的内存空间，扩充哈希表，与此同时，表内所有的元素位置都会被重新排放。 深拷贝和浅拷贝浅拷贝指的是重新分配一块内存，创建一个新的对象，但里面的元素是原对象中各个子对象的引用。 常见的浅拷贝的方法，是使用数据类型本身的构造器。 123list1 = [1, 2, 3]list2 = list(list1)print(list2) 对于可变的序列，还可以通过切片操作符“：”来完成浅拷贝 123list1 = [1, 2, 3]list2 = list1[:]print(list2) 函数 copy.copy() 函数，适用于任何数据类型。 1234import copylist1 = [1, 2, 3]list2 = copy.copy(list1)print(list2) 深拷贝是指重新分配一块内存，创建一个新的对象，并且将原对象中的元素，以递归的方式，通过创建新的子对象拷贝到新对象中。因此，新对象和原对象没有任何关联。 copy.deepcopy() 来实现对象的深度拷贝。 123import copylist1 = [[1, 2], (30, 40)]list2 = copy.deepcopy(list1) 拷贝对象中存在指向自身的引用，那么程序很容易陷入无限循环。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://peapod.top/tags/python/"}]},{"title":"python复杂类型","slug":"python复杂类型","date":"2023-12-17T11:25:41.000Z","updated":"2023-12-18T03:42:29.000Z","comments":true,"path":"2023/12/17/python复杂类型/","link":"","permalink":"http://peapod.top/2023/12/17/python%E5%A4%8D%E6%9D%82%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"python 复杂类型list列表列表可以存储整数、小数、字符串、列表、元组等任何类型的数据，并且同一个列表中元素的类型也可以不同。 同一列表中只放入同一类型的数据，这样可以提高程序的可读性。 创建列表使用[ ]创建列表后，一般使用=将它赋值给某个变量。 12num = [1, 2, 3, 4, 5, 6, 7]emptylist = [ ] # 空列表 内置的函数 list()，使用它可以将其它数据类型转换为列表类型。 123456789# 将字符串转换成列表list1 = list(&quot;hello&quot;)print(list1)#将区间转换成列表range1 = range(1, 6)list4 = list(range1)print(list4)#创建空列表print(list()) 遍历列表使用索引（Index）访问列表中的某个元素（得到的是一个元素的值），也可以使用切片访问列表中的一组元素（得到的是一个新的子列表）。 12listname[start : end : step]# listname 表示列表名字，start 表示起始索引，end 表示结束索引，step 表示步长。 删除列表对于已经创建的列表，如果不再使用，可以使用del关键字将其删除。 1del listname 添加元素列表可以使用+进行连接，相当于在第一个列表的末尾添加了另一个列表。 使用+会生成一个新的列表，原有的列表不会被改变。 append() 方法用于在列表的末尾追加元素。 123456l = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;]# 追加元素l.append(&#x27;PHP&#x27;)print(l)# 追加列表，整个列表也被当成一个元素l.append([&#x27;Ruby&#x27;, &#x27;SQL&#x27;]) extend()方法把包含的元素逐个添加到列表中。 123# 追加列表，列表也被拆分成多个元素l.extend([&#x27;Ruby&#x27;, &#x27;SQL&#x27;])print(l) insert()方法在列表中间某个位置插入元素。 123l = [&#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;Java&#x27;]#插入元素l.insert(1, &#x27;C&#x27;) 删除元素del根据索引值删除元素。 123lang = [&quot;Python&quot;, &quot;C++&quot;, &quot;Java&quot;, &quot;PHP&quot;, &quot;Ruby&quot;, &quot;MATLAB&quot;]#使用正数索引del lang[2] pop()方法pop() 方法用来删除列表中指定索引处的元素。默认会删除列表中的最后一个元素。 12nums = [40, 36, 89, 2, 36, 100, 7]nums.pop(3) remove()方法根据元素本身的值来进行删除操作。 删除第一个和指定值相同的元素，而且必须保证该元素是存在的，否则会引发 ValueError 错误。 1234nums = [40, 36, 89, 2, 36, 100, 7]#第一次删除36nums.remove(36)print(nums) clear()删除列表的所有元素，也即清空列表。 12url = list(&quot;http://c.biancheng.net/python/&quot;)url.clear() 修改元素直接对元素赋值 1nums[2] = -26 #使用正数索引 通过切片语法给一组元素赋值。既可以为列表添加元素，也可以为列表删除元素。 123nums = [40, 36, 89, 2, 36, 100, 7]#修改第 1~4 个元素的值（不包括第4个元素）nums[1: 4] = [45.25, -77, -52.5] 查找元素index() 方法用来查找某个元素在列表中出现的位置。 12345listname.index(obj, start, end)nums = [40, 36, 89, 2, 36, 100, 7, -20.5, -999]#检索列表中的所有元素print( nums.index(2) ) count()方法统计某个元素在列表中出现的次数。count() 返回 0，就表示列表中不存在该元素。 123nums = [40, 36, 89, 2, 36, 100, 7, -20.5, 36]#统计元素出现的次数print(&quot;36出现了%d次&quot; % nums.count(36)) tuple元组元组和列表（list）的不同之处在于： 列表的元素是可以更改的，包括修改元素值，删除和插入元素，所以列表是可变序列； 而元组一旦被创建，它的元素就不可更改了，所以元组是不可变序列。 元组的所有元素都放在一对小括号( )中，相邻元素之间用逗号,分隔。元组可以存储整数、实数、字符串、列表、元组等任何类型的数据，并且在同一个元组中，元素的类型可以不同。 1(&quot;c.biancheng.net&quot;, 1, [2,&#x27;a&#x27;], (&quot;abc&quot;,3.0)) 元组作为很多内置函数和序列类型方法的返回值存在，使用某些函数或者方法时，它的返回值是元组类型。 元组比列表的访问和处理速度更快，对指定元素进行访问，且不涉及修改元素的操作时，使用元组。 元组可以在映射（和集合的成员）中当做“键”使用，而列表不行。 创建元祖通过( )创建元组后，一般使用=将它赋值给某个变量。 1num = (7, 14, 21, 28, 35) tuple()，用来将其它数据类型转换为元组类型。 123#将字符串转换成元组tup1 = tuple(&quot;hello&quot;)print(tup1) 访问元素使用索引访问元组元素，使用切片访问元组元素。 12345#使用索引访问元组中的某个元素print(url[3]) #使用正数索引#使用切片访问元组中的一组元素print(url[9: 18]) #使用正数切片 修改元组只能创建一个新的元组去替代旧的元组。 1234tup = (100, 0.5, -36, 73)print(tup)#对元组进行重新赋值tup = (&#x27;Shell脚本&#x27;,&quot;http://c.biancheng.net/shell/&quot;) 删除元组通过 del 关键字将其删除。 123tup = (&#x27;Java教程&#x27;,&quot;http://c.biancheng.net/java/&quot;)print(tup)del tup dict字典字典（dict）是一种无序的、可变的序列，它的元素以“键值对（key-value）”的形式存储。 字典中的键必须唯一，必须不可变，只能使用数字、字符串或者元组，不能使用列表。 创建字典使用 { } 创建字典。 12345#使用字符串作为keyscores = &#123;&#x27;数学&#x27;: 95, &#x27;英语&#x27;: 92, &#x27;语文&#x27;: 84&#125;#使用元组和数字作为keydict1 = &#123;(20, 30): &#x27;great&#x27;, 30: [1,2,3]&#125; fromkeys() 方法创建字典。带有默认值的字典。 12knowledge = [&#x27;语文&#x27;, &#x27;数学&#x27;, &#x27;英语&#x27;]scores = dict.fromkeys(knowledge, 60) dict() 映射函数创建字典。应用 dict() 函数和 zip() 函数，可将两个列表转换为对应的字典。 123456keys = [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;] values = [1, 2, 3]a = dict( zip(keys, values) )# 创建空的字典d = dict() 访问字典通过键访问值。键必须是存在的，否则会抛出异常。 1dictname[key] get() 方法来获取指定键对应的值。当指定的键不存在时，get() 方法不会抛出异常。 1dictname.get(key[,default]) 当键不存在时，get() 返回空值 None，明确地提示该键不存在，设置 get() 的第二个参数。 12a = dict(two=0.65, one=88, three=100, four=-59)print( a.get(&#x27;five&#x27;, &#x27;该键不存在&#x27;) ) 删除字典使用 del 关键字。 123a = dict(two=0.65, one=88, three=100, four=-59)print(a)del a 判断字典中是否存在指定键值对可以使用 in 或 not in 运算符。in 或 not in 运算符都是基于 key 来判断的。 12345a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;# 判断 a 中是否包含名为&#x27;数学&#x27;的keyprint(&#x27;数学&#x27; in a) # True# 判断 a 是否包含名为&#x27;物理&#x27;的keyprint(&#x27;物理&#x27; in a) # False keys()、values() 和 items() 方法获取字典中的特定数据： keys() 方法用于返回字典中的所有键（key）； values() 方法用于返回字典中所有键对应的值（value）； items() 用于返回字典中所有的键值对（key-value）。 keys()、values() 和 items() 返回值的类型分别为 dict_keys、dict_values 和 dict_items。 list() 函数，将它们返回的数据转换成列表。 使用 for in 循环遍历它们的返回值。 12345678a = &#123;&#x27;数学&#x27;: 95, &#x27;语文&#x27;: 89, &#x27;英语&#x27;: 90&#125;b = list(a.keys())for k in a.keys(): print(k,end=&#x27; &#x27;) for k,v in a.items(): print(&quot;key:&quot;,k,&quot; value:&quot;,v) copy() 方法返回一个字典的拷贝，返回一个具有相同键值对的新字典。 copy() 方法所遵循的拷贝原理，既有深拷贝，也有浅拷贝。对最表层的键值对进行深拷贝，对于某些列表类型的值来说，此方法对其做的是浅拷贝。 123a = &#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: [1,2,3]&#125;b = a.copy()print(b) set集合用来保存不重复的元素，即集合中的元素都是唯一的。集合会将所有元素放在一对大括号 {} 。 同一集合中，只能存储不可变的数据类型，包括整形、浮点型、字符串、元组，无法存储列表、字典、集合这些可变的数据类型。set 集合是无序的，所以每次输出时元素的排序顺序可能都不相同。 创建集合使用 {} 创建。 12a = &#123;1,&#x27;c&#x27;,1,(1,2,3),&#x27;c&#x27;&#125;print(a) set()函数创建集合。 123set1 = set(&quot;c.biancheng.net&quot;)set2 = set([1,2,3,4,5])set3 = set((1,2,3,4,5)) 空集合，只能使用 set() 函数实现。因为直接使用一对 {}，Python 解释器会将其视为一个空字典。 访问元素使用循环结构，将集合中的数据逐一读取出来。 123a = &#123;1,&#x27;c&#x27;,1,(1,2,3),&#x27;c&#x27;&#125;for ele in a: print(ele,end=&#x27; &#x27;) 删除set集合使用 del() 语句。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"python","slug":"python","permalink":"http://peapod.top/tags/python/"}],"author":"taweizhong"},{"title":"python入门","slug":"python入门","date":"2023-12-16T08:09:55.000Z","updated":"2023-12-16T08:44:08.000Z","comments":true,"path":"2023/12/16/python入门/","link":"","permalink":"http://peapod.top/2023/12/16/python%E5%85%A5%E9%97%A8/","excerpt":"","text":"编程基础编译型语言和解释型语言对于编译型语言来说，在执行之前先要经过编译器将源码转换成 CPU 可识别的机器码文件（比如 Windows 下的 .exe 文件）；解释型语言无需预先编译，而是由解释器逐行对源码进行解释，一边解释一边执行。 编译型语言 可执行程序不能跨平台 源代码不能跨平台 解释型语言 一次编写，到处运行 解释型语言的执行效率天生就低于编译型语言 字符集和字符编码Unicode 字符集又称万国码、国际码、统一码等。从名字就可以看出来，它是以统一符号为目标的字符集。 字符集定义了字符和二进制的对应关系，为每个字符分配了唯一的编号。可以将字符集理解成一个很大的表格，它列出了所有字符和二进制的对应关系，计算机显示文字或者存储文字，就是一个查表的过程； 字符编码规定了如何将字符的编号存储到计算机中，为了区分一个字符到底使用了几个字节，就不能将字符的编号直接存储到计算机中，字符编号在存储之前必须要经过转换，在读取时还要再逆向转换一次，这套转换方案就叫做字符编码。 UTF-8 是目前使用最广的一种 Unicode字符集的实现方式。Python 默认采用 UTF-8 编码。 注释解释器在执行代码时会忽略注释，不做任何处理，就好像它不存在一样。 在调试（Debug）程序的过程中，注释还可以用来临时移除无用的代码。 一般情况下，合理的代码注释应该占源代码的 1&#x2F;3 左右。 单行注释Python 使用井号#作为单行注释的符号 123# 注释# 说明单行代码的功能时一般将注释放在代码的右侧print( 100 % 7 ) # 输出余数 多行注释Python 使用三个连续的单引号’’’或者三个连续的双引号”””注释多行内容 12345&#x27;&#x27;&#x27;使用 3 个单引号分别作为注释的开头和结尾可以一次性注释多行内容这里面的内容全部是注释内容&#x27;&#x27;&#x27; 当注释符作为字符串的一部分出现时，就不能再将它们视为注释标记，而应该看做正常代码的一部分 缩进规则通常情况下都是采用 4 个空格长度作为一个缩进量（默认情况下，一个 Tab 键就表示 4 个空格）。 通过设置多行代码的缩进量，可以使用 Ctrl+] 和 Ctrl+[ 快捷键，此快捷键可以使所选中代码快速缩进（或反缩进）。 编码规范Python 采用 PEP 8 作为编码规范，其中 PEP 是 Python Enhancement Proposal（Python 增强建议书）的缩写，8 代表的是 Python 代码的样式指南。 每个 import 语句只导入一个模块，尽量避免一次导入多个模块 不要在行尾添加分号，也不要用分号将两条命令放在同一行 建议每行不超过 80 个字符，如果超过，建议使用小括号将多行内容隐式的连接起来，而不推荐使用反斜杠 \\ 进行连接。 使用必要的空行可以增加代码的可读性 在运算符两侧、函数参数之间以及逗号两侧，都建议使用空格进行分隔。 标识符命名规范 标识符是由字符（AZ 和 az）、下划线和数字组成，但第一个字符不能是数字。 标识符不能和 Python 中的保留字相同。有关保留字，后续章节会详细介绍。 Python中的标识符中，不能包含空格、@、% 以及 $ 等特殊字符。 字母是严格区分大小写 以下划线开头的标识符有特殊含义 当标识符用作模块名时，应尽量短小，并且全部使用小写字母，可以使用下划线分割多个字母，例如 game_mian、game_register 等。 当标识符用作包的名称时，应尽量短小，也全部使用小写字母，不推荐使用下划线，例如 com.mr、com.mr.book 等。 当标识符用作类名时，应采用单词首字母大写的形式。 模块内部的类名，可以采用 “下划线+首字母大写” 的形式。 函数名、类中的属性名和方法名，应全部使用小写字母，多个单词之间可以用下划线分割。 常量命名应全部使用大写字母，单词之间可以用下划线分割。 变量类型变量定义与使用将数据放入变量的过程叫做赋值。 1name = value Python 是弱类型的语言 弱类型语言两个特点： 变量无须声明就可以直接赋值，对一个不存在的变量赋值就相当于定义了一个新变量。 变量的数据类型可以随时改变，比如，同一个变量可以一会儿被赋值为整数，一会儿被赋值为字符串。 弱类型是说在书写代码时不用刻意关注类型，但是在编程语言的内部仍然是有类型的。 int整数就是没有小数部分的数字，Python 中的整数包括正整数、0 和负整数。 Python 整数的取值范围是无限的，不管多大或者多小的数字。 float小数通常以浮点数的形式存储。 print 在输出浮点数时，会根据浮点数的长度和大小适当的舍去一部分数字，或者采用科学计数法。 string若干个字符的集合就是一个字符串（String）。必须由双引号&quot; &quot;或者单引号&#39; &#39;包围。 字符串的内容可以包含字母、标点、特殊符号、中文、日文等全世界的所有文字。 要想换行书写一个比较长的字符串，必须在行尾添加反斜杠\\。 123s2 = &#x27;It took me six months to write this Python tutorial. \\ Please give me more support. \\ I will keep it updated.&#x27; 也支持表达式的换行。 123num = 20 + 3 / 4 + \\ 2 * 3print(num) 长字符串中的换行、空格、缩进等空白符都会原样输出。 1234longstr = &#x27;&#x27;&#x27;It took me 6 months to write this Python tutorial.Please give me a to &#x27;thumb&#x27; to keep it updated.The Python tutorial is available at http://c.biancheng.net/python/.&#x27;&#x27;&#x27;print(longstr) 在普通字符串或者长字符串的开头加上r前缀，就变成了原始字符串。 12str1 = r&#x27;原始字符串内容&#x27;str2 = r&quot;&quot;&quot;原始字符串内容&quot;&quot;&quot; bytesbytes 类型用来表示一个字节串。 字节串（bytes）和字符串（string）的对比： 字符串由若干个字符组成，以字符为单位进行操作；字节串由若干个字节组成，以字节为单位进行操作。 字节串和字符串除了操作的数据单元不同之外，它们支持的所有方法都基本相同。 字节串和字符串都是不可变序列，不能随意增加和删除数据。 bytes 只是简单地记录内存中的原始数据。 字符串的内容都是 ASCII 字符，直接在字符串前面添加b前缀就可以转换成 bytes。 调用构造方法 bytes()，可以将字符串按照指定的字符集转换成 bytes；如果不指定字符集，那么默认采用 UTF-8。 字符串 encode() 方法，该方法专门用来将字符串按照指定的字符集转换成对应的字节串；如果不指定字符集，那么默认采用 UTF-8。 使用不同方式创建 bytes 对象。 1234567b1 = bytes()b2 = b&quot;&quot;#为 bytes() 方法指定字符集b4 = bytes(&#x27;C语言中文网8岁了&#x27;, encoding=&#x27;UTF-8&#x27;)print(&quot;b4: &quot;, b4)#通过 encode() 方法将字符串转换成 bytesb5 = &quot;C语言中文网8岁了&quot;.encode(&#x27;UTF-8&#x27;) bytes decode() 方法，通过该方法可以将 bytes 对象转换为字符串。 123#通过 decode() 方法将 bytes 转换成字符串str1 = b5.decode(&#x27;UTF-8&#x27;)print(&quot;str1: &quot;, str1) 对于非 ASCII 字符，print 输出的是它的字符编码值（十六进制形式），而不是字符本身。 bool布尔类型可以当做整数来对待，即 True 相当于整数值 1，False 相当于整数值 0。 类型转换 函 数 作 用 int(x) 将 x 转换成整数类型 float(x) 将 x 转换成浮点数类型 complex(real，[,imag]) 创建一个复数 str(x) 将 x 转换为字符串 repr(x) 将 x 转换为表达式字符串 eval(str) 计算在字符串中的有效 Python 表达式，并返回一个对象 chr(x) 将整数 x 转换为一个字符 ord(x) 将一个字符 x 转换为它对应的整数值 hex(x) 将一个整数 x 转换为一个十六进制字符串 oct(x) 将一个整数 x 转换为一个八进制的字符串","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://peapod.top/tags/python/"}]},{"title":"go-zero使用","slug":"go-zero使用","date":"2023-10-25T01:44:21.000Z","updated":"2023-10-25T02:06:21.000Z","comments":true,"path":"2023/10/25/go-zero使用/","link":"","permalink":"http://peapod.top/2023/10/25/go-zero%E4%BD%BF%E7%94%A8/","excerpt":"","text":"go-zero使用api domo使用 go-zero 创建一个简单的 HTTP 服务。 1goctl api new demo ~/workspace/api/demo/internal/logic/demologic.go 文件，编辑该文件，在 27 至 28 行添加如下代码： 12resp = new(types.Response)resp.Message = req.Name 启动服务 12go mod tidygo run demo.go grpc dome生成最小化的 gRPC 服务 1goctl rpc new gdemo ~/workspace/rpc/demo/internal/logic/pinglogic.go 文件，编辑该文件，将 29 行替换为如下代码： 123return &amp;demo.Response&#123; Pong:&quot;pong&quot;,&#125;, nil ~/workspace/rpc/demo/etc/demo.yaml，删除 3 至 7 行内容，然后在追加内容 Mode: dev 至末尾，使配置文件内容为： 123Name: demo.rpcListenOn: 0.0.0.0:8080Mode: dev 启动服务 12go mod tidygo run gdome.go","categories":[],"tags":[]},{"title":"go-zero入门","slug":"go-zero入门","date":"2023-10-25T01:32:56.000Z","updated":"2023-10-25T02:33:40.000Z","comments":true,"path":"2023/10/25/go-zero入门/","link":"","permalink":"http://peapod.top/2023/10/25/go-zero%E5%85%A5%E9%97%A8/","excerpt":"","text":"go-zero简介go-zero 是一个集成了各种工程实践的 web 和 rpc 框架。 保持简单，第一原则 弹性设计，面向故障编程 工具大于约定和文档 高可用 高并发 易扩展 对业务开发友好，封装复杂度 约束做一件事只有一种方式 有如下主要特点： 强大的工具支持，尽可能少的代码编写 极简的接口 完全兼容 net&#x2F;http 支持中间件，方便扩展 高性能 面向故障编程，弹性设计 内建服务发现、负载均衡 内建限流、熔断、降载，且自动触发，自动恢复 API 参数自动校验 超时级联控制 自动缓存控制 链路跟踪、统计报警等 高并发支撑，稳定保障了疫情期间每天的流量洪峰 使用1.安装go-zero 12GO111MODULE=on GOPROXY=https://goproxy.cn/,direct go get -u github.com/zeromicro/go-zero 2.安装go-ctl工具 12GOPROXY=https://goproxy.cn/,direct go install github.com/zeromicro/go-zero/tools/goctl@latest","categories":[],"tags":[{"name":"微服务框架","slug":"微服务框架","permalink":"http://peapod.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6/"}]},{"title":"fmt库","slug":"fmt库","date":"2023-10-07T03:14:16.000Z","updated":"2024-04-06T06:35:20.000Z","comments":true,"path":"2023/10/07/fmt库/","link":"","permalink":"http://peapod.top/2023/10/07/fmt%E5%BA%93/","excerpt":"","text":"fmt库使用Print、Printf、PrintlnPrint函数直接输出内容，Printf函数支持格式化输出字符串，Println函数会在输出内容的结尾添加一个换行符。 Fprint将内容输出到一个io.Writer接口类型的变量w中，通常用这个函数往文件中写入内容。 12345678910fmt.Fprintln(os.Stdout, &quot;向标准输出写入内容&quot;)fileObj, err := os.OpenFile(&quot;./xx.txt&quot;, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)if err != nil &#123; fmt.Println(&quot;打开文件出错，err:&quot;, err) return&#125;name := &quot;枯藤&quot;// 向打开的文件句柄中写入内容fmt.Fprintf(fileObj, &quot;往文件中写如信息：%s&quot;, name) SprintSprint系列函数会把传入的数据生成并返回一个字符串。 Errorf根据format参数生成格式化字符串并返回一个包含该字符串的错误。 1func Errorf(format string, a ...interface&#123;&#125;) error 格式化占位符 占位符 说明 %v 值的默认格式表示 %+v 类似%v，但输出结构体时会添加字段名 %#v 值的Go语法表示 %T 打印值的类型 %% 百分号 %t true或false %b 表示为二进制 %c 该值对应的unicode码值 %d 表示为十进制 %o 表示为八进制 %x 表示为十六进制，使用a-f %X 表示为十六进制，使用A-F %U 表示为Unicode格式：U+1234，等价于”U+%04X” %q 该值对应的单引号括起来的go语法字符字面值，必要时会采用安全的转义表示 %b 无小数部分、二进制指数的科学计数法，如-123456p-78 %e 科学计数法，如-1234.456e+78 %E 科学计数法，如-1234.456E+78 %f 有小数部分但无指数部分，如123.456 %F 等价于%f %g 根据实际情况采用%e或%f格式（以获得更简洁、准确的输出） %G 根据实际情况采用%E或%F格式（以获得更简洁、准确的输出） %s 直接输出字符串或者[]byte %q 该值对应的双引号括起来的go语法字符串字面值，必要时会采用安全的转义表示 %x 每个字节用两字符十六进制数表示（使用a-f %X 每个字节用两字符十六进制数表示（使用A-F） %f 默认宽度，默认精度 %9f 宽度9，默认精度 %.2f 默认宽度，精度2 %9.2f 宽度9，精度2 ’+’ 总是输出数值的正负号；对%q（%+q）会生成全部是ASCII字符的输出（通过转义）； ’ ‘ 对数值，正数前加空格而负数前加负号；对字符串采用%x或%X时（% x或% X）会给各打印的字节之间加空格 ’-’ 在输出右边填充空白而不是默认的左边（即从默认的右对齐切换为左对齐）； ’#’ 八进制数前加0（%#o），十六进制数前加0x（%#x）或0X（%#X），指针去掉前面的0x（%#p）对%q（%#q），对%U（%#U）会输出空格和单引号括起来的go字面值； ‘0’ 使用0而不是空格填充，对于数值类型会把填充的0放在正负号后面； 输入一行bufio.NewReader完整获取输入的内容，而输入的内容可能包含空格，这种情况下可以使用bufio包来实现. 1234567func bufioDemo() &#123; reader := bufio.NewReader(os.Stdin) // 从标准输入生成读对象 fmt.Print(&quot;请输入内容：&quot;) text, _ := reader.ReadString(&#x27;\\n&#x27;) // 读到换行 text = strings.TrimSpace(text) fmt.Printf(&quot;%#v\\n&quot;, text)&#125;","categories":[{"name":"golang标准库","slug":"golang标准库","permalink":"http://peapod.top/categories/golang%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"终端使用代理","slug":"终端使用代理","date":"2023-10-06T12:00:44.000Z","updated":"2024-02-28T02:21:36.000Z","comments":true,"path":"2023/10/06/终端使用代理/","link":"","permalink":"http://peapod.top/2023/10/06/%E7%BB%88%E7%AB%AF%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86/","excerpt":"","text":"终端使用代理命令12export http_proxy=http://127.0.0.1:7890export https_proxy=$http_proxy shell脚本12345678910function proxy_on() &#123; export http_proxy=http://127.0.0.1:7890 export https_proxy=\\$http_proxy echo -e &quot;终端代理已开启。&quot;&#125;function proxy_off()&#123; unset http_proxy https_proxy echo -e &quot;终端代理已关闭。&quot;&#125; 通过 proxy_on 启动代理，proxy_off 关闭代理。 1234# ~/.zprofilevim ~/.zshrc# 在文件后添加上面的脚本source ~/.zshrc 查看使用的是哪个shell123echo $SHELL# 安装了哪些shellcat /etc/shells bash和zsh的区别zsh能基本完美兼容bash的命令，并且使用起来更加优雅。由于bash或zsh本质上都是解释器，他们所共同服务的是shell语言，因此在命令语法上基本相同。 二者切换： 切换bash： chsh -s /bin/bash 切换zsh： chsh -s /bin/zsh 在终端app的系统偏好设置里手动设置。 配置文件： bash读取的配置文件：~/.bash_profile文件 zsh读取的配置文件：~/.zshrc文件 当从bash切换为zsh时，如果不想重新配置一遍.zshrc文件，可以__在.zshrc文件中加上source ~/.bash_profile。","categories":[],"tags":[]},{"title":"etcd集群搭建","slug":"etcd集群搭建","date":"2023-10-06T11:55:02.000Z","updated":"2023-10-06T11:56:09.000Z","comments":true,"path":"2023/10/06/etcd集群搭建/","link":"","permalink":"http://peapod.top/2023/10/06/etcd%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"","text":"etcd集群搭建1234567etcd --name infra0 --initial-advertise-peer-urls http://127.0.0.1:12380 \\ --listen-peer-urls http://127.0.0.1:12380 \\ --listen-client-urls http://127.0.0.1:12379,http://127.0.0.1:12379 \\ --advertise-client-urls http://127.0.0.1:12379 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-cluster infra0=http://127.0.0.1:12380,infra1=http://127.0.0.1:22380,infra2=http://127.0.0.1:32380 \\ --initial-cluster-state new 1234567etcd --name infra1 --initial-advertise-peer-urls http://127.0.0.1:22380 \\ --listen-peer-urls http://127.0.0.1:22380 \\ --listen-client-urls http://127.0.0.1:22379,http://127.0.0.1:22379 \\ --advertise-client-urls http://127.0.0.1:22379 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-cluster infra0=http://127.0.0.1:12380,infra1=http://127.0.0.1:22380,infra2=http://127.0.0.1:32380 \\ --initial-cluster-state new 1234567etcd --name infra2 --initial-advertise-peer-urls http://127.0.0.1:32380 \\ --listen-peer-urls http://127.0.0.1:32380 \\ --listen-client-urls http://127.0.0.1:32379,http://127.0.0.1:32379 \\ --advertise-client-urls http://127.0.0.1:32379 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-cluster infra0=http://127.0.0.1:12380,infra1=http://127.0.0.1:22380,infra2=http://127.0.0.1:32380 \\ --initial-cluster-state new","categories":[],"tags":[]},{"title":"Go并发-上","slug":"Go并发-上","date":"2023-10-02T12:53:23.000Z","updated":"2024-03-17T06:44:47.000Z","comments":true,"path":"2023/10/02/Go并发-上/","link":"","permalink":"http://peapod.top/2023/10/02/Go%E5%B9%B6%E5%8F%91-%E4%B8%8A/","excerpt":"","text":"Go并发-上基本概念123进程是程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位。线程是进程的一个执行实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。一个进程可以创建和撤销多个线程;同一个进程中的多个线程之间可以并发执行。 123456多线程程序在一个核的cpu上运行，就是并发。多线程程序在多个核的cpu上运行，就是并行。 协程：独立的栈空间，共享堆空间，调度由用户自己控制，本质上有点类似于用户级线程，这些用户级线程的调度也是自己实现的。线程：一个线程上可以跑多个协程，协程是轻量级的线程。并发主要由切换时间片来实现”同时”运行，并行则是直接利用多核实现多线程的运行，go可以设置使用核数，以发挥多核计算机的能力。 Goroutine goroutine是由Go的运行时（runtime）调度和管理的。Go程序会智能地将 goroutine 中的任务合理地分配给每个CPU。Go语言之所以被称为现代化的编程语言，就是因为它在语言层面已经内置了调度和上下文切换的机制。 一个goroutine必定对应一个函数，可以创建多个goroutine去执行相同的函数。 在程序启动时，Go程序就会为main()函数创建一个默认的goroutine。 goroutine与线程OS线程（操作系统线程）一般都有固定的栈内存（通常为2MB）,一个goroutine的栈在其生命周期开始时只有很小的栈（典型情况下2KB）。 GPM goroutine，里面除了存放本goroutine信息外 还有与所在P的绑定等信息。 P管理着一组goroutine队列，P里面会存储当前goroutine运行的上下文环境（函数指针，堆栈地址及地址边界），P会对自己管理的goroutine队列做一些调度（比如把占用CPU时间较长的goroutine暂停、运行后续的goroutine等等）当自己的队列消费完了就去全局队列里取，如果全局队列里也消费完了会去其他P的队列里抢任务。 M（machine）是Go运行时（runtime）对操作系统内核线程的虚拟， M与内核线程一般是一一映射的关系， 一个groutine最终是要放到M上执行的； P管理着一组G挂载在M上运行。当一个G长久阻塞在一个M上时，runtime会新建一个M，阻塞G所在的P会把其他的G 挂载在新建的M上。当旧的G阻塞完成或者认为其已经死掉时 回收旧的M。 其一大特点是goroutine的调度是在用户态下完成的， 不涉及内核态与用户态之间的频繁切换，包括内存的分配与释放，都是在用户态维护着一块大的内存池， 不直接调用系统的malloc函数（除非内存池需要改变），成本比调度OS线程低很多。 另一方面充分利用了多核的硬件资源，近似的把若干goroutine均分在物理线程上， 再加上本身goroutine的超轻量，以上种种保证了go调度方面的性能。 一个操作系统线程对应用户态多个goroutine。 go程序可以同时使用多个操作系统线程。 goroutine和OS线程是多对多的关系，即m:n。 channel函数与函数间需要交换数据才能体现并发执行函数的意义。 为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。 Go语言的并发模型是CSP（Communicating Sequential Processes），提倡通过通信共享内存而不是通过共享内存而实现通信。 channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制。 channel是一种类型，一种引用类型。声明通道类型的格式如下： 1var 变量类型 chan 元素类型 只有在通知接收方goroutine所有的数据都发送完毕的时候才需要关闭通道。通道是可以被垃圾回收机制回收的，它和关闭文件是不一样的，在结束操作之后关闭文件是必须要做的，但关闭通道不是必须的。 无缓冲的通道只有在有人接收值的时候才能发送值。无缓冲的通道必须有接收才能发送。使用无缓冲通道进行通信将导致发送和接收的goroutine同步化。因此，无缓冲通道也被称为同步通道。 只要通道的容量大于零，那么该通道就是有缓冲的通道，通道的容量表示通道中能存放元素的数量。","categories":[{"name":"golang标准库","slug":"golang标准库","permalink":"http://peapod.top/categories/golang%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Go反射","slug":"Go反射","date":"2023-10-02T11:53:59.000Z","updated":"2023-10-02T12:53:12.000Z","comments":true,"path":"2023/10/02/Go反射/","link":"","permalink":"http://peapod.top/2023/10/02/Go%E5%8F%8D%E5%B0%84/","excerpt":"","text":"Go反射在运行时更新和检查变量的值、调用变量的方法和变量支持的内在操作，但是在编译时并不知道这些变量的具体类型，这种机制被称为反射。 reflect 包来访问程序的反射信息。 定义了两个重要的类型 Type 和 Value 任意接口值在反射中都可以理解为由 reflect.Type 和 reflect.Value 两部分组成， reflect 包提供了 reflect.TypeOf 和 reflect.ValueOf 两个函数来获取任意对象的 Value 和 Type。 反射的类型对象（reflect.Type）12345678910package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)func main() &#123; var a int typeOfA := reflect.TypeOf(a) fmt.Println(typeOfA.Name(), typeOfA.Kind())&#125; Go语言中的类型名称对应的反射获取方法是 reflect.Type 中的 Name() 方法，返回表示类型名称的字符串；类型归属的种类（Kind）使用的是 reflect.Type 中的 Kind() 方法，返回 reflect.Kind 类型的常量。 Go语言程序中对指针获取反射对象时，可以通过 reflect.Elem() 方法获取这个指针指向的元素类型，这个获取过程被称为取元素，等效于对指针类型变量做了一个*操作","categories":[],"tags":[]},{"title":"Go对象","slug":"Go对象","date":"2023-10-02T10:45:28.000Z","updated":"2024-02-27T10:46:38.000Z","comments":true,"path":"2023/10/02/Go对象/","link":"","permalink":"http://peapod.top/2023/10/02/Go%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"第8章：对象匿名字段提供类型而不写字段名的方式，也就是匿名字段，也称为嵌入字段 12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;//go支持只提供类型而不写字段名的方式，也就是匿名字段，也称为嵌入字段type Person struct &#123; name string sex string age int&#125;type Student struct &#123; Person id int addr string&#125;func main() &#123; // 初始化 s1 := Student&#123;Person&#123;&quot;5lmh&quot;, &quot;man&quot;, 20&#125;, 1, &quot;bj&quot;&#125; fmt.Println(s1) s2 := Student&#123;Person: Person&#123;&quot;5lmh&quot;, &quot;man&quot;, 20&#125;&#125; fmt.Println(s2) s3 := Student&#123;Person: Person&#123;name: &quot;5lmh&quot;&#125;&#125; fmt.Println(s3)&#125; 所有的内置类型和自定义类型都是可以作为匿名字段去使用 接口接口（interface）定义了一个对象的行为规范，只定义规范不实现，由具体的对象来实现规范的细节。 在Go语言中接口（interface）是一种类型，一种抽象的类型。 接口定义123456接口是一个或多个方法签名的集合。任何类型的方法集中只要拥有该接口&#x27;对应的全部方法&#x27;签名。就表示它 &quot;实现&quot; 了该接口，无须在该类型上显式声明实现了哪个接口。接口可以匿名嵌入其他接口，或嵌入到结构中。只有当接口存储的类型和对象都为nil时，接口才等于nil。空接口可以作为任何类型数据的容器。 12345type 接口类型名 interface&#123; 方法名1( 参数列表1 ) 返回值列表1 方法名2( 参数列表2 ) 返回值列表2 … &#125; 一个对象只要全部实现了接口中的方法，那么就实现了这个接口。 接口类型变量能够存储所有实现了该接口的实例。 使用值接收者实现接口之后，不管是dog结构体还是结构体指针*dog类型的变量都可以赋值给该接口变量。因为Go语言中有对指针类型变量求值的语法糖. 指针接收者实现接口 12345678910func (d *dog) move() &#123; fmt.Println(&quot;狗会动&quot;)&#125;func main() &#123; var x Mover var wangcai = dog&#123;&#125; // 旺财是dog类型 x = wangcai // x不可以接收dog类型 var fugui = &amp;dog&#123;&#125; // 富贵是*dog类型 x = fugui // x可以接收*dog类型&#125; 此时实现Mover接口的是*dog类型，所以不能给x传入dog类型的wangcai，此时x只能存储*dog类型的值。 一个类型可以同时实现多个接口，而接口间彼此独立，不知道对方的实现。 Go语言中不同的类型还可以实现同一接口. 一个接口的方法，不一定需要由一个类型完全实现，接口的方法可以通过在类型中嵌入其他类型或者结构体来实现。 接口与接口间可以通过嵌套创造出新的接口。 空接口空接口是指没有定义任何方法的接口。因此任何类型都实现了空接口。 空接口类型的变量可以存储任意类型的变量。 空接口作为函数的参数 空接口作为map的值 类型断言一个接口的值（简称接口值）是由一个具体类型和具体类型的值两部分组成的。这两部分分别称为接口的动态类型和动态值。 判断空接口中的值这个时候就可以使用类型断言，其语法格式： 123 x.(T) x：表示类型为interface&#123;&#125;的变量T：表示断言x可能是的类型。 返回两个参数，第一个参数是x转化为T类型后的变量，第二个值是一个布尔值，若为true则表示断言成功，为false则表示断言失败。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Go方法","slug":"Go方法","date":"2023-10-02T10:21:35.000Z","updated":"2023-10-02T10:45:17.000Z","comments":true,"path":"2023/10/02/Go方法/","link":"","permalink":"http://peapod.top/2023/10/02/Go%E6%96%B9%E6%B3%95/","excerpt":"","text":"第7章：方法方法定义方法总是绑定对象实例，并隐式将实例作为第一实参 (receiver)。 一个方法就是一个包含了接受者的函数，接受者可以是命名类型或者结构体类型的一个值或者是一个指针。 123func (recevier type) methodName(参数列表)(返回值列表)&#123;&#125; 参数和返回值可以省略 匿名字段可以像字段成员那样访问匿名字段方法，编译器负责查找。 通过匿名字段，可获得和继承类似的复用能力。依据编译器查找次序，只需在外层定义同名方法，就可以实现 “override”。 1234567891011121314151617181920212223242526272829package mainimport &quot;fmt&quot;type User struct &#123; id int name string&#125;type Manager struct &#123; User title string&#125;func (self *User) ToString() string &#123; return fmt.Sprintf(&quot;User: %p, %v&quot;, self, self)&#125;func (self *Manager) ToString() string &#123; return fmt.Sprintf(&quot;Manager: %p, %v&quot;, self, self)&#125;func main() &#123; m := Manager&#123;User&#123;1, &quot;Tom&quot;&#125;, &quot;Administrator&quot;&#125; fmt.Println(m.ToString()) fmt.Println(m.User.ToString())&#125;","categories":[],"tags":[]},{"title":"Validator 参数验证","slug":"Validator参数验证","date":"2023-06-24T02:18:58.000Z","updated":"2023-06-24T02:49:14.000Z","comments":true,"path":"2023/06/24/Validator参数验证/","link":"","permalink":"http://peapod.top/2023/06/24/Validator%E5%8F%82%E6%95%B0%E9%AA%8C%E8%AF%81/","excerpt":"","text":"Validator 参数验证Validator 简介Validator 是基于 tag（标记）实现结构体和单个字段的值验证库，它包含以下功能： 使用验证 tag（标记）或自定义验证器进行跨字段和跨结构体验证。 关于 slice、数组和 map，允许验证多维字段的任何或所有级别。 能够深入 map 键和值进行验证。 通过在验证之前确定接口的基础类型来处理类型接口。 处理自定义字段类型（如 sql 驱动程序 Valuer）。 别名验证标记，它允许将多个验证映射到单个标记，以便更轻松地定义结构体上的验证。 提取自定义的字段名称，例如，可以指定在验证时提取 JSON 名称，并在生成的 FieldError 中使用该名称。 可自定义 i18n 错误消息。 Web 框架 gin 的默认验证器。 安装1go get github.com/go-playground/validator/v10 使用单个变量验证1234567891011func main() &#123; validate := validator.New() // 验证变量 email := &quot;admin#admin.com&quot; err := validate.Var(email, &quot;required,email&quot;) if err != nil &#123; validationErrors := err.(validator.ValidationErrors) fmt.Println(validationErrors) return &#125;&#125; 结构体1234567891011121314151617181920212223func main() &#123; validate = validator.New() type User struct &#123; ID int64 `json:&quot;id&quot; validate:&quot;gt=0&quot;` Name string `json:&quot;name&quot; validate:&quot;required&quot;` Gender string `json:&quot;gender&quot; validate:&quot;required,oneof=man woman&quot;` Age uint8 `json:&quot;age&quot; validate:&quot;required,gte=0,lte=130&quot;` Email string `json:&quot;email&quot; validate:&quot;required,email&quot;` &#125; user := &amp;User&#123; ID: 1, Name: &quot;frank&quot;, Gender: &quot;boy&quot;, Age: 180, Email: &quot;gopher@88.com&quot;, &#125; err = validate.Struct(user) if err != nil &#123; validationErrors := err.(validator.ValidationErrors) fmt.Println(validationErrors) return &#125;&#125; 错误信息翻译为中文安装翻译包12go get -u github.com/go-playground/localesgo get -u github.com/go-playground/universal-translator 导入1234&quot;github.com/go-playground/locales/zh&quot;ut &quot;github.com/go-playground/universal-translator&quot;&quot;github.com/go-playground/validator/v10&quot;zh_translations &quot;github.com/go-playground/validator/v10/translations/zh&quot; 使用12345678910111213141516171819202122232425262728293031323334353637383940func main() &#123; // 实例化验证器 validate := validator.New() type User struct &#123; ID int64 `json:&quot;id&quot; validate:&quot;gt=0&quot;` Name string `json:&quot;name&quot; validate:&quot;required&quot;` Gender string `json:&quot;gender&quot; validate:&quot;required,oneof=man woman&quot;` Age uint8 `json:&quot;age&quot; validate:&quot;required,gte=0,lte=130&quot;` Email string `json:&quot;email&quot; validate:&quot;required,email&quot;` &#125; user := &amp;User&#123; ID: 1, Name: &quot;frank&quot;, Gender: &quot;boy&quot;, Age: 180, Email: &quot;gopher@88.com&quot;, &#125; // 注册一个函数，获取结构体字段的备用名称 validate.RegisterTagNameFunc(func(fld reflect.StructField) string &#123; name := strings.SplitN(fld.Tag.Get(&quot;json&quot;), &quot;,&quot;, 2)[0] if name == &quot;-&quot; &#123; return &quot;j&quot; &#125; return name &#125;) // 中文翻译器 uni := ut.New(zh.New()) trans, _ := uni.GetTranslator(&quot;zh&quot;) // 注册翻译器到校验器 _ = zh_translations.RegisterDefaultTranslations(validate, trans) err := validate.Struct(user) if err != nil &#123; for _, err := range err.(validator.ValidationErrors) &#123; // 错误翻译 fmt.Println(err.Translate(trans)) &#125; &#125;&#125;","categories":[],"tags":[]},{"title":"GRPC流的使用","slug":"GRPC流的使用","date":"2023-06-22T11:38:45.000Z","updated":"2023-06-22T12:19:42.000Z","comments":true,"path":"2023/06/22/GRPC流的使用/","link":"","permalink":"http://peapod.top/2023/06/22/GRPC%E6%B5%81%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"GRPC流的使用流传输方式简介客户端流客户端发送多次，服务端响应一次（关闭时响应）。 服务端流客户端先发送一次，服务端响应多次。 双向流客户端发送，服务端响应。 客户端流服务定义1rpc ClientStreamPing(stream PingRequest) returns (PingReply); 客户端123456789101112131415161718192021stream, err := client.SayStream(context.Background()) err = stream.Send(&amp;pd.HelloReq&#123; Name: &quot;111&quot;, Age: 3, &#125;) if err != nil &#123; fmt.Printf(err.Error()) &#125; stream.Send(&amp;pd.HelloReq&#123; Name: &quot;111&quot;, Age: 4, &#125;) stream.Send(&amp;pd.HelloReq&#123; Name: &quot;111&quot;, Age: 5, &#125;) recv, err := stream.CloseAndRecv() if err != nil &#123; return &#125; fmt.Printf(&quot;接受：%s&quot;, recv.Say) 创建客户端之后，调用服务生成流 使用流发送消息 关闭流并接受服务端的响应 服务端123456789101112131415func (s *Server) SayStream(stream pd.HelloServer_SayStreamServer) error &#123; for &#123; //源源不断的去接收客户端发来的信息 recv, err := stream.Recv() if err != nil &#123; if err == io.EOF &#123; break &#125; return err &#125; fmt.Println(&quot;服务端接收到的流&quot;, recv.Name, recv.Age) &#125; return stream.SendAndClose(&amp;pd.HelloRep&#123;Say: &quot;结束&quot;&#125;)&#125; 实现流的接口 接受客户端发送的消息 正常关闭时发送响应消息 服务端流服务定义1rpc ServerStreamPing(PingRequest) returns (stream PingReply); 客户端12345678910111213141516171819stream, err := client.SayStreamServer(context.Background(), &amp;pd.HelloReq&#123; Name: &quot;111&quot;, Age: 0, &#125;) for &#123; recv, err := stream.Recv() if err != nil &#123; if err == io.EOF &#123; fmt.Println(&quot;客户端数据接收完成&quot;) err := stream.CloseSend() if err != nil &#123; log.Fatal(err) &#125; break &#125; log.Fatal(err) &#125; fmt.Println(&quot;客户端收到的流&quot;, recv.Say) &#125; 服务端12345678910111213141516func (s *Server) SayStreamServer(req *pd.HelloReq, stream pd.HelloServer_SayStreamServerServer) error &#123; count := 0 fmt.Printf(req.Name, req.Age) for &#123; rsp := &amp;pd.HelloRep&#123;Say: &quot;server send&quot;&#125; err := stream.Send(rsp) if err != nil &#123; return err &#125; time.Sleep(time.Second) count++ if count &gt; 10 &#123; return nil &#125; &#125;&#125; 双向流服务定义1rpc SayDoubleStream(stream helloReq) returns (stream helloRep) &#123;&#125;; 客户端1234567891011121314151617181920stream, err := client.SayDoubleStream(context.Background()) var count int32 = 22 for &#123; request := &amp;pd.HelloReq&#123; Name: &quot;zzz&quot;, Age: count, &#125; err = stream.Send(request) count++ if err != nil &#123; log.Fatal(err) &#125; time.Sleep(time.Second) recv, err := stream.Recv() if err != nil &#123; log.Fatal(err) &#125; //websocket fmt.Println(&quot;客户端收到的流信息&quot;, recv.Say) &#125; 服务端123456789101112131415func (s *Server) SayDoubleStream(stream pd.HelloServer_SayDoubleStreamServer) error &#123; for &#123; recv, err := stream.Recv() if err != nil &#123; return nil &#125; fmt.Println(&quot;服务端收到客户端的消息&quot;, recv.Name, recv.Age) time.Sleep(time.Second) rsp := &amp;pd.HelloRep&#123;Say: fmt.Sprintf(&quot;%s的年龄：%d&quot;, recv.Name, recv.Age)&#125; err = stream.Send(rsp) if err != nil &#123; return nil &#125; &#125;&#125;","categories":[],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://peapod.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"GRPC使用openssl","slug":"GRPC使用openssl","date":"2023-06-22T03:08:18.000Z","updated":"2023-06-22T03:09:06.000Z","comments":true,"path":"2023/06/22/GRPC使用openssl/","link":"","permalink":"http://peapod.top/2023/06/22/GRPC%E4%BD%BF%E7%94%A8openssl/","excerpt":"","text":"GRPC使用openssl证书加密数据传输过程，保证调用的安全性。 证书生成自签证书（root CA）命令解析：https://blog.csdn.net/adminstate/article/details/128662641 生成私钥文件 1openssl genrsa -des3 -out private.key 2048 创建证书请求 1openssl req -new -key private.key -out ca.csr 生成ca.crt 1openssl x509 -req -days 365 -in ca.csr -signkey private.key -out ca.crt SAN证书参考：https://blog.csdn.net/a145127/article/details/126311442 SAN证书需要上述生成的根证书。 设置配置文件 终端openssl version -d可以查找配置文件 修改配置文件 生成服务器密钥和证书 12345678# 生成服务器私钥，密码输入123456$ openssl genpkey -algorithm RSA -out ../server/server.key # 使用私钥来签名证书$ openssl req -new -nodes -key ../server/server.key -out ../server/server.csr -config openssl.cnf -extensions &#x27;v3_req&#x27; # 生成SAN证书$ openssl x509 -req -in ../server/server.csr -out ../server/server.pem -CA ca.crt -CAkey private.key -CAcreateserial -extfile ./openssl.cnf -extensions &#x27;v3_req&#x27; 生成客户端密钥和证书 12345678# 生成客户端私钥，密码输入123456$ openssl genpkey -algorithm RSA -out ../client/client.key # 使用私钥来签名证书$ openssl req -new -nodes -key ../client/client.key -out ../client/client.csr -config openssl.cnf -extensions &#x27;v3_req&#x27; # 生成SAN证书$ openssl x509 -req -in ../client/client.csr -out ../client/client.pem -CA ca.crt -CAkey private.key -CAcreateserial -extfile ./openssl.cnf -extensions &#x27;v3_req&#x27; 目录结构 单项认证 服务端使用证书和私钥 1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;google.golang.org/grpc/credentials&quot; pd &quot;grpc_helloworld/server/proto&quot; &quot;log&quot; &quot;net&quot;)type Server struct &#123; pd.UnimplementedHelloServerServer&#125;func (s *Server) Say(ctx context.Context, q *pd.HelloReq) (*pd.HelloRep, error) &#123; return &amp;pd.HelloRep&#123; Say: fmt.Sprintf(&quot;%s已经%d岁了&quot;, q.Name, q.Age), &#125;, nil&#125;func main() &#123; // 读取证书 file, _ := credentials.NewServerTLSFromFile(&quot;./server.pem&quot;, &quot;./server.key&quot;) listen, _ := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) // 创建服务并添加证书 newServer := grpc.NewServer(grpc.Creds(file)) pd.RegisterHelloServerServer(newServer, new(Server)) err := newServer.Serve(listen) if err != nil &#123; log.Print(&quot;err:&quot;, err) &#125;&#125; 客户端使用公钥(证书中有公钥) 123456789101112131415161718192021222324252627282930313233package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;google.golang.org/grpc/credentials&quot; pd &quot;grpc_helloworld/client/proto&quot; &quot;log&quot;)func main() &#123; // 添加证书 file, err2 := credentials.NewClientTLSFromFile(&quot;../server/server.pem&quot;, &quot;*.test.example.com&quot;) if err2 != nil &#123; log.Fatal(&quot;证书错误&quot;, err2) &#125; conn, err := grpc.Dial(&quot;:8080&quot;, grpc.WithTransportCredentials(file)) if err != nil &#123; fmt.Print(err) &#125; defer conn.Close() client := pd.NewHelloServerClient(conn) feature, err := client.Say(context.Background(), &amp;pd.HelloReq&#123; Name: &quot;hello&quot;, Age: 22, &#125;) if err != nil &#123; log.Print(err) &#125; fmt.Print(feature)&#125; 双向认证服务端1234567891011121314151617181920212223242526272829303132func main() &#123; cert, err := tls.LoadX509KeyPair(&quot;./server.pem&quot;, &quot;./server.key&quot;) if err != nil &#123; log.Fatal(&quot;证书读取错误&quot;, err) &#125; // 创建一个新的、空的 CertPool certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(&quot;../encryption/ca.crt&quot;) if err != nil &#123; log.Fatal(&quot;ca证书读取错误&quot;, err) &#125; // 尝试解析所传入的 PEM 编码的证书。如果解析成功会将其加到 CertPool 中，便于后面的使用 certPool.AppendCertsFromPEM(ca) // 构建基于 TLS 的 TransportCredentials 选项 creds := credentials.NewTLS(&amp;tls.Config&#123; // 设置证书链，允许包含一个或多个 Certificates: []tls.Certificate&#123;cert&#125;, // 要求必须校验客户端的证书。可以根据实际情况选用以下参数 ClientAuth: tls.RequireAndVerifyClientCert, // 设置根证书的集合，校验方式使用 ClientAuth 中设定的模式 ClientCAs: certPool, &#125;) listen, _ := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) // 创建服务并添加证书 newServer := grpc.NewServer(grpc.Creds(creds)) pd.RegisterHelloServerServer(newServer, new(Server)) err = newServer.Serve(listen) if err != nil &#123; log.Print(&quot;err:&quot;, err) &#125;&#125; 客户端1234567891011121314151617181920212223242526272829303132func main() &#123; // 添加证书 cert, _ := tls.LoadX509KeyPair(&quot;./client.pem&quot;, &quot;./client.key&quot;) // 创建一个新的、空的 CertPool certPool := x509.NewCertPool() ca, _ := ioutil.ReadFile(&quot;../encryption/ca.crt&quot;) // 尝试解析所传入的 PEM 编码的证书。如果解析成功会将其加到 CertPool 中，便于后面的使用 certPool.AppendCertsFromPEM(ca) // 构建基于 TLS 的 TransportCredentials 选项 creds := credentials.NewTLS(&amp;tls.Config&#123; // 设置证书链，允许包含一个或多个 Certificates: []tls.Certificate&#123;cert&#125;, // 要求必须校验客户端的证书。可以根据实际情况选用以下参数 ServerName: &quot;*.test.example.com&quot;, RootCAs: certPool, &#125;) conn, err := grpc.Dial(&quot;:8080&quot;, grpc.WithTransportCredentials(creds)) if err != nil &#123; fmt.Print(err) &#125; defer conn.Close() client := pd.NewHelloServerClient(conn) feature, err := client.Say(context.Background(), &amp;pd.HelloReq&#123; Name: &quot;hello&quot;, Age: 22, &#125;) if err != nil &#123; log.Print(err) &#125; fmt.Print(feature)&#125; token认证服务端校验12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;google.golang.org/grpc/codes&quot; &quot;google.golang.org/grpc/metadata&quot; &quot;google.golang.org/grpc/status&quot; pd &quot;grpc_helloworld/server/proto&quot; &quot;log&quot; &quot;net&quot;)type Server struct &#123; pd.UnimplementedHelloServerServer&#125;func (s *Server) Say(ctx context.Context, q *pd.HelloReq) (*pd.HelloRep, error) &#123; return &amp;pd.HelloRep&#123; Say: fmt.Sprintf(&quot;%s已经%d岁了&quot;, q.Name, q.Age), &#125;, nil&#125;func main() &#123; var authInterceptor grpc.UnaryServerInterceptor authInterceptor = func( ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler, ) (resp interface&#123;&#125;, err error) &#123; //拦截普通方法请求，验证 Token err = Auth(ctx) if err != nil &#123; return &#125; // 继续处理请求 return handler(ctx, req) &#125; listen, _ := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) // 创建服务并添加证书 newServer := grpc.NewServer(grpc.UnaryInterceptor(authInterceptor)) pd.RegisterHelloServerServer(newServer, new(Server)) err := newServer.Serve(listen) if err != nil &#123; log.Print(&quot;err:&quot;, err) &#125;&#125;func Auth(ctx context.Context) error &#123; md, ok := metadata.FromIncomingContext(ctx) if !ok &#123; return fmt.Errorf(&quot;missing credentials&quot;) &#125; var user string var password string if val, ok := md[&quot;user&quot;]; ok &#123; user = val[0] &#125; if val, ok := md[&quot;password&quot;]; ok &#123; password = val[0] &#125; if user != &quot;admin&quot; || password != &quot;123456&quot; &#123; return status.Errorf(codes.Unauthenticated, &quot;token不合法&quot;) &#125; return nil&#125; 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;google.golang.org/grpc/credentials/insecure&quot; pd &quot;grpc_helloworld/client/proto&quot; &quot;log&quot;)type Authentication struct &#123; User string Password string&#125;func (a *Authentication) GetRequestMetadata(context.Context, ...string) ( map[string]string, error,) &#123; return map[string]string&#123;&quot;user&quot;: a.User, &quot;password&quot;: a.Password&#125;, nil&#125;func (a *Authentication) RequireTransportSecurity() bool &#123; return false&#125;func main() &#123; user := &amp;Authentication&#123; User: &quot;admin&quot;, Password: &quot;123456&quot;, &#125; conn, err := grpc.Dial(&quot;:8080&quot;, grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithPerRPCCredentials(user)) if err != nil &#123; fmt.Print(err) &#125; defer conn.Close() client := pd.NewHelloServerClient(conn) feature, err := client.Say(context.Background(), &amp;pd.HelloReq&#123; Name: &quot;hello&quot;, Age: 22, &#125;) if err != nil &#123; log.Print(err) &#125; fmt.Print(feature)&#125;","categories":[],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://peapod.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"","slug":"openssl使用","date":"2023-06-22T02:57:27.000Z","updated":"2023-06-22T02:57:27.000Z","comments":true,"path":"2023/06/22/openssl使用/","link":"","permalink":"http://peapod.top/2023/06/22/openssl%E4%BD%BF%E7%94%A8/","excerpt":"","text":"GRPC使用openssl证书加密数据传输过程，保证调用的安全性。 证书生成自签证书（root CA）命令解析：https://blog.csdn.net/adminstate/article/details/128662641 生成私钥文件 1openssl genrsa -des3 -out private.key 2048 创建证书请求 1openssl req -new -key private.key -out ca.csr 生成ca.crt 1openssl x509 -req -days 365 -in ca.csr -signkey private.key -out ca.crt SAN证书参考：https://blog.csdn.net/a145127/article/details/126311442 SAN证书需要上述生成的根证书。 设置配置文件 终端openssl version -d可以查找配置文件 修改配置文件 生成服务器密钥和证书 12345678# 生成服务器私钥，密码输入123456$ openssl genpkey -algorithm RSA -out ../server/server.key # 使用私钥来签名证书$ openssl req -new -nodes -key ../server/server.key -out ../server/server.csr -config openssl.cnf -extensions &#x27;v3_req&#x27; # 生成SAN证书$ openssl x509 -req -in ../server/server.csr -out ../server/server.pem -CA ca.crt -CAkey private.key -CAcreateserial -extfile ./openssl.cnf -extensions &#x27;v3_req&#x27; 生成客户端密钥和证书 12345678# 生成客户端私钥，密码输入123456$ openssl genpkey -algorithm RSA -out ../client/client.key # 使用私钥来签名证书$ openssl req -new -nodes -key ../client/client.key -out ../client/client.csr -config openssl.cnf -extensions &#x27;v3_req&#x27; # 生成SAN证书$ openssl x509 -req -in ../client/client.csr -out ../client/client.pem -CA ca.crt -CAkey private.key -CAcreateserial -extfile ./openssl.cnf -extensions &#x27;v3_req&#x27; 目录结构 单项认证 服务端使用证书和私钥 1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;google.golang.org/grpc/credentials&quot; pd &quot;grpc_helloworld/server/proto&quot; &quot;log&quot; &quot;net&quot;)type Server struct &#123; pd.UnimplementedHelloServerServer&#125;func (s *Server) Say(ctx context.Context, q *pd.HelloReq) (*pd.HelloRep, error) &#123; return &amp;pd.HelloRep&#123; Say: fmt.Sprintf(&quot;%s已经%d岁了&quot;, q.Name, q.Age), &#125;, nil&#125;func main() &#123; // 读取证书 file, _ := credentials.NewServerTLSFromFile(&quot;./server.pem&quot;, &quot;./server.key&quot;) listen, _ := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) // 创建服务并添加证书 newServer := grpc.NewServer(grpc.Creds(file)) pd.RegisterHelloServerServer(newServer, new(Server)) err := newServer.Serve(listen) if err != nil &#123; log.Print(&quot;err:&quot;, err) &#125;&#125; 客户端使用公钥(证书中有公钥) 123456789101112131415161718192021222324252627282930313233package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;google.golang.org/grpc/credentials&quot; pd &quot;grpc_helloworld/client/proto&quot; &quot;log&quot;)func main() &#123; // 添加证书 file, err2 := credentials.NewClientTLSFromFile(&quot;../server/server.pem&quot;, &quot;*.test.example.com&quot;) if err2 != nil &#123; log.Fatal(&quot;证书错误&quot;, err2) &#125; conn, err := grpc.Dial(&quot;:8080&quot;, grpc.WithTransportCredentials(file)) if err != nil &#123; fmt.Print(err) &#125; defer conn.Close() client := pd.NewHelloServerClient(conn) feature, err := client.Say(context.Background(), &amp;pd.HelloReq&#123; Name: &quot;hello&quot;, Age: 22, &#125;) if err != nil &#123; log.Print(err) &#125; fmt.Print(feature)&#125; 双向认证服务端1234567891011121314151617181920212223242526272829303132func main() &#123; cert, err := tls.LoadX509KeyPair(&quot;./server.pem&quot;, &quot;./server.key&quot;) if err != nil &#123; log.Fatal(&quot;证书读取错误&quot;, err) &#125; // 创建一个新的、空的 CertPool certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(&quot;../encryption/ca.crt&quot;) if err != nil &#123; log.Fatal(&quot;ca证书读取错误&quot;, err) &#125; // 尝试解析所传入的 PEM 编码的证书。如果解析成功会将其加到 CertPool 中，便于后面的使用 certPool.AppendCertsFromPEM(ca) // 构建基于 TLS 的 TransportCredentials 选项 creds := credentials.NewTLS(&amp;tls.Config&#123; // 设置证书链，允许包含一个或多个 Certificates: []tls.Certificate&#123;cert&#125;, // 要求必须校验客户端的证书。可以根据实际情况选用以下参数 ClientAuth: tls.RequireAndVerifyClientCert, // 设置根证书的集合，校验方式使用 ClientAuth 中设定的模式 ClientCAs: certPool, &#125;) listen, _ := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) // 创建服务并添加证书 newServer := grpc.NewServer(grpc.Creds(creds)) pd.RegisterHelloServerServer(newServer, new(Server)) err = newServer.Serve(listen) if err != nil &#123; log.Print(&quot;err:&quot;, err) &#125;&#125; 客户端1234567891011121314151617181920212223242526272829303132func main() &#123; // 添加证书 cert, _ := tls.LoadX509KeyPair(&quot;./client.pem&quot;, &quot;./client.key&quot;) // 创建一个新的、空的 CertPool certPool := x509.NewCertPool() ca, _ := ioutil.ReadFile(&quot;../encryption/ca.crt&quot;) // 尝试解析所传入的 PEM 编码的证书。如果解析成功会将其加到 CertPool 中，便于后面的使用 certPool.AppendCertsFromPEM(ca) // 构建基于 TLS 的 TransportCredentials 选项 creds := credentials.NewTLS(&amp;tls.Config&#123; // 设置证书链，允许包含一个或多个 Certificates: []tls.Certificate&#123;cert&#125;, // 要求必须校验客户端的证书。可以根据实际情况选用以下参数 ServerName: &quot;*.test.example.com&quot;, RootCAs: certPool, &#125;) conn, err := grpc.Dial(&quot;:8080&quot;, grpc.WithTransportCredentials(creds)) if err != nil &#123; fmt.Print(err) &#125; defer conn.Close() client := pd.NewHelloServerClient(conn) feature, err := client.Say(context.Background(), &amp;pd.HelloReq&#123; Name: &quot;hello&quot;, Age: 22, &#125;) if err != nil &#123; log.Print(err) &#125; fmt.Print(feature)&#125; token认证服务端校验12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;google.golang.org/grpc/codes&quot; &quot;google.golang.org/grpc/metadata&quot; &quot;google.golang.org/grpc/status&quot; pd &quot;grpc_helloworld/server/proto&quot; &quot;log&quot; &quot;net&quot;)type Server struct &#123; pd.UnimplementedHelloServerServer&#125;func (s *Server) Say(ctx context.Context, q *pd.HelloReq) (*pd.HelloRep, error) &#123; return &amp;pd.HelloRep&#123; Say: fmt.Sprintf(&quot;%s已经%d岁了&quot;, q.Name, q.Age), &#125;, nil&#125;func main() &#123; var authInterceptor grpc.UnaryServerInterceptor authInterceptor = func( ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler, ) (resp interface&#123;&#125;, err error) &#123; //拦截普通方法请求，验证 Token err = Auth(ctx) if err != nil &#123; return &#125; // 继续处理请求 return handler(ctx, req) &#125; listen, _ := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) // 创建服务并添加证书 newServer := grpc.NewServer(grpc.UnaryInterceptor(authInterceptor)) pd.RegisterHelloServerServer(newServer, new(Server)) err := newServer.Serve(listen) if err != nil &#123; log.Print(&quot;err:&quot;, err) &#125;&#125;func Auth(ctx context.Context) error &#123; md, ok := metadata.FromIncomingContext(ctx) if !ok &#123; return fmt.Errorf(&quot;missing credentials&quot;) &#125; var user string var password string if val, ok := md[&quot;user&quot;]; ok &#123; user = val[0] &#125; if val, ok := md[&quot;password&quot;]; ok &#123; password = val[0] &#125; if user != &quot;admin&quot; || password != &quot;123456&quot; &#123; return status.Errorf(codes.Unauthenticated, &quot;token不合法&quot;) &#125; return nil&#125; 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;google.golang.org/grpc/credentials/insecure&quot; pd &quot;grpc_helloworld/client/proto&quot; &quot;log&quot;)type Authentication struct &#123; User string Password string&#125;func (a *Authentication) GetRequestMetadata(context.Context, ...string) ( map[string]string, error,) &#123; return map[string]string&#123;&quot;user&quot;: a.User, &quot;password&quot;: a.Password&#125;, nil&#125;func (a *Authentication) RequireTransportSecurity() bool &#123; return false&#125;func main() &#123; user := &amp;Authentication&#123; User: &quot;admin&quot;, Password: &quot;123456&quot;, &#125; conn, err := grpc.Dial(&quot;:8080&quot;, grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithPerRPCCredentials(user)) if err != nil &#123; fmt.Print(err) &#125; defer conn.Close() client := pd.NewHelloServerClient(conn) feature, err := client.Say(context.Background(), &amp;pd.HelloReq&#123; Name: &quot;hello&quot;, Age: 22, &#125;) if err != nil &#123; log.Print(err) &#125; fmt.Print(feature)&#125;","categories":[],"tags":[]},{"title":"GRPC使用","slug":"GRPC使用","date":"2023-06-19T12:20:34.000Z","updated":"2023-06-20T02:50:30.000Z","comments":true,"path":"2023/06/19/GRPC使用/","link":"","permalink":"http://peapod.top/2023/06/19/GRPC%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Grpc简介及使用简介在 gRPC 中，客户端应用程序可以像本地对象一样直接调用不同机器上的服务器应用程序上的方法，可以更轻松地创建分布式应用程序和服务。 服务端实现了接口，运行一个gRPC服务端来处理客户端调用。客户端提供与服务器相同的方法。 使用 编写.proto文件 使用protoc生成.pd.go和-grpc.pd.go文件 编写服务端代码 实现接口 监听端口 新建grpc服务 注册接口的实现（结构体） 调用grpc服务的Server方法 编写客户端代码 拨号建立连接 创建客户端 客户端调用服务端实现的接口方法 .proto文件12345678910111213syntax = &quot;proto3&quot;;option go_package = &quot;.;helloService&quot;;message helloReq &#123; string name = 1; int32 age = 2;&#125;message helloRep &#123; string say = 1;&#125;service HelloServer &#123; rpc Say(helloReq) returns (helloRep) &#123;&#125;;&#125; 服务端1234567891011121314151617181920212223242526272829package mainimport ( &quot;context&quot; &quot;google.golang.org/grpc&quot; pd &quot;grpc_helloworld/server/proto&quot; &quot;log&quot; &quot;net&quot;)type Server struct &#123; pd.UnimplementedHelloServerServer&#125;func (s *Server) Say(ctx context.Context, q *pd.HelloReq) (*pd.HelloRep, error) &#123; return &amp;pd.HelloRep&#123; Say: q.Name, &#125;, nil&#125;func main() &#123; listen, _ := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) newServer := grpc.NewServer() pd.RegisterHelloServerServer(newServer, new(Server)) err := newServer.Serve(listen) if err != nil &#123; log.Print(&quot;err:&quot;, err) &#125;&#125; 客户端12345678910111213141516171819202122232425262728package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;google.golang.org/grpc/credentials/insecure&quot; pd &quot;grpc_helloworld/client/proto&quot; &quot;log&quot;)func main() &#123; conn, err := grpc.Dial(&quot;:8080&quot;, grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil &#123; fmt.Print(err) &#125; defer conn.Close() client := pd.NewHelloServerClient(conn) feature, err := client.Say(context.Background(), &amp;pd.HelloReq&#123; Name: &quot;hello&quot;, Age: 0, &#125;) if err != nil &#123; log.Print(err) &#125; fmt.Print(feature)&#125; Go work使用 进入工作目录 使用go work init创建go.work文件 生成proto文件夹及文件 创建服务端及客户端文件夹并分别生成go.mod文件 关联依赖","categories":[],"tags":[{"name":"GRPC","slug":"GRPC","permalink":"http://peapod.top/tags/GRPC/"}]},{"title":"Protocol Buffers","slug":"Protocol-Buffers","date":"2023-06-10T12:05:04.000Z","updated":"2023-06-19T11:55:51.000Z","comments":true,"path":"2023/06/10/Protocol-Buffers/","link":"","permalink":"http://peapod.top/2023/06/10/Protocol-Buffers/","excerpt":"","text":"Protocol Buffers 概述简介Protocol Buffers语言无关，平台无关，可扩展的结构化数据序列化方案, 用于协议通讯, 数据存储和其他更多用途。是一个灵活,高效,自动化的结构化数据序列化机制。 原理在.proto文件中定义protocol buffer消息类型来指定要序列化的信息如何组织。 protocol buffer信息是一个小的信息逻辑记录，包含一序列的”名字-值”对。 123456789101112131415161718message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType &#123; MOBILE = 0; HOME = 1; WORK = 2; &#125; message PhoneNumber &#123; required string number = 1; optional PhoneType type = 2 [default = HOME]; &#125; repeated PhoneNumber phone = 4;&#125; 每个消息类型有一个或者多个唯一的编号的字段，而每个字段有一个名字和值类型。 在.proto文件上运行对应应用语言的protcol buffer的编译器来生成数据访问类。 这些类为每个字段(类似name()或者set_name())提供简单的访问器，还有用于序列化&#x2F;解析整个结构到&#x2F;从原始字节的方法。 安装使用安装下载通用编译器地址：https://github.com/protocolbuffers/protobuf/releases Protobuf 运行时安装grpc官网安装12$ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28$ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2 使用 编写.proto文件 使用protoc工具生成代码文件 调用 1234567891011syntax = &quot;proto3&quot;;// 指定版本option go_package = &quot;./model&quot;;// 指定生成的文件存放位置package model;// 指定包名message User&#123; string name = 1; int32 age = 32;&#125; 1protoc --go_out=. --go-grpc_out=. helloworld/helloworld.proto –go_out .pd.go文件生成目录 –go-grpc_out _grpc.pd.go文件生成目录 123456789101112131415161718192021222324252627package mainimport ( &quot;fmt&quot; &quot;google.golang.org/protobuf/proto&quot; &quot;protobuftest/model&quot;)func main() &#123; user := &amp;model.User&#123; Name: &quot;twz&quot;, Age: 32, &#125; marshal, err := proto.Marshal(user) if err != nil &#123; return &#125; newUser := &amp;model.User&#123;&#125; err = proto.Unmarshal(marshal, newUser) if err != nil &#123; return &#125; fmt.Print(newUser)&#125; 定义消息类型定义消息类型.proto文件 12345678syntax = &quot;proto3&quot;;// 使用的是proto3语法message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 results_per_page = 3;&#125;// SearchRequest消息定义指定了三个字段 为消息定义中的每个字段指定一个介于1和#之间的数字,给定的数字在该消息的所有字段中必须是唯一的。 字段规则 required:消息体中必填字段，不设置会导致编解码异常。默认使用。 optional: 消息体中可选字段。生成指针类型。 repeated: 消息体中可重复字段，重复的值的顺序会被保留（例如位置3）在go中重复的会被定义为切片。 123456message User &#123; string username = 1; int32 age = 2; optional string password = 3; repeated string address = 4;&#125; 定义多种消息类型123456789message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 results_per_page = 3;&#125;message SearchResponse &#123; ...&#125; 添加注释12345678/* SearchRequest represents a search query, with pagination options to * indicate which results to include in the response. */message SearchRequest &#123; string query = 1; int32 page_number = 2; // Which page number do we want? int32 results_per_page = 3; // Number of results to return per page.&#125; 对于Go，编译器生成一个.pb.go文件，每个文件都有一个类型消息类型。 值类型 .proto Type GO Type double float64 float float32 int32 Int32 uint32 uint32 int64 long bool bool string string bytes []byte 默认值被编码的消息没有包含特定的简单元素, 被解析的对象对应的字段被设置为默认值。 对于strings, 默认值是空字符串(注, 是””, 而不是null) 对于bytes, 默认值是空字节(注, 应该是byte[0], 注意这里也不是null) 对于boolean, 默认值是false. 对于数字类型, 默认值是0. 对于枚举, 默认值是第一个定义的枚举值, 而这个值必须是0. 对于消息字段, 默认值是null. 枚举能希望某个字段只能有预先定义的多个值中的一个。 123456789101112131415message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3; enum Corpus &#123; UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; &#125; Corpus corpus = 4;&#125; Corpus 枚举的第一个常量设置到0: 每个枚举定义必须包含一个映射到0的常量作为它的第一个元素. 必须有一个0值, 这样我们才能用0来作为数值默认值. 0值必须是第一个元素 消息调用可以使用其他消息类型作为字段类型。 123456789message SearchResponse &#123; repeated Result result = 1;&#125;message Result &#123; string url = 1; string title = 2; repeated string snippets = 3;&#125; 导入定义消息类型已经在其他的.proto文件中定义。 导入来使用来自其他.proto文件的定义. 为了导入其他.proto的定义, 需要在文件的顶端增加导入声明: 1import &quot;myproject/other_protos.proto&quot;; 需要移动.proto文件到新的位置。 在原有位置放置一个伪装的.proto文件, 通过使用import public方式转发所有的import到新的位置。其他任何导入这个包含import public语句的proto文件都可以透明的得到通过import public方法导入的依赖。 protocol编译器在通过命令行-I&#x2F;–proto_path参数指定的目录集合中搜索导入的文件。如果没有指定, 则在编译器被调用的目录下查找. 通常应该设置–proto_path参数到项目所在的根目录然后为所有的导入使用完整限定名。 消息嵌套可以在消息类型内部定义和使用消息类型。 12345678message SearchResponse &#123; message Result &#123; string url = 1; string title = 2; repeated string snippets = 3; &#125; repeated Result result = 1;&#125; 在父消息类型之外重用消息类型。 123message SomeOtherMessage &#123; SearchResponse.Result result = 1;&#125; 定义服务在.proto文件中定义RPC服务接口, 然后protocol buffer编译器会生成所选语言的服务接口代码和桩(stubs)。 定义一个RPC服务,带一个方法处理SearchRequest并返回SearchResponse。 123service SearchService &#123; rpc Search (SearchRequest) returns (SearchResponse);&#125; 生成类 定义在.proto文件中的消息类型 在.proto文件上运行protocol buffer编译器protoc 对于Go, 需要为编译器安装特别的代码生成插件 选项参数 –proto_path&#x3D;：指定一个目录用于查找.proto文件, 当解析导入命令时. 缺省使用当前目录。 –go_out&#x3D;：生成代码文件的目录。 1protoc --proto_path=IMPORT_PATH --go_out=DST_DIR","categories":[{"name":"云原生","slug":"云原生","permalink":"http://peapod.top/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://peapod.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"author":"taweizhong"},{"title":"","slug":"rides配置","date":"2023-06-10T10:46:21.000Z","updated":"2023-06-10T10:46:21.000Z","comments":true,"path":"2023/06/10/rides配置/","link":"","permalink":"http://peapod.top/2023/06/10/rides%E9%85%8D%E7%BD%AE/","excerpt":"","text":"sudo docker run -p 6379:6379 –name redis -v &#x2F;root&#x2F;go&#x2F;src&#x2F;redis&#x2F;redis.conf:&#x2F;etc&#x2F;redis&#x2F;redis.conf -v &#x2F;data&#x2F;redis&#x2F;data:&#x2F;data -d redis redis-server &#x2F;etc&#x2F;redis&#x2F;redis.conf –appendonly yes https://blog.csdn.net/qq_52889967/article/details/126586781 redis-benchmark -h 127.0.0.1 -p 6379 -t set,get -n 10000 -q -d 10240","categories":[],"tags":[]},{"title":"","slug":"GORM","date":"2023-05-11T02:36:35.000Z","updated":"2023-05-11T02:36:35.000Z","comments":true,"path":"2023/05/11/GORM/","link":"","permalink":"http://peapod.top/2023/05/11/GORM/","excerpt":"","text":"GORM手册连接数据库导入驱动 1import _ &quot;github.com/go-sql-driver/mysql&quot; 123456789import ( &quot;github.com/jinzhu/gorm&quot; _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot;)func main() &#123; db, err := gorm.Open(&quot;mysql&quot;, &quot;user:password@tcp(port)/dbname?charset=utf8&amp;parseTime=True&amp;loc=Local&quot;) defer db.Close()&#125; 模型","categories":[],"tags":[]},{"title":"","slug":"gin-blog说明","date":"2023-05-08T10:20:54.000Z","updated":"2023-05-08T10:20:54.000Z","comments":true,"path":"2023/05/08/gin-blog说明/","link":"","permalink":"http://peapod.top/2023/05/08/gin-blog%E8%AF%B4%E6%98%8E/","excerpt":"","text":"gin-blogday1初始化项目目录gin-blog/ ├── conf 存储配置文件 ├── middleware 中间件 ├── models 数据库模型 ├── pkg 三方包 ├── routers 路由 └── runtime运行时数据 初始项目数据库 创建数据库blog 创建三张表 标签表 文章表 认证表 编写项目配置包 拉取go-ini/ini的依赖包 编写配置文件 conf目录下新建app.ini文件 编写配置setting模块 新建setting.go文件 读取配置文件并存储到变量 编写API错误码包 pkg目录下新建e目录，新建code.go和msg.go文件 code.go 编写错误码 msg.go 编写错误信息 编写分页页码的获取方法 util目录下新建pagination.go 编写models init 拉取gorm的依赖包 拉取mysql驱动的依赖包 models目录下新建models.go 读取配置文件 连接数据库 编写项目启动、路由文件 routers目录新建router.go文件 编写路由 编写main.go文件 注册并监听 当前目录结构gin-blog/ ├── conf │ └── app.ini ├── main.go ├── middleware ├── models │ └── models.go ├── pkg │ ├── e │ │ ├── code.go │ │ └── msg.go │ ├── setting │ │ └── setting.go │ └── util │ └── pagination.go ├── routers │ └── router.go ├── runtime","categories":[],"tags":[]},{"title":"","slug":"JavaScript笔记","date":"2023-05-06T12:51:37.000Z","updated":"2023-05-06T12:51:37.000Z","comments":true,"path":"2023/05/06/JavaScript笔记/","link":"","permalink":"http://peapod.top/2023/05/06/JavaScript%E7%AC%94%E8%AE%B0/","excerpt":"","text":"JavaScript 参考第一章：基础语法基本语法只是声明变量而没有赋值，则该变量的值是undefined。undefined是一个特殊的值，表示“无定义”。 JavaScript 是一种动态类型语言，也就是说，变量的类型没有限制，变量可以随时更改类型。 JavaScript 使用大括号，将多个相关的语句组合在一起，称为“区块”（block）。 对于var命令来说，JavaScript 的区块不构成单独的作用域（scope）。","categories":[],"tags":[]},{"title":"Mac视频播放器测试","slug":"Mac视频播放器测试","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-10T10:41:04.000Z","comments":true,"path":"2023/04/19/Mac视频播放器测试/","link":"","permalink":"http://peapod.top/2023/04/19/Mac%E8%A7%86%E9%A2%91%E6%92%AD%E6%94%BE%E5%99%A8%E6%B5%8B%E8%AF%95/","excerpt":"","text":"视频播放器名称 版本 Fig Player 1.2.3 Elmedia Player 8.15 Infuse 7 PRO 7.4.10 Movist Pro 2.9.2 OmniPlayer Pro 2.0.19 测试视频：蚁人2 格式：2160p.MA.WEB-DL.DDP5.1.Atmos.DV.HDR10.H.265-CMRG.mkv 样张： ![截屏2023-04-19 20.02.59](&#x2F;Users&#x2F;taweizhong&#x2F;Desktop&#x2F;截屏2023-04-19 20.02.59.png) ![截屏2023-04-19 20.02.42](&#x2F;Users&#x2F;taweizhong&#x2F;Desktop&#x2F;截屏2023-04-19 20.02.42.png) ![截屏2023-04-19 20.03.37](&#x2F;Users&#x2F;taweizhong&#x2F;Desktop&#x2F;截屏2023-04-19 20.03.37.png) ![截屏2023-04-19 20.03.30](&#x2F;Users&#x2F;taweizhong&#x2F;Desktop&#x2F;截屏2023-04-19 20.03.30.png)","categories":[],"tags":[{"name":"测试","slug":"测试","permalink":"http://peapod.top/tags/%E6%B5%8B%E8%AF%95/"}]},{"title":"Vue3入门教程","slug":"Vue3","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-19T11:56:58.000Z","comments":true,"path":"2023/04/19/Vue3/","link":"","permalink":"http://peapod.top/2023/04/19/Vue3/","excerpt":"","text":"Vue3入门教程简介Vue是一款用于构建用户界面的 JavaScript 框架。 Vue 的两个核心功能： 声明式渲染：Vue 基于标准 HTML 拓展了一套模板语法，使得我们可以声明式地描述最终输出的 HTML 和 JavaScript 状态之间的关系。 响应性：Vue 会自动跟踪 JavaScript 状态并在其发生变化时响应式地更新 DOM。 渐进式框架用不同的方式使用 Vue： 无需构建步骤，渐进式增强静态的 HTML 在任何页面中作为 Web Components 嵌入 单页应用 (SPA) 全栈 &#x2F; 服务端渲染 (SSR) Jamstack &#x2F; 静态站点生成 (SSG) 开发桌面端、移动端、WebGL，甚至是命令行终端中的界面 单文件组件单文件组件 (也被称为 *.vue 文件，英文 Single-File Components，缩写为 SFC)。顾名思义，Vue 的单文件组件会将一个组件的逻辑 (JavaScript)，模板 (HTML) 和样式 (CSS) 封装在同一个文件里。 选项式 API (Options API)用包含多个选项的对象来描述组件的逻辑，例如 data、methods 和 mounted。选项所定义的属性都会暴露在函数内部的 this 上，它会指向当前的组件实例。 1234567891011121314151617181920212223242526272829&lt;script&gt;export default &#123; // data() 返回的属性将会成为响应式的状态 // 并且暴露在 `this` 上 data() &#123; return &#123; count: 0 &#125; &#125;, // methods 是一些用来更改状态与触发更新的函数 // 它们可以在模板中作为事件监听器绑定 methods: &#123; increment() &#123; this.count++ &#125; &#125;, // 生命周期钩子会在组件生命周期的各个不同阶段被调用 // 例如这个函数就会在组件挂载完成后被调用 mounted() &#123; console.log(`The initial count is $&#123;this.count&#125;.`) &#125;&#125;&lt;/script&gt;&lt;template&gt; &lt;button @click=&quot;increment&quot;&gt;Count is: &#123;&#123; count &#125;&#125;&lt;/button&gt;&lt;/template&gt; 组合式 API (Composition API)与 搭配使用。 中的导入和顶层变量/函数都能够在模板中直接使用。 组合式 API 的核心思想是直接在函数作用域内定义响应式状态变量，并将从多个函数中得到的状态组合起来处理复杂问题。 1234567891011121314151617181920&lt;script setup&gt;import &#123; ref, onMounted &#125; from &#x27;vue&#x27;// 响应式状态const count = ref(0)// 用来修改状态、触发更新的函数function increment() &#123; count.value++&#125;// 生命周期钩子onMounted(() =&gt; &#123; console.log(`The initial count is $&#123;count.value&#125;.`)&#125;)&lt;/script&gt;&lt;template&gt; &lt;button @click=&quot;increment&quot;&gt;Count is: &#123;&#123; count &#125;&#125;&lt;/button&gt;&lt;/template&gt; 第一个vue每个 Vue 应用都是通过 createApp 函数创建一个新的 应用实例 12345import &#123; createApp &#125; from &#x27;vue&#x27;const app = createApp(&#123; /* 根组件选项 */&#125;) 直接从另一个文件中导入根组件。 12345import &#123; createApp &#125; from &#x27;vue&#x27;// 从一个单文件组件中导入根组件import App from &#x27;./App.vue&#x27;const app = createApp(App) 应用实例必须在调用了 .mount() 方法后才会渲染出来。 应用根组件的内容将会被渲染在容器元素里面。容器元素自己将不会被视为应用的一部分。 模版语法文本插值1&lt;span&gt;Message: &#123;&#123; msg &#125;&#125;&lt;/span&gt; 双大括号 原始HTML12&lt;p&gt;Using text interpolation: &#123;&#123; rawHtml &#125;&#125;&lt;/p&gt;&lt;p&gt;Using v-html directive: &lt;span v-html=&quot;rawHtml&quot;&gt;&lt;/span&gt;&lt;/p&gt; 使用 v-html 指令 span 的内容将会被替换为 rawHtml 属性的值，插值为纯 HTML——数据绑定将会被忽略。 Attribute 绑定响应式地绑定一个 attribute，应该使用 v-bind 指令： 1&lt;div v-bind:id=&quot;dynamicId&quot;&gt;&lt;/div&gt; id attribute 与组件的 dynamicId 属性保持一致。 依据 true / false 值来决定 attribute 是否应该存在于该元素上。disabled就是最常见的例子之一。 1&lt;button :disabled=&quot;isButtonDisabled&quot;&gt;Button&lt;/button&gt; 当 isButtonDisabled 为真值或一个空字符串 (即 &lt;button disabled=&quot;&quot;&gt;) 时，元素会包含这个 disabled attribute。而当其为其他假值时 attribute 将被忽略。 动态绑定多个值12345678data() &#123; return &#123; objectOfAttrs: &#123; id: &#x27;container&#x27;, class: &#x27;wrapper&#x27; &#125; &#125;&#125; 通过不带参数的 v-bind，你可以将它们绑定到单个元素上： 1&lt;div v-bind=&quot;objectOfAttrs&quot;&gt;&lt;/div&gt; 使用 JavaScript 表达式 Vue 实际上在所有的数据绑定中都支持完整的 JavaScript 表达式： 1234567&#123;&#123; number + 1 &#125;&#125;&#123;&#123; ok ? &#x27;YES&#x27; : &#x27;NO&#x27; &#125;&#125;&#123;&#123; message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125;&lt;div :id=&quot;`list-$&#123;id&#125;`&quot;&gt;&lt;/div&gt; JavaScript 表达式可以被使用在如下场景上： 在文本插值中 (双大括号) 在任何 Vue 指令 (以 v- 开头的特殊 attribute) attribute 的值中 动态参数在指令参数上也可以使用一个 JavaScript 表达式，需要包含在一对方括号内： 12345678&lt;!--注意，参数表达式有一些约束，参见下面“动态参数值的限制”与“动态参数语法的限制”章节的解释--&gt;&lt;a v-bind:[attributeName]=&quot;url&quot;&gt; ... &lt;/a&gt;&lt;!-- 简写 --&gt;&lt;a :[attributeName]=&quot;url&quot;&gt; ... &lt;/a&gt;","categories":[{"name":"Web前端","slug":"Web前端","permalink":"http://peapod.top/categories/Web%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"http://peapod.top/tags/Vue3/"}],"author":"taweizhong"},{"title":"javascript对象","slug":"javascript对象","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-10T10:42:33.000Z","comments":true,"path":"2023/04/19/javascript对象/","link":"","permalink":"http://peapod.top/2023/04/19/javascript%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"javascript对象对象JavaScript 语言使用构造函数（constructor）作为对象的模板。 构造函数的特点有两个。 函数体内部使用了this关键字，代表了所要生成的对象实例。 生成对象的时候，必须使用new命令。 new命令的作用，就是执行构造函数，返回一个实例对象。 new 命令的原理 创建一个空对象，作为将要返回的对象实例。 将这个空对象的原型，指向构造函数的prototype属性。 将这个空对象赋值给函数内部的this关键字。 开始执行构造函数内部的代码。 Object.create() 创建实例对象现有的对象作为模板，生成新的实例对象，这时就可以使用Object.create()方法。 12345678910var person1 = &#123; name: &#x27;张三&#x27;, age: 38, greeting: function() &#123; console.log(&#x27;Hi! I\\&#x27;m &#x27; + this.name + &#x27;.&#x27;); &#125;&#125;;var person2 = Object.create(person1);person2.name // 张三person2.greeting() // Hi! I&#x27;m 张三. this关键字this可以用在构造函数之中，表示实例对象。this都有一个共同点：它总是返回一个对象。 它的设计目的就是在函数体内部，指代函数当前的运行环境。 使用场合全局环境使用this，它指的就是顶层对象window。 构造函数中的this，指的是实例对象。 对象的方法里面包含this，this的指向就是方法运行时所在的对象。 Function.prototype.call()函数实例的call方法，可以指定函数内部this的指向（即函数执行时所在的作用域），然后在所指定的作用域中，调用该函数。 call方法的参数，应该是一个对象。如果参数为空、null和undefined，则默认传入全局对象。 继承通过构造函数为实例对象定义属性，虽然很方便，但是有一个缺点。同一个构造函数的多个实例之间，无法共享属性，从而造成对系统资源的浪费。 问题的解决方法，就是 JavaScript 的原型对象（prototype）。 原型对象的所有属性和方法，都能被实例对象共享。 每个函数都有一个prototype属性，指向一个对象。 12function f() &#123;&#125;typeof f.prototype // &quot;object&quot; 生成实例的时候，该属性会自动成为实例对象的原型。原型对象的属性不是实例对象自身的属性。 当实例对象本身没有某个属性或方法的时候，它会到原型对象去寻找该属性或方法。 原型对象的作用，就是定义所有实例对象共享的属性和方法。 对象自身和它的原型，都定义了一个同名属性，那么优先读取对象自身的属性，这叫做“覆盖”（overriding）。 原型对象相当于父类 constructor 属性prototype对象有一个constructor属性，默认指向prototype对象所在的构造函数。 constructor属性的作用是，可以得知某个实例对象，到底是哪一个构造函数产生的。 有了constructor属性，就可以从一个实例对象新建另一个实例。constructor属性表示原型对象与构造函数之间的关联关系。 instanceof 运算符返回一个布尔值，表示对象是否为某个构造函数的实例。 instanceof运算符的左边是实例对象，右边是构造函数。它会检查右边构建函数的原型对象（prototype），是否在左边对象的原型链上。 构造函数的继承第一步是在子类的构造函数中，调用父类的构造函数。 第二步，是让子类的原型指向父类的原型，这样子类就可以继承父类原型。 123Sub.prototype = Object.create(Super.prototype);Sub.prototype.constructor = Sub;Sub.prototype.method = &#x27;...&#x27;; Sub.prototype是子类的原型，要将它赋值为Object.create(Super.prototype)，而不是直接等于Super.prototype。否则后面两行对Sub.prototype的操作，会连父类的原型Super.prototype一起修改掉。 12345678910111213141516171819202122function Shape() &#123; this.x = 0; this.y = 0;&#125;Shape.prototype.move = function (x, y) &#123; this.x += x; this.y += y; console.info(&#x27;Shape moved.&#x27;);&#125;;// 第一步，子类继承父类的实例function Rectangle() &#123; Shape.call(this); // 调用父类构造函数&#125;// 另一种写法function Rectangle() &#123; this.base = Shape; this.base();&#125;// 第二步，子类继承父类的原型Rectangle.prototype = Object.create(Shape.prototype);Rectangle.prototype.constructor = Rectangle;","categories":[],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://peapod.top/tags/javascript/"}]},{"title":"props","slug":"props","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-10T10:44:01.000Z","comments":true,"path":"2023/04/19/props/","link":"","permalink":"http://peapod.top/2023/04/19/props/","excerpt":"","text":"propsProps 声明使用 &lt;script setup&gt; 的单文件组件中，props 可以使用 defineProps() 宏来声明： 12345&lt;script setup&gt;const props = defineProps([&#x27;foo&#x27;])console.log(props.foo)&lt;/script&gt; 单向数据流所有的 props 都遵循着单向绑定原则，props 因父组件的更新而变化，自然地将新的状态向下流往子组件，而不会逆向传递。 不应该在子组件中去更改一个 prop。警告！prop 是只读的！ 更改一个 prop 的需求：prop 被用于传入初始值；而子组件想在之后将其作为一个局部数据属性。 12345const props = defineProps([&#x27;initialCounter&#x27;])// 计数器只是将 props.initialCounter 作为初始值// 像下面这样做就使 prop 和后续更新无关了const counter = ref(props.initialCounter) 需要对传入的 prop 值做进一步的转换。 1234const props = defineProps([&#x27;size&#x27;])// 该 prop 变更时计算属性也会自动更新const normalizedSize = computed(() =&gt; props.size.trim().toLowerCase()) Prop 校验向 defineProps() 宏提供一个带有 props 校验选项的对象，例如： 12345678910111213141516171819202122232425262728293031323334353637383940414243defineProps(&#123; // 基础类型检查 // （给出 `null` 和 `undefined` 值则会跳过任何类型检查） propA: Number, // 多种可能的类型 propB: [String, Number], // 必传，且为 String 类型 propC: &#123; type: String, required: true &#125;, // Number 类型的默认值 propD: &#123; type: Number, default: 100 &#125;, // 对象类型的默认值 propE: &#123; type: Object, // 对象或数组的默认值 // 必须从一个工厂函数返回。 // 该函数接收组件所接收到的原始 prop 作为参数。 default(rawProps) &#123; return &#123; message: &#x27;hello&#x27; &#125; &#125; &#125;, // 自定义类型校验函数 propF: &#123; validator(value) &#123; // The value must match one of these strings return [&#x27;success&#x27;, &#x27;warning&#x27;, &#x27;danger&#x27;].includes(value) &#125; &#125;, // 函数类型的默认值 propG: &#123; type: Function, // 不像对象或数组的默认，这不是一个 // 工厂函数。这会是一个用来作为默认值的函数 default() &#123; return &#x27;Default function&#x27; &#125; &#125;&#125;)","categories":[],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"http://peapod.top/tags/Vue3/"}]},{"title":"侦听器","slug":"侦听器","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-19T11:58:33.000Z","comments":true,"path":"2023/04/19/侦听器/","link":"","permalink":"http://peapod.top/2023/04/19/%E4%BE%A6%E5%90%AC%E5%99%A8/","excerpt":"","text":"侦听器在状态变化时执行一些“副作用”：例如更改 DOM，或是根据异步操作的结果去修改另一处的状态。 响应式变量的状态发生变化时，调用回调函数。 使用 watch 函数在每次响应式状态发生变化时触发回调函数 watch 的第一个参数可以是不同形式的“数据源”：它可以是一个 ref (包括计算属性)、一个响应式对象、一个 getter 函数、或多个数据源组成的数组： 1234567891011121314151617181920const x = ref(0)const y = ref(0)// 单个 refwatch(x, (newX) =&gt; &#123; console.log(`x is $&#123;newX&#125;`)&#125;)// getter 函数watch( () =&gt; x.value + y.value, (sum) =&gt; &#123; console.log(`sum of x + y is: $&#123;sum&#125;`) &#125;)// 多个来源组成的数组watch([x, () =&gt; y.value], ([newX, newY]) =&gt; &#123; console.log(`x is $&#123;newX&#125; and y is $&#123;newY&#125;`)&#125;) 不能直接侦听响应式对象的属性值，例如: 123456const obj = reactive(&#123; count: 0 &#125;)// 错误，因为 watch() 得到的参数是一个 numberwatch(obj.count, (count) =&gt; &#123; console.log(`count is: $&#123;count&#125;`)&#125;) 需要用一个返回该属性的 getter 函数： 1234567// 提供一个 getter 函数watch( () =&gt; obj.count, (count) =&gt; &#123; console.log(`count is: $&#123;count&#125;`) &#125;) 深层侦听器给 watch() 传入一个响应式对象，会隐式地创建一个深层侦听器——该回调函数在所有嵌套的变更时都会被触发： 123456789const obj = reactive(&#123; count: 0 &#125;)watch(obj, (newValue, oldValue) =&gt; &#123; // 在嵌套的属性变更时触发 // 注意：`newValue` 此处和 `oldValue` 是相等的 // 因为它们是同一个对象！&#125;)obj.count++ 相比之下，一个返回响应式对象的 getter 函数，只有在返回不同的对象时，才会触发回调： 123456watch( () =&gt; state.someObject, () =&gt; &#123; // 仅当 state.someObject 被替换时触发 &#125;) 即时回调的侦听器通过传入 immediate: true 选项来强制侦听器的回调立即执行： 123watch(source, (newValue, oldValue) =&gt; &#123; // 立即执行，且当 `source` 改变时再次执行&#125;, &#123; immediate: true &#125;) watchEffect()123456789const todoId = ref(1)const data = ref(null)watch(todoId, async () =&gt; &#123; const response = await fetch( `https://jsonplaceholder.typicode.com/todos/$&#123;todoId.value&#125;` ) data.value = await response.json()&#125;, &#123; immediate: true &#125;) watchEffect() 允许我们自动跟踪回调的响应式依赖。上面的侦听器可以重写为： 123456watchEffect(async () =&gt; &#123; const response = await fetch( `https://jsonplaceholder.typicode.com/todos/$&#123;todoId.value&#125;` ) data.value = await response.json()&#125;) 不需要指定 immediate: true。在执行期间，它会自动追踪 todoId.value 作为依赖（和计算属性类似）。每当 todoId.value 变化时，回调会再次执行。有了 watchEffect()，我们不再需要明确传递 todoId 作为源值。 watch 只追踪明确侦听的数据源。它不会追踪任何在回调中访问到的东西。另外，仅在数据源确实改变时才会触发回调。watch 会避免在发生副作用时追踪依赖，因此，我们能更加精确地控制回调函数的触发时机。 watchEffect，则会在副作用发生期间追踪依赖。它会在同步执行过程中，自动追踪所有能访问到的响应式属性。这更方便，而且代码往往更简洁，但有时其响应性依赖关系会不那么明确。 回调的触发时机当你更改了响应式状态，它可能会同时触发 Vue 组件更新和侦听器回调。 默认情况下，用户创建的侦听器回调，都会在 Vue 组件更新之前被调用。这意味着你在侦听器回调中访问的 DOM 将是被 Vue 更新之前的状态。 在侦听器回调中能访问被 Vue 更新之后的 DOM，你需要指明 flush: &#39;post&#39; 选项： 1234567watch(source, callback, &#123; flush: &#x27;post&#x27;&#125;)watchEffect(callback, &#123; flush: &#x27;post&#x27;&#125;) 停止侦听器在 setup() 或 &lt;script setup&gt; 中用同步语句创建的侦听器，会自动绑定到宿主组件实例上，并且会在宿主组件卸载时自动停止。 侦听器必须用同步语句创建：如果用异步回调创建一个侦听器，那么它不会绑定到当前组件上，你必须手动停止它，以防内存泄漏。如下方这个例子： 1234567891011&lt;script setup&gt;import &#123; watchEffect &#125; from &#x27;vue&#x27;// 它会自动停止watchEffect(() =&gt; &#123;&#125;)// ...这个则不会！setTimeout(() =&gt; &#123; watchEffect(() =&gt; &#123;&#125;)&#125;, 100)&lt;/script&gt; 手动停止一个侦听器 1234const unwatch = watchEffect(() =&gt; &#123;&#125;)// ...当该侦听器不再需要时unwatch()","categories":[{"name":"Web前端","slug":"Web前端","permalink":"http://peapod.top/categories/Web%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"http://peapod.top/tags/Vue3/"}],"author":"taweizhong"},{"title":"模版引用（访问DOM元素）","slug":"模版引用","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-19T11:58:04.000Z","comments":true,"path":"2023/04/19/模版引用/","link":"","permalink":"http://peapod.top/2023/04/19/%E6%A8%A1%E7%89%88%E5%BC%95%E7%94%A8/","excerpt":"","text":"模版引用（访问DOM元素）需要直接访问底层 DOM 元素。要实现这一点，我们可以使用特殊的 ref attribute： 1&lt;input ref=&quot;input&quot;&gt; 允许我们在一个特定的 DOM 元素或子组件实例被挂载后，获得对它的直接引用。 访问模版引用为了通过组合式 API 获得该模板引用，我们需要声明一个同名的 ref： 123456789101112131415&lt;script setup&gt;import &#123; ref, onMounted &#125; from &#x27;vue&#x27;// 声明一个 ref 来存放该元素的引用// 必须和模板里的 ref 同名const input = ref(null)onMounted(() =&gt; &#123; input.value.focus()&#125;)&lt;/script&gt;&lt;template&gt; &lt;input ref=&quot;input&quot; /&gt;&lt;/template&gt; 侦听一个模板引用 ref 的变化，确保考虑到其值为 null 的情况： 1234567watchEffect(() =&gt; &#123; if (input.value) &#123; input.value.focus() &#125; else &#123; // 此时还未挂载，或此元素已经被卸载（例如通过 v-if 控制） &#125;&#125;) v-for 中的模板引用对应的 ref 中包含的值是一个数组，它将在元素被挂载后包含对应整个列表的所有元素： 12345678910111213141516171819&lt;script setup&gt;import &#123; ref, onMounted &#125; from &#x27;vue&#x27;const list = ref([ /* ... */])const itemRefs = ref([])onMounted(() =&gt; console.log(itemRefs.value))&lt;/script&gt;&lt;template&gt; &lt;ul&gt; &lt;li v-for=&quot;item in list&quot; ref=&quot;itemRefs&quot;&gt; &#123;&#123; item &#125;&#125; &lt;/li&gt; &lt;/ul&gt;&lt;/template&gt; 组件上的ref引用中获得的值是组件实例： 1234567891011121314&lt;script setup&gt;import &#123; ref, onMounted &#125; from &#x27;vue&#x27;import Child from &#x27;./Child.vue&#x27;const child = ref(null)onMounted(() =&gt; &#123; // child.value 是 &lt;Child /&gt; 组件的实例&#125;)&lt;/script&gt;&lt;template&gt; &lt;Child ref=&quot;child&quot; /&gt;&lt;/template&gt; 使用了 &lt;script setup&gt; 的组件是默认私有的：一个父组件无法访问到一个使用了 &lt;script setup&gt; 的子组件中的任何东西，除非子组件在其中通过 defineExpose 宏显式暴露： 123456789101112&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;const a = 1const b = ref(2)// 像 defineExpose 这样的编译器宏不需要导入defineExpose(&#123; a, b&#125;)&lt;/script&gt;","categories":[{"name":"Web前端","slug":"Web前端","permalink":"http://peapod.top/categories/Web%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"http://peapod.top/tags/Vue3/"}],"author":"taweizhong"},{"title":"全局注册","slug":"注册","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-10T10:44:29.000Z","comments":true,"path":"2023/04/19/注册/","link":"","permalink":"http://peapod.top/2023/04/19/%E6%B3%A8%E5%86%8C/","excerpt":"","text":"全局注册 app.component() 方法，让组件在当前 Vue 应用中全局可用。 123import MyComponent from &#x27;./App.vue&#x27;app.component(&#x27;MyComponent&#x27;, MyComponent) 全局注册的组件可以在此应用的任意组件的模板中使用： 1234&lt;!-- 这在当前应用的任意组件中都可用 --&gt;&lt;ComponentA/&gt;&lt;ComponentB/&gt;&lt;ComponentC/&gt; 局部注册在使用 &lt;script setup&gt; 的单文件组件中，导入的组件可以直接在模板中使用，无需注册： 1234567&lt;script setup&gt;import ComponentA from &#x27;./ComponentA.vue&#x27;&lt;/script&gt;&lt;template&gt; &lt;ComponentA /&gt;&lt;/template&gt;","categories":[],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"http://peapod.top/tags/Vue3/"}]},{"title":"组件 v-model","slug":"组件 v-model","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-10T10:43:25.000Z","comments":true,"path":"2023/04/19/组件 v-model/","link":"","permalink":"http://peapod.top/2023/04/19/%E7%BB%84%E4%BB%B6%20v-model/","excerpt":"","text":"组件 v-modelv-model 可以在组件上使用以实现双向绑定。 当使用在一个组件上时，v-model 会被展开为如下的形式： 1234&lt;CustomInput :modelValue=&quot;searchText&quot; @update:modelValue=&quot;newValue =&gt; searchText = newValue&quot;/&gt; &lt;CustomInput&gt; 组件内部需要做两件事： 将内部原生 &lt;input&gt; 元素的 value attribute 绑定到 modelValue prop 当原生的 input 事件触发时，触发一个携带了新值的 update:modelValue 自定义事件 123456789101112&lt;!-- CustomInput.vue --&gt;&lt;script setup&gt;defineProps([&#x27;modelValue&#x27;])defineEmits([&#x27;update:modelValue&#x27;])&lt;/script&gt;&lt;template&gt; &lt;input :value=&quot;modelValue&quot; @input=&quot;$emit(&#x27;update:modelValue&#x27;, $event.target.value)&quot; /&gt;&lt;/template&gt; v-model 的参数默认情况下，v-model 在组件上都是使用 modelValue 作为 prop，并以 update:modelValue 作为对应的事件。我们可以通过给 v-model 指定一个参数来更改这些名字： 1&lt;MyComponent v-model:title=&quot;bookTitle&quot; /&gt; 子组件应声明一个 title prop，并通过触发 update:title 事件更新父组件值： 12345678910111213&lt;!-- MyComponent.vue --&gt;&lt;script setup&gt;defineProps([&#x27;title&#x27;])defineEmits([&#x27;update:title&#x27;])&lt;/script&gt;&lt;template&gt; &lt;input type=&quot;text&quot; :value=&quot;title&quot; @input=&quot;$emit(&#x27;update:title&#x27;, $event.target.value)&quot; /&gt;&lt;/template&gt;","categories":[],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"http://peapod.top/tags/Vue3/"}]},{"title":"插槽 Slots","slug":"插槽 Slots","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-10T10:43:05.000Z","comments":true,"path":"2023/04/19/插槽 Slots/","link":"","permalink":"http://peapod.top/2023/04/19/%E6%8F%92%E6%A7%BD%20Slots/","excerpt":"","text":"插槽 Slots插槽内容与出口一个 &lt;FancyButton&gt; 组件，可以像这样使用： 123&lt;FancyButton&gt; Click me! &lt;!-- 插槽内容 --&gt;&lt;/FancyButton&gt; 而 &lt;FancyButton&gt; 的模板是这样的： 123&lt;button class=&quot;fancy-btn&quot;&gt; &lt;slot&gt;&lt;/slot&gt; &lt;!-- 插槽出口 --&gt;&lt;/button&gt; &lt;slot&gt; 元素是一个插槽出口 (slot outlet)，标示了父元素提供的插槽内容 (slot content) 将在哪里被渲染。 插槽内容可以是任意合法的模板内容，不局限于文本。例如我们可以传入多个元素，甚至是组件： 1234&lt;FancyButton&gt; &lt;span style=&quot;color:red&quot;&gt;Click me!&lt;/span&gt; &lt;AwesomeIcon name=&quot;plus&quot; /&gt;&lt;/FancyButton&gt; 渲染作用域插槽内容可以访问到父组件的数据作用域，因为插槽内容本身是在父组件模板中定义的。 插槽内容无法访问子组件的数据。Vue 模板中的表达式只能访问其定义时所处的作用域。 具名插槽&lt;slot&gt; 元素可以有一个特殊的 attribute name，用来给各个插槽分配唯一的 ID，以确定每一处要渲染的内容： 1234567891011&lt;div class=&quot;container&quot;&gt; &lt;header&gt; &lt;slot name=&quot;header&quot;&gt;&lt;/slot&gt; &lt;/header&gt; &lt;main&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/main&gt; &lt;footer&gt; &lt;slot name=&quot;footer&quot;&gt;&lt;/slot&gt; &lt;/footer&gt;&lt;/div&gt; 要为具名插槽传入内容，我们需要使用一个含 v-slot 指令的 &lt;template&gt; 元素，并将目标插槽的名字传给该指令： 12345&lt;BaseLayout&gt; &lt;template v-slot:header&gt; &lt;!-- header 插槽的内容放这里 --&gt; &lt;/template&gt;&lt;/BaseLayout&gt; v-slot 有对应的简写 # 作用域插槽插槽的内容无法访问到子组件的状态。 像对组件传递 props 那样，向一个插槽的出口上传递 attributes： 1234&lt;!-- &lt;MyComponent&gt; 的模板 --&gt;&lt;div&gt; &lt;slot :text=&quot;greetingMessage&quot; :count=&quot;1&quot;&gt;&lt;/slot&gt;&lt;/div&gt; 默认插槽接受 props 123&lt;MyComponent v-slot=&quot;slotProps&quot;&gt; &#123;&#123; slotProps.text &#125;&#125; &#123;&#123; slotProps.count &#125;&#125;&lt;/MyComponent&gt; 具名作用域插槽12345678910111213&lt;MyComponent&gt; &lt;template #header=&quot;headerProps&quot;&gt; &#123;&#123; headerProps &#125;&#125; &lt;/template&gt; &lt;template #default=&quot;defaultProps&quot;&gt; &#123;&#123; defaultProps &#125;&#125; &lt;/template&gt; &lt;template #footer=&quot;footerProps&quot;&gt; &#123;&#123; footerProps &#125;&#125; &lt;/template&gt;&lt;/MyComponent&gt; 向具名插槽中传入 props： 1&lt;slot name=&quot;header&quot; message=&quot;hello&quot;&gt;&lt;/slot&gt;","categories":[],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"http://peapod.top/tags/Vue3/"}]},{"title":"组件事件","slug":"组件事件","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-10T10:43:44.000Z","comments":true,"path":"2023/04/19/组件事件/","link":"","permalink":"http://peapod.top/2023/04/19/%E7%BB%84%E4%BB%B6%E4%BA%8B%E4%BB%B6/","excerpt":"","text":"组件事件触发与监听事件子组件上抛 12&lt;!-- MyComponent --&gt;&lt;button @click=&quot;$emit(&#x27;someEvent&#x27;)&quot;&gt;click me&lt;/button&gt; 父组件监听 1&lt;MyComponent @some-event=&quot;callback&quot; /&gt; 事件参数给 $emit 提供一个额外的参数： 123&lt;button @click=&quot;$emit(&#x27;increaseBy&#x27;, 1)&quot;&gt; Increase by 1&lt;/button&gt; 父组件 1&lt;MyButton @increase-by=&quot;(n) =&gt; count += n&quot; /&gt; 声明触发的事件显式地通过 defineEmits() 宏来声明它要触发的事件： 1234567&lt;script setup&gt;const emit = defineEmits([&#x27;inFocus&#x27;, &#x27;submit&#x27;])function buttonClick() &#123; emit(&#x27;submit&#x27;)&#125;&lt;/script&gt; 事件校验要为事件添加校验，那么事件可以被赋值为一个函数，接受的参数就是抛出事件时传入 emit的内容，返回一个布尔值来表明事件是否合法。 1234567891011121314151617181920&lt;script setup&gt;const emit = defineEmits(&#123; // 没有校验 click: null, // 校验 submit 事件 submit: (&#123; email, password &#125;) =&gt; &#123; if (email &amp;&amp; password) &#123; return true &#125; else &#123; console.warn(&#x27;Invalid submit event payload!&#x27;) return false &#125; &#125;&#125;)function submitForm(email, password) &#123; emit(&#x27;submit&#x27;, &#123; email, password &#125;)&#125;&lt;/script&gt;","categories":[],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"http://peapod.top/tags/Vue3/"}]},{"title":"组件基础","slug":"组件基础","date":"2023-04-19T11:39:51.000Z","updated":"2023-06-19T11:57:27.000Z","comments":true,"path":"2023/04/19/组件基础/","link":"","permalink":"http://peapod.top/2023/04/19/%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/","excerpt":"","text":"组件基础定义一个组件将 Vue 组件定义在一个单独的 .vue 文件中，这被叫做单文件组件 (简称 SFC) 123456789&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;const count = ref(0)&lt;/script&gt;&lt;template&gt; &lt;button @click=&quot;count++&quot;&gt;You clicked me &#123;&#123; count &#125;&#125; times.&lt;/button&gt;&lt;/template&gt; 使用一个组件要使用一个子组件，我们需要在父组件中导入它。这个组件将会以默认导出的形式被暴露给外部。 12345678&lt;script setup&gt;import ButtonCounter from &#x27;./ButtonCounter.vue&#x27;&lt;/script&gt;&lt;template&gt; &lt;h1&gt;Here is a child component!&lt;/h1&gt; &lt;ButtonCounter /&gt;&lt;/template&gt; 通过 &lt;script setup&gt;，导入的组件都在模板中直接可用。 传递props（父-子）向组件中传递数据，这就会使用到 props。 父组件向子组件传递数据使用子组件使用props。 Props 是一种特别的 attributes，你可以在组件上声明注册。 12345678&lt;!-- BlogPost.vue --&gt;&lt;script setup&gt;defineProps([&#x27;title&#x27;])&lt;/script&gt;&lt;template&gt; &lt;h4&gt;&#123;&#123; title &#125;&#125;&lt;/h4&gt;&lt;/template&gt; 当一个 prop 被注册后，可以像这样以自定义 attribute 的形式传递数据给它： 123&lt;BlogPost title=&quot;My journey with Vue&quot; /&gt;&lt;BlogPost title=&quot;Blogging with Vue&quot; /&gt;&lt;BlogPost title=&quot;Why Vue is so fun&quot; /&gt; defineProps 会返回一个对象，其中包含了可以传递给组件的所有 props： 12const props = defineProps([&#x27;title&#x27;])console.log(props.title) 使用 v-bind 来传递动态 prop 值的。 1234567891011const posts = ref([ &#123; id: 1, title: &#x27;My journey with Vue&#x27; &#125;, &#123; id: 2, title: &#x27;Blogging with Vue&#x27; &#125;, &#123; id: 3, title: &#x27;Why Vue is so fun&#x27; &#125;])&lt;BlogPost v-for=&quot;post in posts&quot; :key=&quot;post.id&quot; :title=&quot;post.title&quot; /&gt; 监听事件（子-父）子组件使用 $emit 方法向上抛出自定义事件，向父组件传递行为（自定义事件），父组件监听上抛的事件。 123&lt;BlogPost @enlarge-text=&quot;postFontSize += 0.1&quot; /&gt; 1234567&lt;!-- BlogPost.vue, 省略了 &lt;script&gt; --&gt;&lt;template&gt; &lt;div class=&quot;blog-post&quot;&gt; &lt;h4&gt;&#123;&#123; title &#125;&#125;&lt;/h4&gt; &lt;button @click=&quot;$emit(&#x27;enlarge-text&#x27;)&quot;&gt;Enlarge text&lt;/button&gt; &lt;/div&gt;&lt;/template&gt; 当点击按钮之后，抛出的事件会被父组件监听，同时父组件触发该事件并引发行为。 通过 defineEmits 宏来声明需要抛出的事件： 12345&lt;!-- BlogPost.vue --&gt;&lt;script setup&gt;defineProps([&#x27;title&#x27;])defineEmits([&#x27;enlarge-text&#x27;])&lt;/script&gt; 声明了一个组件可能触发的所有事件，还可以对事件的参数进行验证。 返回一个等同于 $emit 方法的 emit 函数。它可以被用于在组件的 &lt;script setup&gt;中抛出事件，因为此处无法直接访问 $emit： 12345&lt;script setup&gt;const emit = defineEmits([&#x27;enlarge-text&#x27;])emit(&#x27;enlarge-text&#x27;)&lt;/script&gt; 插槽分配内容（父-子）将父组件中的内容会自动替换插槽中的内容。 通过 Vue 的自定义 &lt;slot&gt; 元素来实现： 123456789101112&lt;template&gt; &lt;div class=&quot;alert-box&quot;&gt; &lt;strong&gt;This is an Error for Demo Purposes&lt;/strong&gt; &lt;slot /&gt; &lt;/div&gt;&lt;/template&gt;&lt;style scoped&gt;.alert-box &#123; /* ... */&#125;&lt;/style&gt; 使用 &lt;slot&gt; 作为一个占位符，父组件传递进来的内容就会渲染在这里。 动态组件当使用 &lt;component :is=&quot;...&quot;&gt; 来在多个组件间作切换时，被切换掉的组件会被卸载。 被传给 :is 的值可以是以下几种： 被注册的组件名 导入的组件对象 12345678910111213141516171819202122232425262728&lt;script setup&gt;import Home from &#x27;./Home.vue&#x27;import Posts from &#x27;./Posts.vue&#x27;import Archive from &#x27;./Archive.vue&#x27;import &#123; ref &#125; from &#x27;vue&#x27; const currentTab = ref(&#x27;Home&#x27;)const tabs = &#123; Home, Posts, Archive&#125;&lt;/script&gt;&lt;template&gt; &lt;div class=&quot;demo&quot;&gt; &lt;button v-for=&quot;(_, tab) in tabs&quot; :key=&quot;tab&quot; :class=&quot;[&#x27;tab-button&#x27;, &#123; active: currentTab === tab &#125;]&quot; @click=&quot;currentTab = tab&quot; &gt; &#123;&#123; tab &#125;&#125; &lt;/button&gt; &lt;component :is=&quot;tabs[currentTab]&quot; class=&quot;tab&quot;&gt;&lt;/component&gt; &lt;/div&gt;&lt;/template&gt;","categories":[{"name":"Web前端","slug":"Web前端","permalink":"http://peapod.top/categories/Web%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"http://peapod.top/tags/Vue3/"}],"author":"taweizhong"},{"title":"Web APIs - 第4天笔记","slug":"Web-APIs-第4天笔记","date":"2023-04-17T08:05:56.000Z","updated":"2023-04-17T08:05:58.000Z","comments":true,"path":"2023/04/17/Web-APIs-第4天笔记/","link":"","permalink":"http://peapod.top/2023/04/17/Web-APIs-%E7%AC%AC4%E5%A4%A9%E7%AC%94%E8%AE%B0/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Web APIs - 第3天笔记","slug":"Web-APIs-第3天笔记","date":"2023-04-17T08:05:53.000Z","updated":"2023-04-17T08:08:28.000Z","comments":true,"path":"2023/04/17/Web-APIs-第3天笔记/","link":"","permalink":"http://peapod.top/2023/04/17/Web-APIs-%E7%AC%AC3%E5%A4%A9%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Web APIs - 第3天 进一步学习 事件进阶，实现更多交互的网页特效，结合事件流的特征优化事件执行的效率 掌握阻止事件冒泡的方法 理解事件委托的实现原理 事件流事件流是对事件执行过程的描述，了解事件的执行过程有助于加深对事件的理解，提升开发实践中对事件运用的灵活度。 ![event](&#x2F;Users&#x2F;taweizhong&#x2F;Desktop&#x2F;js&#x2F;web APIs第三天&#x2F;02-笔记&#x2F;assets&#x2F;event.png) 如上图所示，任意事件被触发时总会经历两个阶段：【捕获阶段】和【冒泡阶段】。 简言之，捕获阶段是【从父到子】的传导过程，冒泡阶段是【从子向父】的传导过程。 捕获和冒泡了解了什么是事件流之后，我们来看事件流是如何影响事件执行的： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;body&gt; &lt;h3&gt;事件流&lt;/h3&gt; &lt;p&gt;事件流是事件在执行时的底层机制，主要体现在父子盒子之间事件的执行上。&lt;/p&gt; &lt;div class=&quot;outer&quot;&gt; &lt;div class=&quot;inner&quot;&gt; &lt;div class=&quot;child&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;script&gt; // 获取嵌套的3个节点 const outer = document.querySelector(&#x27;.outer&#x27;); const inner = document.querySelector(&#x27;.inner&#x27;); const child = document.querySelector(&#x27;.child&#x27;); // html 元素添加事件 document.documentElement.addEventListener(&#x27;click&#x27;, function () &#123; console.log(&#x27;html...&#x27;) &#125;) // body 元素添加事件 document.body.addEventListener(&#x27;click&#x27;, function () &#123; console.log(&#x27;body...&#x27;) &#125;) // 外层的盒子添加事件 outer.addEventListener(&#x27;click&#x27;, function () &#123; console.log(&#x27;outer...&#x27;) &#125;) // 中间的盒子添加事件 outer.addEventListener(&#x27;click&#x27;, function () &#123; console.log(&#x27;inner...&#x27;) &#125;) // 内层的盒子添加事件 outer.addEventListener(&#x27;click&#x27;, function () &#123; console.log(&#x27;child...&#x27;) &#125;) &lt;/script&gt;&lt;/body&gt; 执行上述代码后发现，当单击事件触发时，其祖先元素的单击事件也【相继触发】，这是为什么呢？ 结合事件流的特征，我们知道当某个元素的事件被触发时，事件总是会先经过其祖先才能到达当前元素，然后再由当前元素向祖先传递，事件在流动的过程中遇到相同的事件便会被触发。 再来关注一个细节就是事件相继触发的【执行顺序】，事件的执行顺序是可控制的，即可以在捕获阶段被执行，也可以在冒泡阶段被执行。 如果事件是在冒泡阶段执行的，我们称为冒泡模式，它会先执行子盒子事件再去执行父盒子事件，默认是冒泡模式。 如果事件是在捕获阶段执行的，我们称为捕获模式，它会先执行父盒子事件再去执行子盒子事件。 12345678910111213141516171819202122&lt;body&gt; &lt;h3&gt;事件流&lt;/h3&gt; &lt;p&gt;事件流是事件在执行时的底层机制，主要体现在父子盒子之间事件的执行上。&lt;/p&gt; &lt;div class=&quot;outer&quot;&gt; &lt;div class=&quot;inner&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;script&gt; // 获取嵌套的3个节点 const outer = document.querySelector(&#x27;.outer&#x27;) const inner = document.querySelector(&#x27;.inner&#x27;) // 外层的盒子 outer.addEventListener(&#x27;click&#x27;, function () &#123; console.log(&#x27;outer...&#x27;) &#125;, true) // true 表示在捕获阶段执行事件 // 中间的盒子 outer.addEventListener(&#x27;click&#x27;, function () &#123; console.log(&#x27;inner...&#x27;) &#125;, true) &lt;/script&gt;&lt;/body&gt; 结论： addEventListener 第3个参数决定了事件是在捕获阶段触发还是在冒泡阶段触发 addEventListener 第3个参数为 true 表示捕获阶段触发，false 表示冒泡阶段触发，默认值为 false 事件流只会在父子元素具有相同事件类型时才会产生影响 绝大部分场景都采用默认的冒泡模式（其中一个原因是早期 IE 不支持捕获） 阻止冒泡阻止冒泡是指阻断事件的流动，保证事件只在当前元素被执行，而不再去影响到其对应的祖先元素。 123456789101112131415161718192021222324252627282930313233343536&lt;body&gt; &lt;h3&gt;阻止冒泡&lt;/h3&gt; &lt;p&gt;阻止冒泡是指阻断事件的流动，保证事件只在当前元素被执行，而不再去影响到其对应的祖先元素。&lt;/p&gt; &lt;div class=&quot;outer&quot;&gt; &lt;div class=&quot;inner&quot;&gt; &lt;div class=&quot;child&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;script&gt; // 获取嵌套的3个节点 const outer = document.querySelector(&#x27;.outer&#x27;) const inner = document.querySelector(&#x27;.inner&#x27;) const child = document.querySelector(&#x27;.child&#x27;) // 外层的盒子 outer.addEventListener(&#x27;click&#x27;, function () &#123; console.log(&#x27;outer...&#x27;) &#125;) // 中间的盒子 inner.addEventListener(&#x27;click&#x27;, function (ev) &#123; console.log(&#x27;inner...&#x27;) // 阻止事件冒泡 ev.stopPropagation() &#125;) // 内层的盒子 child.addEventListener(&#x27;click&#x27;, function (ev) &#123; console.log(&#x27;child...&#x27;) // 借助事件对象，阻止事件向上冒泡 ev.stopPropagation() &#125;) &lt;/script&gt;&lt;/body&gt; 结论：事件对象中的 ev.stopPropagation 方法，专门用来阻止事件冒泡。 鼠标经过事件： mouseover 和 mouseout 会有冒泡效果 mouseenter 和 mouseleave 没有冒泡效果 (推荐) 事件委托事件委托是利用事件流的特征解决一些现实开发需求的知识技巧，主要的作用是提升程序效率。 大量的事件监听是比较耗费性能的，如下代码所示 1234567891011&lt;script&gt; // 假设页面中有 10000 个 button 元素 const buttons = document.querySelectorAll(&#x27;table button&#x27;); for(let i = 0; i &lt;= buttons.length; i++) &#123; // 为 10000 个 button 元素添加了事件 buttons.addEventListener(&#x27;click&#x27;, function () &#123; // 省略具体执行逻辑... &#125;) &#125;&lt;/script&gt; 利用事件流的特征，可以对上述的代码进行优化，事件的的冒泡模式总是会将事件流向其父元素的，如果父元素监听了相同的事件类型，那么父元素的事件就会被触发并执行，正是利用这一特征对上述代码进行优化，如下代码所示： 12345678910&lt;script&gt; // 假设页面中有 10000 个 button 元素 let buttons = document.querySelectorAll(&#x27;table button&#x27;); // 假设上述的 10000 个 buttom 元素共同的祖先元素是 table let parents = document.querySelector(&#x27;table&#x27;); parents.addEventListener(&#x27;click&#x27;, function () &#123; console.log(&#x27;点击任意子元素都会触发事件...&#x27;); &#125;)&lt;/script&gt; 我们的最终目的是保证只有点击 button 子元素才去执行事件的回调函数，如何判断用户点击是哪一个子元素呢？ ![event](&#x2F;Users&#x2F;taweizhong&#x2F;Desktop&#x2F;js&#x2F;web APIs第三天&#x2F;02-笔记&#x2F;assets&#x2F;event.png) 事件对象中的属性 target 或 srcElement属性表示真正触发事件的元素，它是一个元素类型的节点。 1234567891011121314&lt;script&gt; // 假设页面中有 10000 个 button 元素 const buttons = document.querySelectorAll(&#x27;table button&#x27;) // 假设上述的 10000 个 buttom 元素共同的祖先元素是 table const parents = document.querySelector(&#x27;table&#x27;) parents.addEventListener(&#x27;click&#x27;, function (ev) &#123; // console.log(ev.target); // 只有 button 元素才会真正去执行逻辑 if(ev.target.tagName === &#x27;BUTTON&#x27;) &#123; // 执行的逻辑 &#125; &#125;)&lt;/script&gt; 优化过的代码只对祖先元素添加事件监听，相比对 10000 个元素添加事件监听执行效率要高许多！！！ 其他事件页面加载事件加载外部资源（如图片、外联CSS和JavaScript等）加载完毕时触发的事件 有些时候需要等页面资源全部处理完了做一些事情 事件名：load 监听页面所有资源加载完毕： 123window.addEventListener(&#x27;load&#x27;, function() &#123; // xxxxx&#125;) 元素滚动事件滚动条在滚动的时候持续触发的事件 123window.addEventListener(&#x27;scroll&#x27;, function() &#123; // xxxxx&#125;) 页面尺寸事件会在窗口尺寸改变的时候触发事件： 123window.addEventListener(&#x27;resize&#x27;, function() &#123; // xxxxx&#125;) 元素尺寸与位置获取元素的自身宽高、包含元素自身设置的宽高、padding、border offsetWidth和offsetHeight 获取出来的是数值,方便计算 注意: 获取的是可视宽高, 如果盒子是隐藏的,获取的结果是0","categories":[],"tags":[]},{"title":"Web APIs - 第2天笔记","slug":"Web-APIs-第2天笔记","date":"2023-04-17T08:05:49.000Z","updated":"2023-04-17T08:07:56.000Z","comments":true,"path":"2023/04/17/Web-APIs-第2天笔记/","link":"","permalink":"http://peapod.top/2023/04/17/Web-APIs-%E7%AC%AC2%E5%A4%A9%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Web APIs - 第2天 学会通过为DOM注册事件来实现可交互的网页特效。 能够判断函数运行的环境并确字 this 所指代的对象 理解事件的作用，知道应用事件的 3 个步骤 学习会为 DOM 注册事件，实现简单可交互的网页特交。 事件事件是编程语言中的术语，它是用来描述程序的行为或状态的，一旦行为或状态发生改变，便立即调用一个函数。 例如：用户使用【鼠标点击】网页中的一个按钮、用户使用【鼠标拖拽】网页中的一张图片 事件监听结合 DOM 使用事件时，需要为 DOM 对象添加事件监听，等待事件发生（触发）时，便立即调用一个函数。 addEventListener 是 DOM 对象专门用来添加事件监听的方法，它的两个参数分别为【事件类型】和【事件回调】。 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;事件监听&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;事件监听&lt;/h3&gt; &lt;p id=&quot;text&quot;&gt;为 DOM 元素添加事件监听，等待事件发生，便立即执行一个函数。&lt;/p&gt; &lt;button id=&quot;btn&quot;&gt;点击改变文字颜色&lt;/button&gt; &lt;script&gt; // 1. 获取 button 对应的 DOM 对象 const btn = document.querySelector(&#x27;#btn&#x27;) // 2. 添加事件监听 btn.addEventListener(&#x27;click&#x27;, function () &#123; console.log(&#x27;等待事件被触发...&#x27;) // 改变 p 标签的文字颜色 let text = document.getElementById(&#x27;text&#x27;) text.style.color = &#x27;red&#x27; &#125;) // 3. 只要用户点击了按钮，事件便触发了！！！ &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 完成事件监听分成3个步骤： 获取 DOM 元素 通过 addEventListener 方法为 DOM 节点添加事件监听 等待事件触发，如用户点击了某个按钮时便会触发 click 事件类型 事件触发后，相对应的回调函数会被执行 大白话描述：所谓的事件无非就是找个机会（事件触发）调用一个函数（回调函数）。 事件类型click 译成中文是【点击】的意思，它的含义是监听（等着）用户鼠标的单击操作，除了【单击】还有【双击】dblclick 1234567891011&lt;script&gt; // 双击事件类型 btn.addEventListener(&#x27;dblclick&#x27;, function () &#123; console.log(&#x27;等待事件被触发...&#x27;); // 改变 p 标签的文字颜色 const text = document.querySelector(&#x27;.text&#x27;) text.style.color = &#x27;red&#x27; &#125;) // 只要用户双击击了按钮，事件便触发了！！！&lt;/script&gt; 结论：【事件类型】决定了事件被触发的方式，如 click 代表鼠标单击，dblclick 代表鼠标双击。 事件处理程序addEventListener 的第2个参数是函数，这个函数会在事件被触发时立即被调用，在这个函数中可以编写任意逻辑的代码，如改变 DOM 文本颜色、文本内容等。 123456789101112&lt;script&gt; // 双击事件类型 btn.addEventListener(&#x27;dblclick&#x27;, function () &#123; console.log(&#x27;等待事件被触发...&#x27;) const text = document.querySelector(&#x27;.text&#x27;) // 改变 p 标签的文字颜色 text.style.color = &#x27;red&#x27; // 改变 p 标签的文本内容 text.style.fontSize = &#x27;20px&#x27; &#125;)&lt;/script&gt; 结论：【事件处理程序】决定了事件触发后应该执行的逻辑。 事件类型将众多的事件类型分类可分为：鼠标事件、键盘事件、表单事件、焦点事件等，我们逐一展开学习。 鼠标事件鼠标事件是指跟鼠标操作相关的事件，如单击、双击、移动等。 &#96;mouseenter 监听鼠标是否移入 DOM 元素 123456789101112131415161718&lt;body&gt; &lt;h3&gt;鼠标事件&lt;/h3&gt; &lt;p&gt;监听与鼠标相关的操作&lt;/p&gt; &lt;hr&gt; &lt;div class=&quot;box&quot;&gt;&lt;/div&gt; &lt;script&gt; // 需要事件监听的 DOM 元素 const box = document.querySelector(&#x27;.box&#x27;); // 监听鼠标是移入当前 DOM 元素 box.addEventListener(&#x27;mouseenter&#x27;, function () &#123; // 修改文本内容 this.innerText = &#x27;鼠标移入了...&#x27;; // 修改光标的风格 this.style.cursor = &#x27;move&#x27;; &#125;) &lt;/script&gt;&lt;/body&gt; &#96;mouseleave 监听鼠标是否移出 DOM 元素 12345678910111213141516&lt;body&gt; &lt;h3&gt;鼠标事件&lt;/h3&gt; &lt;p&gt;监听与鼠标相关的操作&lt;/p&gt; &lt;hr&gt; &lt;div class=&quot;box&quot;&gt;&lt;/div&gt; &lt;script&gt; // 需要事件监听的 DOM 元素 const box = document.querySelector(&#x27;.box&#x27;); // 监听鼠标是移出当前 DOM 元素 box.addEventListener(&#x27;mouseleave&#x27;, function () &#123; // 修改文本内容 this.innerText = &#x27;鼠标移出了...&#x27;; &#125;) &lt;/script&gt;&lt;/body&gt; 键盘事件keydown 键盘按下触发keyup 键盘抬起触发 焦点事件focus 获得焦点 blur 失去焦点 文本框输入事件input 事件对象任意事件类型被触发时与事件相关的信息会被以对象的形式记录下来，我们称这个对象为事件对象。 123456789101112131415161718&lt;body&gt; &lt;h3&gt;事件对象&lt;/h3&gt; &lt;p&gt;任意事件类型被触发时与事件相关的信息会被以对象的形式记录下来，我们称这个对象为事件对象。&lt;/p&gt; &lt;hr&gt; &lt;div class=&quot;box&quot;&gt;&lt;/div&gt; &lt;script&gt; // 获取 .box 元素 const box = document.querySelector(&#x27;.box&#x27;) // 添加事件监听 box.addEventListener(&#x27;click&#x27;, function (e) &#123; console.log(&#x27;任意事件类型被触发后，相关信息会以对象形式被记录下来...&#x27;); // 事件回调函数的第1个参数即所谓的事件对象 console.log(e) &#125;) &lt;/script&gt;&lt;/body&gt; 事件回调函数的【第1个参数】即所谓的事件对象，通常习惯性的将这个对数命名为 event、ev 、ev 。 接下来简单看一下事件对象中包含了哪些有用的信息： ev.type 当前事件的类型 ev.clientX/Y 光标相对浏览器窗口的位置 ev.offsetX/Y 光标相于当前 DOM 元素的位置 注：在事件回调函数内部通过 window.event 同样可以获取事件对象。 环境对象 能够分析判断函数运行在不同环境中 this 所指代的对象。 环境对象指的是函数内部特殊的变量 this ，它代表着当前函数运行时所处的环境。 1234567891011121314151617181920212223242526&lt;script&gt; // 声明函数 function sayHi() &#123; // this 是一个变量 console.log(this); &#125; // 声明一个对象 let user = &#123; name: &#x27;张三&#x27;, sayHi: sayHi // 此处把 sayHi 函数，赋值给 sayHi 属性 &#125; let person = &#123; name: &#x27;李四&#x27;, sayHi: sayHi &#125; // 直接调用 sayHi() // window window.sayHi() // window // 做为对象方法调用 user.sayHi()// user person.sayHi()// person&lt;/script&gt; 结论： this 本质上是一个变量，数据类型为对象 函数的调用方式不同 this 变量的值也不同 【谁调用 this 就是谁】是判断 this 值的粗略规则 函数直接调用时实际上 window.sayHi() 所以 this 的值为 window 回调函数如果将函数 A 做为参数传递给函数 B 时，我们称函数 A 为回调函数。 1234567891011121314151617&lt;script&gt; // 声明 foo 函数 function foo(arg) &#123; console.log(arg); &#125; // 普通的值做为参数 foo(10); foo(&#x27;hello world!&#x27;); foo([&#x27;html&#x27;, &#x27;css&#x27;, &#x27;javascript&#x27;]); function bar() &#123; console.log(&#x27;函数也能当参数...&#x27;); &#125; // 函数也可以做为参数！！！！ foo(bar);&lt;/script&gt; 函数 bar 做参数传给了 foo 函数，bar 就是所谓的回调函数了！！！ 我们回顾一下间歇函数 setInterval 1234567&lt;script&gt; function fn() &#123; console.log(&#x27;我是回调函数...&#x27;); &#125; // 调用定时器 setInterval(fn, 1000);&lt;/script&gt; fn 函数做为参数传给了 setInterval ，这便是回调函数的实际应用了，结合刚刚学习的函数表达式上述代码还有另一种更常见写法。 123456&lt;script&gt; // 调用定时器，匿名函数做为参数 setInterval(function () &#123; console.log(&#x27;我是回调函数...&#x27;); &#125;, 1000);&lt;/script&gt; 结论： 回调函数本质还是函数，只不过把它当成参数使用 使用匿名函数做为回调函数比较常见","categories":[],"tags":[]},{"title":"Web APIs - 第1天笔记","slug":"Web-APIs-第1天笔记","date":"2023-04-17T08:05:44.000Z","updated":"2023-04-17T08:07:26.000Z","comments":true,"path":"2023/04/17/Web-APIs-第1天笔记/","link":"","permalink":"http://peapod.top/2023/04/17/Web-APIs-%E7%AC%AC1%E5%A4%A9%E7%AC%94%E8%AE%B0/","excerpt":"","text":"复习： splice() 方法用于添加或删除数组中的元素。 注意：这种方法会改变原始数组。 删除数组： splice(起始位置， 删除的个数) 比如：1 123let arr = [&#x27;red&#x27;, &#x27;green&#x27;, &#x27;blue&#x27;]arr.splice(1,1) // 删除green元素console.log(arr) // [&#x27;red, &#x27;blue&#x27;] 添加元素 splice(起始位置，删除个数，添加数组元素) 12345let arr = [&#x27;red&#x27;, &#x27;green&#x27;, &#x27;blue&#x27;]//arr.splice(1, 0, &#x27;pink&#x27;) // 在索引号是1的位置添加 pink//console.log(arr) // [&#x27;red&#x27;, &#x27;pink&#x27;, &#x27;green&#x27;, &#x27;blue&#x27;]arr.splice(1, 0, &#x27;pink&#x27;, &#x27;hotpink&#x27;) // 在索引号是1的位置添加 pink hotpinkconsole.log(arr) // [&#x27;red&#x27;, &#x27;pink&#x27;, &#x27;hotpink&#x27;, &#x27;green&#x27;, &#x27;blue&#x27;] Web APIs - 第1天笔记 了解 DOM 的结构并掌握其基本的操作，体验 DOM 的在开发中的作用 知道 ECMAScript 与 JavaScript 的关系 了解 DOM 的相关概念及DOM 的本质是一个对象 掌握查找节点的基本方法 掌握节点属性和文本的操作 能够使用间歇函数创建定时任务 介绍 知道 ECMAScript 与 JavaScript 的关系，Web APIs 是浏览器扩展的功能。 严格意义上讲，我们在 JavaScript 阶段学习的知识绝大部分属于 ECMAScript 的知识体系，ECMAScript 简称 ES 它提供了一套语言标准规范，如变量、数据类型、表达式、语句、函数等语法规则都是由 ECMAScript 规定的。浏览器将 ECMAScript 大部分的规范加以实现，并且在此基础上又扩展一些实用的功能，这些被扩展出来的内容我们称为 Web APIs。 ![guide](&#x2F;Users&#x2F;taweizhong&#x2F;Desktop&#x2F;js&#x2F;web APIs第一天&#x2F;02-笔记&#x2F;assets&#x2F;guide.png) ECMAScript 运行在浏览器中然后再结合 Web APIs 才是真正的 JavaScript，Web APIs 的核心是 DOM 和 BOM。 扩展阅读：ECMAScript 规范在不断的更新中，存在多个不同的版本，早期的版本号采用数字顺序编号如 ECMAScript3、ECMAScript5，后来由于更新速度较快便采用年份做为版本号，如 ECMAScript2017、ECMAScript2018 这种格式，ECMAScript6 是 2015 年发布的，常叫做 EMCAScript2015。 关于 JavaScript 历史的扩展阅读。 知道 DOM 相关的概念，建立对 DOM 的初步认识，学习 DOM 的基本操作，体会 DOM 的作用 DOM（Document Object Model）是将整个 HTML 文档的每一个标签元素视为一个对象，这个对象下包含了许多的属性和方法，通过操作这些属性或者调用这些方法实现对 HTML 的动态更新，为实现网页特效以及用户交互提供技术支撑。 简言之 DOM 是用来动态修改 HTML 的，其目的是开发网页特效及用户交互。 观察一个小例子： ![demo](&#x2F;Users&#x2F;taweizhong&#x2F;Desktop&#x2F;js&#x2F;web APIs第一天&#x2F;02-笔记&#x2F;assets&#x2F;demo.gif) 上述的例子中当用户分分别点击【开始】或【结束】按钮后，通过右侧调试窗口可以观察到 html 标签的内容在不断的发生改变，这便是通过 DOM 实现的。 概念DOM 树12345678910111213&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;标题&lt;/title&gt;&lt;/head&gt;&lt;body&gt; 文本 &lt;a href=&quot;&quot;&gt;链接名&lt;/a&gt; &lt;div id=&quot;&quot; class=&quot;&quot;&gt;文本&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 如下图所示，将 HTML 文档以树状结构直观的表现出来，我们称之为文档树或 DOM 树，文档树直观的体现了标签与标签之间的关系。 ![dom](&#x2F;Users&#x2F;taweizhong&#x2F;Desktop&#x2F;js&#x2F;web APIs第一天&#x2F;02-笔记&#x2F;assets&#x2F;web-api.jpg) DOM 节点节点是文档树的组成部分，每一个节点都是一个 DOM 对象，主要分为元素节点、属性节点、文本节点等。 【元素节点】其实就是 HTML 标签，如上图中 head、div、body 等都属于元素节点。 【属性节点】是指 HTML 标签中的属性，如上图中 a 标签的 href 属性、div 标签的 class 属性。 【文本节点】是指 HTML 标签的文字内容，如 title 标签中的文字。 【根节点】特指 html 标签。 其它… documentdocument 是 JavaScript 内置的专门用于 DOM 的对象，该对象包含了若干的属性和方法，document 是学习 DOM 的核心。 12345678910111213&lt;script&gt; // document 是内置的对象 // console.log(typeof document); // 1. 通过 document 获取根节点 console.log(document.documentElement); // 对应 html 标签 // 2. 通过 document 节取 body 节点 console.log(document.body); // 对应 body 标签 // 3. 通过 document.write 方法向网页输出内容 document.write(&#x27;Hello World!&#x27;);&lt;/script&gt; 上述列举了 document 对象的部分属性和方法，我们先对 document 有一个整体的认识。 获取DOM对象 querySelector 满足条件的第一个元素 querySelectorAll 满足条件的元素集合 返回伪数组 了解其他方式 getElementById getElementsByTagName 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;DOM - 查找节点&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;查找元素类型节点&lt;/h3&gt; &lt;p&gt;从整个 DOM 树中查找 DOM 节点是学习 DOM 的第一个步骤。&lt;/p&gt; &lt;ul&gt; &lt;li&gt;元素&lt;/li&gt; &lt;li&gt;元素&lt;/li&gt; &lt;li&gt;元素&lt;/li&gt; &lt;li&gt;元素&lt;/li&gt; &lt;/ul&gt; &lt;script&gt; const p = document.querySelector(&#x27;p&#x27;) // 获取第一个p元素 const lis = document.querySelectorAll(&#x27;li&#x27;) // 获取第一个p元素 &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 总结： document.getElementById 专门获取元素类型节点，根据标签的 id 属性查找 任意 DOM 对象都包含 nodeType 属性，用来检检测节点类型 操作元素内容通过修改 DOM 的文本内容，动态改变网页的内容。 innerText 将文本内容添加&#x2F;更新到任意标签位置，文本中包含的标签不会被解析。 123456&lt;script&gt; // innerText 将文本内容添加/更新到任意标签位置 const intro = document.querySelector(&#x27;.intro&#x27;) // intro.innerText = &#x27;嗨~ 我叫李雷！&#x27; // intro.innerText = &#x27;&lt;h4&gt;嗨~ 我叫李雷！&lt;/h4&gt;&#x27;&lt;/script&gt; innerHTML 将文本内容添加&#x2F;更新到任意标签位置，文本中包含的标签会被解析。 123456&lt;script&gt; // innerHTML 将文本内容添加/更新到任意标签位置 const intro = document.querySelector(&#x27;.intro&#x27;) intro.innerHTML = &#x27;嗨~ 我叫韩梅梅！&#x27; intro.innerHTML = &#x27;&lt;h4&gt;嗨~ 我叫韩梅梅！&lt;/h4&gt;&#x27;&lt;/script&gt; 总结：如果文本内容中包含 html 标签时推荐使用 innerHTML，否则建议使用 innerText 属性。 ##操作元素属性 有3种方式可以实现对属性的修改： 常用属性修改 直接能过属性名修改，最简洁的语法 12345678&lt;script&gt; // 1. 获取 img 对应的 DOM 元素 const pic = document.querySelector(&#x27;.pic&#x27;) // 2. 修改属性 pic.src = &#x27;./images/lion.webp&#x27; pic.width = 400; pic.alt = &#x27;图片不见了...&#x27;&lt;/script&gt; 控制样式属性 应用【修改样式】，通过修改行内样式 style 属性，实现对样式的动态修改。 通过元素节点获得的 style 属性本身的数据类型也是对象，如 box.style.color、box.style.width 分别用来获取元素节点 CSS 样式的 color 和 width 的值。 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;练习 - 修改样式&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;box&quot;&gt;随便一些文本内容&lt;/div&gt; &lt;script&gt; // 获取 DOM 节点 const box = document.querySelector(&#x27;.intro&#x27;) box.style.color = &#x27;red&#x27; box.style.width = &#x27;300px&#x27; // css 属性的 - 连接符与 JavaScript 的 减运算符 // 冲突，所以要改成驼峰法 box.style.backgroundColor = &#x27;pink&#x27; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 任何标签都有 style 属性，通过 style 属性可以动态更改网页标签的样式，如要遇到 css 属性中包含字符 - 时，要将 - 去掉并将其后面的字母改成大写，如 background-color 要写成 box.style.backgroundColor 操作类名(className) 操作CSS 如果修改的样式比较多，直接通过style属性修改比较繁琐，我们可以通过借助于css类名的形式。 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;练习 - 修改样式&lt;/title&gt; &lt;style&gt; .pink &#123; background: pink; color: hotpink; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;box&quot;&gt;随便一些文本内容&lt;/div&gt; &lt;script&gt; // 获取 DOM 节点 const box = document.querySelector(&#x27;.intro&#x27;) box.className = &#x27;pink&#x27; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 注意： 1.由于class是关键字, 所以使用className去代替 2.className是使用新值换旧值, 如果需要添加一个类,需要保留之前的类名 通过 classList 操作类控制CSS 为了解决className 容易覆盖以前的类名，我们可以通过classList方式追加和删除类名 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; div &#123; width: 200px; height: 200px; background-color: pink; &#125; .active &#123; width: 300px; height: 300px; background-color: hotpink; margin-left: 100px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;one&quot;&gt;&lt;/div&gt; &lt;script&gt; // 1.获取元素 // let box = document.querySelector(&#x27;css选择器&#x27;) let box = document.querySelector(&#x27;div&#x27;) // add是个方法 添加 追加 // box.classList.add(&#x27;active&#x27;) // remove() 移除 类 // box.classList.remove(&#x27;one&#x27;) // 切换类 box.classList.toggle(&#x27;one&#x27;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 操作表单元素属性表单很多情况，也需要修改属性，比如点击眼睛，可以看到密码，本质是把表单类型转换为文本框 正常的有属性有取值的跟其他的标签属性没有任何区别 获取:DOM对象.属性名 设置:DOM对象.属性名&#x3D; 新值 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;input type=&quot;text&quot; value=&quot;请输入&quot;&gt; &lt;button disabled&gt;按钮&lt;/button&gt; &lt;input type=&quot;checkbox&quot; name=&quot;&quot; id=&quot;&quot; class=&quot;agree&quot;&gt; &lt;script&gt; // 1. 获取元素 let input = document.querySelector(&#x27;input&#x27;) // 2. 取值或者设置值 得到input里面的值可以用 value // console.log(input.value) input.value = &#x27;小米手机&#x27; input.type = &#x27;password&#x27; // 2. 启用按钮 let btn = document.querySelector(&#x27;button&#x27;) // disabled 不可用 = false 这样可以让按钮启用 btn.disabled = false // 3. 勾选复选框 let checkbox = document.querySelector(&#x27;.agree&#x27;) checkbox.checked = false &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 自定义属性标准属性: 标签天生自带的属性 比如class id title等, 可以直接使用点语法操作比如： disabled、checked、selected 自定义属性： 在html5中推出来了专门的data-自定义属性 在标签上一律以data-开头 在DOM对象上一律以dataset对象方式获取 1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div data-id=&quot;1&quot;&gt; 自定义属性 &lt;/div&gt; &lt;script&gt; // 1. 获取元素 let div = document.querySelector(&#x27;div&#x27;) // 2. 获取自定义属性值 console.log(div.dataset.id) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 间歇函数 知道间歇函数的作用，利用间歇函数创建定时任务。 setInterval 是 JavaScript 中内置的函数，它的作用是间隔固定的时间自动重复执行另一个函数，也叫定时器函数。 12345678910&lt;script&gt; // 1. 定义一个普通函数 function repeat() &#123; console.log(&#x27;不知疲倦的执行下去....&#x27;) &#125; // 2. 使用 setInterval 调用 repeat 函数 // 间隔 1000 毫秒，重复调用 repeat setInterval(repeat, 1000)&lt;/script&gt;","categories":[],"tags":[]},{"title":"Fabric入门教程","slug":"Fabric入门教程","date":"2023-03-27T01:42:39.000Z","updated":"2023-04-17T08:07:04.000Z","comments":true,"path":"2023/03/27/Fabric入门教程/","link":"","permalink":"http://peapod.top/2023/03/27/Fabric%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"Hyperledger Fabric 2.0 使用教程简介区块链是一个由分布式网络中的节点维护的不可篡改的账本。 Hyperledger Fabric 是一个开源的企业级许可分布式账本技术（Distributed Ledger Technology，DLT）平台，专为在企业环境中使用而设计。 模块化Fabric 由以下模块化的组件组成： 可插拔的排序服务对交易顺序建立共识，然后向节点广播区块； 可插拔的成员服务提供者负责将网络中的实体与加密身份相关联； 可选的P2P gossip 服务通过排序服务将区块发送到其他节点； 智能合约（“链码”）隔离运行在容器环境（例如 Docker）中。它们可以用标准编程语言编写，但不能直接访问账本状态； 账本可以通过配置支持多种 DBMS； 可插拔的背书和验证策略，每个应用程序可以独立配置。 许可区块链在一组已知的、已识别的且经常经过审查的参与者中操作区块链，这些参与者在产生一定程度信任的治理模型下运作。 通过依赖参与者的身份，许可区块链可以使用更传统的崩溃容错（CFT）或拜占庭容错（BFT）共识协议，而不需要昂贵的挖掘。 在许可的情况下，降低了参与者故意通过智能合约引入恶意代码的风险。 链码三个关键点适用于智能合约，尤其是应用于平台时： 多个智能合约在网络中同时运行， 它们可以动态部署（很多情况下任何人都可以部署）， 应用代码应视为不被信任的，甚至可能是恶意的。 顺序执行架构，其中共识协议： 验证并将交易排序，然后将它们传播到所有的节点， 每个节点按顺序执行交易。 结果一定是确定的。 执行-排序-验证架构，它将交易流分为三个步骤： 执行一个交易并检查其正确性，从而给它背书， 通过（可插拔的）共识协议将交易排序， 提交交易到账本前先根据特定应用程序的背书策略验证交易 在交易顺序达成最终一致前执行交易。每个交易只需要由满足交易的背书策略所必需的节点的子集来执行（背书）。这样可以并行执行，从而提高系统的整体性能和规模。第一阶段也消除了任何非确定性，因为在排序之前可以过滤掉不一致的结果。 隐私和保密在一个公共的、非许可的区块链网络中，利用 PoW 作为其共识模型，交易在每个节点上执行。这意味着合约本身和他们处理的交易数据都不保密。每个交易以及实现它的代码，对于网络中的每个节点都是可见的。 Hyperledger Fabric 是一个许可平台，通过其通道架构和 私有数据特性实现保密。 在通道方面，参与到通道的节点才有权访问智能合约（链码）和交易数据，以此保证了隐私性和保密性。 私有数据通过在通道中的成员间使用集合，实现了和通道相同的隐私能力并且不用创建和维护独立的通道。 可插拔共识Fabric 目前提供了一种基于etcd 库 中 Raft 协议 的 CFT 排序服务的实现。 一个 Fabric 网络中可以有多种排序服务以支持不同的应用或应用需求。 性能和可扩展一个区块链平台的性能可能会受到许多因素的影响，例如交易大小、区块大小、网络大小以及硬件限制等。 Hyperledger Caliper的基准测试框架。 将 Fabric 扩展到 20000 笔交易每秒（Scaled Fabric to 20,000 transactions per second）。 更新说明智能合约的去中心化治理新的 Fabric 链码生命周期支持多个组织在链码和账本交互之前协商链码的参数，例如链码背书策略。 新的模式有几个改进: 多个组织必须认同链码参数。去中心化的模型要求在链码在通道上变为活动状态之前，要有足够数量的组织就背书策略和其他细节达成一致意见。 更周密的链码升级过程。只有在足够数量的组织批准升级后才能升级链码。 更简单的背书策略和私有数据集合更新 。支持在不重新打包或重新安装链码的情况下，更改背书策略或私有数据集合配置。 可查验的链码包 Fabric 生命周期将链码封装在可读性更强的 tar 文件中。 使用一个包在通道上启动多个链码。 通道成员之间的链码包不需要为同一个。 使用新的链码生命周期 私有数据增强私有数据模式： 共享和验证私有数据 集合级别的背书策略 每个组织的隐式集合 外部链码启动器 消除 Docker 守护进程依赖 容器的替代品 不再要求链码在 Docker 容器中运行，可以在运营者选择的环境（包括容器）中执行。 可执行的外部构建器 操作员可以提供一组可执行的外部构建器，以覆盖 Peer 节点构建和启动链码方式。 作为外部服务的链码 提高状态数据库缓存 在使用外部 CouchDB 状态数据库时，背书和验证阶段的读取延迟历来是性能瓶颈。 在 Fabric v2.0 中，用快速的本地缓存读取取代了 Peer 节点中那些耗费资源的查找操作。可以使用 core.yaml 文件中的属性 cachesize 来配置缓存大小。 关键概念1.账本一个状态（您的银行余额）和一组促成该状态的有序交易（收入和支出）。 呈现一组账本状态的当前值，同时记录下促成了以上账本状态的交易的历史。 Hyperledger Fabric 中的账本由“世界状态“和”区块链“这两部分组成，它们彼此不同但却相互关联。 世界状态是一个数据库，它存储了一组账本状态的当前值。（余额） 通过世界状态，程序可以直接访问一个账本状态的当前值，不需要遍历整个交易日志来计算当前值。 可以创建、更新和删除状态，所以世界状态能够频繁更改。 区块链是交易日志，它记录了促成当前世界状态的所有改变。 一旦把数据写入区块链，就无法修改，它是不可篡改的。 从世界状态中可以直接获取当前值。世界状态被作为数据库来实现。这一点很有意义，因为数据库为有效存储和状态检索提供了充分的算子。 所有被提交的交易，无论有效与否，都会被收进区块链。 关键设计在于，只有那些受到相关背书组织签名的交易才会更新世界状态。 每当更新状态时，都会检查该状态的版本，以确保当前状态与背书时的版本相匹配。这就确保了世界状态是按照预期进行更新的，没有发生并发更新。 区块链记录了每个账本状态之前的所有版本以及状态是如何被更改的。 区块链的结构是一群相互链接的区块的序列化日志，其中每个区块都包含一系列交易，各项交易代表了一个对世界状态进行的查询或更新操作。 区块链总是以文件实现，而与之相反的是，世界状态以数据库实现。 创世区块包含了一个配置交易，该交易含有网络配置（未显示）的初始状态。 世界状态数据库选项LevelDB 是世界状态数据库的默认选项，当账本状态是简单的键值对时，使用 LevelDB 非常合适。LevelDB 数据库与 peer 节点位于相同位置，它被嵌入与 peer 节点相同的操作系统进程中。 当账本状态结构为 JSON 文档时，以 CouchDB 来实现世界状态非常合适，这是因为业务交易涉及的数据类型通常十分丰富，而 CouchDB 可支持对这些数据类型进行各种形式的查询和更新。在实现方面，CouchDB 是在单独的操作系统进程中运行的，但是节点和 CouchDB 实例之间仍然存在1:1的关系。 命名空间每个链码都有自己的世界状态，并且与所有其他链码的世界状态分离。世界状态位于一个命名空间中，因此只有位于同一链码中的智能合约才能访问一个给定的命名空间。 每个通道都有一个完全独立的账本。这意味着完全独立的区块链和完全独立的世界状态，包括命名空间。 2.通道功能（capabilities）支持不同的版本 才使得Fabric节点能够滚动升级。 capabilities在每个通道的配置中定义， 通过定义行为会产生一致结果的版本，确保了确定性。 capabilities使运行在不同版本的节点能够 以兼容和一致的方式在给定特定区块高度的通道配置下运行。 每次发布版本不一定都有一个新的capability level。 在通道中，节点版本必须不能低于特定的capability版本。 3.策略策略是一组规则，用来定义如何做出决策和实现特定结果。 Fabric 策略表示成员如何同意或者拒绝网络、通道或者智能合约的变更。策略是基础设施的管理机制。 策略决定了那些组织可以访问或者更新 Fabric 网络，并且提供了强制执行这些决策的机制。 系统通道配置排序系统通道配置区块中的策略治理着排序服务使用的共识，并定义了新区块如何被创建。系统通道也治理着联盟中的哪些成员可以创建新通道。","categories":[],"tags":[]},{"title":"Git教程","slug":"Git教程","date":"2023-01-15T07:59:39.000Z","updated":"2024-08-27T01:38:05.905Z","comments":true,"path":"2023/01/15/Git教程/","link":"","permalink":"http://peapod.top/2023/01/15/Git%E6%95%99%E7%A8%8B/","excerpt":"","text":"git基础获取git仓库两种获取 Git 项目仓库的方式： 将尚未进行版本控制的本地目录转换为 Git 仓库； 从其它服务器 克隆 一个已存在的 Git 仓库。 初始化仓库1git init 该命令将创建一个名为 .git 的子目录，这个子目录含有你初始化的 Git 仓库中所有的必须文件，这些文件是 Git 仓库的骨干。项目里的文件还没有被跟踪。 开始追踪这些文件并进行初始提交。 123git add *git add REMADEgit commit -m &quot;first version&quot; 克隆仓库执行 git clone 命令的时候，默认配置下远程 Git 仓库中的每一个文件的每一个版本都将被拉取下来。 12git clone https://github.com/libgit2/libgit2git clone https://github.com/libgit2/libgit2 mylibgit // 克隆并自定义文件 记录每次更新到仓库对这些文件做些修改，每当完成了一个阶段的目标，想要将记录下它时，就将它提交到仓库。 工作目录下的每一个文件都不外乎这两种状态：已跟踪 或 未跟踪。 已跟踪的文件是指那些被纳入了版本控制的文件，除已跟踪文件外的其它所有文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有被放入暂存区。 检查当前文件状态1git status 使用 git status -s 命令或 git status --short 命令，你将得到一种格式更为紧凑的输出。 新添加的未跟踪文件前面有 ?? 标记，新添加到暂存区中的文件前面有 A 标记，修改过的文件前面有 M 标记。 输出中有两栏，左栏指明了暂存区的状态，右栏指明了工作区的状态。 123456$ git status -s M READMEMM RakefileA lib/git.rbM lib/simplegit.rb?? LICENSE.txt 跟踪新文件1git add git add 命令使用文件或目录的路径作为参数；如果参数是目录的路径，该命令将递归地跟踪该目录下的所有文件。 忽略文件创建一个名为 .gitignore 的文件，列出要忽略的文件的模式。 星号（*）匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符 （这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）； 问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符， 表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。 使用两个星号（**）表示匹配任意中间目录，比如 a/**/z 可以匹配 a/z 、 a/b/z 或 a/b/c/z 等。 123$ cat .gitignore*.[oa]*~ 查看已暂存和未暂存的修改想知道具体修改了什么地方,用 git diff 命令。 git diff比较的是当前文件和暂存区域快照之间的差异。 也就是修改之后还没有暂存起来的变化内容。 git diff --staged 这条命令将比对已暂存文件与最后一次提交的文件差异。 提交更新每次准备提交前，先用 git status 看下，你所需要的文件是不是都已暂存起来了， 然后再运行提交命令 git commit。 12git commit -m &quot;&quot;git commit -a -m &quot;&quot; # 跳过使用暂存区域 移除文件从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。 把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。 1$ git rm --cached README 移动文件在 Git 中对文件改名 1git mv file_from file_to 查看提交历史不传入任何参数的默认情况下，git log 会按时间先后顺序列出所有的提交，最近的更新排在最上面。 -p 或 --patch ，它会显示每次提交所引入的差异（按 补丁 的格式输出）。 --stat ，每次提交的简略统计信息。可以使用在每次提交的下面列出所有被修改过的文件、有多少文件被修改了以及被修改过的文件的哪些行被移除或是添加了。 --pretty， 这个选项可以使用不同于默认格式的方式展示提交历史。 format ，可以定制记录的显示格式。 --graph ，添加了一些 ASCII 字符串来形象地展示你的分支、合并历史。 1234git log --pretty=format:&quot;%h - %an, %ar : %s&quot;ca82a6d - Scott Chacon, 6 years ago : changed the version number085bb3b - Scott Chacon, 6 years ago : removed unnecessary testa11bef0 - Scott Chacon, 6 years ago : first commit 选项 说明 %H 提交的完整哈希值 %h 提交的简写哈希值 %T 树的完整哈希值 %t 树的简写哈希值 %P 父提交的完整哈希值 %p 父提交的简写哈希值 %an 作者名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 –date&#x3D;选项 来定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者的名字 %ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期（距今多长时间） %s 提交说明 作者指的是实际作出修改的人，提交者指的是最后将此工作成果提交到仓库的人。 撤消操作提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 --amend 选项的提交命令来重新提交： 提交后发现忘记了暂存某些需要的修改 123git commit -m &#x27;initial commit&#x27;git add forgotten_filegit commit --amend 第二次提交将代替第一次提交的结果。 取消暂存的文件使用 git reset HEAD &lt;file&gt;… 来取消暂存 1git reset HEAD CONTRIBUTING.md 撤消对文件的修改撤消修改——将它还原成上次提交时的样子 1git checkout -- CONTRIBUTING.md 那些被删除的分支中的提交或使用 --amend 选项覆盖的提交也可以恢复 远程仓库的使用管理远程仓库包括了解如何添加远程仓库、移除无效的远程仓库、管理不同的远程分支并定义它们是否被跟踪等等。 查看远程仓库 git remote 命令。 它会列出你指定的每一个远程服务器的简写。 -v，会显示需要读写远程仓库使用的 Git 保存的简写与其对应的 URL。 123git remote -vorigin https://github.com/schacon/ticgit (fetch)origin https://github.com/schacon/ticgit (push) 表示能拉取，可以拥有向他们推送的权限。 添加远程仓库运行 git remote add &lt;shortname&gt; &lt;url&gt; 添加一个新的远程 Git 仓库，同时指定一个方便使用的简写： 123456git remote add pb https://github.com/paulboone/ticgitgit remote -vorigin https://github.com/schacon/ticgit (fetch)origin https://github.com/schacon/ticgit (push)pb https://github.com/paulboone/ticgit (fetch)pb https://github.com/paulboone/ticgit (push) 拉取 Paul 的仓库中有但你没有的信息，可以运行 git fetch pb： 12345678git fetch pbremote: Counting objects: 43, done.remote: Compressing objects: 100% (36/36), done.remote: Total 43 (delta 10), reused 31 (delta 5)Unpacking objects: 100% (43/43), done.From https://github.com/paulboone/ticgit * [new branch] master -&gt; pb/master * [new branch] ticgit -&gt; pb/ticgit 从远程仓库中抓取与拉取1git fetch &lt;remote&gt; 这个命令会访问远程仓库，从中拉取所有你还没有的数据。 执行完成后，你将会拥有那个远程仓库中所有分支的引用，可以随时合并或查看。 使用 clone 命令克隆了一个仓库，命令会自动将其添加为远程仓库并默认以 “origin” 为简写。 所以，git fetch origin 会抓取克隆（或上一次抓取）后新推送的所有工作。 默认情况下，git clone 命令会自动设置本地 master 分支跟踪克隆的远程仓库的 master 分支。运行 git pull 通常会从最初克隆的服务器上抓取数据并自动尝试合并到当前所在的分支。 推送到远程仓库将 master 分支推送到 origin 服务器 1git push origin master 必须先抓取他们的工作并将其合并进你的工作后才能推送。 查看某个远程仓库使用 git remote show &lt;remote&gt; 命令。 远程仓库的重命名与移除运行 git remote rename 来修改一个远程仓库的简写名。 想要移除一个远程仓库使用 git remote remove 或 git remote rm 使用这种方式删除了一个远程仓库，那么所有和这个远程仓库相关的远程跟踪分支以及配置信息也会一起被删除。 标签Git 可以给仓库历史中的某一个提交打上标签，以示重要。 比较有代表性的是人们会使用这个功能来标记发布结点（ v1.0 、 v2.0 等等）。 列出标签在 Git 中列出已有的标签非常简单，只需要输入 git tag 创建标签Git 支持两种标签：轻量标签（lightweight）与附注标签（annotated）。 创建附注标签十分简单。 最简单的方式是当你在运行 tag 命令时指定 -a。 12345git tag -a v1.4 -m &quot;my version 1.4&quot;git tagv0.1v1.3v1.4 -m 选项指定了一条将会存储在标签中的信息。 使用 git show 命令可以看到标签信息和与之对应的提交信息： 1git show v1.4 轻量标签本质上是将提交校验和存储到一个文件中——没有保存任何其他信息。 创建轻量标签，不需要使用 -a、-s 或 -m 选项，只需要提供标签名字： 1$ git tag v1.4-lw 在标签上运行 git show，你不会看到额外的标签信息。 命令只会显示出提交信息。 后期打标签1git tag -a v1.2 9fceb02 # 在命令的末尾指定提交的校验和 共享标签git push 命令并不会传送标签到远程仓库服务器上。 在创建完标签后你必须显式地推送标签到共享服务器上。 这个过程就像共享远程分支一样——你可以运行 git push origin &lt;tagname&gt;。 一次性推送很多标签，也可以使用带有 --tags 选项。 1git push origin --tags Git 别名如果不想每次都输入完整的 Git 命令，可以通过 git config 文件来轻松地为每一个命令设置一个别名。 1234$ git config --global alias.co checkout$ git config --global alias.br branch$ git config --global alias.ci commit$ git config --global alias.st status 当要输入 git commit 时，只需要输入 git ci。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://peapod.top/tags/Git/"}],"author":"taweizhong"},{"title":"区块链环境配置教程","slug":"区块链环境配置教程","date":"2022-11-10T14:10:37.000Z","updated":"2023-01-03T14:59:00.000Z","comments":true,"path":"2022/11/10/区块链环境配置教程/","link":"","permalink":"http://peapod.top/2022/11/10/%E5%8C%BA%E5%9D%97%E9%93%BE%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B/","excerpt":"","text":"Hyperledger Fabric v2.2 Ubuntu准备阶段运行环境：Ubuntu18.04安装git（分布式版本控制系统）1apt install git 安装cURL（利用URL语法在命令行下工作的文件传输工具）1apt install curl 安装docker在 Ubuntu | 上安装 Docker 引擎码头工人文档 1apt install docker.io 设置docker服务 123systemctl start docker // 启动docker的服务systemctl enable docker // 设置开机启动usermod -a -G docker root // 将root用户添加到docker组中 安装docker-compose（注：这个地方版本要2.xx）centos 8安装docker-compose - 民工黑猫 - 博客园 (cnblogs.com) 安装golang0.16 下载安装包 解压 配置环境变量 验证 安装clash服务器安装Clash - 秋季的blog (taweizhong.github.io) 安装示例、二进制和 Docker 镜像1curl -sSL https://bit.ly/2ysbOFE | bash -s -- 2.2.0 Hyperledger Fabric v2.2 Centos准备阶段运行环境：Centos v8安装git（分布式版本控制系统）1yum install git 安装cURL（利用URL语法在命令行下工作的文件传输工具）1yum install curl 安装docker在 CentOS | 上安装 Docker 引擎码头工人文档 设置docker服务 123systemctl start docker // 启动docker的服务systemctl enable docker // 设置开机启动usermod -a -G docker root // 将root用户添加到docker组中 安装docker-compose（注：这个地方版本要2.xx）centos 8安装docker-compose - 民工黑猫 - 博客园 (cnblogs.com) 安装golang0.16 下载安装包 解压 配置环境变量 验证 安装clash服务器安装Clash - 秋季的blog (taweizhong.github.io) 安装示例、二进制和 Docker 镜像1curl -sSL https://bit.ly/2ysbOFE | bash -s -- 2.2.0","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[],"author":"taweizhong"},{"title":"GCC","slug":"GCC","date":"2022-11-04T11:23:05.000Z","updated":"2022-11-04T12:41:06.000Z","comments":true,"path":"2022/11/04/GCC/","link":"","permalink":"http://peapod.top/2022/11/04/GCC/","excerpt":"","text":"GCCGNU 计划，最终的目标是打造一套完全自由、开源的操作系统。 早期 GCC 的全拼为 GNU C Compiler，即 GUN 计划诞生的 C 语言编译器，显然最初 GCC 的定位确实只用于编译 C 语言。 GCC的功能得到了很大的扩展，它不仅可以用来编译C语言程序，还可以处理C++、GO等多种语言。被重新定义为 GNU Compiler Collection，即 GNU 编译器套件。 安装GCC编译器12yum -y install gccyum -y install gcc-c++ 以源码的方式安装 12yum install -y glibc-static libstdc++-static # 所需的静态链接库yum install -y gcc gcc-c++ 安装包 gcc-10.1.0.tar.gz Windows平台安装GCC 移植版主要有 2 种，分别为 MinGW 和 Cygwin。 MinGW 侧重于服务 Windows 用户可以使用 GCC 编译环境，直接生成可运行 Windows 平台上的可执行程序，相比后者体积更小，使用更方便。 Cygwin 则可以提供一个完整的 Linux 环境，借助它不仅可以在 Windows 平台上使用 GCC 编译器，理论上可以运行 Linux 平台上所有的程序。 GCC的组成部分 部分 描述 c++ gcc 的一个版木，默认语言设置为 C++，而且在连接的时候自动包含标准 C++ 库。这和 g++ 一样 ccl 实际的C编译程序 cclplus 实际的 C++ 编泽程序 collect2 在不使用 GNU 连接程序的系统上，有必要运行 collect2 来产生特定的全局初始化代码（例如 C++ 的构造函数和析构函数） configure GCC 源代码树根目录中的一个脚木。用于设置配置值和创建GCC 编译程序必需的 make 程序的描述文件 crt0.o 这个初始化和结束代码是为每个系统定制的，而且也被编译进该文件，该文件然后会被连接到每个可执行文件中来执行必要的启动和终止程序 cygwin1.dll Windows 的共享库提供的 API，模拟 UNIX 系统调用 f77 该驱动程序可用于编译 Fortran f771 实际的 Fortran 编译程序 g++ gcc 的一个版木，默认语言设置为 C++，而且在连接的时候自动包含标准 C++ 库。这和 c++ 一样 gcc 该驱动程序等同于执行编译程序和连接程序以产生需要的输出 gcj 该驱动程序用于编译 Java gnat1 实际的 Ada 编译程序 gnatbind 一种工具，用于执行 Ada 语言绑定 gnatlink 一种工具，用于执行 Ada 语言连接 jc1 实际的 Java 编译程序 libgcc 该库包含的例程被作为编泽程序的一部分，是因为它们可被连接到实际的可执行程序中。 它们是特殊的例程，连接到可执行程序，来执行基木的任务，例如浮点运算。这些库中的例程通常都是平台相关的 libgcj 运行时库包含所有的核心 Java 类 libobjc 对所有 Objective-C 程序都必须的运行时库 libstdc++ 运行时库，包括定义为标准语言一部分的所有的 C++ 类和函数 C程序的编译过程 预处理处理那些源文件和头文件中以#开头的命令。 规则： 将所有的#define删除，并展开所有的宏定义。 处理所有条件编译命令，比如 #if、#ifdef、#elif、#else、#endif 等。 处理#include命令，将被包含文件的内容插入到该命令所在的位置，这与复制粘贴的效果一样。注意，这个过程是递归进行的，也就是说被包含的文件可能还会包含其他的文件。 删除所有的注释//和/* ... */。 添加行号和文件名标识，便于在调试和出错时给出具体的代码位置。 保留所有的#pragma命令，因为编译器需要使用它们。 预处理的结果是生成.i文件。 命令： 1g++ -E hello.cpp -o hello.i -E表示只进行预编译。 编译进行一些列的词法分析、语法分析、语义分析以及优化后生成相应的汇编代码文件。 编译的结果是生成.s文件。 命令： 12g++ -S hello.cpp -o hello.sg++ -S hello.i -o hello.s 汇编将汇编代码转换成可以执行的机器指令。 汇编的结果是产生目标文件，在 GCC 下的后缀为.o，在 Visual Studio 下的后缀为.obj。 链接目标文件已经是二进制文件，与可执行文件的组织形式类似，只是有些函数和全局变量的地址还未找到，程序不能执行。 链接的作用就是找到这些目标地址，将所有的目标文件组织成一个可以执行的二进制文件。 GCC编译C&#x2F;C++程序1g++ hello.cpp GCC 编译器会在当前目录下生成一个名为 a.out 的可执行文件。 gcc&#x2F;g++指令选项 功 能 -E（大写） 预处理指定的源文件，不进行编译。 -S（大写） 编译指定的源文件，但是不进行汇编。 -c 编译、汇编指定的源文件，但是不进行链接。 -o 指定生成文件的文件名。 -llibrary（-I library） 其中 library 表示要搜索的库文件的名称。该选项用于手动指定链接环节中程序可以调用的库文件。建议 -l 和库文件名之间不使用空格，比如 -lstdc++。 -ansi 对于 C 语言程序来说，其等价于 -std&#x3D;c90；对于 C++ 程序来说，其等价于 -std&#x3D;c++98。 -std&#x3D; 手动指令编程语言所遵循的标准，例如 c89、c90、c++98、c++11 等。 GCC -E选项通过为 gcc 指令添加 -E 选项，即可控制 GCC 编译器仅对源代码做预处理操作。 默认情况下 gcc -E 指令只会将预处理操作的结果输出到屏幕上，并不会自动保存到某个文件。 和 -o 选项连用，将结果导入到指令的文件中。 1g++ -E hello.cpp -o hello.i 为 gcc 指令再添加一个 -C 选项，阻止 GCC 删除源文件和头文件中的注释。 1gcc -E -C demo.c -o demo.i GCC -S选项：编译非汇编文件编译是整个程序构建的核心部分，也是最复杂的部分之一。 编译，简单理解就是将预处理得到的程序代码，经过一系列的词法分析、语法分析、语义分析以及优化，加工为当前机器支持的汇编代码。 默认情况下，编译操作会自行新建一个文件名和指定文件相同、后缀名为 .s 的文件，并将编译的结果保存在该文件中。 为 gcc -S 指令添加 -o 选项，令 GCC 编译器将编译结果保存在我们指定的文件中。 1gcc -S demo.i -o test.i 最终生成的 .s 汇编文件。 GCC -c选项：生成目标文件汇编其实就是将汇编代码转换成可以执行的机器指令。 为 gcc 指令添加 -c 选项，即可让 GCC 编译器将指定文件加工至汇编阶段，并生成相应的目标文件。 1gcc -c demo.s 生成了和 demo.s 同名但后缀名为 .o 的文件，这就是经过汇编操作得到的目标文件。 可以为 gcc -c 指令在添加一个 -o 选项，用于将汇编操作的结果输入到指定文件中。 1gcc -c demo.s -o test.o GCC -l选项：手动添加链接库链接器把多个二进制的目标文件（object file）链接成一个单独的可执行文件。 在链接过程中，它必须把符号（变量名、函数名等一些列标识符）用对应的数据的内存地址（变量地址、函数地址等）替代，以完成程序中多个模块的外部引用。 当把程序链接到一个链接库时，只会链接程序所用到的函数的目标文件。 标准库的大部分函数通常放在文件 libc.a 中，或者放在用于共享的动态链接文件 libc.so 中。 链接库一般位于 &#x2F;lib&#x2F; 或 &#x2F;usr&#x2F;lib&#x2F;，或者位于 GCC 默认搜索的其他目录。 GCC 默认会链接 libc.a 或者 libc.so，但是对于其他的库（例如非标准库、第三方库等），就需要手动添加。 1gcc main.c -o main.out -lm 有三种方式可以链接在 GCC 搜索路径以外的链接库： 链接库作为一般的目标文件，为 GCC 指定该链接库的完整路径与文件名。 1gcc main.c -o main.out /usr/lib/libm.a 用-L选项，为 GCC 增加另一个搜索链接库的目录： 1gcc main.c -o main.out -L/usr/lib -lm 包括所需链接库的目录加到环境变量 LIBRARYPATH 中。 gcc指令一次处理多个文件1gcc -c demo1.c demo2.c GCC编译多文件项目12345gcc -c myfun.c main.clsmain.c main.o myfun.c myfun.ogcc myfun.o main.o -o main.exe ./main.exe gcc 指令还可以直接编译并链接它们 12gcc myfun.c main.c -o main.exe ./main.exe 如果一个项目中有十几个甚至几十个源文件,用 *.c 表示所有的源文件。 1gcc *.c -o main.exe GCC使用静态链接库和动态链接库库文件中每个目标文件存储的代码，并非完整的程序，而是一个个实用的功能模块。 C++ 库文件不仅提供有使用的函数，还有大量事先设计好的类（如 string 字符串类）。 头文件和库文件并不是一码事，它们最大的区别在于：头文件只存储变量、函数或者类等这些功能模块的声明部分，库文件才负责存储各模块具体的实现部分。 所有的库文件都提供有相应的头文件作为调用它的接口。 库文件是无法直接使用的，只能通过头文件间接调用。 库文件只是一个统称，代指的是一类压缩包，它们都包含有功能实用的目标文件。 库文件用于程序的链接阶段。 采用静态链接方式实现链接操作的库文件，称为静态链接库；采用动态链接方式实现链接操作的库文件，称为动态链接库。 静态链接库程序文件中哪里用到了库文件中的功能模块，GCC 编译器就会将该模板代码直接复制到程序文件的适当位置，最终生成可执行文件。 优势劣势： 优势是，生成的可执行文件不再需要任何静态库文件的支持就可以独立运行（可移植性强）； 劣势是，如果程序文件中多次调用库中的同一功能模块，则该模块代码势必就会被复制多次，生成的可执行文件中会包含多段完全相同的代码，造成代码的冗余。 动态链接库程序文件中哪里需要库文件的功能模块，GCC 编译器不会直接将该功能模块的代码拷贝到文件中，而是将功能模块的位置信息记录到文件中，直接生成可执行文件。 采用动态链接库生成的可执行文件运行时，GCC 编译器会将对应的动态链接库一同加载在内存中，由于可执行文件中事先记录了所需功能模块的位置信息，所以在现有动态链接库的支持下，也可以成功运行。 优势劣势： 真正的实现代码会在程序运行时被载入内存，这意味着，即便功能模块被调用多次，使用的都是同一份实现代码。 此方式生成的可执行文件无法独立运行，必须借助相应的库文件（可移植性差）。 动态链接库生成的可执行文件的体积更小，因为其内部不会被复制一堆冗余的代码。 GCC 编译器生成可执行文件时，默认情况下会优先使用动态链接库实现链接操作，除非当前系统环境中没有程序文件所需要的动态链接库，GCC 编译器才会选择相应的静态链接库。 静态链接库和动态链接库通常存放在 &#x2F;usr&#x2F;bin 或者 &#x2F;bin 目录下。","categories":[],"tags":[]},{"title":"分布式系统","slug":"分布式系统","date":"2022-10-26T11:07:12.000Z","updated":"2022-10-27T00:21:50.000Z","comments":true,"path":"2022/10/26/分布式系统/","link":"","permalink":"http://peapod.top/2022/10/26/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"课程笔记翻译多处理器与多核处理器 多核处理器 多处理器 芯片组 DDR5 是第五代 DDR SDRAM 的简称，DDR SDRAM 是英文 Double Data Rate SDRAM 的缩写，中文译为双倍速率 SDRAM。 nvme是通信协议，主流的主板上，都支持m.2 nvme协议。 高速串行总线，pcie总线有两种规格，即pcie3.0和pcie4.0。 分布式系统软件负载均衡 Nginx：高性能、高并发的web服务器；功能包括负载均衡、反向代理、静态内容缓存、访问控制；工作在应用层 LVS： Linux virtual server，基于集群技术和Linux操作系统实现一个高性能、高可用的服务器；工作在网络层 容器 docker kubernetes cache memcache redis 协调中心： etcd zookeeper：使用了Paxos协议Paxos是强一致性。 rpc框架 grpc dubbo是阿里开源的Java语言开发的高性能RPC框架 分布式系统的应用区块链 分布式账本 In Search of an Understandable Consensus Algorithm (raft.github.io) 大数据 Hadoop生态圈 CAP定理BASE理论Paxos共识算法Gossip协议Raft算法","categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://peapod.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/tags/%E7%AC%94%E8%AE%B0/"}],"author":"taweizhong"},{"title":"知链区块链教程","slug":"知链区块链教程","date":"2022-10-19T08:47:26.000Z","updated":"2022-10-19T09:58:38.000Z","comments":true,"path":"2022/10/19/知链区块链教程/","link":"","permalink":"http://peapod.top/2022/10/19/%E7%9F%A5%E9%93%BE%E5%8C%BA%E5%9D%97%E9%93%BE%E6%95%99%E7%A8%8B/","excerpt":"","text":"目录初识区块链诞生区块链诞生http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=6JYM32GCS7GIGTLWH45BD5 发展区块链的发展http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=UORY960KQ8CKNGRTYO5JBF 结构与特性区块链的结构与特性http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=V_5BMPQISOOGIYVMNVKV6B 区块头与区块体区块与区块体http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=T97CBLZBSQCM3X6QVHFK46 区块链原理数据存储：分布式记账分布式记账http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=XFMUBGQUT8--SUHYGSBS2C 公链记账：挖矿与奖励挖矿与奖励http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=-YGVXCXOSYOL48Q0EHFOAA 交易支付：代币交易代币交易http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=SAXYHAPGR3W6WKG1E1HZDA 系统奖励：交易币基交易币基http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=CXR_CND6FHD3EXP2EXF5DA 溯源的基础：Merkle树结构Merkle树结构http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=B8ZGAYF9TPOE1CXEKL6_89 Merkle树与区块链Merkle树与区块链http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=ZNGLK5CUQ-009TEQNUDZD9 区块链关键技术数据链上ID：哈希哈希http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=FNFYC3X6FHJ3EHR9F3R_EW 链上数据的加密基础：公钥公钥http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=FN99DXN0FHN1ENJ9FXN-CG 区块链时代下的账户钥匙：私钥私钥http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=YC-BKMBTRJGCVWCGIY6591 数据加密：非对称加密非对称加密http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=CNRYF39ZFHL1EHVZF3LXFW 数据归属：数字签名数字签名http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=1ULR6AVAQHWILGCJSLKYDC 数据防篡改的手段：数字摘要数字摘要http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=7JLZ62MDTYWRAN4MPMGY1E 安全技术：数字证书数字证书http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=W0RZTWCETXWKAHHG7M0C39 链上通信：P2P传播机制P2P传播机制http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=QQOWLWEHRX8DHNKLIX0BC1 交易先后顺序：时间戳时间戳http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=A3WPWDKPSTOPZNXUBXEI15 实力挖矿：POW共识机制POW共识机制http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=SCC4HRMDSLCNBD4PJGUP21 权益挖矿：POS共识机制POS共识机制http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=F3T_FHZ5FH91FNJ3E4B4DQ 董事会体制：DPOS共识机制DPOS共识机制http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=F357EH52FHL3F3Z4FXT5CW 少数服从多数：PBFT共识机制PBFT共识机制http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=EWFN9RDRTJOWWL1S-YXVE3 区块链核心代表1.0代表：比特币概述与特性比特币概述与特性http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=KZAQ3GAKTLSZDN-XN3KBAC 比特币与交易比特币与交易http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=I5F8MCXLRZKEIKAHOGMN18 2.0代表：以太坊简介以太坊简介http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=D55GTFFXRMOSZV2TMZY529 3.0代表：EOS简介EOS简介http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=YKRGHFKOTPSS8SX7SENX47 典型联盟链：超级账本超级账本http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=DCYEGSVIRVC7ZTH1OJPFBF 交易瓶颈的处理手段：DAGDAGhttp://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=7LJQXLWMQDKV03QZDPE3A3 技术风险隐患依旧：51%攻击51%攻击http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=SEXW8R4ESUKND3JBRYSN7C 增加区块容量：扩容与隔离见证扩容与隔离见证http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=LIJA1OODTS49GGME1KGSAB 提高交易效率：侧链与闪电网络侧链与闪电网络http://study.educhainx.com/newres/static/pdfjs/web/viewer.html?file=GIB9DXF1FHF2C3DYENF6CW","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/tags/%E7%AC%94%E8%AE%B0/"}],"author":"taweizhong"},{"title":"Hyperledger-Fabric 网络构建","slug":"Hyperledger-Fabric-网络构建","date":"2022-10-15T06:22:10.000Z","updated":"2022-10-19T09:24:50.000Z","comments":true,"path":"2022/10/15/Hyperledger-Fabric-网络构建/","link":"","permalink":"http://peapod.top/2022/10/15/Hyperledger-Fabric-%E7%BD%91%E7%BB%9C%E6%9E%84%E5%BB%BA/","excerpt":"","text":"网络构建生成组织结构和身份证书配置文件orderer路径：frist-network/organizations/cryptogen/crypto-config-orderer.yaml 1234567891011121314151617181920212223# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0## ---------------------------------------------------------------------------# &quot;OrdererOrgs&quot; - Definition of organizations managing orderer nodes# ---------------------------------------------------------------------------OrdererOrgs: # --------------------------------------------------------------------------- # Orderer # --------------------------------------------------------------------------- - Name: Orderer Domain: example.com EnableNodeOUs: true # --------------------------------------------------------------------------- # &quot;Specs&quot; - See PeerOrgs for complete description # --------------------------------------------------------------------------- Specs: - Hostname: orderer SANS: - localhost org1路径：frist-network/organizations/cryptogen/crypto-config-org1.yaml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0## ---------------------------------------------------------------------------# &quot;PeerOrgs&quot; - Definition of organizations managing peer nodes# ---------------------------------------------------------------------------PeerOrgs: # --------------------------------------------------------------------------- # Org1 # --------------------------------------------------------------------------- - Name: Org1 Domain: org1.example.com EnableNodeOUs: true # --------------------------------------------------------------------------- # &quot;Specs&quot; # --------------------------------------------------------------------------- # Uncomment this section to enable the explicit definition of hosts in your # configuration. Most users will want to use Template, below # # Specs is an array of Spec entries. Each Spec entry consists of two fields: # - Hostname: (Required) The desired hostname, sans the domain. # - CommonName: (Optional) Specifies the template or explicit override for # the CN. By default, this is the template: # # &quot;&#123;&#123;.Hostname&#125;&#125;.&#123;&#123;.Domain&#125;&#125;&quot; # # which obtains its values from the Spec.Hostname and # Org.Domain, respectively. # --------------------------------------------------------------------------- # - Hostname: foo # implicitly &quot;foo.org1.example.com&quot; # CommonName: foo27.org5.example.com # overrides Hostname-based FQDN set above # - Hostname: bar # - Hostname: baz # --------------------------------------------------------------------------- # &quot;Template&quot; # --------------------------------------------------------------------------- # Allows for the definition of 1 or more hosts that are created sequentially # from a template. By default, this looks like &quot;peer%d&quot; from 0 to Count-1. # You may override the number of nodes (Count), the starting index (Start) # or the template used to construct the name (Hostname). # # Note: Template and Specs are not mutually exclusive. You may define both # sections and the aggregate nodes will be created for you. Take care with # name collisions # --------------------------------------------------------------------------- Template: Count: 1 SANS: - localhost # Start: 5 # Hostname: &#123;&#123;.Prefix&#125;&#125;&#123;&#123;.Index&#125;&#125; # default # --------------------------------------------------------------------------- # &quot;Users&quot; # --------------------------------------------------------------------------- # Count: The number of user accounts _in addition_ to Admin # --------------------------------------------------------------------------- Users: Count: 1 org2路径：frist-network/organizations/cryptogen/crypto-config-org2.yaml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0## ---------------------------------------------------------------------------# &quot;PeerOrgs&quot; - Definition of organizations managing peer nodes# ---------------------------------------------------------------------------PeerOrgs: # --------------------------------------------------------------------------- # Org2 # --------------------------------------------------------------------------- - Name: Org2 Domain: org2.example.com EnableNodeOUs: true # --------------------------------------------------------------------------- # &quot;Specs&quot; # --------------------------------------------------------------------------- # Uncomment this section to enable the explicit definition of hosts in your # configuration. Most users will want to use Template, below # # Specs is an array of Spec entries. Each Spec entry consists of two fields: # - Hostname: (Required) The desired hostname, sans the domain. # - CommonName: (Optional) Specifies the template or explicit override for # the CN. By default, this is the template: # # &quot;&#123;&#123;.Hostname&#125;&#125;.&#123;&#123;.Domain&#125;&#125;&quot; # # which obtains its values from the Spec.Hostname and # Org.Domain, respectively. # --------------------------------------------------------------------------- # Specs: # - Hostname: foo # implicitly &quot;foo.org1.example.com&quot; # CommonName: foo27.org5.example.com # overrides Hostname-based FQDN set above # - Hostname: bar # - Hostname: baz # --------------------------------------------------------------------------- # &quot;Template&quot; # --------------------------------------------------------------------------- # Allows for the definition of 1 or more hosts that are created sequentially # from a template. By default, this looks like &quot;peer%d&quot; from 0 to Count-1. # You may override the number of nodes (Count), the starting index (Start) # or the template used to construct the name (Hostname). # # Note: Template and Specs are not mutually exclusive. You may define both # sections and the aggregate nodes will be created for you. Take care with # name collisions # --------------------------------------------------------------------------- Template: Count: 1 SANS: - localhost # Start: 5 # Hostname: &#123;&#123;.Prefix&#125;&#125;&#123;&#123;.Index&#125;&#125; # default # --------------------------------------------------------------------------- # &quot;Users&quot; # --------------------------------------------------------------------------- # Count: The number of user accounts _in addition_ to Admin # --------------------------------------------------------------------------- Users: Count: 1 生成1234cd /frist-network/organizations../../bin/cryptogen generate --congfig=./cryptogen/crypto-config-orderer.yaml../../bin/cryptogen generate --congfig=./cryptogen/crypto-config-org1.yaml../../bin/cryptogen generate --congfig=./cryptogen/crypto-config-org2.yaml 命令：generate 生成组织结构和身份证书信息。 参数：--congfig指定使用的配置模板文件，--output指定生成内容的输出目录。 在当前文件夹下生成两个子目录： ordererOrganizations peerOrganizations 初始区块和通道交易配置文件配置文件路径：frist-network/configtx/configtx.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#---################################################################################## Section: Organizations## - This section defines the different organizational identities which will# be referenced later in the configuration.#################################################################################Organizations: # SampleOrg defines an MSP using the sampleconfig. It should never be used # in production but may be used as a template for other definitions - &amp;OrdererOrg # DefaultOrg defines the organization which is used in the sampleconfig # of the fabric.git development environment Name: OrdererOrg # ID to load the MSP definition as ID: OrdererMSP # MSPDir is the filesystem path which contains the MSP configuration MSPDir: ../organizations/ordererOrganizations/example.com/msp # Policies defines the set of policies at this level of the config tree # For organization policies, their canonical path is usually # /Channel/&lt;Application|Orderer&gt;/&lt;OrgName&gt;/&lt;PolicyName&gt; Policies: Readers: Type: Signature Rule: &quot;OR(&#x27;OrdererMSP.member&#x27;)&quot; Writers: Type: Signature Rule: &quot;OR(&#x27;OrdererMSP.member&#x27;)&quot; Admins: Type: Signature Rule: &quot;OR(&#x27;OrdererMSP.admin&#x27;)&quot; OrdererEndpoints: - orderer.example.com:7050 - &amp;Org1 # DefaultOrg defines the organization which is used in the sampleconfig # of the fabric.git development environment Name: Org1MSP # ID to load the MSP definition as ID: Org1MSP MSPDir: ../organizations/peerOrganizations/org1.example.com/msp # Policies defines the set of policies at this level of the config tree # For organization policies, their canonical path is usually # /Channel/&lt;Application|Orderer&gt;/&lt;OrgName&gt;/&lt;PolicyName&gt; Policies: Readers: Type: Signature Rule: &quot;OR(&#x27;Org1MSP.admin&#x27;, &#x27;Org1MSP.peer&#x27;, &#x27;Org1MSP.client&#x27;)&quot; Writers: Type: Signature Rule: &quot;OR(&#x27;Org1MSP.admin&#x27;, &#x27;Org1MSP.client&#x27;)&quot; Admins: Type: Signature Rule: &quot;OR(&#x27;Org1MSP.admin&#x27;)&quot; Endorsement: Type: Signature Rule: &quot;OR(&#x27;Org1MSP.peer&#x27;)&quot; - &amp;Org2 # DefaultOrg defines the organization which is used in the sampleconfig # of the fabric.git development environment Name: Org2MSP # ID to load the MSP definition as ID: Org2MSP MSPDir: ../organizations/peerOrganizations/org2.example.com/msp # Policies defines the set of policies at this level of the config tree # For organization policies, their canonical path is usually # /Channel/&lt;Application|Orderer&gt;/&lt;OrgName&gt;/&lt;PolicyName&gt; Policies: Readers: Type: Signature Rule: &quot;OR(&#x27;Org2MSP.admin&#x27;, &#x27;Org2MSP.peer&#x27;, &#x27;Org2MSP.client&#x27;)&quot; Writers: Type: Signature Rule: &quot;OR(&#x27;Org2MSP.admin&#x27;, &#x27;Org2MSP.client&#x27;)&quot; Admins: Type: Signature Rule: &quot;OR(&#x27;Org2MSP.admin&#x27;)&quot; Endorsement: Type: Signature Rule: &quot;OR(&#x27;Org2MSP.peer&#x27;)&quot;################################################################################## SECTION: Capabilities## - This section defines the capabilities of fabric network. This is a new# concept as of v1.1.0 and should not be utilized in mixed networks with# v1.0.x peers and orderers. Capabilities define features which must be# present in a fabric binary for that binary to safely participate in the# fabric network. For instance, if a new MSP type is added, newer binaries# might recognize and validate the signatures from this type, while older# binaries without this support would be unable to validate those# transactions. This could lead to different versions of the fabric binaries# having different world states. Instead, defining a capability for a channel# informs those binaries without this capability that they must cease# processing transactions until they have been upgraded. For v1.0.x if any# capabilities are defined (including a map with all capabilities turned off)# then the v1.0.x peer will deliberately crash.#################################################################################Capabilities: # Channel capabilities apply to both the orderers and the peers and must be # supported by both. # Set the value of the capability to true to require it. Channel: &amp;ChannelCapabilities # V2_0 capability ensures that orderers and peers behave according # to v2.0 channel capabilities. Orderers and peers from # prior releases would behave in an incompatible way, and are therefore # not able to participate in channels at v2.0 capability. # Prior to enabling V2.0 channel capabilities, ensure that all # orderers and peers on a channel are at v2.0.0 or later. V2_0: true # Orderer capabilities apply only to the orderers, and may be safely # used with prior release peers. # Set the value of the capability to true to require it. Orderer: &amp;OrdererCapabilities # V2_0 orderer capability ensures that orderers behave according # to v2.0 orderer capabilities. Orderers from # prior releases would behave in an incompatible way, and are therefore # not able to participate in channels at v2.0 orderer capability. # Prior to enabling V2.0 orderer capabilities, ensure that all # orderers on channel are at v2.0.0 or later. V2_0: true # Application capabilities apply only to the peer network, and may be safely # used with prior release orderers. # Set the value of the capability to true to require it. Application: &amp;ApplicationCapabilities # V2_0 application capability ensures that peers behave according # to v2.0 application capabilities. Peers from # prior releases would behave in an incompatible way, and are therefore # not able to participate in channels at v2.0 application capability. # Prior to enabling V2.0 application capabilities, ensure that all # peers on channel are at v2.0.0 or later. V2_0: true################################################################################## SECTION: Application## - This section defines the values to encode into a config transaction or# genesis block for application related parameters#################################################################################Application: &amp;ApplicationDefaults # Organizations is the list of orgs which are defined as participants on # the application side of the network Organizations: # Policies defines the set of policies at this level of the config tree # For Application policies, their canonical path is # /Channel/Application/&lt;PolicyName&gt; Policies: Readers: Type: ImplicitMeta Rule: &quot;ANY Readers&quot; Writers: Type: ImplicitMeta Rule: &quot;ANY Writers&quot; Admins: Type: ImplicitMeta Rule: &quot;MAJORITY Admins&quot; LifecycleEndorsement: Type: ImplicitMeta Rule: &quot;MAJORITY Endorsement&quot; Endorsement: Type: ImplicitMeta Rule: &quot;MAJORITY Endorsement&quot; Capabilities: &lt;&lt;: *ApplicationCapabilities################################################################################## SECTION: Orderer## - This section defines the values to encode into a config transaction or# genesis block for orderer related parameters#################################################################################Orderer: &amp;OrdererDefaults # Orderer Type: The orderer implementation to start OrdererType: etcdraft # Addresses used to be the list of orderer addresses that clients and peers # could connect to. However, this does not allow clients to associate orderer # addresses and orderer organizations which can be useful for things such # as TLS validation. The preferred way to specify orderer addresses is now # to include the OrdererEndpoints item in your org definition Addresses: - orderer.example.com:7050 EtcdRaft: Consenters: - Host: orderer.example.com Port: 7050 ClientTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt ServerTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt # Batch Timeout: The amount of time to wait before creating a batch BatchTimeout: 2s # Batch Size: Controls the number of messages batched into a block BatchSize: # Max Message Count: The maximum number of messages to permit in a batch MaxMessageCount: 10 # Absolute Max Bytes: The absolute maximum number of bytes allowed for # the serialized messages in a batch. AbsoluteMaxBytes: 99 MB # Preferred Max Bytes: The preferred maximum number of bytes allowed for # the serialized messages in a batch. A message larger than the preferred # max bytes will result in a batch larger than preferred max bytes. PreferredMaxBytes: 512 KB # Organizations is the list of orgs which are defined as participants on # the orderer side of the network Organizations: # Policies defines the set of policies at this level of the config tree # For Orderer policies, their canonical path is # /Channel/Orderer/&lt;PolicyName&gt; Policies: Readers: Type: ImplicitMeta Rule: &quot;ANY Readers&quot; Writers: Type: ImplicitMeta Rule: &quot;ANY Writers&quot; Admins: Type: ImplicitMeta Rule: &quot;MAJORITY Admins&quot; # BlockValidation specifies what signatures must be included in the block # from the orderer for the peer to validate it. BlockValidation: Type: ImplicitMeta Rule: &quot;ANY Writers&quot;################################################################################## CHANNEL## This section defines the values to encode into a config transaction or# genesis block for channel related parameters.#################################################################################Channel: &amp;ChannelDefaults # Policies defines the set of policies at this level of the config tree # For Channel policies, their canonical path is # /Channel/&lt;PolicyName&gt; Policies: # Who may invoke the &#x27;Deliver&#x27; API Readers: Type: ImplicitMeta Rule: &quot;ANY Readers&quot; # Who may invoke the &#x27;Broadcast&#x27; API Writers: Type: ImplicitMeta Rule: &quot;ANY Writers&quot; # By default, who may modify elements at this config level Admins: Type: ImplicitMeta Rule: &quot;MAJORITY Admins&quot; # Capabilities describes the channel level capabilities, see the # dedicated Capabilities section elsewhere in this file for a full # description Capabilities: &lt;&lt;: *ChannelCapabilities################################################################################## Profile## - Different configuration profiles may be encoded here to be specified# as parameters to the configtxgen tool#################################################################################Profiles: TwoOrgsOrdererGenesis: &lt;&lt;: *ChannelDefaults Orderer: &lt;&lt;: *OrdererDefaults Organizations: - *OrdererOrg Capabilities: &lt;&lt;: *OrdererCapabilities Consortiums: SampleConsortium: Organizations: - *Org1 - *Org2 TwoOrgsChannel: Consortium: SampleConsortium &lt;&lt;: *ChannelDefaults Application: &lt;&lt;: *ApplicationDefaults Organizations: - *Org1 - *Org2 Capabilities: &lt;&lt;: *ApplicationCapabilities 初始区块的创建12cd /frist-network/configtx../../bin/configtxgen -profile TwoOrgsOrdererGenesis -outputBlock ../system-genesis-block/genesis.block 应用通道交易配置文件创建1../../bin/configtxgen -profile TwoOrgsChannel -outpotCreateChannelTx ../channel-artifacts/mychannel.tx 启动网络配置文件路径：frist-network/docker/docker-compose-test-net.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: &#x27;2&#x27;volumes: orderer.example.com: peer0.org1.example.com: peer0.org2.example.com:networks: test: name: fabric_testservices: orderer.example.com: container_name: orderer.example.com image: hyperledger/fabric-orderer:latest environment: - FABRIC_LOGGING_SPEC=INFO - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_LISTENPORT=7050 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP - ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp - ORDERER_OPERATIONS_LISTENADDRESS=0.0.0.0:17050 # enabled TLS - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] - ORDERER_KAFKA_TOPIC_REPLICATIONFACTOR=1 - ORDERER_KAFKA_VERBOSE=true - ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_CLUSTER_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] working_dir: /opt/gopath/src/github.com/hyperledger/fabric command: orderer volumes: - ../system-genesis-block/genesis.block:/var/hyperledger/orderer/orderer.genesis.block - ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp:/var/hyperledger/orderer/msp - ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/:/var/hyperledger/orderer/tls - orderer.example.com:/var/hyperledger/production/orderer ports: - 7050:7050 - 17050:17050 networks: - test peer0.org1.example.com: container_name: peer0.org1.example.com image: hyperledger/fabric-peer:latest environment: #Generic peer variables - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=fabric_test - FABRIC_LOGGING_SPEC=INFO #- FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt # Peer specific variabes - CORE_PEER_ID=peer0.org1.example.com - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LISTENADDRESS=0.0.0.0:7051 - CORE_PEER_CHAINCODEADDRESS=peer0.org1.example.com:7052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_OPERATIONS_LISTENADDRESS=0.0.0.0:17051 volumes: - /var/run/docker.sock:/host/var/run/docker.sock - ../organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/etc/hyperledger/fabric/msp - ../organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/etc/hyperledger/fabric/tls - peer0.org1.example.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 7051:7051 - 17051:17051 networks: - test peer0.org2.example.com: container_name: peer0.org2.example.com image: hyperledger/fabric-peer:latest environment: #Generic peer variables - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=fabric_test - FABRIC_LOGGING_SPEC=INFO #- FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt # Peer specific variabes - CORE_PEER_ID=peer0.org2.example.com - CORE_PEER_ADDRESS=peer0.org2.example.com:9051 - CORE_PEER_LISTENADDRESS=0.0.0.0:9051 - CORE_PEER_CHAINCODEADDRESS=peer0.org2.example.com:9052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:9052 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org2.example.com:9051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org2.example.com:9051 - CORE_PEER_LOCALMSPID=Org2MSP - CORE_OPERATIONS_LISTENADDRESS=0.0.0.0:19051 volumes: - /var/run/docker.sock:/host/var/run/docker.sock - ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/msp:/etc/hyperledger/fabric/msp - ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls:/etc/hyperledger/fabric/tls - peer0.org2.example.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 9051:9051 - 19051:19051 networks: - test cli: container_name: cli image: hyperledger/fabric-tools:latest tty: true stdin_open: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=INFO #- FABRIC_LOGGING_SPEC=DEBUG working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: /bin/bash volumes: - /var/run/:/host/var/run/ - ../organizations:/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations - ../scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/ depends_on: - peer0.org1.example.com - peer0.org2.example.com networks: - test 启动1docker-compose -f docker-compose-test-net.yaml up -d 创建通道进入CLI容器1docker exec -it cli bash 创建1peer channel create -o orderer.example.com:7075 -c mychannel -f ./channel-artifacts/mychannel.tx --tls --cafile ./organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 节点加入通道1peer channel join -b mychannel.block","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric进阶","slug":"Hyperledger-Fabric进阶","permalink":"http://peapod.top/tags/Hyperledger-Fabric%E8%BF%9B%E9%98%B6/"}],"author":"taweizhong"},{"title":"Hyperledger-Fabric 核心配置文件","slug":"Hyperledger-Fabric-核心配置文件","date":"2022-10-15T06:21:21.000Z","updated":"2022-10-15T07:01:04.000Z","comments":true,"path":"2022/10/15/Hyperledger-Fabric-核心配置文件/","link":"","permalink":"http://peapod.top/2022/10/15/Hyperledger-Fabric-%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","excerpt":"","text":"核心配置文件core.yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0################################################################################## Peer section# 节点部分###############################################################################peer: # The peer id provides a name for this peer instance and is used when # naming docker resources. # 指定节点ID id: jdoe # The networkId allows for logical separation of networks and is used when # naming docker resources. # 指定网络ID networkId: dev # The Address at local network interface this Peer will listen on. # By default, it will listen on all network interfaces listenAddress: 0.0.0.0:7051 # The endpoint this peer uses to listen for inbound chaincode connections. # If this is commented-out, the listen address is selected to be # the peer&#x27;s address (see below) with port 7052 # chaincodeListenAddress: 0.0.0.0:7052 # The endpoint the chaincode for this peer uses to connect to the peer. # If this is not specified, the chaincodeListenAddress address is selected. # And if chaincodeListenAddress is not specified, address is selected from # peer address (see below). If specified peer address is invalid then it # will fallback to the auto detected IP (local IP) regardless of the peer # addressAutoDetect value. # chaincodeAddress: 0.0.0.0:7052 # When used as peer config, this represents the endpoint to other peers # in the same organization. For peers in other organization, see # gossip.externalEndpoint for more info. # When used as CLI config, this means the peer&#x27;s endpoint to interact with address: 0.0.0.0:7051 # Whether the Peer should programmatically determine its address # This case is useful for docker containers. # When set to true, will override peer address. addressAutoDetect: false # Keepalive settings for peer server and clients keepalive: # Interval is the duration after which if the server does not see # any activity from the client it pings the client to see if it&#x27;s alive interval: 7200s # Timeout is the duration the server waits for a response # from the client after sending a ping before closing the connection timeout: 20s # MinInterval is the minimum permitted time between client pings. # If clients send pings more frequently, the peer server will # disconnect them minInterval: 60s # Client keepalive settings for communicating with other peer nodes client: # Interval is the time between pings to peer nodes. This must # greater than or equal to the minInterval specified by peer # nodes interval: 60s # Timeout is the duration the client waits for a response from # peer nodes before closing the connection timeout: 20s # DeliveryClient keepalive settings for communication with ordering # nodes. deliveryClient: # Interval is the time between pings to ordering nodes. This must # greater than or equal to the minInterval specified by ordering # nodes. interval: 60s # Timeout is the duration the client waits for a response from # ordering nodes before closing the connection timeout: 20s # Gossip related configuration gossip: # Bootstrap set to initialize gossip with. # This is a list of other peers that this peer reaches out to at startup. # Important: The endpoints here have to be endpoints of peers in the same # organization, because the peer would refuse connecting to these endpoints # unless they are in the same organization as the peer. bootstrap: 127.0.0.1:7051 # NOTE: orgLeader and useLeaderElection parameters are mutual exclusive. # Setting both to true would result in the termination of the peer # since this is undefined state. If the peers are configured with # useLeaderElection=false, make sure there is at least 1 peer in the # organization that its orgLeader is set to true. # Defines whenever peer will initialize dynamic algorithm for # &quot;leader&quot; selection, where leader is the peer to establish # connection with ordering service and use delivery protocol # to pull ledger blocks from ordering service. useLeaderElection: false # Statically defines peer to be an organization &quot;leader&quot;, # where this means that current peer will maintain connection # with ordering service and disseminate block across peers in # its own organization. Multiple peers or all peers in an organization # may be configured as org leaders, so that they all pull # blocks directly from ordering service. orgLeader: true # Interval for membershipTracker polling membershipTrackerInterval: 5s # Overrides the endpoint that the peer publishes to peers # in its organization. For peers in foreign organizations # see &#x27;externalEndpoint&#x27; endpoint: # Maximum count of blocks stored in memory maxBlockCountToStore: 10 # Max time between consecutive message pushes(unit: millisecond) maxPropagationBurstLatency: 10ms # Max number of messages stored until a push is triggered to remote peers maxPropagationBurstSize: 10 # Number of times a message is pushed to remote peers propagateIterations: 1 # Number of peers selected to push messages to propagatePeerNum: 3 # Determines frequency of pull phases(unit: second) # Must be greater than digestWaitTime + responseWaitTime pullInterval: 4s # Number of peers to pull from pullPeerNum: 3 # Determines frequency of pulling state info messages from peers(unit: second) requestStateInfoInterval: 4s # Determines frequency of pushing state info messages to peers(unit: second) publishStateInfoInterval: 4s # Maximum time a stateInfo message is kept until expired stateInfoRetentionInterval: # Time from startup certificates are included in Alive messages(unit: second) publishCertPeriod: 10s # Should we skip verifying block messages or not (currently not in use) skipBlockVerification: false # Dial timeout(unit: second) dialTimeout: 3s # Connection timeout(unit: second) connTimeout: 2s # Buffer size of received messages recvBuffSize: 20 # Buffer size of sending messages sendBuffSize: 200 # Time to wait before pull engine processes incoming digests (unit: second) # Should be slightly smaller than requestWaitTime digestWaitTime: 1s # Time to wait before pull engine removes incoming nonce (unit: milliseconds) # Should be slightly bigger than digestWaitTime requestWaitTime: 1500ms # Time to wait before pull engine ends pull (unit: second) responseWaitTime: 2s # Alive check interval(unit: second) aliveTimeInterval: 5s # Alive expiration timeout(unit: second) aliveExpirationTimeout: 25s # Reconnect interval(unit: second) reconnectInterval: 25s # Max number of attempts to connect to a peer maxConnectionAttempts: 120 # Message expiration factor for alive messages msgExpirationFactor: 20 # This is an endpoint that is published to peers outside of the organization. # If this isn&#x27;t set, the peer will not be known to other organizations. externalEndpoint: # Leader election service configuration election: # Longest time peer waits for stable membership during leader election startup (unit: second) startupGracePeriod: 15s # Interval gossip membership samples to check its stability (unit: second) membershipSampleInterval: 1s # Time passes since last declaration message before peer decides to perform leader election (unit: second) leaderAliveThreshold: 10s # Time between peer sends propose message and declares itself as a leader (sends declaration message) (unit: second) leaderElectionDuration: 5s pvtData: # pullRetryThreshold determines the maximum duration of time private data corresponding for a given block # would be attempted to be pulled from peers until the block would be committed without the private data pullRetryThreshold: 60s # As private data enters the transient store, it is associated with the peer&#x27;s ledger&#x27;s height at that time. # transientstoreMaxBlockRetention defines the maximum difference between the current ledger&#x27;s height upon commit, # and the private data residing inside the transient store that is guaranteed not to be purged. # Private data is purged from the transient store when blocks with sequences that are multiples # of transientstoreMaxBlockRetention are committed. transientstoreMaxBlockRetention: 1000 # pushAckTimeout is the maximum time to wait for an acknowledgement from each peer # at private data push at endorsement time. pushAckTimeout: 3s # Block to live pulling margin, used as a buffer # to prevent peer from trying to pull private data # from peers that is soon to be purged in next N blocks. # This helps a newly joined peer catch up to current # blockchain height quicker. btlPullMargin: 10 # the process of reconciliation is done in an endless loop, while in each iteration reconciler tries to # pull from the other peers the most recent missing blocks with a maximum batch size limitation. # reconcileBatchSize determines the maximum batch size of missing private data that will be reconciled in a # single iteration. reconcileBatchSize: 10 # reconcileSleepInterval determines the time reconciler sleeps from end of an iteration until the beginning # of the next reconciliation iteration. reconcileSleepInterval: 1m # reconciliationEnabled is a flag that indicates whether private data reconciliation is enable or not. reconciliationEnabled: true # skipPullingInvalidTransactionsDuringCommit is a flag that indicates whether pulling of invalid # transaction&#x27;s private data from other peers need to be skipped during the commit time and pulled # only through reconciler. skipPullingInvalidTransactionsDuringCommit: false # implicitCollectionDisseminationPolicy specifies the dissemination policy for the peer&#x27;s own implicit collection. # When a peer endorses a proposal that writes to its own implicit collection, below values override the default values # for disseminating private data. # Note that it is applicable to all channels the peer has joined. The implication is that requiredPeerCount has to # be smaller than the number of peers in a channel that has the lowest numbers of peers from the organization. implicitCollectionDisseminationPolicy: # requiredPeerCount defines the minimum number of eligible peers to which the peer must successfully # disseminate private data for its own implicit collection during endorsement. Default value is 0. requiredPeerCount: 0 # maxPeerCount defines the maximum number of eligible peers to which the peer will attempt to # disseminate private data for its own implicit collection during endorsement. Default value is 1. maxPeerCount: 1 # Gossip state transfer related configuration state: # indicates whenever state transfer is enabled or not # default value is true, i.e. state transfer is active # and takes care to sync up missing blocks allowing # lagging peer to catch up to speed with rest network enabled: false # checkInterval interval to check whether peer is lagging behind enough to # request blocks via state transfer from another peer. checkInterval: 10s # responseTimeout amount of time to wait for state transfer response from # other peers responseTimeout: 3s # batchSize the number of blocks to request via state transfer from another peer batchSize: 10 # blockBufferSize reflects the size of the re-ordering buffer # which captures blocks and takes care to deliver them in order # down to the ledger layer. The actual buffer size is bounded between # 0 and 2*blockBufferSize, each channel maintains its own buffer blockBufferSize: 20 # maxRetries maximum number of re-tries to ask # for single state transfer request maxRetries: 3 # TLS Settings tls: # Require server-side TLS enabled: false # Require client certificates / mutual TLS. # Note that clients that are not configured to use a certificate will # fail to connect to the peer. clientAuthRequired: false # X.509 certificate used for TLS server cert: file: tls/server.crt # Private key used for TLS server (and client if clientAuthEnabled # is set to true key: file: tls/server.key # Trusted root certificate chain for tls.cert rootcert: file: tls/ca.crt # Set of root certificate authorities used to verify client certificates clientRootCAs: files: - tls/ca.crt # Private key used for TLS when making client connections. If # not set, peer.tls.key.file will be used instead clientKey: file: # X.509 certificate used for TLS when making client connections. # If not set, peer.tls.cert.file will be used instead clientCert: file: # Authentication contains configuration parameters related to authenticating # client messages authentication: # the acceptable difference between the current server time and the # client&#x27;s time as specified in a client request message timewindow: 15m # Path on the file system where peer will store data (eg ledger). This # location must be access control protected to prevent unintended # modification that might corrupt the peer operations. fileSystemPath: /var/hyperledger/production # BCCSP (Blockchain crypto provider): Select which crypto implementation or # library to use BCCSP: Default: SW # Settings for the SW crypto provider (i.e. when DEFAULT: SW) SW: # TODO: The default Hash and Security level needs refactoring to be # fully configurable. Changing these defaults requires coordination # SHA2 is hardcoded in several places, not only BCCSP Hash: SHA2 Security: 256 # Location of Key Store FileKeyStore: # If &quot;&quot;, defaults to &#x27;mspConfigPath&#x27;/keystore KeyStore: # Settings for the PKCS#11 crypto provider (i.e. when DEFAULT: PKCS11) PKCS11: # Location of the PKCS11 module library Library: # Token Label Label: # User PIN Pin: Hash: Security: # Path on the file system where peer will find MSP local configurations mspConfigPath: msp # Identifier of the local MSP # ----!!!!IMPORTANT!!!-!!!IMPORTANT!!!-!!!IMPORTANT!!!!---- # Deployers need to change the value of the localMspId string. # In particular, the name of the local MSP ID of a peer needs # to match the name of one of the MSPs in each of the channel # that this peer is a member of. Otherwise this peer&#x27;s messages # will not be identified as valid by other nodes. localMspId: SampleOrg # CLI common client config options client: # connection timeout connTimeout: 3s # Delivery service related config deliveryclient: # It sets the total time the delivery service may spend in reconnection # attempts until its retry logic gives up and returns an error reconnectTotalTimeThreshold: 3600s # It sets the delivery service &lt;-&gt; ordering service node connection timeout connTimeout: 3s # It sets the delivery service maximal delay between consecutive retries reConnectBackoffThreshold: 3600s # A list of orderer endpoint addresses which should be overridden # when found in channel configurations. addressOverrides: # - from: # to: # caCertsFile: # - from: # to: # caCertsFile: # Type for the local MSP - by default it&#x27;s of type bccsp localMspType: bccsp # Used with Go profiling tools only in none production environment. In # production, it should be disabled (eg enabled: false) profile: enabled: false listenAddress: 0.0.0.0:6060 # Handlers defines custom handlers that can filter and mutate # objects passing within the peer, such as: # Auth filter - reject or forward proposals from clients # Decorators - append or mutate the chaincode input passed to the chaincode # Endorsers - Custom signing over proposal response payload and its mutation # Valid handler definition contains: # - A name which is a factory method name defined in # core/handlers/library/library.go for statically compiled handlers # - library path to shared object binary for pluggable filters # Auth filters and decorators are chained and executed in the order that # they are defined. For example: # authFilters: # - # name: FilterOne # library: /opt/lib/filter.so # - # name: FilterTwo # decorators: # - # name: DecoratorOne # - # name: DecoratorTwo # library: /opt/lib/decorator.so # Endorsers are configured as a map that its keys are the endorsement system chaincodes that are being overridden. # Below is an example that overrides the default ESCC and uses an endorsement plugin that has the same functionality # as the default ESCC. # If the &#x27;library&#x27; property is missing, the name is used as the constructor method in the builtin library similar # to auth filters and decorators. # endorsers: # escc: # name: DefaultESCC # library: /etc/hyperledger/fabric/plugin/escc.so handlers: authFilters: - name: DefaultAuth - name: ExpirationCheck # This filter checks identity x509 certificate expiration decorators: - name: DefaultDecorator endorsers: escc: name: DefaultEndorsement library: validators: vscc: name: DefaultValidation library: # library: /etc/hyperledger/fabric/plugin/escc.so # Number of goroutines that will execute transaction validation in parallel. # By default, the peer chooses the number of CPUs on the machine. Set this # variable to override that choice. # NOTE: overriding this value might negatively influence the performance of # the peer so please change this value only if you know what you&#x27;re doing validatorPoolSize: # The discovery service is used by clients to query information about peers, # such as - which peers have joined a certain channel, what is the latest # channel config, and most importantly - given a chaincode and a channel, # what possible sets of peers satisfy the endorsement policy. discovery: enabled: true # Whether the authentication cache is enabled or not. authCacheEnabled: true # The maximum size of the cache, after which a purge takes place authCacheMaxSize: 1000 # The proportion (0 to 1) of entries that remain in the cache after the cache is purged due to overpopulation authCachePurgeRetentionRatio: 0.75 # Whether to allow non-admins to perform non channel scoped queries. # When this is false, it means that only peer admins can perform non channel scoped queries. orgMembersAllowedAccess: false # Limits is used to configure some internal resource limits. limits: # Concurrency limits the number of concurrently running requests to a service on each peer. # Currently this option is only applied to endorser service and deliver service. # When the property is missing or the value is 0, the concurrency limit is disabled for the service. concurrency: # endorserService limits concurrent requests to endorser service that handles chaincode deployment, query and invocation, # including both user chaincodes and system chaincodes. endorserService: 2500 # deliverService limits concurrent event listeners registered to deliver service for blocks and transaction events. deliverService: 2500################################################################################# VM section################################################################################vm: # Endpoint of the vm management system. For docker can be one of the following in general # unix:///var/run/docker.sock # http://localhost:2375 # https://localhost:2376 endpoint: unix:///var/run/docker.sock # settings for docker vms docker: tls: enabled: false ca: file: docker/ca.crt cert: file: docker/tls.crt key: file: docker/tls.key # Enables/disables the standard out/err from chaincode containers for # debugging purposes attachStdout: false # Parameters on creating docker container. # Container may be efficiently created using ipam &amp; dns-server for cluster # NetworkMode - sets the networking mode for the container. Supported # standard values are: `host`(default),`bridge`,`ipvlan`,`none`. # Dns - a list of DNS servers for the container to use. # Note: `Privileged` `Binds` `Links` and `PortBindings` properties of # Docker Host Config are not supported and will not be used if set. # LogConfig - sets the logging driver (Type) and related options # (Config) for Docker. For more info, # https://docs.docker.com/engine/admin/logging/overview/ # Note: Set LogConfig using Environment Variables is not supported. hostConfig: NetworkMode: host Dns: # - 192.168.0.1 LogConfig: Type: json-file Config: max-size: &quot;50m&quot; max-file: &quot;5&quot; Memory: 2147483648################################################################################# Chaincode section################################################################################chaincode: # The id is used by the Chaincode stub to register the executing Chaincode # ID with the Peer and is generally supplied through ENV variables # the `path` form of ID is provided when installing the chaincode. # The `name` is used for all other requests and can be any string. id: path: name: # Generic builder environment, suitable for most chaincode types builder: $(DOCKER_NS)/fabric-ccenv:$(TWO_DIGIT_VERSION) # Enables/disables force pulling of the base docker images (listed below) # during user chaincode instantiation. # Useful when using moving image tags (such as :latest) pull: false golang: # golang will never need more than baseos runtime: $(DOCKER_NS)/fabric-baseos:$(TWO_DIGIT_VERSION) # whether or not golang chaincode should be linked dynamically dynamicLink: false java: # This is an image based on java:openjdk-8 with addition compiler # tools added for java shim layer packaging. # This image is packed with shim layer libraries that are necessary # for Java chaincode runtime. runtime: $(DOCKER_NS)/fabric-javaenv:$(TWO_DIGIT_VERSION) node: # This is an image based on node:$(NODE_VER)-alpine runtime: $(DOCKER_NS)/fabric-nodeenv:$(TWO_DIGIT_VERSION) # List of directories to treat as external builders and launchers for # chaincode. The external builder detection processing will iterate over the # builders in the order specified below. externalBuilders: [] # - path: /path/to/directory # name: descriptive-builder-name # propagateEnvironment: # - ENVVAR_NAME_TO_PROPAGATE_FROM_PEER # - GOPROXY # The maximum duration to wait for the chaincode build and install process # to complete. installTimeout: 300s # Timeout duration for starting up a container and waiting for Register # to come through. startuptimeout: 300s # Timeout duration for Invoke and Init calls to prevent runaway. # This timeout is used by all chaincodes in all the channels, including # system chaincodes. # Note that during Invoke, if the image is not available (e.g. being # cleaned up when in development environment), the peer will automatically # build the image, which might take more time. In production environment, # the chaincode image is unlikely to be deleted, so the timeout could be # reduced accordingly. executetimeout: 30s # There are 2 modes: &quot;dev&quot; and &quot;net&quot;. # In dev mode, user runs the chaincode after starting peer from # command line on local machine. # In net mode, peer will run chaincode in a docker container. mode: net # keepalive in seconds. In situations where the communication goes through a # proxy that does not support keep-alive, this parameter will maintain connection # between peer and chaincode. # A value &lt;= 0 turns keepalive off keepalive: 0 # enabled system chaincodes system: _lifecycle: enable cscc: enable lscc: enable escc: enable vscc: enable qscc: enable # Logging section for the chaincode container logging: # Default level for all loggers within the chaincode container level: info # Override default level for the &#x27;shim&#x27; logger shim: warning # Format for the chaincode container logs format: &#x27;%&#123;color&#125;%&#123;time:2006-01-02 15:04:05.000 MST&#125; [%&#123;module&#125;] %&#123;shortfunc&#125; -&gt; %&#123;level:.4s&#125; %&#123;id:03x&#125;%&#123;color:reset&#125; %&#123;message&#125;&#x27;################################################################################# Ledger section - ledger configuration encompasses both the blockchain# and the state################################################################################ledger: blockchain: state: # stateDatabase - options are &quot;goleveldb&quot;, &quot;CouchDB&quot; # goleveldb - default state database stored in goleveldb. # CouchDB - store state database in CouchDB stateDatabase: goleveldb # Limit on the number of records to return per query totalQueryLimit: 100000 couchDBConfig: # It is recommended to run CouchDB on the same server as the peer, and # not map the CouchDB container port to a server port in docker-compose. # Otherwise proper security must be provided on the connection between # CouchDB client (on the peer) and server. couchDBAddress: 127.0.0.1:5984 # This username must have read and write authority on CouchDB username: # The password is recommended to pass as an environment variable # during start up (eg CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD). # If it is stored here, the file must be access control protected # to prevent unintended users from discovering the password. password: # Number of retries for CouchDB errors maxRetries: 3 # Number of retries for CouchDB errors during peer startup. # The delay between retries doubles for each attempt. # Default of 10 retries results in 11 attempts over 2 minutes. maxRetriesOnStartup: 10 # CouchDB request timeout (unit: duration, e.g. 20s) requestTimeout: 35s # Limit on the number of records per each CouchDB query # Note that chaincode queries are only bound by totalQueryLimit. # Internally the chaincode may execute multiple CouchDB queries, # each of size internalQueryLimit. internalQueryLimit: 1000 # Limit on the number of records per CouchDB bulk update batch maxBatchUpdateSize: 1000 # Warm indexes after every N blocks. # This option warms any indexes that have been # deployed to CouchDB after every N blocks. # A value of 1 will warm indexes after every block commit, # to ensure fast selector queries. # Increasing the value may improve write efficiency of peer and CouchDB, # but may degrade query response time. warmIndexesAfterNBlocks: 1 # Create the _global_changes system database # This is optional. Creating the global changes database will require # additional system resources to track changes and maintain the database createGlobalChangesDB: false # CacheSize denotes the maximum mega bytes (MB) to be allocated for the in-memory state # cache. Note that CacheSize needs to be a multiple of 32 MB. If it is not a multiple # of 32 MB, the peer would round the size to the next multiple of 32 MB. # To disable the cache, 0 MB needs to be assigned to the cacheSize. cacheSize: 64 history: # enableHistoryDatabase - options are true or false # Indicates if the history of key updates should be stored. # All history &#x27;index&#x27; will be stored in goleveldb, regardless if using # CouchDB or alternate database for the state. enableHistoryDatabase: true pvtdataStore: # the maximum db batch size for converting # the ineligible missing data entries to eligible missing data entries collElgProcMaxDbBatchSize: 5000 # the minimum duration (in milliseconds) between writing # two consecutive db batches for converting the ineligible missing data entries to eligible missing data entries collElgProcDbBatchesInterval: 1000################################################################################# Operations section################################################################################operations: # host and port for the operations server listenAddress: 127.0.0.1:9443 # TLS configuration for the operations endpoint tls: # TLS enabled enabled: false # path to PEM encoded server certificate for the operations server cert: file: # path to PEM encoded server key for the operations server key: file: # most operations service endpoints require client authentication when TLS # is enabled. clientAuthRequired requires client certificate authentication # at the TLS layer to access all resources. clientAuthRequired: false # paths to PEM encoded ca certificates to trust for client authentication clientRootCAs: files: []################################################################################# Metrics section################################################################################metrics: # metrics provider is one of statsd, prometheus, or disabled provider: disabled # statsd configuration statsd: # network type: tcp or udp network: udp # statsd server address address: 127.0.0.1:8125 # the interval at which locally cached counters and gauges are pushed # to statsd; timings are pushed immediately writeInterval: 10s # prefix is prepended to all emitted statsd metrics prefix: orderer.yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#---################################################################################## Orderer Configuration## - This controls the type and configuration of the orderer.#################################################################################General: # Listen address: The IP on which to bind to listen. ListenAddress: 127.0.0.1 # Listen port: The port on which to bind to listen. ListenPort: 7050 # TLS: TLS settings for the GRPC server. TLS: Enabled: false # PrivateKey governs the file location of the private key of the TLS certificate. PrivateKey: tls/server.key # Certificate governs the file location of the server TLS certificate. Certificate: tls/server.crt RootCAs: - tls/ca.crt ClientAuthRequired: false ClientRootCAs: # Keepalive settings for the GRPC server. Keepalive: # ServerMinInterval is the minimum permitted time between client pings. # If clients send pings more frequently, the server will # disconnect them. ServerMinInterval: 60s # ServerInterval is the time between pings to clients. ServerInterval: 7200s # ServerTimeout is the duration the server waits for a response from # a client before closing the connection. ServerTimeout: 20s # Cluster settings for ordering service nodes that communicate with other ordering service nodes # such as Raft based ordering service. Cluster: # SendBufferSize is the maximum number of messages in the egress buffer. # Consensus messages are dropped if the buffer is full, and transaction # messages are waiting for space to be freed. SendBufferSize: 10 # ClientCertificate governs the file location of the client TLS certificate # used to establish mutual TLS connections with other ordering service nodes. ClientCertificate: # ClientPrivateKey governs the file location of the private key of the client TLS certificate. ClientPrivateKey: # The below 4 properties should be either set together, or be unset together. # If they are set, then the orderer node uses a separate listener for intra-cluster # communication. If they are unset, then the general orderer listener is used. # This is useful if you want to use a different TLS server certificates on the # client-facing and the intra-cluster listeners. # ListenPort defines the port on which the cluster listens to connections. ListenPort: # ListenAddress defines the IP on which to listen to intra-cluster communication. ListenAddress: # ServerCertificate defines the file location of the server TLS certificate used for intra-cluster # communication. ServerCertificate: # ServerPrivateKey defines the file location of the private key of the TLS certificate. ServerPrivateKey: # Bootstrap method: The method by which to obtain the bootstrap block # system channel is specified. The option can be one of: # &quot;file&quot; - path to a file containing the genesis block or config block of system channel # &quot;none&quot; - allows an orderer to start without a system channel configuration BootstrapMethod: file # Bootstrap file: The file containing the bootstrap block to use when # initializing the orderer system channel and BootstrapMethod is set to # &quot;file&quot;. The bootstrap file can be the genesis block, and it can also be # a config block for late bootstrap of some consensus methods like Raft. # Generate a genesis block by updating $FABRIC_CFG_PATH/configtx.yaml and # using configtxgen command with &quot;-outputBlock&quot; option. # Defaults to file &quot;genesisblock&quot; (in $FABRIC_CFG_PATH directory) if not specified. BootstrapFile: # LocalMSPDir is where to find the private crypto material needed by the # orderer. It is set relative here as a default for dev environments but # should be changed to the real location in production. LocalMSPDir: msp # LocalMSPID is the identity to register the local MSP material with the MSP # manager. IMPORTANT: The local MSP ID of an orderer needs to match the MSP # ID of one of the organizations defined in the orderer system channel&#x27;s # /Channel/Orderer configuration. The sample organization defined in the # sample configuration provided has an MSP ID of &quot;SampleOrg&quot;. LocalMSPID: SampleOrg # Enable an HTTP service for Go &quot;pprof&quot; profiling as documented at: # https://golang.org/pkg/net/http/pprof Profile: Enabled: false Address: 0.0.0.0:6060 # BCCSP configures the blockchain crypto service providers. BCCSP: # Default specifies the preferred blockchain crypto service provider # to use. If the preferred provider is not available, the software # based provider (&quot;SW&quot;) will be used. # Valid providers are: # - SW: a software based crypto provider # - PKCS11: a CA hardware security module crypto provider. Default: SW # SW configures the software based blockchain crypto provider. SW: # TODO: The default Hash and Security level needs refactoring to be # fully configurable. Changing these defaults requires coordination # SHA2 is hardcoded in several places, not only BCCSP Hash: SHA2 Security: 256 # Location of key store. If this is unset, a location will be # chosen using: &#x27;LocalMSPDir&#x27;/keystore FileKeyStore: KeyStore: # Settings for the PKCS#11 crypto provider (i.e. when DEFAULT: PKCS11) PKCS11: # Location of the PKCS11 module library Library: # Token Label Label: # User PIN Pin: Hash: Security: FileKeyStore: KeyStore: # Authentication contains configuration parameters related to authenticating # client messages Authentication: # the acceptable difference between the current server time and the # client&#x27;s time as specified in a client request message TimeWindow: 15m################################################################################## SECTION: File Ledger## - This section applies to the configuration of the file or json ledgers.#################################################################################FileLedger: # Location: The directory to store the blocks in. # NOTE: If this is unset, a new temporary location will be chosen every time # the orderer is restarted, using the prefix specified by Prefix. Location: /var/hyperledger/production/orderer # The prefix to use when generating a ledger directory in temporary space. # Otherwise, this value is ignored. Prefix: hyperledger-fabric-ordererledger################################################################################## SECTION: Kafka## - This section applies to the configuration of the Kafka-based orderer, and# its interaction with the Kafka cluster.#################################################################################Kafka: # Retry: What do if a connection to the Kafka cluster cannot be established, # or if a metadata request to the Kafka cluster needs to be repeated. Retry: # When a new channel is created, or when an existing channel is reloaded # (in case of a just-restarted orderer), the orderer interacts with the # Kafka cluster in the following ways: # 1. It creates a Kafka producer (writer) for the Kafka partition that # corresponds to the channel. # 2. It uses that producer to post a no-op CONNECT message to that # partition # 3. It creates a Kafka consumer (reader) for that partition. # If any of these steps fail, they will be re-attempted every # &lt;ShortInterval&gt; for a total of &lt;ShortTotal&gt;, and then every # &lt;LongInterval&gt; for a total of &lt;LongTotal&gt; until they succeed. # Note that the orderer will be unable to write to or read from a # channel until all of the steps above have been completed successfully. ShortInterval: 5s ShortTotal: 10m LongInterval: 5m LongTotal: 12h # Affects the socket timeouts when waiting for an initial connection, a # response, or a transmission. See Config.Net for more info: # https://godoc.org/github.com/Shopify/sarama#Config NetworkTimeouts: DialTimeout: 10s ReadTimeout: 10s WriteTimeout: 10s # Affects the metadata requests when the Kafka cluster is in the middle # of a leader election.See Config.Metadata for more info: # https://godoc.org/github.com/Shopify/sarama#Config Metadata: RetryBackoff: 250ms RetryMax: 3 # What to do if posting a message to the Kafka cluster fails. See # Config.Producer for more info: # https://godoc.org/github.com/Shopify/sarama#Config Producer: RetryBackoff: 100ms RetryMax: 3 # What to do if reading from the Kafka cluster fails. See # Config.Consumer for more info: # https://godoc.org/github.com/Shopify/sarama#Config Consumer: RetryBackoff: 2s # Settings to use when creating Kafka topics. Only applies when # Kafka.Version is v0.10.1.0 or higher Topic: # The number of Kafka brokers across which to replicate the topic ReplicationFactor: 3 # Verbose: Enable logging for interactions with the Kafka cluster. Verbose: false # TLS: TLS settings for the orderer&#x27;s connection to the Kafka cluster. TLS: # Enabled: Use TLS when connecting to the Kafka cluster. Enabled: false # PrivateKey: PEM-encoded private key the orderer will use for # authentication. PrivateKey: # As an alternative to specifying the PrivateKey here, uncomment the # following &quot;File&quot; key and specify the file name from which to load the # value of PrivateKey. #File: path/to/PrivateKey # Certificate: PEM-encoded signed public key certificate the orderer will # use for authentication. Certificate: # As an alternative to specifying the Certificate here, uncomment the # following &quot;File&quot; key and specify the file name from which to load the # value of Certificate. #File: path/to/Certificate # RootCAs: PEM-encoded trusted root certificates used to validate # certificates from the Kafka cluster. RootCAs: # As an alternative to specifying the RootCAs here, uncomment the # following &quot;File&quot; key and specify the file name from which to load the # value of RootCAs. #File: path/to/RootCAs # SASLPlain: Settings for using SASL/PLAIN authentication with Kafka brokers SASLPlain: # Enabled: Use SASL/PLAIN to authenticate with Kafka brokers Enabled: false # User: Required when Enabled is set to true User: # Password: Required when Enabled is set to true Password: # Kafka protocol version used to communicate with the Kafka cluster brokers # (defaults to 0.10.2.0 if not specified) Version:################################################################################## Debug Configuration## - This controls the debugging options for the orderer#################################################################################Debug: # BroadcastTraceDir when set will cause each request to the Broadcast service # for this orderer to be written to a file in this directory BroadcastTraceDir: # DeliverTraceDir when set will cause each request to the Deliver service # for this orderer to be written to a file in this directory DeliverTraceDir:################################################################################## Operations Configuration## - This configures the operations server endpoint for the orderer#################################################################################Operations: # host and port for the operations server ListenAddress: 127.0.0.1:8443 # TLS configuration for the operations endpoint TLS: # TLS enabled Enabled: false # Certificate is the location of the PEM encoded TLS certificate Certificate: # PrivateKey points to the location of the PEM-encoded key PrivateKey: # Most operations service endpoints require client authentication when TLS # is enabled. ClientAuthRequired requires client certificate authentication # at the TLS layer to access all resources. ClientAuthRequired: false # Paths to PEM encoded ca certificates to trust for client authentication ClientRootCAs: []################################################################################## Metrics Configuration## - This configures metrics collection for the orderer#################################################################################Metrics: # The metrics provider is one of statsd, prometheus, or disabled Provider: disabled # The statsd configuration Statsd: # network type: tcp or udp Network: udp # the statsd server address Address: 127.0.0.1:8125 # The interval at which locally cached counters and gauges are pushed # to statsd; timings are pushed immediately WriteInterval: 30s # The prefix is prepended to all emitted statsd metrics Prefix:################################################################################## Consensus Configuration## - This section contains config options for a consensus plugin. It is opaque# to orderer, and completely up to consensus implementation to make use of.#################################################################################Consensus: # The allowed key-value pairs here depend on consensus plugin. For etcd/raft, # we use following options: # WALDir specifies the location at which Write Ahead Logs for etcd/raft are # stored. Each channel will have its own subdir named after channel ID. WALDir: /var/hyperledger/production/orderer/etcdraft/wal # SnapDir specifies the location at which snapshots for etcd/raft are # stored. Each channel will have its own subdir named after channel ID. SnapDir: /var/hyperledger/production/orderer/etcdraft/snapshot","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric进阶","slug":"Hyperledger-Fabric进阶","permalink":"http://peapod.top/tags/Hyperledger-Fabric%E8%BF%9B%E9%98%B6/"}],"author":"taweizhong"},{"title":"锁和 sync 包","slug":"锁和-sync-包","date":"2022-10-04T06:57:58.000Z","updated":"2024-02-27T10:47:04.000Z","comments":true,"path":"2022/10/04/锁和-sync-包/","link":"","permalink":"http://peapod.top/2022/10/04/%E9%94%81%E5%92%8C-sync-%E5%8C%85/","excerpt":"","text":"锁和 sync 包map 类型是不存在锁的机制来实现这种效果(出于对性能的考虑)，所以 map 类型是非线程安全的。当并行访问一个共享的 map 类型的数据，map 数据将会出错。 一次只能让一个线程对共享变量进行操作。当变量被一个线程改变时(临界区)，我们为它上锁，直到这个线程执行完成并解锁后，其他线程才能访问它。 sync.Mutex 是一个互斥锁，它的作用是守护在临界区入口来确保同一时间只能有一个线程进入临界区。 1234567891011121314import &quot;sync&quot;type Info struct &#123; mu sync.Mutex // ... other fields, e.g.: Str string&#125;func Update(info *Info) &#123; info.mu.Lock() // critical section: info.Str = // new value // end critical section info.mu.Unlock()&#125; Mutex 来实现一个可以上锁的共享缓冲器: 1234type SyncedBuffer struct &#123; lock sync.Mutex buffer bytes.Buffer&#125; 在 sync 包中还有一个 RWMutex 锁：他能通过 RLock() 来允许同一时间多个线程对变量进行读操作，但是只能一个线程进行写操作。 包中还有一个方便的 Once 类型变量的方法 once.Do(call)，这个方法确保被调用函数只能被调用一次。","categories":[{"name":"golang标准库","slug":"golang标准库","permalink":"http://peapod.top/categories/golang%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"regexp包","slug":"regexp包","date":"2022-10-04T06:22:40.000Z","updated":"2022-10-06T03:24:50.000Z","comments":true,"path":"2022/10/04/regexp包/","link":"","permalink":"http://peapod.top/2022/10/04/regexp%E5%8C%85/","excerpt":"","text":"regexp 包正则表达式语法是一种字符串匹配模式或者规则，用来检索、替换那些符合特定规则的文本。 元字符 元字符 匹配内容 . 匹配除换行符以外的任意字符 \\w 匹配所有普通字符(数字、字母或下划线) \\s 匹配任意的空白符 \\d 匹配数字 \\n 匹配一个换行符 \\t 匹配一个制表符 \\b 匹配一个单词的结尾 ^ 匹配字符串的开始位置 $ 匹配字符串的结尾位置 \\W 匹配非字母或数字或下划线 \\D 匹配非数字 \\S 匹配非空白符 a|b 匹配字符 a 或字符 b () 正则表达式分组所用符号，匹配括号内的表达式，表示一个组。 […] 匹配字符组中的字符 [^…] 匹配除了字符组中字符的所有字符 量词 量词 用法说明 * 重复零次或者更多次 + 重复一次或者更多次 ？ 重复0次或者一次 {n} 重复n次 {n,} 重复n次或者更多次 {n,m} 重复n到m次 字符组 正则 待匹配字符 匹配结果 说明 [0123456789] 8 True 在一个字符组里枚举所有字符，字符组里的任意一个字符 和”待匹配字符”相同都视为可以匹配。 [0123456789] a False 由于字符组中没有 “a” 字符，所以不能匹配。 [0-9] 7 True 也可以用-表示范围，[0-9] 就和 [0123456789] 是一个意思。 [a-z] s True 同样的如果要匹配所有的小写字母，直接用 [a-z] 就可以表示。 [A-Z] B True [A-Z] 就表示所有的大写字母。 [0-9a-fA-F] e True 可以匹配数字，大小写形式的 a～f，用来验证十六进制字符。 贪婪匹配和非贪婪匹配正则表达式默认为贪婪匹配，也就是尽可能多的向后匹配字符，比如 {n,m} 表示匹配前面的内容出现 n 到 m 次（n 小于 m），在贪婪模式下，首先以匹配 m 次为目标，而在非贪婪模式是尽可能少的向后匹配内容，也就是说匹配 n 次即可。 元字符(贪婪模式) 非贪婪模式 * *? + +？ ？ ?? {n,m} {n,m}？ 实现12345678910111213141516171819202122232425262728package mainimport ( &quot;fmt&quot; &quot;regexp&quot; &quot;strconv&quot;)func main() &#123; //目标字符串 searchIn := &quot;John: 2578.34 William: 4567.23 Steve: 5632.18&quot; pat := &quot;[0-9]+.[0-9]+&quot; //正则 f := func(s string) string&#123; v, _ := strconv.ParseFloat(s, 32) return strconv.FormatFloat(v * 2, &#x27;f&#x27;, 2, 32) &#125; if ok, _ := regexp.Match(pat, []byte(searchIn)); ok &#123; fmt.Println(&quot;Match Found!&quot;) &#125; re, _ := regexp.Compile(pat) //将匹配到的部分替换为&quot;##.#&quot; str := re.ReplaceAllString(searchIn, &quot;##.#&quot;) fmt.Println(str) //参数为函数时 str2 := re.ReplaceAllStringFunc(searchIn, f) fmt.Println(str2)&#125;","categories":[{"name":"golang标准库","slug":"golang标准库","permalink":"http://peapod.top/categories/golang%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Go标准库 输入输出","slug":"Go标准库-输入输出","date":"2022-09-27T01:26:09.000Z","updated":"2024-02-27T10:54:33.000Z","comments":true,"path":"2022/09/27/Go标准库-输入输出/","link":"","permalink":"http://peapod.top/2022/09/27/Go%E6%A0%87%E5%87%86%E5%BA%93-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/","excerpt":"","text":"输入输出io-基本的IO接口io包为I&#x2F;O原语提供了基本的接口。包装了原语的已有实现。 只要满足Reader和Writer接口，就可以使用IO包的功能。 Reader接口定义： 123type Reader interface &#123; Read(p []byte) (n int, err error)&#125; Read将len(p)个字节读取到p中。返回读取的字节数n和遇到的错误。 Reader接口的方法集只包含了一个Read方法，所有实现了Read方法的类型都可以满足io.Reader接口。 12345678910111213141516func ReadFrom(reader io.Reader, num int) ([]byte, error) &#123; p := make([]byte, num) n, err := reader.Read(p) if n &gt; 0 &#123; return p[:n], nil &#125; return p, err&#125;// 从标准输入读取data, err = ReadFrom(os.Stdin, 11)// 从普通文件读取，其中 file 是 os.File 的实例data, err = ReadFrom(file, 9)// 从字符串读取data, err = ReadFrom(strings.NewReader(&quot;from string&quot;), 12) 传递的参数是个接口，在函数中调用了这个接口变量的Read方法，只需要在向ReadFrom函数传递实参的时候传递一个实现了该接口的对象，这样就把对象赋值给了接口。 Writer 接口定义： 123type Write interface &#123; Write(p byte[]) (n int, err error)&#125; 所有实现了Write方法的类型都实现了 io.Writer 接口。 实现了io.Reader接口或io.Writer接口的类型 os.File 同时实现了 io.Reader 和 io.Writer strings.Reader 实现了 io.Reader bufio.Reader&#x2F;Writer 分别实现了 io.Reader 和 io.Writer bytes.Buffer 同时实现了 io.Reader 和 io.Writer bytes.Reader 实现了 io.Reader encoding&#x2F;csv.Reader&#x2F;Writer 分别实现了 io.Reader 和 io.Writer net&#x2F;conn 分别实现了 io.Reader 和 io.Writer(Conn接口定义了Read&#x2F;Write) 常用的类型有：os.File、strings.Reader、bufio.Reader&#x2F;Writer、bytes.Buffer、bytes.Reader Go 中接口的命名约定：接口名以 er 结尾。 ReaderAt 和 WriterAt 接口ReaderAt 接口的定义：123type ReaderAt interface &#123; ReadAt(p []byte, off int64) (n int, err error)&#125; ReadAt 从基本输入源的偏移量 off 处开始，将 len(p) 个字节读取到 p 中。它返回读取的字节数 n（0 &lt;&#x3D; n &lt;&#x3D; len(p)）以及任何遇到的错误。 123456789reader := strings.NewReader(&quot;Go语言中文网&quot;)p := make([]byte, 6)n, err := reader.ReadAt(p, 2)if err != nil &#123; panic(err)&#125;fmt.Printf(&quot;%s, %d\\n&quot;, p, n)// 语言, 6 WriterAt 接口的定义：123type WriterAt interface &#123; WriteAt(p []byte, off int64) (n int, err error)&#125; WriteAt 从 p 中将 len(p) 个字节写入到偏移量 off 处的基本数据流中。它返回从 p 中被写入的字节数 n（0 &lt;&#x3D; n &lt;&#x3D; len(p)）以及任何遇到的引起写入提前停止的错误。 1234567891011file, err := os.Create(&quot;writeAt.txt&quot;)if err != nil &#123; panic(err)&#125;defer file.Close()file.WriteString(&quot;Golang中文社区——这里是多余&quot;)n, err := file.WriteAt([]byte(&quot;Go语言中文网&quot;), 24)if err != nil &#123; panic(err)&#125;fmt.Println(n) ReaderFrom 和 WriterTo 接口ReaderFrom 的定义:123type ReaderFrom interface &#123; ReadFrom(r Reader) (n int64, err error)&#125; ReadFrom 从 r 中读取数据，直到 EOF 或发生错误。其返回值 n 为读取的字节数。 12345678file, err := os.Open(&quot;writeAt.txt&quot;)if err != nil &#123; panic(err)&#125;defer file.Close()writer := bufio.NewWriter(os.Stdout)writer.ReadFrom(file)writer.Flush() WriterTo的定义:123type WriterTo interface &#123; WriteTo(w Writer) (n int64, err error)&#125; WriteTo 将数据写入 w 中，直到没有数据可写或发生错误。其返回值 n 为写入的字节数。 12reader := bytes.NewReader([]byte(&quot;Go语言中文网&quot;))reader.WriteTo(os.Stdout) ioutil — 方便的IO操作函数集ReadAll 函数Go 提供了 ReadAll 这个函数，用来从io.Reader 中一次读取所有数据。 1func ReadAll(r io.Reader) ([]byte, error) 它是通过 bytes.Buffer 中的 ReadFrom 来实现读取所有数据的。 ReadDri 函数读取目录并返回排好序的文件和子目录名（ []os.FileInfo ）。 1fileInfos, err := ioutil.ReadDir(path) ReadFile 和 WriteFile 函数ReadFile 读取整个文件的内容。 ReadFile 的实现和ReadAll 类似，不过，ReadFile 会先判断文件的大小，给 bytes.Buffer 一个预定义容量，避免额外分配内存。 1func ReadFile(filename string) ([]byte, error) ReadFile 从 filename 指定的文件中读取数据并返回文件的内容。 WriteFile 函数： 1func WriteFile(filename string, data []byte, perm os.FileMode) error WriteFile 将data写入filename文件中，当文件不存在时会根据perm指定的权限进行创建一个,文件存在时会先清空文件内容。 TempDir 和 TempFile 函数TempDir 创建临时目录。 1b.work, err = ioutil.TempDir(&quot;&quot;, &quot;go-build&quot;) 第一个参数如果为空，表明在系统默认的临时目录（ os.TempDir ）中创建临时目录；第二个参数指定临时目录名的前缀，该函数返回临时目录的路径。 TempFile 用于创建临时文件。 1f1, err := ioutil.TempFile(&quot;&quot;, &quot;gofmt&quot;) 第一个参数如果为空，表明在系统默认的临时目录（ os.TempDir ）中创建临时文件；第二个参数指定临时文件名的前缀，该函数返回临时文件的路径。 创建者创建的临时文件和临时目录要负责删除这些临时目录和文件。 如删除临时文件： 1234defer func() &#123; f.Close() os.Remove(f.Name()) &#125;() fmt — 格式化IOPrintingSample12345678910111213141516171819202122232425262728293031type user struct &#123; name string&#125;func main() &#123; u := user&#123;&quot;tang&quot;&#125; //Printf 格式化输出 fmt.Printf(&quot;% + v\\n&quot;, u) //格式化输出结构 fmt.Printf(&quot;%#v\\n&quot;, u) //输出值的 Go 语言表示方法 fmt.Printf(&quot;%T\\n&quot;, u) //输出值的类型的 Go 语言表示 fmt.Printf(&quot;%t\\n&quot;, true) //输出值的 true 或 false fmt.Printf(&quot;%b\\n&quot;, 1024) //二进制表示 fmt.Printf(&quot;%c\\n&quot;, 11111111) //数值对应的 Unicode 编码字符 fmt.Printf(&quot;%d\\n&quot;, 10) //十进制表示 fmt.Printf(&quot;%o\\n&quot;, 8) //八进制表示 fmt.Printf(&quot;%q\\n&quot;, 22) //转化为十六进制并附上单引号 fmt.Printf(&quot;%x\\n&quot;, 1223) //十六进制表示，用a-f表示 fmt.Printf(&quot;%X\\n&quot;, 1223) //十六进制表示，用A-F表示 fmt.Printf(&quot;%U\\n&quot;, 1233) //Unicode表示 fmt.Printf(&quot;%b\\n&quot;, 12.34) //无小数部分，两位指数的科学计数法6946802425218990p-49 fmt.Printf(&quot;%e\\n&quot;, 12.345) //科学计数法，e表示 fmt.Printf(&quot;%E\\n&quot;, 12.34455) //科学计数法，E表示 fmt.Printf(&quot;%f\\n&quot;, 12.3456) //有小数部分，无指数部分 fmt.Printf(&quot;%g\\n&quot;, 12.3456) //根据实际情况采用%e或%f输出 fmt.Printf(&quot;%G\\n&quot;, 12.3456) //根据实际情况采用%E或%f输出 fmt.Printf(&quot;%s\\n&quot;, &quot;wqdew&quot;) //直接输出字符串或者[]byte fmt.Printf(&quot;%q\\n&quot;, &quot;dedede&quot;) //双引号括起来的字符串 fmt.Printf(&quot;%x\\n&quot;, &quot;abczxc&quot;) //每个字节用两字节十六进制表示，a-f表示 fmt.Printf(&quot;%X\\n&quot;, &quot;asdzxc&quot;) //每个字节用两字节十六进制表示，A-F表示 fmt.Printf(&quot;%p\\n&quot;, 0x123) //0x开头的十六进制数表示&#125; 占位符 占位符 说明 %v 相应值的默认格式。“加号”标记（%+v）会添加字段名 %#v 相应值的Go语法表示 %T 相应值的类型的Go语法表示 %% 字面上的百分号，并非值的占位符 %t true 或 false。 %b 二进制表示 %c 相应Unicode码点所表示的字符 %d 十进制表示 %o 八进制表示 %q 单引号围绕的字符字面值，由Go语法安全地转义 %x 十六进制表示，字母形式为小写 a-f %X 十六进制表示，字母形式为大写 A-F %s 输出字符串表示（string类型或[]byte) %p 十六进制表示，前缀 0x %f 有小数点而无指数，例如 123.456 %e 科学计数法，例如 -1234.456e+78 %g 根据情况选择 %e 或 %f 以产生更紧凑的（无末尾的0）输出 %G 根据情况选择 %E 或 %f 以产生更紧凑的（无末尾的0）输出 %E 科学计数法，例如 -1234.456E+78 对数值而言，宽度为该数值占用区域的最小宽度；精度为小数点之后的位数。 ScanningScan、Scanf 和 Scanln 从 os.Stdin 中读取； Fscan、Fscanf 和 Fscanln 从指定的 io.Reader 中读取； Sscan、Sscanf 和 Sscanln 从实参字符串中读取。 Scanf、Fscanf 和 Sscanf 需要输入换行符来匹配格式中的换行符；其它函数则将换行符视为空格。 Scanf、Fscanf 和 Sscanf 根据格式字符串解析实参。 宽度被解释为输入的文本（%5s 意为最多从输入中读取5个 rune 来扫描成字符串），而扫描函数则没有精度的语法（没有 %5.2f，只有 %5f）。 Print 序列函数Fprint&#x2F;Fprintf&#x2F;Fprintln 函数的第一个参数接收一个io.Writer类型，会将内容输出到 io.Writer 中去。 Print&#x2F;Printf&#x2F;Println 函数是将内容输出到标准输出中。 Sprint&#x2F;Sprintf&#x2F;Sprintln 是格式化内容为 string 类型，而并不输出到某处，需要格式化字符串并返回时。 Scan 序列函数Fscan&#x2F;Fscanf&#x2F;Fscanln 函数的第一个参数接收一个 io.Reader 类型，从其读取内容并赋值给相应的实参。 Scan&#x2F;Scanf&#x2F;Scanln 正是从标准输入获取内容。 Sscan&#x2F;Sscanf&#x2F;Sscanln 则直接从字符串中获取内容。 bufio — 缓存IOReader 类型和方法bufio.Reader 结构包装了一个 io.Reader 对象，提供缓存功能，同时实现了 io.Reader 接口。 12345678910type Reader struct &#123; buf []byte // 缓存 rd io.Reader // 底层的io.Reader // r:从buf中读走的字节（偏移）；w:buf中填充内容的偏移； // w - r 是buf中可被读的长度（缓存数据的大小），也是Buffered()方法的返回值 r, w int err error // 读过程中遇到的错误 lastByte int // 最后一次读到的字节（ReadByte/UnreadByte) lastRuneSize int // 最后一次读到的Rune的大小 (ReadRune/UnreadRune) &#125; 实列化bufio 包提供了两个实例化 bufio.Reader 对象的函数：NewReader 和 NewReaderSize。其中，NewReader 函数是调用 NewReaderSize 函数实现的： 1234func NewReader(rd io.Reader) *Reader &#123; // 默认缓存大小：defaultBufSize=4096 return NewReaderSize(rd, defaultBufSize) &#125; NewReaderSize的源码： 123456789101112131415161718func NewReaderSize(rd io.Reader, size int) *Reader &#123; // 已经是bufio.Reader类型，且缓存大小不小于 size，则直接返回 b, ok := rd.(*Reader) if ok &amp;&amp; len(b.buf) &gt;= size &#123; return b &#125; // 缓存大小不会小于 minReadBufferSize （16字节） if size &lt; minReadBufferSize &#123; size = minReadBufferSize &#125; // 构造一个bufio.Reader实例 return &amp;Reader&#123; buf: make([]byte, size), rd: rd, lastByte: -1, lastRuneSize: -1, &#125; &#125;","categories":[{"name":"golang标准库","slug":"golang标准库","permalink":"http://peapod.top/categories/golang%E6%A0%87%E5%87%86%E5%BA%93/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"JSON 指南","slug":"JSON-指南","date":"2022-09-26T12:32:19.000Z","updated":"2022-10-07T03:39:24.000Z","comments":true,"path":"2022/09/26/JSON-指南/","link":"","permalink":"http://peapod.top/2022/09/26/JSON-%E6%8C%87%E5%8D%97/","excerpt":"","text":"JSON 基础轻量级的、基于文本的、开放的数据交换格式，最受欢迎的、使用最广泛的交换格式之一。 JSON是一种纯字符串形式的数据，本身不提供任何方法，适合在网络中进行传输。 在JSON中，使用两种方式表示数据： Object（对象）：键值对的集合，使用&#123;&#125;定义。 如&#123;&quot;name&quot;:&quot;taweizhong&quot;,&quot;age&quot;:&quot;22&quot;&#125; Array（数组）：值的有序集合，使用[]定义。 &quot;Article&quot;:[ &quot;JSON 是什么？&quot;, &quot;JSONP 是什么？&quot;, &quot;JSON 语法规则&quot; ] JSON的存储 JSON可以存储在.JSON格式的文件中，也可以以字符串的形式存储在数据库、Cookie、Session中。 JSON的使用 定义接口 Web开发领域 使用Ajax异步加载 RPC远程调用 前后端分离 开发API 序列化：将内存中的数据保存起来的过程称为序列化。 生成Token：直接使用Token读取保存的用户的信息。 配置文件：作为程序的配置文件。 JSON语法规则JSON中的键JSON 数据是以键&#x2F;值对（名称&#x2F;值）的形式书写的，键表示数据的名称，需要以字符串的形式定义（在双引号中定义），后面紧跟一个冒号，最后是值。 1&quot;name&quot;:&quot;C语言中文网&quot; JSON中的值JSON 中的值可以是以下数据类型： 数字（整数或浮点数）； 字符串（需要在双引号中定义）； 布尔值（true 或 false）； 数组（在方括号中定义）； 对象（在花括号中定义）； null（空）。 JSON 中每个键都必须是一个字符串","categories":[{"name":"实用","slug":"实用","permalink":"http://peapod.top/categories/%E5%AE%9E%E7%94%A8/"}],"tags":[{"name":"JSON","slug":"JSON","permalink":"http://peapod.top/tags/JSON/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric 私有数据","slug":"Hyperledger-Fabric-私有数据","date":"2022-09-23T09:19:56.000Z","updated":"2022-09-24T02:25:50.000Z","comments":true,"path":"2022/09/23/Hyperledger-Fabric-私有数据/","link":"","permalink":"http://peapod.top/2022/09/23/Hyperledger-Fabric-%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE/","excerpt":"","text":"私有数据Fabric 提供了创建私有数据集合的功能，它允许在通道上定义的组织子集能够背书、提交或查询私有数据，而无需创建单独的通道。 私有数据集合集合是两个元素的组合: 实际的私有数据，通过 Gossip 协议点对点地发送给授权可以看到它的组织。 该数据的 hash 值，该 hash 值被背书、排序之后写入通道上每个节点的账本。 下面的图表说明了被授权和未被授权拥有私有数据的节点的账本内容。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric 排序服务","slug":"Hyperledger-Fabric-排序服务","date":"2022-09-23T09:19:46.000Z","updated":"2022-09-24T02:25:10.000Z","comments":true,"path":"2022/09/23/Hyperledger-Fabric-排序服务/","link":"","permalink":"http://peapod.top/2022/09/23/Hyperledger-Fabric-%E6%8E%92%E5%BA%8F%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"排序服务排序排序节点使交易有序，并与其他排序节点一起形成一个排序服务。 本不会像其他分布式的以及无需许可的区块链中那样产生分叉。 排序节点还将链码执行的背书（发生在节点）与排序分离。 排序节点和通道配置排序节点还维护着允许创建通道的组织列表。 列表本身保存在“排序节点系统通道”（也称为“排序系统通道”）的配置中。 排序节点还对通道执行基本访问控制，限制谁可以读写数据，以及谁可以配置数据。 谁有权修改通道中的配置元素取决于相关管理员在创建联盟或通道时设置的策略。 排序节点和身份节点、应用程序、管理员和排序节点，都从它们的数字证书和成员服务提供者（MSP）定义中获取它们的组织身份。 与 Peer 节点一样，排序节点属于组织。也应该像 Peer 节点一样为每个组织使用单独的证书授权中心（CA）。 排序节点与交易流程提案客户端应用程序将交易提案发送给一组节点 节点将调用智能合约来生成一个账本更新提案，然后背书该结果。 背书节点将向客户端应用程序返回一个提案响应。 打包应用程序客户端把包含已背书交易提案响应的交易提交到排序服务节点。 排序服务创建交易区块，这些交易区块最终将分发给通道上的所有 Peer 节点 排序节点的第一个角色是打包提案的账本更新。 一个区块中交易的顺序不一定与排序服务接收的顺序相同，因为可能有多个排序服务节点几乎同时接收交易。 在 Hyperledger Fabric 中，由排序服务生成的区块是最终的。一旦一笔交易被写进一个区块，它在账本中的地位就得到了保证。 Hyperledger Fabric 的最终性意味着没有账本分叉，也就是说，经过验证的交易永远不会被重写或删除。 验证和提交每个节点将独立地以确定的方式验证区块，以确保账本保持一致。 无效的交易仍然保留在排序节点创建的区块中，但是节点将它们标记为无效，并且不更新账本的状态。 排序服务的实现几种不同的实现可以在排序服务节点之间就严格的交易排序达成共识。 Raft (推荐) 作为 v1.4.1 的新特性，Raft 是一种基于 etcd 中 Raft 协议实现的崩溃容错（Crash Fault Tolerant，CFT）排序服务。Raft 遵循“领导者跟随者”模型，这个模型中，在每个通道上选举领导者节点，其决策被跟随者复制。Raft 排序服务会比基于 Kafka 的排序服务更容易设置和管理，它的设计允许不同的组织为分布式排序服务贡献节点。 RaftFabric 实现了使用“领导者跟随者”模型的 Raft 协议，领导者是在一个通道的排序节点中动态选择的（这个集合的节点称为“共识者集合（consenter set）”），领导者将信息复制到跟随者节点。 Raft 被称为“崩溃容错”是因为系统可以承受节点的损失，包括领导者节点，前提是要剩余大量的排序节点（称为“法定人数（quorum）”）。 使用 Raft，所有内容都会嵌入到您的排序节点中。Raft 更容易设置。 使用 Raft，每个组织都可以有自己的排序节点参与排序服务，从而形成一个更加分散的系统。 Raft 是原生支持的，Raft 允许用户指定哪个排序节点要部署到哪个通道。 Raft 是向开发拜占庭容错（BFT）排序服务迈出的第一步。 日志条目（Log entry）Raft 排序服务中的主要工作单元是一个“日志条目”，该项的完整序列称为“日志”。 大多数成员（换句话说是一个法定人数）同意条目及其顺序，则我们认为条目是一致的，然后将日志复制到不同排序节点上。 共识者集合（Consenter set）主动参与给定通道的共识机制并接收该通道的日志副本的排序节点。 有限状态机（Finite-State Machine，FSM）Raft 中的每个排序节点都有一个 FSM，它们共同用于确保各个排序节点中的日志序列是确定（以相同的顺序编写）。 法定人数（Quorum）描述需要确认提案的最小同意人数。 对于每个共识者集合，这是大多数节点。 领导者通道的共识者集合都选择一个节点作为领导者，领导者负责接收新的日志条目，将它们复制到跟随者的排序节点，并在认为提交了某个条目时进行管理。 跟随者跟随者从领导者那里接收日志并复制它们，确保日志保持一致。 交易中的Raft在 Raft 中，交易（以提案或配置更新的形式）由接收交易的排序节点自动路由到该通道的当前领导者。 架构说明Raft 是如何选举领导者节点总是处于以下三种状态之一：跟随者、候选人或领导者。 所有节点最初都是作为跟随者开始的。 在一段时间内没有接收到日志条目或心跳（例如，5秒），节点将自己提升到候选状态。 在候选状态中，节点从其他节点请求选票。如果候选人获得法定人数的选票，那么他就被提升为领导者。 快照Raft 使用了一个称为“快照”的过程，在这个过程中，用户可以定义日志中要保留多少字节的数据。这个数据量将决定区块的数量。 快照中只存储完整的区块","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric 账本","slug":"Hyperledger-Fabric-账本","date":"2022-09-23T09:19:33.000Z","updated":"2022-09-24T02:24:44.000Z","comments":true,"path":"2022/09/23/Hyperledger-Fabric-账本/","link":"","permalink":"http://peapod.top/2022/09/23/Hyperledger-Fabric-%E8%B4%A6%E6%9C%AC/","excerpt":"","text":"账本账本、事实和状态账本储存的其实并不是业务对象本身，而是与业务对象相关的事实信息。 与业务对象当前状态相关的事实可能会发生改变，但是与之相关的事实历史是不可变的。 账本账本由“世界状态“和”区块链“这两部分组成，它们彼此不同但却相互关联。 世界状态是一个数据库，它存储了一组账本状态的当前值。 通过世界状态，程序可以直接访问一个账本状态的当前值，不需要遍历整个交易日志来计算当前值。 区块链是交易日志，它记录了促成当前世界状态的所有改变。 世界状态 W 由区块链 B 决定。 Fabric 网络维护着一个账本的多个副本，这些副本通过名为共识的过程来与其他副本保持一致。分布式账本技术（DLT） 世界状态世界状态将业务对象属性的当前值保存为唯一的账本状态。 世界状态包含两个状态。第一个状态是： key&#x3D;CAR1 和 value&#x3D;Audi。第二个状态中有一个更复杂的值：key&#x3D;CAR2 和 value&#x3D;{model:BMW, color&#x3D;red, owner&#x3D;Jane} 。 账本状态记录了一组与特定业务对象有关的事实。我们的示例展示的是 CAR1 和 CAR2 这两辆车的账本状态，二者都各有一个值和一个键。 世界状态被作为数据库来实现。 （所有被提交的交易，无论有效与否，都会被收进区块链）。 关键设计在于，只有那些受到相关背书组织签名的交易才会更新世界状态。 首次创建账本时，世界状态是空的。 个人理解：这个世界状态相当于比特币中的UTXO。 区块链世界状态存储了与业务对象当前状态相关的事实信息，而区块链是一种历史记录，它记录了这些业务对象是如何到达各自当前状态的相关事实。 区块链记录了每个账本状态之前的所有版本以及状态是如何被更改的。 区块排序以及区块内的交易排序，这一机制是在 Hyperledger Fabric 的排序服务组件首次创建区块时被建立起来的。 区块链总是以文件实现，而与之相反的是，世界状态以数据库实现。 区块链 B 包含了 B0、B1、B2、B3这四个区块。B0 是该区块链的第一个区块，也叫创世区块。 创世区块包含了一个配置交易，该交易含有网络配置（未显示）的初始状态。 区块区块结构： 区块头 包含三个字段，这些字段是在创建一个区块时候被写入的。 区块编号：编号从0（初始区块）开始，每在区块链上增加一个新区块，编号的数字都会加1。 当前区块的哈希值：当前区块中包含的所有交易的哈希值。 前一个区块头的哈希值：区块链中前一个区块头的哈希值。 区块数据：包含了一个有序的交易列表。区块数据是在排序服务创建区块时被写入的。 区块元数据：包含了区块被写入的时间，还有区块写入者的证书、公钥以及签名。 交易交易记录了世界状态发生的更新。 T4包括的内容如下：交易头 H4，一个交易签名 S4，一个交易提案 P4，一个交易响应 R4 和一系列背书 E4。 头 这部分用 H4 表示，它记录了关于交易的一些重要元数据，比如，相关链码的名字以及版本。 签名 这部分用 S4 表示，它包含了一个由客户端应用程序创建的加密签名。该字段是用来检查交易细节是否未经篡改，因为交易签名的生成需要用到应用程序的私钥。 提案 这部分用 P4 表示，它负责对应用程序供给智能合约的输入参数进行编码，随后该智能合约生成提案账本更新。在智能合约运行时，这个提案提供了一套输入参数，这些参数同当前的世界状态一起决定了新的账本世界状态。 响应 这部分用 R4 表示，它是以读写集 （RW-set）的形式记录下世界状态之前和之后的值。交易响应是智能合约的输出，如果交易验证成功，那么该交易会被应用到账本上，从而更新世界状态。 背书 就像 E4 显示的那样，它指的是一组签名交易响应，这些签名都来自背书策略规定的相关组织，并且这些组织的数量必须满足背书策略的要求。 世界状态数据库的选择世界状态是以数据库的形式实现的，旨在提供简单有效的账本状态存储和检索。 世界状态数据库的选项包括 LevelDB 和 CouchDB 。 LevelDB 是世界状态数据库的默认选项，当账本状态是简单的键值对时，使用 LevelDB 非常合适。 当账本状态结构为 JSON 文档时，以 CouchDB 来实现世界状态非常合适，这是因为业务交易涉及的数据类型通常十分丰富，而 CouchDB 可支持对这些数据类型进行各种形式的查询和更新。 在实现方面，CouchDB 是在单独的操作系统进程中运行的，但是节点和 CouchDB 实例之间仍然存在1:1的关系。 命名空间每个链码都有自己的世界状态，并且与所有其他链码的世界状态分离。 世界状态位于一个命名空间中，因此只有位于同一链码中的智能合约才能访问一个给定的命名空间。 区块链没有命名空间。它包含来自许多不同智能合约命名空间的交易。 通道每个通道都有一个完全独立的账本。这意味着完全独立的区块链和完全独立的世界状态，包括命名空间。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric 智能合约","slug":"Hyperledger-Fabric-智能合约","date":"2022-09-23T09:19:19.000Z","updated":"2022-09-24T02:24:26.000Z","comments":true,"path":"2022/09/23/Hyperledger-Fabric-智能合约/","link":"","permalink":"http://peapod.top/2022/09/23/Hyperledger-Fabric-%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/","excerpt":"","text":"智能合约和链码账本包含了与一组业务对象的当前和历史状态有关的事实，而智能合约定义了生成这些被添加到账本中的新事实的可执行逻辑。 管理员通常使用链码将相关的智能合约组织起来进行部署，并且链码也可以用于 Fabric 的底层系统编程。 智能合约在各业务彼此进行交互之前，必须先定义一套通用的合约，其中包括通用术语、数据、规则、概念定义和流程。 智能合约用可执行的代码定义了不同组织之间的规则。 应用程序调用智能合约来生成被记录到账本上的交易。 组织 ORG1 和 ORG2 是如何通过定义一个 car 智能合约来实现 查询、转移 和 更新 汽车的。 可以将智能合约看成交易的管理者，而链码则管理着如何将智能合约打包以便用于部署。 一个智能合约定义在一个链码中。而多个智能合约也可以定义在同一个链码中。当一个链码部署完毕，该链码中的所有智能合约都可供应用程序使用。 vehicle 链码包含了以下三个智能合约：cars、boats 和 trucks；而 insurance 链码包含了以下四个智能合约：policy、liability、syndication 和 securitization。 账本智能合约以编程方式访问账本两个不同的部分： 一个是区块链（记录所有交易的历史，且记录不可篡改） 一个是世界状态（保存这些状态当前值的缓存，是经常需要用到的对象的当前值）。 智能合约主要在世界状态中将状态写入（put）、读取（get）和删除（delete），还可以查询不可篡改的区块链交易记录。 读取（get） 操作一般代表的是查询，目的是获取关于交易对象当前状态的信息。 写入（put） 操作通常生成一个新的业务对象或者对账本世界状态中现有的业务对象进行修改。 删除（delete） 操作代表的是将一个业务对象从账本的当前状态中移除，但不从账本的历史中移除。 开发智能合约是应用程序开发的重点。 智能合约的核心是一组 交易 定义。 例如，在 fabcar.js 中，创建了一辆新车的智能合约交易： 123456789101112async createCar(ctx, carNumber, make, model, color, owner) &#123; const car = &#123; color, docType: &#x27;car&#x27;, make, model, owner, &#125;; await ctx.stub.putState(carNumber, Buffer.from(JSON.stringify(car)));&#125; 背书每个链码都有一个背书策略与之相关联，该背书策略适用于此链码中定义的所有智能合约。 背书策略非常重要，它指明了区块链网络中哪些组织必须对一个给定的智能合约所生成的交易进行签名，以此来宣布该交易有效。 一个示例背书策略可能这样定义：参与区块链网络的四个组织中有三个必须在交易被认为有效之前签署该交易。所有的交易，无论是有效的还是无效的，都会被添加到分布式账本中，但只有有效交易会更新世界状态。 交易必须由 Fabric 网络中受信任的组织验证。 例如，一个政府组织必须签署一个有效的 issueIdentity 交易，或者一辆车的 买家 和 卖家 都必须签署一个 车辆 转移交易。 有效交易智能合约提取一组名为交易提案的输入参数，并将其与程序逻辑结合起来使用以读写账本。对世界状态的更改被捕获为交易提案响应（或简称交易响应），该响应包含一个读写集，其中既含有已读取的状态，也含有还未书写的新状态（如果交易有效的话）。 在执行智能合约时世界状态没有更新！ 所有交易，无论是否有效，都会被记录在区块链上，但仅有效交易会更新世界状态。 各节点通过两个阶段对其进行验证。 根据背书策略检查交易，确保该交易已被足够的组织签署。 该交易在受到背书节点签名时它的交易读集与世界状态的当前值匹配，并且中间过程中没有被更新。 交易通过了这两个测试，它就被标记为有效。 通道 通道在一群组织之间提供了一种完全独立的通信机制。当链码定义被提交到通道上时，该通道上所有的应用程序都可以使用此链码中的智能合约。 链码定义是一种包含了许多参数的结构，这些参数管理着链码的运行方式，包含着链码名、版本以及背书策略。各通道成员批准各自组织的一个链码定义，以表示其对该链码的参数表示同意。 链码的定义为通道成员提供了一种他们在通道上使用智能合约来交易之前，同意对于一个链码的管理的方式。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric 节点","slug":"Hyperledger-Fabric-节点","date":"2022-09-23T09:19:11.000Z","updated":"2022-09-24T02:23:54.000Z","comments":true,"path":"2022/09/23/Hyperledger-Fabric-节点/","link":"","permalink":"http://peapod.top/2022/09/23/Hyperledger-Fabric-%E8%8A%82%E7%82%B9/","excerpt":"","text":"节点Peer 是网络的基本元素，因为他们存储了账本和智能合约。 Peer 节点可以被创建、启动、停止、重新配置甚至删除。 暴露了一系列的 API，这就可以让管理者和应用程序同这些 API 提供的服务互动。 账本和链码Peer 节点在维护账本和链码。 Peer 节点维护的是账本及链码的实例。 应用程序及管理员访问这些资源，他们必须要和 Peer 节点进行交互。 多账本 大多数的 Peer 节点将会至少安装一个链码，用来查询或更新 Peer 节点的账本实例。 多链码 应用程序和节点当应用程序需要访问账本和链码的时候，他们总是需要连接到 Peer 节点。 Hyperledger Fabric SDK 将这个操作变得非常简单，它的 API 使应用程序能够连接到 Peer 节点，调用链码生成交易，提交交易到网络。 查询过程： A 连接到了 P1 且调用了链码 S1 来查询账本 L1 P1 调用了链码 S1 来生成提案响应（响应包含了查询结果） A 接收到了提案的响应 更新过程： A 连接到了 P1 且调用了链码 S1 来更新账本 L1 P1 调用了链码 S1 来生成提案响应（账本更新的提案） A 接收到了提案的响应 A 会从所有的响应中创建一笔交易 交易发送给排序节点 O1 进行排序。 区块分发到所有 Peer 节点上。 当 L1 被更新之后，P1 会生成一个事件，该事件会被 A 接收到，来标识这个过程结束了。 一个独立的 Peer 节点目前是不能进行账本更新的，因为其他的 Peer 节点必须首先要同意这个变动（即达成共识）。 因此，Peer 节点会返回给应用程序一个被提案过的更新，这个 Peer 节点会依据其他节点之前的协议来应用这个更新。 通道与节点 通道允许区块链网络中特定的一些 Peer 节点以及应用程序来彼此交互。 组织与节点 有一个工作原则：如果组织不为这个网络贡献他们的资源，这个网络是不会存在的。更关键的是，这个网络会随着这些互相合作的组织提供的资源而增长或者萎缩。 身份与节点Peer 节点会有一个身份信息被分给他们，这是通过一个特定的证书认证机构颁发的数字证书来实现的。 在网络中的每个 Peer 节点都会被所属组织的管理员分配一个数字证书。 当 Peer 节点连接到一个通道的时候，它的数字证书会通过通道 MSP 来识别它的所属组织。 P1 和 P2 具有由 CA1 颁发的身份信息。 通道 C 通过在它的通道配置中的策略来决定来自 CA1 的身份信息应该使用 ORG1.MSP 被关联到 Org1。 在通道配置中的策略会使用 Peer 节点的身份信息来确定它的权利。 关于身份信息和组织的映射是由成员服务提供者（MSP）来提供的，它决定了一个 Peer 节点如何在指定的组织中分配到特定的角色以及得到访问区块链资源的相关权限。 Peer 节点只能被一个组织所有，因此也就只能被关联到一个单独的 MSP。 Peer节点和排序节点一个单独的 Peer 节点不能够由它自己来更新账本——更新需要网络中其他节点的同意。 Peer 节点会请求网络中的其他 Peer 节点来批准这次更新。这个过程被称为共识。 更新账本的应用程序会被引入到一个三阶段的流程，确保 Peer 节点都彼此保持着一致的账本。 在第一个阶段，应用程序会跟背书节点的子集一起工作，其中的每个节点都会向应用程序为提案的账本更新提供背书，但是不会将提案的更新应用到他们的账本副本上。 在第二个阶段，这些分散的背书会被搜集到一起当做交易被打包进区块中。 在最后一个阶段，这些区块会被分发回每个 Peer 节点，在这些 Peer 节点上每笔交易在被应用到 Peer 节点的账本副本之前会被验证。 提案第一阶段只在乎应用程序询问不同组织的背书节点同意链码调用的提案结果。 应用程序会生成一笔交易的提案，它会把这个提案发送给一系列的被要求的节点来获得背书。 每一个背书节点接下来都会独立地使用交易提案来执行链码，以此来生成这个交易提案的响应。 简单地为它提供签名然后将它返回给应用程序。当应用程序接收到有效数量的被签过名的提案响应之后，交易流程中的第一个阶段就结束了。 应用程序 A1 生成了交易 T1 和提案 P 应用程序会将交易及提案发送给通道 C 上的 Peer 节点 P1 和 Peer 节点 P2 P1 使用交易 T1 和 提案 P 来执行链码 S1，这会生成对交易 T1 的响应 R1，它会提供背书 E1。 P2 使用交易 T1 提案 P 执行了链码 S1，这会生成对于交易 T1 的响应 R2，它会提供背书 E2。 应用程序 A1 对于交易 T1 接收到了两个背书响应，称为 E1 和 E2。 Peer 节点通过向提案的响应添加自己的数字签名的方式提供背书，并且使用它的私钥为整个的负载提供签名。 排序和将交易打包到区块排序节点是这个过程的关键——它接收交易，这些交易中包含了来自很多个应用的已经背书过的交易提案，并且将交易排序并打包进区块。 验证和提交在每个 Peer 节点上，区块中的每笔交易都会被验证，以确保它在被提交到账本之前，已经被所有相关的组织一致地背书过了。 排序节点 O1 将区块 B2 分发给了 Peer 节点 P1 和 Peer 节点 P2。 Peer P1 处理了区块 B2，产生了一个会被添加到 P1 的账本 L1 中的新区块。 peer P2 处理了区块 B2，产生了一个会被添加到 P2 的账本 L1 中的新区块。 阶段三是从排序节点将区块分发到所有与它连接的 Peer 节点开始的。Peer 节点会和通道中的排序节点相连，所有跟这个排序节点相连的 Peer 节点将会收到一个新的区块的副本。 不是每个 Peer 节点都需要连接到排序节点——Peer 节点可以使用 gossip 协议将区块的信息发送给其他 Peer 节点，其他 Peer 节点也可以独立地处理这些区块。 链码仅仅需要在背书节点中有效，而不需要在区块链网络的所有部分都要有。 当区块被提交到 Peer 节点的账本的时候，那个 Peer 节点会生成一个合适的事件。 应用程序可以对这些事件类型进行注册，所以在这些事件发生的时候他们能够被通知到。这些通知结束了交易流程的第三以及最后的阶段。 排序节点和共识整个交易处理流程被称为共识，因为所有 Peer 节点在由排序节点提供的流程中对交易的排序及内容都达成了一致。 排序节点理解为这样一些节点，它们从应用程序收集和分发账本更新提案以供 Peer 节点验证并写入账本中。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric 策略","slug":"Hyperledger-Fabric-策略","date":"2022-09-23T09:18:56.000Z","updated":"2022-09-24T02:23:36.000Z","comments":true,"path":"2022/09/23/Hyperledger-Fabric-策略/","link":"","permalink":"http://peapod.top/2022/09/23/Hyperledger-Fabric-%E7%AD%96%E7%95%A5/","excerpt":"","text":"策略策略是一组规则，用来定义如何做出决策和实现特定结果。 Fabric 策略表示成员如何同意或者拒绝网络、通道或者智能合约的变更。 策略是使 Hyperledger Fabric 不同于其他区块链系统的内容之一。 策略决定了那些组织可以访问或者更新 Fabric 网络，并且提供了强制执行这些决策的机制。 实现策略策略实现在 Fabric 网络的不同层次。 系统通道配置网络中必须有至少一个排序服务的排序系统通道，它是第一个被创建的通道。 该通道也包含着谁是排序服务（排序服务组织）以及在网络中交易（联盟组织）的成员。 策略治理着排序服务使用的共识，并定义了新区块如何被创建。 系统通道也治理着联盟中的哪些成员可以创建新通道。 应用通道配置应用 通道 用于向联盟中的组织间提供私有通信机制。 策略治理着从通道中添加和删除成员的能力。 治理着使用 Fabric 链码生命周期在链码定义和提交到通道前需要哪些组织同意。 权限从控制列表ACL 通过将资源和已有策略相关联的方式提供了资源访问配置的能力。 Fabric ACL 的默认集合在 configtx.yaml 文件的 Application: &amp;ApplicationDefaults 部分。 configtx.yaml 中定义的资源列表是 Fabric 当前定义的所有内部资源的完整集合。 智能合约背书策略每一个智能合约都有一个背书策略，该策略指明了需要通道中多少不同组织的成员根据指定智能合约执行和验证交易才能使一笔交易有效。 背书策略定义了必须“背书”（批准）提案执行的组织（的 Peer 节点）。 修改策略它是定义如何更新策略的策略。 策略作用域 系统通道配置为联盟成员提供了创建通道的能力。 应用通道和 ACL 是联盟组织用来从通道中添加或删除成员以及限制通道中智能合约和数据访问的机制。 写策略在 Hyperledger Fabric 中，策略中明确的签名使用 Signature 语法，隐含的签名使用 ImplicitMeta 语法。 签名策略Signature 策略定义了要满足策略就必须签名的特定用户类型，比如 Org1.Peer OR Org2.Peer。 例如，一个策略可以简单表达为使用 AND (Org1, Org2) ，表示满足该策略就同时需要 Org1 中的一个成员和 Org2 中的一个成员的签名。 隐元策略隐元策略只在通道配置上下文中有效，通道配置在配置树策略中是基于分层的层次结构。 应用通道分层的策略结构： 当满足配置层级中它的 Admins 子策略时，就代表也满足了其子策略的子策略条件。 隐元通道配置管理策略（称为 /Channel/Admins）。 在配置树中所有 Admins 策略都引用了的 Admin 子策略。 隐元策略比如 MAJORITY Admins 的主要优势在于当你向通道添加新组织的时候，你不必更新通道策略。 链码的生命周期configtx.yaml 文件中 Application 部分包含了默认的链码生命周期背书策略。 12345678910111213141516171819202122232425Application: &amp;ApplicationDefaults # Organizations is the list of orgs which are defined as participants on # the application side of the network Organizations: # Policies defines the set of policies at this level of the config tree # For Application policies, their canonical path is # /Channel/Application/&lt;PolicyName&gt; Policies: Readers: Type: ImplicitMeta Rule: &quot;ANY Readers&quot; Writers: Type: ImplicitMeta Rule: &quot;ANY Writers&quot; Admins: Type: ImplicitMeta Rule: &quot;MAJORITY Admins&quot; LifecycleEndorsement: Type: ImplicitMeta Rule: &quot;MAJORITY Endorsement&quot; Endorsement: Type: ImplicitMeta Rule: &quot;MAJORITY Endorsement&quot; LifecycleEndorsement 策略控制需要谁 批准链码定义 。 Endorsement 策略是 链码的默认背书策略 。 链码背书策略链码被批准并提交到通道时会指定一个背书策略。 批准阶段没有明确指明背书策略，就默认使用 Endorsement 策略 &quot;MAJORITY Endorsement&quot;。 要想使交易生效就需要大多数不同通道成员（组织）的执行并验证交易。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric MSP","slug":"Hyperledger-Fabric-MSP","date":"2022-09-23T04:46:20.000Z","updated":"2022-09-24T02:23:04.000Z","comments":true,"path":"2022/09/23/Hyperledger-Fabric-MSP/","link":"","permalink":"http://peapod.top/2022/09/23/Hyperledger-Fabric-MSP/","excerpt":"","text":"成员服务提供者（MSP）证书机构通过生成可以用来证实身份的由公钥和私钥形成的键值对来发放认证信息。 MSP是一个可让身份被信任和被网络中其他参与者公认的，而不需要暴露成员的私钥的机制。 MSP将一个身份(信用卡)转换为一个角色(在商店购买东西的能力)。 它给予组织、节点和通道建立MSPs的能力，使其确定谁可以在组织、节点和通道层次上运作。 加入一个需要许可的区块链网络： 拥有一个由网络信任的CA颁发的身份。 成为一个被网络成员认可和认可的 组织 的成员。MSP将身份与组织的成员资格联系在一起。成员资格是通过将成员的公钥添加到组织的MSP来实现的。 将MSP添加到网络上的一个联盟 或者通道。 确保MSP包括在网络中的策略 定义。 MSP通过标识参与者在节点或通道上拥有的特定特权，将身份转换为角色。 MSP域MSP 出现在两个位置： 在参与者节点本地（本地 MSP） 在通道配置中（通道 MSP） 本地MSP为客户端和节点(peer节点和排序节点)定义的。 本地MSPs定义节点的权限。(例如，谁是可以操作节点的peer节点管理员)。 每个节点都必须定义一个本地MSP，它定义了在该级别上谁拥有管理权或参与权。 通道MSP通道MSP在通道层面上定义了管理权和参与权。 本地MSP表现为文件系统上的文件夹结构，而通道MSP则在通道配置中被描述。 通道MSP识别谁在通道层次拥有权限。 每个参与通道的组织都必须为其定义一个MSP。 系统通道MSP包括参与排序服务的所有组织的MSP。 通道MSP也在通道中的每个节点的文件系统上实例化，并通过共识保持同步。 尽管每个节点的本地文件系统上都有每个通道MSP的副本，但从逻辑上讲，通道MSP存在并被维护于通道或网络上。 组织组织是一个逻辑上成员们的管理组。在单个MSP下管理其成员。 以组织的名字为前缀命名MSP。 组织单元（ou）一个组织也可以被划分为多个组织单元，每个单元都有一定的职责。 当CA颁发X.509证书时，证书中的OU字段指定该身份所属的业务流水线。 节点组织单元特殊类型的组织单元，有时称为节点组织单元，可用于授予角色以身份标识。 为了使用节点组织单元角色，通过在MSP目录下的配置文件config.yaml中启用“Node OUs”字段来实现: 1234567891011121314NodeOUs: Enable: true ClientOUIdentifier: Certificate: cacerts/ca.sampleorg-cert.pem OrganizationalUnitIdentifier: client PeerOUIdentifier: Certificate: cacerts/ca.sampleorg-cert.pem OrganizationalUnitIdentifier: peer AdminOUIdentifier: Certificate: cacerts/ca.sampleorg-cert.pem OrganizationalUnitIdentifier: admin OrdererOUIdentifier: Certificate: cacerts/ca.sampleorg-cert.pem OrganizationalUnitIdentifier: orderer MSP有4种节点组织单元角色: client peer admin orderer 联盟中的不同组织可以使用组织单元来区分彼此。在这种情况下，不同的组织必须为其信任链使用相同的根CA和中间CA，并分配OU字段来标识每个组织的成员们。 MSP结构本地MSP文件夹：","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric 身份\"","slug":"Hyperledger-Fabric-身份","date":"2022-09-23T04:09:28.000Z","updated":"2022-09-24T02:22:42.000Z","comments":true,"path":"2022/09/23/Hyperledger-Fabric-身份/","link":"","permalink":"http://peapod.top/2022/09/23/Hyperledger-Fabric-%E8%BA%AB%E4%BB%BD/","excerpt":"","text":"身份身份：确定了对资源的确切权限以及对参与者在区块链网络中拥有的信息的访问权限。 一个 MSP 是定义管理该组织有效身份规则的组件。 MSP 将可验证的身份转变为区块链网络的成员 。 Fabric 中默认的 MSP 实现使用 X.509 证书作为身份，采用传统的公钥基础结构（Public Key Infrastructure,PKI）分层模型。 PKI提供身份列表，MSP说哪些是参与网络的给定组织的成员。 PKI公钥基础结构（PKI）是一组互联网技术，可在网络中提供安全通信。 PKI 由向各方发布数字证书的证书授权中心组成。 PKI 有四个关键要素： 数字证书 公钥和私钥 证书授权中心 证书撤销列表 数字证书 数字证书是包含与证书持有者相关的属性的文档。 公钥是在证书中分发的，而私人签名密钥则不是。 只要对方信任证书颁发者，即证书授权中心（CA），密码学就允许 将证书提交给其他人以证明其身份。 CA 安全地保存某些加密信息（CA 的私钥），任何阅读证书的人都可以确定有关 Mary 的信息没有被篡改，它将始终具有 Mary Morris 的特定属性。 授权，公钥和私钥身份验证要求确保交换消息的各方创建特定消息的身份。 “完整性”的消息意味着在其传输期间不能被修改。 密钥之间唯一的数学关系使得私钥在消息上的签名，只有对应公钥在相同的消息上才可以与之匹配。 Mary 使用她的私钥对邮件进行签名。任何使用她的公钥查看签名消息的人都可以验证签名。 证书授权中心人员或节点能够通过由系统信任的机构为其发布的数字身份参与区块链网络。 数字身份：符合 X.509 标准并由证书授权中心（CA）颁发的经加密验证的数字证书。 证书授权中心向不同的参与者颁发证书。 证书由 CA 进行签名，并将参与者的公钥绑定在一起（并且可选是否具有全部属性列表）。 根 CA，中间 CA 和信任链 中间 CA 在跨多个组织颁发证书时提供了巨大的灵活性。 不同的组织可能使用不同的根 CA，或者使用具有不同中间 CA 的相同根 CA，这取决于网络的需求。 Fabric CA是一个私有根 CA 提供者，能够管理具有 X.509 证书形式的 Fabric 参与者的数字身份。 证书撤销列表是 CA 知道由于某些原因而被撤销的证书的引用列表。 当第三方想要验证另一方的身份时，它首先检查颁发 CA 的 CRL 以确保证书尚未被撤销。 MSP 发挥作用的地方——它确定了区块链网络特定组织的成员。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric网络架构","slug":"Hyperledger-Fabric网络架构","date":"2022-09-23T02:16:21.000Z","updated":"2022-09-24T02:22:20.000Z","comments":true,"path":"2022/09/23/Hyperledger-Fabric网络架构/","link":"","permalink":"http://peapod.top/2022/09/23/Hyperledger-Fabric%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/","excerpt":"","text":"区块链网络概念上描述组织以区块链网络的形式进行合作。 概念：区块链网络是一个为应用程序提供账本及智能合约服务的技术基础设施。 多个组织作为一个联盟形成一个网络，权限是由网络最初配置的时候联盟定义的规则实现。 实例网络 R4 被分配作为网络的初始者，它有权设置网络的初始版本。 网络是根据在网络配置 NC4 中指定的规则来进行管理 整个网络由组织 R1 和 R4 管理。 通道 C1 是根据在通道配置 CC1 中指定的规则来管理 排序服务 O4 作为这个网络 N 的一个网络管理员节点，并且使用系统通道。 每个组织都有一个首选的 CA。 创建网络 排序服务 O4 由一个单独的节点组成，是根据一个网络配置 NC4 来进行配置 证书颁发机构 CA4 被用来向管理员和组织 R4 的网络节点分配身份信息。 在定义 网络 N 的时候，第一件事情就是定义一个 排序服务 证书颁发机构CA4，它会被用来给管理者和网络节点颁发证书。 CA 颁发的证书也可以用来为交易提供签名，来表明一个组织对交易的结果进行背书。 每个组织会有一个 CA。 成员服务提供者将证书同成员组织进行匹配。 NC4使用MSP来分配在网络资源上的特殊权利。 个人理解： CA用来证明某一个成员属于那个组织，属于组织层面。 MSP表明某个成员在组织里的定位（如组织内的权限等），属于成员（组织内的成员）层面 X.509 证书被用于客户端应用的交易提案和智能合约的交易响应，来对交易进行数字签名。 添加网络管理员 使组织 R1 也成为了管理员。 R1 和 R4 在网络配置中便具有了相同的权限。 证书颁发机构 CA1 也被添加进来了，他用来标识 R1 组织的用户。 定义联盟 定义联盟 X1 联盟的定义被存储在了网络配置 NC4 为联盟创建通道 联盟 X1 为 R1 和 R2 创建的的通道 C1。 通道通过通道配置 CC1 来进行管理。 通道 C1 为联盟 X1 提供了一个私有的通信机制。 CC1 包含了赋予 R1 和 R2 在通道 C1 上的权利的规则。 被排序服务使用的特殊的系统通道。 节点和账本新增了两个组件，称作 Peer 节点 P1 和账本实例 L1。 物理上 P1 会存储账本 L1 的副本。 P1 和 O4 可以使用通道 C1 来进行通信。 Peer 节点是存储区块链账本副本的网络组件。 L1 会被物理地存储在 P1 上，但是 逻辑上 是存储在通道 C1 上。 CA1 颁发的 X.509 身份信息，它将 P1 和组织 R1 关联了起来。 使用排序 O4将P1 加入通道C1。 通道配置 CC1 来决定 P1 在这个通道中的权限。 个人理解： CA1将P1和R1连接起来。O4将P1和C1连接起来。 CA1：信息验证，CC1权限控制。 app和chaincode 智能合约 S5 被安装在了 P1 上。 组织 R1 中的客户端应用 A1 可以通过 Peer 节点 P1 使用 S5 来访问账本。 应用 A1 能够使用通道 C1 来连接指定的网络资源。 所有的访问都是由一个称为智能合约链码 S5 的特殊程序来管理的。 智能合约被用来帮助生成被分发到网络中每个节点的交易。 智能合约必须被安装，然后在通道中被定义。 作用：智能合约定义了交易逻辑，它控制了在世界状态中包含的一个业务对象的生命周期。 智能合约—&gt;打包—&gt;链码 链码部署到一个区块链网络中。 智能合约：管理交易。 链码：管理着智能合约应该如何被打包部署。 安装链码包组织 R1 中的管理员把S5安装到节点 P1 上。 定义链码链码安装在组织的 Peer 节点上。在一个通道范围内被管理和维护的。 每个组织需要批准一个链码定义，一系列参数来定义在一个通道中链码应该被如何使用。 管理员 R1 必须要批准 S5 的链码定义。 需要有效数量的组织来批准一个链码的定义（默认为大多数）。 R1 的管理员-&gt;提交 S5 的链码定义-&gt;通道 C1 定义提交后,S5 就可以被客户端应用 A1 调用了。 实际上是定义并提交了智能合约的接口到通道，而不是安装了智能合约的实现。 安装智能合约展示了我们是如何将它物理地存储在 Peer 节点上，实例化智能合约展示了我们是如何将它逻辑地存储在通道中。 背书策略链码定义提供的信息中最重要的部分就是背书策略。 它描述了在交易被其他的组织接受并存储在他们的账本副本上之前，哪些组织必须要同意此交易。 只有当 R1 和 R2 对交易进行背书之后，交易才能够被接受并存储到账本 L1 中。 调用智能合约客户端应用是通过发送交易提案给智能合约背书策略所指定的 Peer 的节点方式来调用智能合约的。 交易的提案会作为智能合约的输入 智能合约会使用它来生成一个背书交易响应 Peer 节点返回给客户端应用 完成网络将组织 R2 的基础设施添加到网络中。 生成并接受交易Peer 节点 存储智能合约; 节点只有在安装了智能合约之后才能够运行它 不存; 可以通过连接到通道来获取一个智能合约的接口信息。 带有智能合约的 Peer 节点：帮助生成交易。 所有的 Peer 节点：可以验证并接受或者拒绝交易存入他们的账本 L1 的副本中。 只有安装了智能合约的 Peer 节点才能够参与交易背书的流程。 Peer 节点的类型 提交节点：每个 Peer 节点都是一个提交节点。接收生成的区块，提交到 Peer 节点的账本副本中。 背书节点：安装了智能合约的 Peer 节点都可以作为一个背书节点。智能合约必须要被客户端应用使用，来生成一个被签名的交易响应。 Peer 节点的角色 主节点：负责将交易从排序节点分发到该组织中其他的提交节点。 锚节点：锚节点能够帮助很多不同的跨组织间的通信。 一般都会有一个主节点，至少一个背书节点和一个提交节点。 gossip 协议，可以容纳大量的 Peer 节点来支持这样的拓扑。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric 模型","slug":"Hyperledger-Fabric-模型","date":"2022-09-22T01:59:07.000Z","updated":"2022-09-24T02:21:52.000Z","comments":true,"path":"2022/09/22/Hyperledger-Fabric-模型/","link":"","permalink":"http://peapod.top/2022/09/22/Hyperledger-Fabric-%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"Hyperledger Fabric 模型简介模型： 资产 链码 账本 隐私 成员服务 共识 资产有形（房地产和硬件）到无形资产（合同和知识产权）。 提供使用链码交易来修改资产的功能。 资产在 Hyperledger Fabric 中表示为键值对的集合，状态更改记录为 Channel 账本上的交易。资产可以用二进制或 JSON 格式表示。 链码链码是定义单项或多项资产的软件，和能修改资产的交易指令；换句话说，它是业务逻辑。 强制执行读取或更改键值对或其他状态数据库信息的规则。 账本特点特点： 基于键的查找、范围查询和组合键查询来查询和更新账本； 富查询语言进行只读查询； 查询一个键的账本历史记录（数据溯源）； 交易包括链码读取键&#x2F;值（读集）以及链码写入键&#x2F;值（写集）； 交易包含每个背书节点的签名，并被提交给排序服务； 交易按顺序打包到区块，并被排序服务“分发”到通道上的节点； 节点根据背书策略验证交易并执行策略； 附加一个区块之前，会执行一次版本检查，以确保被读取的资产的状态自链码执行以来未发生更改； 一旦交易被验证并提交，就具有不变性； 一个通道的账本包含一个配置区块，用于定义策略、访问控制列表和其他相关信息； 通道包含MSP的实例，允许从不同的证书颁发机构（CA）生成加密材料 隐私当该通道上的组织子集需要对其交易数据保密时，私有数据集合用于将此数据隔离在私有数据库中，在逻辑上与通道账本分开，只有经授权的组织子集才能访问。 通道在更广泛的网络上保持交易的私密性，而集合则在通道上的组织子集之间保持数据的私密性。 进一步模糊数据：在将交易发送到排序服务并将区块附加到账本之前，可以使用诸如 AES 之类的通用加密算法对链码内的值进行加密（部分或全部）。 成员服务所有参与者都拥有已知的身份。 公钥基础设施（PKI）用于生成与组织、网络组件以及终端用户或客户端应用程序相关联的加密证书。 共识整个交易流程：从提案和背书到排序、验证和提交。 共识被定义为组成区块的一组交易的正确性的闭环验证。 背书策略：规定哪些特定成员必须背书某个交易类别。 系统链码：确保背书策略得到执行和维护。 提交之前，节点通过系统链码确保存在足够的背书，并且来自适当的实体。 共识并不仅仅局限于一批交易的商定顺序；相反，它的首要特征是交易从提案到提交的过程中不断进行核查而附带实现的。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"Hyperledger Fabric 简介","slug":"Hyperledger-Fabric-简介","date":"2022-09-22T01:10:34.000Z","updated":"2022-09-22T01:42:56.000Z","comments":true,"path":"2022/09/22/Hyperledger-Fabric-简介/","link":"","permalink":"http://peapod.top/2022/09/22/Hyperledger-Fabric-%E7%AE%80%E4%BB%8B/","excerpt":"","text":"简介比特币和以太坊属于同一类区块链，我们将其归类为公共非许可（Public Permissionless）区块链技术。 Hyperledger Fabric开源的企业级许可分布式账本技术平台。（DLT） Fabric 具有高度模块化和可配置的架构。 支持通用编程语言编写智能合约。 Fabric 平台也是许可的。 支持可插拔的共识协议。 模块化组成： 可插拔的排序服务 排序 广播 可插拔的成员服务提供者 将网络中的实体与加密身份相关联 智能合约（“链码”）隔离运行在容器环境 配置支持多种 DBMS 可插拔的背书和验证策略 许可和非许可非许可：基于“工作量证明（PoW）”的拜占庭容错共识许可： 崩溃容错（CFT）或拜占庭容错（BFT）共识协议 智能合约区块链应用的业务逻辑。关键点： 多个智能合约在网络中同时运行 动态部署 不被信任 执行-排序-验证为了解决顺序执行模型面临的弹性、灵活性、可伸缩性、性能和机密性问题 步骤： 执行交易并背书 共识协议排序 在提交到账本之前，背书策略验证交易 Fabric 在交易顺序达成最终一致前执行交易。 并行执行：每个交易只需要由满足交易的背书策略所必需的节点的子集来执行（背书）。第一阶段消除了任何非确定性。Fabric 是第一个能使用标准编程语言的区块链技术。 隐私和保密零知识证明（Zero Knowledge Proofs，ZKP）。通过其通道架构和私有数据特性实现保密。参与到通道的节点才有权访问智能合约（链码）和交易数据，以此保证了隐私性和保密性。 可插拔共识进行 CFT（崩溃容错）或 BFT（拜占庭容错）的排序。提供了一种基于etcd 库 中 Raft 协议 的 CFT 排序服务的实现。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"}],"author":"taweizhong"},{"title":"服务器安装Clash","slug":"服务器安装Clash","date":"2022-09-17T09:58:46.000Z","updated":"2022-09-17T10:30:42.000Z","comments":true,"path":"2022/09/17/服务器安装Clash/","link":"","permalink":"http://peapod.top/2022/09/17/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E8%A3%85Clash/","excerpt":"","text":"Clash安装教程下载地址（https://github.com/Dreamacro/clash） 找到对应的版本复制下载地址. 123456mkdir Clsahwget ‘包的地址’gunzip ‘下载下来的文件’ -d ./Clashcd Clashmv ‘文件名’ clashchmod +x clash 配置订阅信息123cd /Clashsudo wget -O config.yaml [订阅链接]sudo wget -O Country.mmdb https://www.sub-speeder.com/client-download/Country.mmdb 设置系统代理1vim /etc/profile 在最后面添加 12export http_proxy=&quot;http://127.0.0.1:7890&quot;export https_proxy=&quot;http://127.0.0.1:7890&quot; 保存退出后 1source /etc/profile 启动1./clash -d . 实现网络代理的切换首先启动clash 可以看到外部可以访问的端口为9090 记得配置服务器的端口，可以使外部访问9090端口 点击clash.razord.top进行配置 host 设置为服务器的IP，密码可以不用配置。 在代理中切换 在GUI界面中实现配置点击查看配置 clash for linux ，适用于ubuntu 20.04（更新于2021.11.6） - 知乎 (zhihu.com)","categories":[{"name":"实用","slug":"实用","permalink":"http://peapod.top/categories/%E5%AE%9E%E7%94%A8/"}],"tags":[{"name":"clash","slug":"clash","permalink":"http://peapod.top/tags/clash/"}],"author":"taweizhong"},{"title":"BeeGo实现文件的上传与下载","slug":"BeeGo实现文件的上传与下载","date":"2022-09-14T13:41:30.000Z","updated":"2022-09-14T14:11:20.000Z","comments":true,"path":"2022/09/14/BeeGo实现文件的上传与下载/","link":"","permalink":"http://peapod.top/2022/09/14/BeeGo%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%8A%E4%BC%A0%E4%B8%8E%E4%B8%8B%E8%BD%BD/","excerpt":"","text":"beego实现文件的上传和下载文件的上传html的处理 1234&lt;form id=&quot;&quot; method=&quot;POST&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;input id=&quot;myfile&quot; name=&quot;myfile&quot; type=&quot;file&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;保存&quot; /&gt;&lt;/form&gt; 控制器处理 123456789type ServiceController struct&#123; beego.Controller&#125;func (c *ServiceController) Post()&#123; f, h, _ := this.GetFile(&quot;myfile&quot;) //获取上传的文件 path := h.Filename //文件目录 f.Close() //关闭上传的文件 this.SaveToFile(&quot;myfile&quot;, path) &#125; 文件的下载123456789type FileOptDownloadController struct &#123; beego.Controller&#125;func (this *FileOptDownloadController) Get() &#123; //第一个参数是文件的地址，第二个参数是下载显示的文件的名称 this.Ctx.Output.Download(&quot;static/img/1.jpg&quot;,&quot;tu1.jpg&quot;)&#125;","categories":[{"name":"Web","slug":"Web","permalink":"http://peapod.top/categories/Web/"}],"tags":[{"name":"beego","slug":"beego","permalink":"http://peapod.top/tags/beego/"}],"author":"taweizhong"},{"title":"BeeGo教程","slug":"BeeGo教程","date":"2022-09-13T08:36:10.000Z","updated":"2022-09-13T12:42:56.000Z","comments":true,"path":"2022/09/13/BeeGo教程/","link":"","permalink":"http://peapod.top/2022/09/13/BeeGo%E6%95%99%E7%A8%8B/","excerpt":"","text":"Beego 框架1.beego框架 工作流程beego框架是一个使用Go语言快速开发API、Web及后端服务等各种应用的MVC框架。beego是一个完整的MVC框架，包括controller、model以及view等MVC必备模板。 HTTP请求从main函数进入框架 解析url路由，确定执行那个控制器 执行前请求过滤器 执行控制器 执行请求后的过滤器 输出结果 2.beego框架 安装 设置代理 12$ go env -w GO111MODULE=on$ go env -w GOPROXY=https://goproxy.cn,direct 安装beego和bee（项目工具） 1$ go get github.com/beego/beego 使用bee创建项目 1bee new 项目名称 项目结构 运行项目 1bee run 3.框架使用使用beego开发go语言项目，需要编写控制器、业务模型以及view等模块。 控制器controller 1234567891011121314// 定义一个控制器结构体// 一般一个模块定义一个控制器type MainController struct &#123; beego.Controller&#125;// 覆盖beego.Controller的Get方法，用于处理 RESTful 请求中的 get 请求// beego.Controller 默认支持多种 RESTful方法，例如：Post、Put、Delete等func (c *MainController) Get() &#123; // Data是继承过来的属性，是 map 类型，可以保存任意类型数据，主要用于保存请求响应数据 c.Data[&quot;Website&quot;] = &quot;&quot; c.Data[&quot;Email&quot;] = &quot;&quot; // 设置需要渲染的模板文件，框架会去 views 目录查找这个模板文件 c.TplName = &quot;index.html&quot;&#125; 设置路由Url 123456func init() &#123; // 使用 beego.Router 函数，注册路由规则。 // 第一个参数是url路由，第二个参数是控制器 // 这里的意思就是将访问 / 这个url的请求，交给controllers.MainController控制器处理。 beego.Router(&quot;/&quot;, &amp;controllers.MainController&#123;&#125;)&#125; 路由规则说明： ​ 只是定义了Url 由哪个控制器执行，但是没有说明 Url 请求由控制器的那个函数执行，一个控制器可以包含多个函数。 编写model业务逻辑 定义表结构 123456CREATE TABLE `users` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;自增ID&#x27;, `username` varchar(30) NOT NULL COMMENT &#x27;账号&#x27;, `password` varchar(100) NOT NULL COMMENT &#x27;密码&#x27;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 初始化数据库连接 1234567891011121314151617181920212223package mainimport ( _ &quot;codebaoku/routers&quot; &quot;github.com/astaxie/beego&quot; &quot;github.com/astaxie/beego/orm&quot; _ &quot;github.com/go-sql-driver/mysql&quot;)func init() &#123; // 这里注册一个default默认数据库，数据库驱动是mysql. // 第三个参数是数据库dsn, 配置数据库的账号密码，数据库名等参数 // dsn参数说明： // username - mysql账号 // password - mysql密码 // db_name - 数据库名 // 127.0.0.1:3306 - 数据库的地址和端口 orm.RegisterDataBase(&quot;default&quot;, &quot;mysql&quot;, &quot;username:password@tcp(主机IP:端口号)/db_name?charset=utf8&quot;)&#125;func main() &#123; beego.Run()&#125; 创建model 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 定义User模型，绑定users表结构, 其实就是用来保存sql查询结果。type User struct &#123; Id int Username string Password string&#125;// 定义User 模型绑定那个表？func (u *User) TableName() string &#123; // 返回mysql表名 return &quot;users&quot;&#125;//初始化函数，可以用来向orm注册modelfunc init() &#123; // 向orm注册user模型 orm.RegisterModel(&amp;User&#123;&#125;)&#125;//初始化函数，可以用来向orm注册modelfunc init() &#123; // 向orm注册user模型 orm.RegisterModel(&amp;User&#123;&#125;)&#125;// 根据id查询用户信息func GetUserById(id int) *User &#123; if id == 0 &#123; return nil &#125; // 创建orm对象, 后面都是通过orm对象操作数据库 o := orm.NewOrm() // 初始化一个User模型对象 user := User&#123;&#125; // 设置查询参数 user.Id = id // 调用Read方法，根据user设置的参数，查询一条记录，结果保存到user结构体变量中 // 默认是根据主键进行查询 // 等价sql： SELECT `id`, `username`, `password` FROM `users` WHERE `id` = 1 err := o.Read(&amp;user) // 检测查询结果， if err == orm.ErrNoRows &#123; // 找不到记录 return nil &#125; else if err == orm.ErrMissPK &#123; // 找不到住建 return nil &#125; return &amp;user&#125; 控制器调用model 12345678910111213func (c *MainController) Get() &#123; c.Data[&quot;Website&quot;] = &quot;codebaoku.com&quot; c.Data[&quot;Email&quot;] = &quot;go@codebaoku.com&quot; // 调用model，查询用户id为1 的用户信息 user := models.GetUserById(1) // 然后将user数据保存到Data中, 将参数传给后面的 views 视图模板处理 c.Data[&quot;user&quot;] = user // 使用新的视图模板user.tpl c.TplName = &quot;user.tpl&quot;&#125; 编写view视图 项目打包 使用 bee 工具打包，bee 工具可以一键将项目需要的相关文件一起打包成一个压缩包，只需要到线上解压即可。 1bee pack 参数配置beego 默认使用了 INI 格式解析配置文件，通常在项目中会存在很多系统参数、业务参数配置，这些参数通常都是通过配置文件进行配置，而且不是写死在代码里面。 提示：修改配置文件后，需要重启应用，配置才生效，即使使用bee run运行项目也得重启。 系统参数 1234567# 这是注释#应用名称appname = codebaoku#http 服务端口httpport = 8080#运行模式，常用的运行模式有dev, test, prodrunmode = dev 参数名 默认值 说明 AppName beego 应用名 RunMode dev 程序运行模式，常用模式有dev、test、prod，一般用于区分不同的运行环境 RouterCaseSensitive true 是否路由忽略大小写匹配 ServerName beego beego 服务器默认在请求的时候输出 server 头的值。 RecoverPanic true 是否异常恢复，默认值为 true，即当应用出现异常的情况，通过 recover 恢复回来，而不会导致应用异常退出。 EnableGzip false 是否开启 gzip 支持 MaxMemory 64M 文件上传默认内存缓存大小，单位是字节 AutoRender true 是否模板自动渲染，对于 API 类型的应用，应用需要把该选项设置为 false，不需要渲染模板。 StaticDir static 静态文件目录设置 ViewsPath views 模板路径 Graceful false 是否开启热升级，默认是 false，关闭热升级。 ServerTimeOut 0 设置 HTTP 的超时时间，默认是 0，不超时。 HTTPAddr 应用监听地址，默认为空，监听所有的网卡 IP。 HTTPPort 8080 应用监听端口 EnableHTTPS false 是否启用 HTTPS，默认是 false 关闭。当需要启用时，先设置 EnableHTTPS &#x3D; true，并设置 HTTPSCertFile 和 HTTPSKeyFile HTTPSAddr https应用监听地址，默认为空，监听所有的网卡 IP。 HTTPSPort 10443 https应用监听端口 HTTPSCertFile 开启 HTTPS 后，ssl 证书路径 HTTPSKeyFile 开启 HTTPS 之后，SSL 证书 keyfile 的路径。 EnableAdmin false 是否开启进程内监控模块，默认 false 关闭。 AdminAddr localhost 监控程序监听的地址。 AdminPort 8088 监控程序监听的地址。 SessionOn false session 是否开启 SessionProvider memory session 的引擎， 详情参考session章节的教程 SessionName beegosessionID 存在客户端的 cookie 名称。 SessionGCMaxLifetime 3600 session 过期时间, 单位秒。 SessionProviderConfig 配置信息，根据不同的session引擎设置不同的配置信息，详细的配置请参考session章节的教程 SessionCookieLifeTime 3600 session 默认存在客户端的 cookie 的时间, 单位秒。 SessionDomain session cookie 存储域名。 自定义参数 可以自定义配置，然后通过beego.AppConfig对象的函数读取配置。 12345# 下面是关于mysql数据库的配置参数mysql_user = &quot;root&quot;mysql_password = &quot;123456&quot;mysql_host = &quot;127.0.0.1:3306&quot;mysql_dbname = &quot;codebaoku&quot; 读取配置代码: 1234beego.AppConfig.String(&quot;mysql_user&quot;)beego.AppConfig.String(&quot;mysql_password&quot;)beego.AppConfig.String(&quot;mysql_host&quot;)beego.AppConfig.String(&quot;mysql_dbname&quot;)","categories":[{"name":"Web","slug":"Web","permalink":"http://peapod.top/categories/Web/"}],"tags":[{"name":"beego","slug":"beego","permalink":"http://peapod.top/tags/beego/"}],"author":"taweizhong"},{"title":"匿名函数用作回调函数","slug":"匿名函数用作回调函数","date":"2022-09-09T07:32:30.000Z","updated":"2022-09-13T09:11:56.000Z","comments":true,"path":"2022/09/09/匿名函数用作回调函数/","link":"","permalink":"http://peapod.top/2022/09/09/%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%E7%94%A8%E4%BD%9C%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/","excerpt":"","text":"匿名函数用作回调函数123456789101112131415package mainimport &quot;fmt&quot;func fun(list []int, f func(int))&#123; for _, v := range list &#123; f(v) &#125;&#125;func main() &#123; fun([]int&#123;1, 2, 3, 4, 5&#125;, func(n int) &#123; fmt.Printf(&quot;n: %v\\n&quot;, n) &#125;)&#125; 先执行fun()函数 在执行f(v)的时候回调 传值的匿名函数。会将参数v的值传递给匿名函数的形参，在你匿名函数实现打印。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Go设计模式","slug":"go工厂模式","date":"2022-09-09T00:54:08.000Z","updated":"2022-09-11T00:43:56.000Z","comments":true,"path":"2022/09/09/go工厂模式/","link":"","permalink":"http://peapod.top/2022/09/09/go%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"Go 设计模式工厂设计模式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293package maintype an interface&#123; eat() call()&#125;type cat struct&#123; name string&#125;type dog struct&#123; name string&#125;func (*cat)eat()&#123; fmt.Println(&quot;cat eat&quot;)&#125;func (*cat)call()&#123; fmt.Println(&quot;cat call&quot;)&#125;func (*dog)eat()&#123; fmt.Println(&quot;dog eat&quot;)&#125;func (*dog)call()&#123; fmt.Println(&quot;dog call&quot;)&#125;func fun(i int) an &#123; if i == 1 &#123; return &amp;cat&#123;&#125; &#125; else &#123; return &amp;dog&#123;&#125; &#125;&#125;// 多态 向上转型func main()&#123; cat := fun(1) cat.eat() cat.call() dog := fun(2) dog.eat() dog.call()&#125;``` &gt; 将实现接口的对象赋值与接口变量### 单例设计模式 一个类只有一个对象实例```gopackage mainimport ( &quot;fmt&quot; &quot;sync&quot;)type Sing interface &#123; do()&#125;type some struct &#123;&#125;func (*some) do() &#123; fmt.Println(&quot;do some&quot;)&#125;var ( once sync.Once s *some)func Fun() Sing &#123; once.Do( func() &#123; s = &amp;some&#123;&#125; &#125;, ) return s&#125;func main() &#123; s1 := Fun() fmt.Printf(&quot;s1: %p\\n&quot;, s1) s2 := Fun() fmt.Printf(&quot;s1: %p\\n&quot;, s2)&#125; 抽象工厂模式构建者模式","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"部署测试","slug":"部署测试","date":"2022-09-08T12:21:54.000Z","updated":"2022-09-08T12:46:48.000Z","comments":true,"path":"2022/09/08/部署测试/","link":"","permalink":"http://peapod.top/2022/09/08/%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/","excerpt":"","text":"这是一个测试文件","categories":[],"tags":[{"name":"测试","slug":"测试","permalink":"http://peapod.top/tags/%E6%B5%8B%E8%AF%95/"}],"author":"taweizhong"},{"title":"Hello World","slug":"hello-world","date":"2022-09-08T07:27:58.000Z","updated":"2022-09-08T07:27:58.000Z","comments":true,"path":"2022/09/08/hello-world/","link":"","permalink":"http://peapod.top/2022/09/08/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"说明","slug":"说明","permalink":"http://peapod.top/categories/%E8%AF%B4%E6%98%8E/"}],"tags":[{"name":"说明","slug":"说明","permalink":"http://peapod.top/tags/%E8%AF%B4%E6%98%8E/"}],"author":"taweizhong"},{"title":"","slug":"Gin框架","date":"2022-09-05T13:45:23.000Z","updated":"2022-09-05T13:45:23.000Z","comments":true,"path":"2022/09/05/Gin框架/","link":"","permalink":"http://peapod.top/2022/09/05/Gin%E6%A1%86%E6%9E%B6/","excerpt":"","text":"第一个Gin项目12345678package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func main()&#123; e := gin.Default() e.Run()//默认端口号8080&#125; Gin处理form表单go程序1234567891011121314151617181920212223package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func gologin(c *gin.Context)&#123; c.HTML(200, &quot;login.html&quot;, nil)&#125;func login(c *gin.Context)&#123; username := c.PostForm(&quot;username&quot;) password := c.PostForm(&quot;password&quot;) c.HTML(200, &quot;index.html&quot;, gin.H&#123; &quot;username&quot;: username, &quot;password&quot;: password, &#125;)&#125;func main()&#123; e := gin.Default() e.Static(&quot;assets&quot;, &quot;./assets&quot;) e.LoadHTMLGlob(&quot;tempates/*&quot;) e.GET(&quot;/login&quot;, gologin) e.POST(&quot;/login&quot;, login) e.Run()&#125; index.html1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;主页&lt;/h1&gt; &#123;&#123;.name&#125;&#125; &#123;&#123;.password&#125;&#125;&lt;/body&gt;&lt;/html&gt; login.html123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;./assets/css/login.css&quot;&gt; &lt;title&gt;login&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;form-container&quot;&gt; &lt;div class=&quot;formleft&quot;&gt; &lt;img src=&quot;./assets/img/touxiang.png&quot;&gt; &lt;/div&gt; &lt;div class=&quot;formright&quot;&gt; &lt;h1&gt;欢迎回来&lt;/h1&gt; &lt;p class=&quot;py-1&quot;&gt;请先登录&lt;/p&gt; &lt;form action=&quot;/login&quot; method=&quot;post&quot;&gt; &lt;label&gt; &lt;p&gt;用户名&lt;/p&gt; &lt;input type=&quot;text&quot; name=&quot;user&quot; class=&quot;user-input&quot;&gt; &lt;/label&gt; &lt;label&gt; &lt;p&gt;密码&lt;/p&gt; &lt;input type=&quot;password&quot; name=&quot;password&quot; class=&quot;pw-input&quot;&gt; &lt;/label&gt; &lt;button class=&quot;login&quot; type=&quot;submit&quot;&gt;登录&lt;/button&gt; &lt;/form&gt; &lt;a href=&quot;./register&quot;&gt;&lt;button class=&quot;qiehuan&quot; type=&quot;submit&quot;&gt;注册&lt;/button&gt;&lt;/button&gt;&lt;/a&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 当有多选框时，使用c.PostFormArray(&quot;name&quot;)函数得到参数数组。 Gin获取请求参数GET请求参数12345678910111213141516package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func login(c *gin.Context)&#123; key := c.Query(&quot;wd&quot;) // value := c.DefaultQuery(&quot;wd&quot;, &quot;世界&quot;) 查询不到用默认值 c.String(200, key)&#125;func main()&#123; e := gin.Default() e.GET(&quot;/login&quot;, login) e.Run()&#125; POST请求参数12345func fun(c *gin.Context)&#123; username := c.PostForm(&quot;username&quot;) password := c.DefaultPostForm(&quot;password&quot;) // 查询不到用默认值 c.String(200, username)&#125; 路径参数12345678910111213141516package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func login(c *gin.Context)&#123; s := c.Param(&quot;username&quot;) c.String(200, s)&#125;func main()&#123; e := gin.Default() // localhost:8080/login/taweizhong e.GET(&quot;/login/:username&quot;, login) e.Run()&#125; Gin数据绑定POST和GET参数绑定123456789101112131415161718192021package mainimport &quot;github.com/gin-gonic/gin&quot;type User struct&#123; Uaername string `form:&quot;username&quot;` Password string `form:&quot;password&quot;`&#125;func login(c *gin.Context)&#123; var user User c.ShouldBind(&amp;user) // form表单绑定结构体 c.String(200, &quot;User:%s&quot;, user)&#125;func main() &#123; e := gin.Default() // localhost:8080/login?username=taweizhong&amp;password=111 可以绑定查询参数 e.POST(&quot;/login&quot;, login) e.Run()&#125; 路径绑定123456789101112131415161718192021package mainimport ( &quot;github.com/gin-gonic/gin&quot;)type User struct&#123; Uaername string `uri:&quot;username&quot;` Password string `uri:&quot;password&quot;`&#125;func login(c *gin.Context)&#123; var user User c.ShouldBindUri(&amp;user) c.String(200, &quot;User:%s&quot;, user)&#125;func main()&#123; e := gin.Default() // localhost:8080/login/taweizhong/111 e.GET(&quot;/login/:username/:password&quot;, login) e.Run()&#125; Gin访问静态文件和模板文件1234567891011121314151617181920212223package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func gologin(c *gin.Context)&#123; c.HTML(200, &quot;login.html&quot;, nil)&#125;func login(c *gin.Context)&#123; username := c.PostForm(&quot;username&quot;) password := c.PostForm(&quot;password&quot;) c.HTML(200, &quot;index.html&quot;, gin.H&#123; &quot;username&quot;: username, &quot;password&quot;: password, &#125;)&#125;func main()&#123; e := gin.Default() e.Static(&quot;/assets&quot;, &quot;./assets&quot;) e.LoadHTMLGlob(&quot;tempates/*&quot;) e.GET(&quot;/login&quot;, gologin) e.POST(&quot;/login&quot;, login) e.Run()&#125; e.Static(&quot;/assets&quot;, &quot;./assets&quot;)读取css和js等静态文件 e.LoadHTMLGlob(&quot;tempates/*&quot;)读取html等模板文件 cookie123456789101112131415161718package mainimport &quot;github.com/gin-gonic/gin&quot;func login(c *gin.Context) &#123; s, err := c.Cookie(&quot;username&quot;) if err != nil &#123; s = &quot;taweizhong&quot; c.SetCookie(&quot;username&quot;, s, 60*60, &quot;/&quot;, &quot;localhost&quot;, false, true) //cookie的名称 值 存活时间 路径 域 安全访问 是否是HTTP &#125; c.String(200, &quot;test&quot;)&#125;func main() &#123; e := gin.Default() e.GET(&quot;/login&quot;, login) e.Run()&#125; session123456789101112131415161718192021222324252627282930package mainimport ( &quot;fmt&quot; &quot;github.com/gin-contrib/sessions&quot; &quot;github.com/gin-contrib/sessions/cookie&quot; &quot;github.com/gin-gonic/gin&quot;)func login(c *gin.Context) &#123; sessions := sessions.Default(c) fmt.Printf(&quot;sessions:----------- %v\\n&quot;, sessions) S := sessions.Get(&quot;name&quot;) fmt.Printf(&quot;S:---------- %v\\n&quot;, S) if sessions.Get(&quot;hello&quot;) != &quot;world&quot;&#123; sessions.Set(&quot;hello&quot;, &quot;world&quot;) sessions.Save() &#125; fmt.Printf(&quot;sessions:------- %v\\n&quot;, sessions)&#125;func main() &#123; e := gin.Default() store := cookie.NewStore([]byte(&quot;1&quot;)) e.Use(sessions.Sessions(&quot;name&quot;, store)) e.GET(&quot;/login&quot;, login) e.Run()&#125;","categories":[],"tags":[]},{"title":"Gin访问静态文件和模板文件","slug":"Gin访问静态文件和模板文件","date":"2022-09-05T03:26:27.000Z","updated":"2022-09-07T03:47:52.000Z","comments":true,"path":"2022/09/05/Gin访问静态文件和模板文件/","link":"","permalink":"http://peapod.top/2022/09/05/Gin%E8%AE%BF%E9%97%AE%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E5%92%8C%E6%A8%A1%E6%9D%BF%E6%96%87%E4%BB%B6/","excerpt":"","text":"Gin访问静态文件和模板文件1234567891011121314151617181920212223package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func gologin(c *gin.Context)&#123; c.HTML(200, &quot;login.html&quot;, nil)&#125;func login(c *gin.Context)&#123; username := c.PostForm(&quot;username&quot;) password := c.PostForm(&quot;password&quot;) c.HTML(200, &quot;index.html&quot;, gin.H&#123; &quot;username&quot;: username, &quot;password&quot;: password, &#125;)&#125;func main()&#123; e := gin.Default() e.Static(&quot;/assets&quot;, &quot;./assets&quot;) e.LoadHTMLGlob(&quot;tempates/*&quot;) e.GET(&quot;/login&quot;, gologin) e.POST(&quot;/login&quot;, login) e.Run()&#125; e.Static(&quot;/assets&quot;, &quot;./assets&quot;)读取css和js等静态文件 e.LoadHTMLGlob(&quot;tempates/*&quot;)读取html等模板文件","categories":[{"name":"Web","slug":"Web","permalink":"http://peapod.top/categories/Web/"}],"tags":[{"name":"Gin","slug":"Gin","permalink":"http://peapod.top/tags/Gin/"}],"author":"taweizhong"},{"title":"Gin数据绑定","slug":"Gin数据绑定","date":"2022-09-05T03:26:14.000Z","updated":"2022-09-07T03:49:06.000Z","comments":true,"path":"2022/09/05/Gin数据绑定/","link":"","permalink":"http://peapod.top/2022/09/05/Gin%E6%95%B0%E6%8D%AE%E7%BB%91%E5%AE%9A/","excerpt":"","text":"Gin数据绑定POST和GET参数绑定123456789101112131415161718192021package mainimport &quot;github.com/gin-gonic/gin&quot;type User struct&#123; Uaername string `form:&quot;username&quot;` Password string `form:&quot;password&quot;`&#125;func login(c *gin.Context)&#123; var user User c.ShouldBind(&amp;user) // form表单绑定结构体 c.String(200, &quot;User:%s&quot;, user)&#125;func main() &#123; e := gin.Default() // localhost:8080/login?username=taweizhong&amp;password=111 可以绑定查询参数 e.POST(&quot;/login&quot;, login) e.Run()&#125; 路径绑定123456789101112131415161718192021package mainimport ( &quot;github.com/gin-gonic/gin&quot;)type User struct&#123; Uaername string `uri:&quot;username&quot;` Password string `uri:&quot;password&quot;`&#125;func login(c *gin.Context)&#123; var user User c.ShouldBindUri(&amp;user) c.String(200, &quot;User:%s&quot;, user)&#125;func main()&#123; e := gin.Default() // localhost:8080/login/taweizhong/111 e.GET(&quot;/login/:username/:password&quot;, login) e.Run()&#125;","categories":[{"name":"Web","slug":"Web","permalink":"http://peapod.top/categories/Web/"}],"tags":[{"name":"Gin","slug":"Gin","permalink":"http://peapod.top/tags/Gin/"}],"author":"taweizhong"},{"title":"Gin获取请求参数","slug":"Gin获取请求参数","date":"2022-09-05T03:25:57.000Z","updated":"2022-09-07T03:48:40.000Z","comments":true,"path":"2022/09/05/Gin获取请求参数/","link":"","permalink":"http://peapod.top/2022/09/05/Gin%E8%8E%B7%E5%8F%96%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0/","excerpt":"","text":"Gin获取请求参数GET请求参数12345678910111213141516package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func login(c *gin.Context)&#123; key := c.Query(&quot;wd&quot;) // value := c.DefaultQuery(&quot;wd&quot;, &quot;世界&quot;) 查询不到用默认值 c.String(200, key)&#125;func main()&#123; e := gin.Default() e.GET(&quot;/login&quot;, login) e.Run()&#125; POST请求参数12345func fun(c *gin.Context)&#123; username := c.PostForm(&quot;username&quot;) password := c.DefaultPostForm(&quot;password&quot;) // 查询不到用默认值 c.String(200, username)&#125; 路径参数12345678910111213141516package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func login(c *gin.Context)&#123; s := c.Param(&quot;username&quot;) c.String(200, s)&#125;func main()&#123; e := gin.Default() // localhost:8080/login/taweizhong e.GET(&quot;/login/:username&quot;, login) e.Run()&#125;","categories":[{"name":"Web","slug":"Web","permalink":"http://peapod.top/categories/Web/"}],"tags":[{"name":"Gin","slug":"Gin","permalink":"http://peapod.top/tags/Gin/"}],"author":"taweizhong"},{"title":"Gin处理form表单","slug":"Gin处理form表单","date":"2022-09-05T03:25:22.000Z","updated":"2023-12-16T09:25:10.000Z","comments":true,"path":"2022/09/05/Gin处理form表单/","link":"","permalink":"http://peapod.top/2022/09/05/Gin%E5%A4%84%E7%90%86form%E8%A1%A8%E5%8D%95/","excerpt":"","text":"Gin处理form表单go程序1234567891011121314151617181920212223package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func gologin(c *gin.Context)&#123; c.HTML(200, &quot;login.html&quot;, nil)&#125;func login(c *gin.Context)&#123; username := c.PostForm(&quot;username&quot;) password := c.PostForm(&quot;password&quot;) c.HTML(200, &quot;index.html&quot;, gin.H&#123; &quot;username&quot;: username, &quot;password&quot;: password, &#125;)&#125;func main()&#123; e := gin.Default() e.Static(&quot;assets&quot;, &quot;./assets&quot;) e.LoadHTMLGlob(&quot;tempates/*&quot;) e.GET(&quot;/login&quot;, gologin) e.POST(&quot;/login&quot;, login) e.Run()&#125; index.html1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;主页&lt;/h1&gt; &#123;&#123;.name&#125;&#125; &#123;&#123;.password&#125;&#125;&lt;/body&gt;&lt;/html&gt; login.html123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;./assets/css/login.css&quot;&gt; &lt;title&gt;login&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;form-container&quot;&gt; &lt;div class=&quot;formleft&quot;&gt; &lt;img src=&quot;./assets/img/touxiang.png&quot;&gt; &lt;/div&gt; &lt;div class=&quot;formright&quot;&gt; &lt;h1&gt;欢迎回来&lt;/h1&gt; &lt;p class=&quot;py-1&quot;&gt;请先登录&lt;/p&gt; &lt;form action=&quot;/login&quot; method=&quot;post&quot;&gt; &lt;label&gt; &lt;p&gt;用户名&lt;/p&gt; &lt;input type=&quot;text&quot; name=&quot;user&quot; class=&quot;user-input&quot;&gt; &lt;/label&gt; &lt;label&gt; &lt;p&gt;密码&lt;/p&gt; &lt;input type=&quot;password&quot; name=&quot;password&quot; class=&quot;pw-input&quot;&gt; &lt;/label&gt; &lt;button class=&quot;login&quot; type=&quot;submit&quot;&gt;登录&lt;/button&gt; &lt;/form&gt; &lt;a href=&quot;./register&quot;&gt;&lt;button class=&quot;qiehuan&quot; type=&quot;submit&quot;&gt;注册&lt;/button&gt;&lt;/button&gt;&lt;/a&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 当有多选框时，使用c.PostFormArray(&quot;name&quot;)函数得到参数数组。","categories":[{"name":"Web","slug":"Web","permalink":"http://peapod.top/categories/Web/"}],"tags":[{"name":"Gin","slug":"Gin","permalink":"http://peapod.top/tags/Gin/"}],"author":"taweizhong"},{"title":"","slug":"css","date":"2022-08-31T09:04:27.000Z","updated":"2022-08-31T09:04:27.000Z","comments":true,"path":"2022/08/31/css/","link":"","permalink":"http://peapod.top/2022/08/31/css/","excerpt":"","text":"css选择器通用选择器通用选择器用星号*表示，它不匹配某个特定的 HTML 元素，而是匹配 HTML 文档中的每个元素。在开发中，我们通常使用通用选择器来清除 HTML 元素中默认的内外边距。 1234* &#123; margin: 0 auto; 设置一个元素所有外边距的宽度 padding: 0; 内边距&#125; 标签选择器标签选择器可以通过具体的标签名称来匹配文档内所有同名的标签。 123p &#123; color: blue;&#125; ID选择器ID 选择器用来匹配 HTML 文档中具有指定 ID 属性的标签，ID 选择器的定义需要用到井号#，后面紧跟 ID 属性的值。 123#nav &#123; color: red;&#125; 类选择器根据标签的 class 属性匹配具体的 HTML 标签，所有符合条件的标签都会根据选择器内的样式进行格式化。类选择器的定义需要用到一个英文的句号.，后面紧跟 class 属性的值。 1234567891011121314151617.black &#123; color: black;&#125;p.black &#123; color: black;&#125;.info &#123; font-weight:bold;&#125;.selected &#123; color: red;&#125;.info.selected &#123; background: blue;&#125;多类选择器 后代选择器123ul li a &#123; text-decoration: none;&#125; background 背景background-color设置元素的背景颜色； 值 描述 color_name 使用具体颜色名称为元素设置背景颜色（例如 red） hex_number 使用十六进制码为元素设置背景颜色（例如 #ff0000） rgb_number 使用 rgb() 函数为元素设置背景颜色（例如 rgb(255,0,0)） transparent 默认值，设置背景颜色为透明，大多数情况下我们并不会用到它。但如果您不希望某个元素拥有背景颜色，或者不希望用户对浏览器的设置（比如开启夜间模式、护眼模式）影响到您的设计，那么就可以使用 transparent 来将颜色设置为透明的 inherit 从父元素继承对背景颜色的设置 background-image设置元素的背景图像； 值 描述 url(‘URL’) 指向图像的路径，可以将 url() 看作是一个函数，括号中的 URL 为图像的具体路径 none 默认值，不显示背景图像 inherit 从父元素继承背景图像的设置 background-repeat控制背景图像是否重复； 值 描述 repeat 默认值，背景图像将在垂直方向和水平方向上重复 repeat-x 背景图像仅在水平方向上重复 repeat-y 背景图像仅在垂直方向上重复 no-repeat 背景图像仅显示一次，不在任何方向上重复 inherit 从父元素继承 background-repeat 属性的设置 background-attachment控制背景图像是否跟随窗口滚动； 值 描述 scroll 默认值，背景图像随着页面元素的滚动而移动 fixed 当页面的其余部分滚动时，背景图像固定不动 inherit 从父元素继承 background-attachment 属性的设置 background-size设置背景图像的尺寸； 值 描述 xpos ypos 使用像素（px）或其它 CSS 单位来设置背景图像的高度和宽度，xpos 表示宽度，ypos 表示高度，如果只设置第一个值，那么第二个值将被设置为默认值 auto（自动） x% y% 使用百分比表示背景图像相对于所在元素宽度与高度的百分比，x% 表示宽度，y% 表示高度，如果只设置第一个值，那么第二个值将被设置为默认值 auto（自动） cover 保持背景图像的横纵比例并将图像缩放至足够大，使背景图像可以完全覆盖元素所在的区域，这么做可能会导致背景图像的某些部分超出元素区域而无法显示 contain 保持背景图像的横纵比例并将图像缩放至足够大，使背景图像可以完整的显示在元素所在区域，背景图像可能无法完全覆盖整个元素区域 background-position设置背景图像的起始位置 值 描述 left top（左上）、 left center（左中）、 left bottom（左下）、 right top（右上）、 right center（右中）、 right bottom（右下）、 center top（中上）、 center center（居中）、 center bottom（中下） 使用一些关键词表示背景图像的位置，如果您仅设置第一个关键词，那么第二个将默认为 center x% y% 使用百分比表示背景图像距离元素左上角的距离，x% 为水平方向，y% 为垂直方向，左上角为 0% 0%，右下角是 100% 100%，如果您仅设置第一个值，那么另一个值将是 50%，默认值为 0% 0% xpos ypos 使用像素（px）或者其它 CSS 单位表示背景图像距离元素左上角的距离，xpos 为水平方向，ypos 为垂直方向，左上角为 0px 0px，右下角视元素的尺寸而定，百分比和单位的形式可以混用，如果您仅设置第一个值，那么另一个值将默认为 50% CSS字体样式（font） font-family：设置字体； font-style：设置字体的风格，例如倾斜、斜体等； font-weight：设置字体粗细； font-size：设置字体尺寸； font-variant：将小写字母转换为小型大写字母； font-stretch：对字体进行伸缩变形（使用较少，并且主流浏览器都不支持）； font：字体属性的缩写，可以在一个声明中设置多个字体属性。 CSS文本格式化 text-align：设置文本的水平对齐方式； text-decoration：设置文本的装饰； text-transform：设置文本中英文的大小写转换方式； text-indent：设置文本的缩进方式； line-height：设置行高； letter-spacing：设置字符间距； word-spacing：设置单词与单词之间的间距（对中文无效）； text-shadow：设置文本阴影； vertical-align：设置文本的垂直对齐方式； white-space：设置文本中空白的处理方式； direction：设置文本方向。 css链接链接有四种不同的状态，分别是 link、visited、active 和 hover。 可以通过以下伪类选择器来为链接的四种状态设置不同的样式： :link：定义普通或未访问链接的样式； :visited：定义已经访问过链接的样式； :hover：定义当鼠标经过或悬停在链接上时的样式； :active：定义点击链接时的样式。 边框CSS 中的边框是围绕着元素内容和内边距的一条或多条线段，您可以自定义这些线段的样式、宽度以及颜色。您可以通过下面几个属性分别定义边框的样式、宽度和颜色： border-style：设置边框的样式，例如实线、虚线等； border-width：设置边框的宽度（厚度）； border-color：设置边框的颜色； border：上面三个边框属性的缩写。 列表 CSS 中也提供了几种专门用来设置和格式化列表的属性，如下所示： list-style-type：设置列表项前面标记的形状（外观）； list-style-position：设置标记和列表中文本之间的距离； list-style-image：使用图像代替默认的标记； list-style：统一设置上面的三个属性。 响应式布局要实现响应式布局，常用的方式有以下几种： 使用 CSS 中的媒体查询（最简单）； 使用 JavaScript（使用成本比较高）； 使用第三方开源框架（例如 bootstrap，可以很好的支持各种浏览器）。 CSS resize（调整元素大小）该属性允许用户通过拖动的方式来自由缩放元素的尺寸。 语法说明如下： none：用户无法调整元素的尺寸； both：用户可调整元素的高度和宽度； horizontal：用户可调整元素的宽度； vertical：用户可调整元素的高度。 在使用 resize 属性时还需要注意以下几点： 单独设置 resize 属性是无效的，resize 属性需要与 overflow 属性结合使用才有效，并且 overflow 属性的值需要设置为 auto、hidden 或 scroll； 并不是所有的元素都可以设置 resize 属性，比如 img 和 table 属性就没办法使用 resize 属性。 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;style&gt; div &#123; border: 1px solid; width: 300px; resize: both; overflow: auto; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;通过 resize 属性您可以调整元素在水平和垂直方向的大小&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; CSS flex布局（弹性布局&#x2F;弹性盒子）可以简便、完整、响应式地实现各种页面布局，当页面需要适应不同的屏幕大小以及设备类型时非常适用。 采用 Flex 布局的元素，称为 Flex 容器（flex container），简称“容器”。它的所有子元素自动成为容器成员，称为 Flex 项目（flex item），简称“项目”。 1) flex-directionflex-direction 属性用来决定主轴的方向（即项目的排列方向），属性的可选值如下： 值 描述 row 默认值，主轴沿水平方向从左到右 row-reverse 主轴沿水平方向从右到左 column 主轴沿垂直方向从上到下 column-reverse 主轴沿垂直方向从下到上 initial 将此属性设置为属性的默认值 inherit 从父元素继承此属性的值 2) flex-wrapflex-wrap 属性用来设置当弹性盒子的子元素（项目）超出父容器时是否换行，属性的可选值如下： 值 描述 nowrap 默认值，表示项目不会换行 wrap 表示项目会在需要时换行 wrap-reverse 表示项目会在需要时换行，但会以相反的顺序 initial 将此属性设置为属性的默认值 inherit 从父元素继承属性的值 3) justify-contentjustify-content 属性用于设置弹性盒子中元素在主轴（横轴）方向上的对齐方式，属性的可选值如下： 值 描述 flex-start 默认值，左对齐 flex-end 右对齐 center 居中 space-between 两端对齐，项目之间的间隔是相等的 space-around 每个项目两侧的间隔相等 initial 将此属性设置为属性的默认值 inherit 从父元素继承属性的值 4) align-itemsalign-items 属性用来设置弹性盒子中元素在侧轴（纵轴）方向上的对齐方式，属性的可选值如下： 值 描述 stretch 默认值，项目将被拉伸以适合容器 center 项目位于容器的中央 flex-start 项目位于容器的顶部 flex-end 项目位于容器的底部 baseline 项目与容器的基线对齐 initial 将此属性设置为属性的默认值 inherit 从父元素继承属性的值 5) orderorder 属性用来设置项目在容器中出现的顺序，您可以通过具体的数值来定义项目在容器中的位置，属性的语法格式如下： 1order: number; 其中 number 就是项目在容器中的位置，默认值为 0。 CSS box-sizing：改变盒子模型box-sizing 属性来改变默认的盒子模型，通过 box-sizing 属性可以将元素的内边距和外边距在元素内容区内绘制，以使元素呈现的宽度和高度与设置的宽度和高度相同。 box-sizing 属性的可选值如下： 值 描述 content-box 默认值，元素的实际宽度或高度等于元素内容区的宽度或高度、内边距和边框的和 border-box 在元素的内容区内绘制内边距或边框，内边距或边框不会影响元素的实际宽度或高度 inherit 从父元素继承 box-sizing 属性的值。 CSS column（多列布局）CSS3 中提供了一系列实现多列布局的属性，如下表所示： 属性 说明 column-count 指定元素应该分为几列 column-fill 指定如何填充每个列 column-gap 指定列与列之间的间隙 column-rule 所有 column-rule-* 属性的简写形式 column-rule-color 指定列与列之间边框的颜色 column-rule-style 指定列与列之间边框的样式 column-rule-width 指定列与列之间边框的宽度 column-span 指定元素应该横跨多少列 column-width 指定列的宽度 columns column-width 与 column-count 属性的简写属性 CSS transition（过渡效果）可以将元素从一种样式在指定时间内平滑的过渡到另一种样式，类似于简单的动画。 CSS 中提供了 5 个有关过渡的属性，如下所示： transition-property：设置元素中参与过渡的属性； transition-duration：设置元素过渡的持续时间； transition-timing-function：设置元素过渡的动画类型； transition-delay：设置过渡效果延迟的时间，默认为 0； transition：简写属性，用于同时设置上面的四个过渡属性。 要成功实现过渡效果，必须定义以下两项内容： 元素中参数与过渡效果的属性； 过渡效果持续的时间。 transition-propertytransition-property 属性用来设置元素中参与过渡的属性名称，语法格式如下： transition-property: none | all | property; 参数说明如下： none：表示没有属性参与过渡效果； all：表示所有属性都参与过渡效果； property：定义应用过渡效果的 CSS 属性名称列表，多个属性名称之间使用逗号,进行分隔。 123456789101112131415161718192021&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;style&gt; div &#123; width: 100px; height: 100px; border: 3px solid black; margin: 10px 0px 0px 10px; transition-property: width, background; &#125; div:hover &#123; width: 200px; background-color: blue; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; CSS动画（animation）@keyframes 规则要创建 CSS 动画，您首先需要了解 @keyframes 规则，@keyframes 规则用来定义动画各个阶段的属性值，类似于 flash 动画中的关键帧，语法格式如下： 1234567891011121314151617181920212223@keyframes animationName &#123; from &#123; properties: value; &#125; percentage &#123; properties: value; &#125; to &#123; properties: value; &#125;&#125;// 或者@keyframes animationName &#123; 0% &#123; properties: value; &#125; percentage &#123; properties: value; &#125; 100% &#123; properties: value; &#125;&#125; 语法说明如下： animationName：表示动画的名称； from：定义动画的开头，相当于 0%； percentage：定义动画的各个阶段，为百分比值，可以添加多个； to：定义动画的结尾，相当于 100%； properties：不同的样式属性名称，例如 color、left、width 等等。 1234567@keyframes ball &#123; 0% &#123; top: 0px; left: 0px;&#125; 25% &#123; top: 0px; left: 350px;&#125; 50% &#123; top: 200px; left: 350px;&#125; 75% &#123; top: 200px; left: 0px;&#125; 100% &#123; top: 0px; left: 0px;&#125; &#125; 要将动画应用到指定的 HTML 元素需要借助 CSS 属性，CSS 中提供了如下所示的动画属性： animation-name：设置需要绑定到元素的动画名称； animation-duration：设置完成动画所需要花费的时间，单位为秒或毫秒，默认为 0； animation-timing-function：设置动画的速度曲线，默认为 ease； animation-fill-mode：设置当动画不播放时（动画播放完或延迟播放时）的状态； animation-delay：设置动画开始之前的延迟时间，默认为 0； animation-iteration-count：设置动画被播放的次数，默认为 1； animation-direction：设置是否在下一周期逆向播放动画，默认为 normal； animation-play-state：设置动画是正在运行还是暂停，默认是 running； animation：所有动画属性的简写属性。 animation-name12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;style&gt; @keyframes ball &#123; 0% &#123; top: 0px; left: 0px;&#125; 25% &#123; top: 0px; left: 350px;&#125; 50% &#123; top: 200px; left: 350px;&#125; 75% &#123; top: 200px; left: 0px;&#125; 100% &#123; top: 0px; left: 0px;&#125; &#125; div &#123; width: 100px; height: 100px; border-radius: 50%; border: 3px solid black; position: relative; animation-name: ball; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 注意：要想让动画成功播放，您还需要定义 animation-duration 属性，否则会因为 animation-duration 属性的默认值为 0，导致动画并不会播放。 CSS阴影效果1. text-shadow使用 CSS 的 text-shadow 属性我们可以为文本设置阴影效果，属性的语法格式如下： 1text-shadow: offset-x offset-y blur color; 语法说明如下： offset-x：必填参数，设置阴影的水平偏移量，可以为负值； offset-y：必填参数，设置阴影的垂直偏移量，可以为负值； blur：可选参数，设置模糊的半径，值越大，模糊越大，阴影的边缘越模糊，不允许使用负值； color：可选参数，设置阴影的颜色，如果省略或未指定该值，则采用 color 属性的值。 2. box-shadow使用 CSS 的 box-shadow 属性我们可以为 HTML 元素设置阴影效果，属性的语法格式如下： 1box-shadow: h-shadow v-shadow blur spread color inset; 语法说明如下： h-shadow：必填参数，设置阴影水平方向的偏移量，可以为负值； v-shadow：必填参数，设置阴影垂直方向的偏移量，可以为负值； blur：可选参数，设置模糊的半径，值越大，模糊越大，阴影的边缘越模糊，不允许使用负值； spread：可选参数，设置阴影的尺寸； color：可选参数，设置阴影的颜色； inset：可选参数，将默认的外部阴影 (outset) 改为内部阴影。 提示：与 text-shadow 属性相似，box-shadow 属性也可以同时设定多组阴影效果，每组之间使用逗号分隔，定义的多组阴影效果会按照定义顺序依次罗列，第一个阴影在最上面，以此类推。 CSS渐变色线性渐变线性渐变指的是颜色沿一条直线进行渐变（例如右上到下，从左到右等），要创建线性渐变，您至少需要定义两个色标（色标指的是想要平滑过渡的颜色），若要创建更加复杂的渐变效果，则需要定义更多的色标。创建线性渐变的基本语法如下： 1linear-gradient(direction, color-stop1, color-stop2, ...); 参数说明如下： direction 可选值，定义渐变的方向（例如从左到右，从上到下），可以是具体角度（例如 90deg），也可以通过 to 加 left、right、top、bottom 等关键字来表示渐变方向，例如： to left：表示从右到左，相当于 270deg； to right：表示从左到右，相当于 90deg； to top：表示从下到上，相当于 0deg； to bottom：默认值，表示从上到下，相当于 180deg； to right bottom：表示从左上到右下； to right top：表示从左下到右上； to left bottom：表示从右上到左下； to left top：表示从右下到左上。 color-stop1、color-stop2、…：表示定义的多个色标，在每个色标中除了可以定义颜色外，还可以通过数值加单位或者百分比的形式定义颜色的起止位置。 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;style&gt; div &#123; width: 210px; height: 50px; float: left; margin: 10px; &#125; .one &#123; background: linear-gradient(to right bottom, red, blue 70px); &#125; .two &#123; background: linear-gradient(190deg, #000, #FFF); &#125; .three &#123; background: linear-gradient(red, green, blue); &#125; .four &#123; background: linear-gradient(to right, red, orange, yellow, green, blue, indigo, violet); &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;one&quot;&gt;&lt;/div&gt; &lt;div class=&quot;two&quot;&gt;&lt;/div&gt; &lt;div class=&quot;three&quot;&gt;&lt;/div&gt; &lt;div class=&quot;four&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; CSS圆角（border-radius）CSS3 中提供了一系列属性来设置元素的圆角效果，如下所示： border-top-left-radius：为元素左上角设置圆角效果； border-top-right-radius：为元素右上角设置圆角效果； border-bottom-right-radius：为元素右下角设置圆角效果； border-bottom-left-radius：为元素左下角设置圆角效果； border-radius：上面四个属性的简写形式，可以同时为元素的四个角设置圆角效果。 border-radius 属性的格式如下： 1border-radius：[ &lt;length&gt; | &lt;percentage&gt; ]&#123;1,4&#125; [ / [ &lt;length&gt; | &lt;percentage&gt; ]&#123;1,4&#125; ]? CSS透明度（opacity）CSS 中提供了一个 opacity 属性用来设置元素的透明度，它不仅对颜色有效，对图像或者页面中其它的元素也有效。其语法格式如下： 1opacity: number; 其中 number 为一个 0~1 之间的浮点数（小数），用来表示元素的透明度，值越小则越透明（0 表示完全透明，1 表示完全不透明）。","categories":[],"tags":[]},{"title":"css简介","slug":"css简介","date":"2022-08-27T07:48:03.000Z","updated":"2022-09-08T12:00:58.000Z","comments":true,"path":"2022/08/27/css简介/","link":"","permalink":"http://peapod.top/2022/08/27/css%E7%AE%80%E4%BB%8B/","excerpt":"","text":"css简介CSS 是“Cascading Style Sheet”的缩写，中文意思为“层叠样式表”，它是一种标准的样式表语言，用于描述网页的表现形式（例如网页元素的位置、大小、颜色等）。 CSS 的主要作用是定义网页的样式（美化网页），对网页中元素的位置、字体、颜色、背景等属性进行精确控制。 css特点在网页中实现各式各样的效果，例如： 为任何元素设置不同的边框，以及边框与元素之间的内外间距； 改变文字的大小、颜色、字体，为文字添加修饰（例如下划线、删除线）； 为网页设置背景颜色或者背景图片等等。 可以对同一个 HTML 元素多次定义 CSS 样式，后面定义的样式会覆盖前面定义的样式。 css语法规则CSS 样式规则由三个部分组成，分别是选择器、属性和值： 选择器：由 HTML 元素的 id、class 属性或元素名本身以及一些特殊符号构成，用来指定要为哪个 HTML 元素定义样式，例如选择器p就表示为页面中的所有&lt;p&gt;标签定义样式； 属性：给 HTML 元素设置的样式名称，由一系列关键词组成，例如 color（颜色）、border（边框）、font（字体）等，CSS 中提供了众多属性，您可以通过 W3C 官网查看； 值：由数值和单位或者关键字组成，用来控制某个属性的显示效果，例如 color 属性的值可以是 red 或 #F1F1F1 等。 在 CSS 的语法规则中，属性和值之间需要使用冒号:进行分隔，每个属性和值的组合可以看作一个声明，每个声明的末尾都需要使用分号;作为结尾，属于同一选择器的声明需要使用花括号&#123; &#125;包裹起来。","categories":[{"name":"前端","slug":"前端","permalink":"http://peapod.top/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"css","slug":"css","permalink":"http://peapod.top/tags/css/"}],"author":"taweizhong"},{"title":"vim常用命令","slug":"vim常用命令","date":"2022-08-27T04:23:00.000Z","updated":"2022-09-07T03:51:28.000Z","comments":true,"path":"2022/08/27/vim常用命令/","link":"","permalink":"http://peapod.top/2022/08/27/vim%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"vim常用命令命令模式 快捷键 功能描述 gg 光标移动到文档首行 G 光标移动到文档尾行 ctrl+b或pageUp键 翻屏操作，向上翻 ctrl+f或pageDn键 翻屏操作，向下翻 数字+G 快速将光标移动到指定行 shift+6 光标移动到行首 shift+4 光标移动到行尾 数字+上下方向键 以当前光标为准，向上&#x2F;下移动n行 数字+左右方向键 以当前光标为准，向左&#x2F;右移动n个字符 ctrl+v + 方向键+yy ctrl+v，并按方向键选中区块，按下yy复制 p 将剪贴板中的内容粘贴到光标后 dd 删除光标所在行，删除之后，下一行上移 D 删除光标位置到行尾的内容，删除之后，下一行不上移 :a1,a2d 删除从 a1 行到 a2 行的文本内容 u 撤销 ctrl+r 恢复 末行模式 命令 功能描述 :wq 保存并退出 Vim 编辑器 :wq! 保存并强制退出 Vim 编辑器 :q 不保存就退出 Vim 编辑器 :q! 不保存，且强制退出 Vim 编辑器 &#x2F;abc 从光标所在位置向前查找字符串 abc &#x2F;^abc 查找以 abc 为行首的行 &#x2F;abc$ 查找以 abc 为行尾的行 ?abc 从光标所在位置向后查找字符串 abc : set nu 行号显示 : syntax on&#x2F;off 代码颜色显示 更多点击查看更多","categories":[{"name":"实用","slug":"实用","permalink":"http://peapod.top/categories/%E5%AE%9E%E7%94%A8/"}],"tags":[{"name":"vim","slug":"vim","permalink":"http://peapod.top/tags/vim/"}],"author":"taweizhong"},{"title":"HTML标签","slug":"HTML标签","date":"2022-08-27T03:19:09.000Z","updated":"2022-09-08T07:19:30.000Z","comments":true,"path":"2022/08/27/HTML标签/","link":"","permalink":"http://peapod.top/2022/08/27/HTML%E6%A0%87%E7%AD%BE/","excerpt":"","text":"HTML标签标题标签HTML 中提供了从&lt;h1&gt;到&lt;h6&gt;六个级别的标题标签，&lt;h1&gt;标签的级别最高，&lt;h6&gt;标签的级别最低，通过这些标签可以定义网页中的标题（与 word 中的标题类似），合理使用标题可以使网页的层次结构更加清晰。 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;mate charset=&quot;utf-8&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;h1 标题&lt;/h1&gt; &lt;h2&gt;h2 标题&lt;/h2&gt; &lt;h3&gt;h3 标题&lt;/h3&gt; &lt;h4&gt;h4 标题&lt;/h4&gt; &lt;h5&gt;h5 标题&lt;/h5&gt; &lt;h6&gt;h6 标题&lt;/h6&gt;&lt;/body&gt;&lt;/html&gt; 段落标签HTML 中可以使用段落标签 &lt;p&gt;来将文档中的内容分割为若干个段落。 1&lt;p&gt;段落中的内容。&lt;/p&gt; 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;mate charset=&quot;utf-8&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;这是一个段落。&lt;a href=&quot;http://43.138.70.17:4000/&quot; target=&quot;_blank&quot;&gt;这是一个链接&lt;/a&gt;&lt;/p&gt; &lt;p&gt;这是第二个标签&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 超链接标签 标签的语法格式如下： 1&lt;a href=&quot;&quot; target=&quot;_blank&quot;&gt;这是一个链接&lt;/a&gt; href 属性指定链接的目标，也就是要跳转到什么位置。 target 是可选属性，用来指明新页面的打开方式。 属性值 说明 _self 默认，在现有窗口中打开新页面，原窗口将被覆盖。 _blank 在新窗口中打开新页面，原窗口将被保留。 _parent 在当前框架的上一层打开新页面。 _top 在顶层框架中打开新页面。 &lt;img标签&gt; 标签的语法格式如下： 1&lt;img src=&quot;url&quot; alt=&quot;text&quot;&gt; src 是必选属性，它是 source 的简称，用来指明图片的地址或者路径。 alt 是可选属性，用来定义图片的文字描述信息。 使用 width 和 height 属性来指定图片的宽度和高度。 12&lt;img src=&quot;./html5.png&quot; alt=&quot;HTML5 Logo&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;&lt;img src=&quot;./html5.png&quot; alt=&quot;HTML5 Logo&quot; style=&quot;width: 150px; height: 150px;&quot;&gt; 表格标签12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;mate charset=&quot;utf-8&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;table&gt; &lt;caption&gt;这是表格的标题&lt;/caption&gt; &lt;tr&gt; &lt;th&gt;name &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;taweizhong &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 列表标签有序列表12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;HTML有序列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;煮米饭的步骤：&lt;/p&gt; &lt;ol&gt; &lt;li&gt;将水煮沸&lt;/li&gt; &lt;li&gt;加入一勺米&lt;/li&gt; &lt;li&gt;搅拌均匀&lt;/li&gt; &lt;li&gt;继续煮10分钟&lt;/li&gt; &lt;/ol&gt;&lt;/body&gt;&lt;/html&gt; 无序列表12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;HTML无序列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;早餐的种类：&lt;/p&gt; &lt;ul&gt; &lt;li&gt;鸡蛋&lt;/li&gt; &lt;li&gt;牛奶&lt;/li&gt; &lt;li&gt;面包&lt;/li&gt; &lt;li&gt;生菜&lt;/li&gt; &lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; 定义列表12345678&lt;dl&gt; &lt;dt&gt;标题1&lt;dt&gt; &lt;dd&gt;描述文本2&lt;dd&gt; &lt;dt&gt;标题2&lt;dt&gt; &lt;dd&gt;描述文本2&lt;dd&gt; &lt;dt&gt;标题3&lt;dt&gt; &lt;dd&gt;描述文本3&lt;dd&gt;&lt;/dl&gt; 表单标签表单可以接收用户输入的信息，然后将其发送到后端应用程序。 语法如下所示： 123&lt;form action=&quot;URL&quot; method=&quot;GET|POST&quot;&gt; 表单中的其它标签&lt;/form&gt; action 属性用来指明将表单提交到哪个页面。 method 属性表示使用哪个方式提交数据，包括 GET 和 POST 两种方式。 表单属性 属性 可选值 描述 accept MIME_type HTML5 中不再支持，设置服务器要接收的文件类型 accept-charset character_set 设置表单数据的字符集（默认为 HTML 文档字符集） action URL 设置要将表单提交到何处（默认为当前页面） autocomplete on、off 设置是否启用表单的自动完成功能（默认开启） enctype application&#x2F;x-www-form-urlencoded、 multipart&#x2F;form-data、 text&#x2F;plain 设置在提交表单数据之前如何对数据进行编码（适用于 method&#x3D;”post” 的情况） method get、post 设置使用哪种 HTTP 方法来提交表单数据（默认为 get） name text 设置表单的名称 novalidate novalidate 如果使用该属性，则提交表单时不进行验证 target _blank、_self、_parent、_top 设置在何处打开 action 属性设定的链接（默认为 _self） 表单控件 控件&#x2F;标签 描述 &lt;input&gt; 定义输入框 &lt;textarea&gt; 定义文本域（一个可以输入多行文本的控件） &lt;label&gt; 为表单中的各个控件定义标题 &lt;fieldset&gt; 定义一组相关的表单元素，并使用边框包裹起来 &lt;legend&gt; 定义 &lt;fieldset&gt; 元素的标题 &lt;select&gt; 定义下拉列表 &lt;optgroup&gt; 定义选项组 &lt;option&gt; 定义下拉列表中的选项 &lt;button&gt; 定义一个可以点击的按钮 &lt;datalist&gt; 指定一个预先定义的输入控件选项列表 &lt;keygen&gt; 定义表单的密钥对生成器字段 &lt;output&gt; 定义一个计算结果 &amp;emsp HTML空格 12345678910111213141516171819202122232425262728293031323334353637383940&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;HTML form表单演示&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=&quot;./userinfo.php&quot; method=&quot;POST&quot;&gt; &lt;!-- 文本输入框控件 --&gt; &lt;label&gt;用户名： &lt;/label&gt;&lt;input name=&quot;username&quot; type=&quot;text&quot;&gt;&lt;br&gt; &lt;!-- 密码框控件 --&gt; &lt;label&gt;密&amp;emsp;码： &lt;/label&gt;&lt;input name=&quot;password&quot; type=&quot;password&quot;&gt;&lt;br&gt; &lt;!-- 下拉菜单控件 --&gt; &lt;label&gt;性&amp;emsp;别：&lt;/label&gt; &lt;select name=&quot;sex&quot;&gt; &lt;option value=&quot;1&quot;&gt;男&lt;/option&gt; &lt;option value=&quot;2&quot;&gt;女&lt;/option&gt; &lt;option value=&quot;3&quot;&gt;未知&lt;/option&gt; &lt;/select&gt; &lt;br&gt; &lt;!-- 复选框控件 --&gt; &lt;label&gt;爱&amp;emsp;好：&lt;/label&gt; &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;1&quot;&gt;听音乐 &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;2&quot;&gt;看电影 &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;3&quot;&gt;打游戏 &lt;br&gt; &lt;!-- 单选按钮控件 --&gt; &lt;label&gt;学&amp;emsp;历：&lt;/label&gt; &lt;input type=&quot;radio&quot; name=&quot;education&quot; value=&quot;1&quot;&gt;小学 &lt;input type=&quot;radio&quot; name=&quot;education&quot; value=&quot;2&quot;&gt;中学 &lt;input type=&quot;radio&quot; name=&quot;education&quot; value=&quot;3&quot;&gt;本科 &lt;input type=&quot;radio&quot; name=&quot;education&quot; value=&quot;4&quot;&gt;硕士 &lt;input type=&quot;radio&quot; name=&quot;education&quot; value=&quot;5&quot;&gt;博士 &lt;br&gt; &lt;!-- 按钮 --&gt; &lt;input type=&quot;submit&quot; value=&quot;提 交&quot;&gt;&amp;emsp;&amp;emsp; &lt;input type=&quot;reset&quot; value=&quot;重 置&quot;&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 块级元素和内联元素块级元素块级元素最主要的特点是它们自己独占一行，块级元素中最具代表性的就是&lt;div&gt;，此外还有&lt;p&gt;、&lt;nav&gt;、&lt;aside&gt;、&lt;header&gt;、&lt;footer&gt;、&lt;section&gt;、&lt;article&gt;、&lt;ul&gt;、&lt;address&gt;、&lt;h1&gt;~&#96;&#96;等。 主要特征如下所示： 块级元素总是在新行上开始； 宽度、高度以及外边距和内边距等都可以控制； 省略块级元素的宽度，那么它的宽度默认为当前浏览器窗口的宽度； 包含其它的内联元素和块级元素。 内联元素内联元素也可以称为行内元素，行内元素中最常用的是&lt;span&gt;，此外还有&lt;b&gt;、&lt;i&gt;、&lt;u&gt;。 主要特征如下所示： 和其他元素会在同一行上显示； 宽、高以及外边距和内边距都不可以改变； 宽度就是其中内容的宽度，且不可以改变； 只能容纳文本或者其他内联元素。 可以通过 line-height 来设置行高； 可以设置 margin 外边距，但只对左右外边距有效，上下无效； 设置 padding 内边距时，只有左右 padding 有效，上下则无效 标签&lt;div&gt;&lt;div&gt;是非常重要的块级标记，在网页布局（Layout）方面发挥着重要的作用，使用&lt;div&gt;我们可以定义页面的各个部分，通过与 CSS 相结合可以实现各种各样的效果。 &lt;div&gt; 标签及其包围的内容可以看做网页的一个板块， 标签本身并没有什么特殊的显示效果，需要借助 CSS 样式对外边距、内边距、背景、边框等进行设置，从而达到对板块布局的目的。 &lt;span&gt;标签HTML 中的&lt;span&gt;标签是一个内联元素，可以对 HTML 文档中的内容进行修饰，此标签不会为文档内容提供任何视觉效果，但可以与 CSS 结合使用来美化网页。 布局HTML5 提出了多个专门用于布局的标签，它们用来定义网页的不同部分，语义更加明确。 标签 说明 &lt;header&gt; 用于定义网页的头部，头部中一般包含一些介绍性的内容，例如网站名称、logo 或者作者的信息。 &lt;nav&gt; 用于定义网页中的导航栏。 &lt;section&gt; 用于在网页中定义一个单独的部分，其中可以包含文本、图像、表格等等。 &lt;section&gt; 代表 HTML 文档中的“节”或“段”，“段”可以理解为一篇文章里按照主题的分段，“节”则可以理解为一个页面里的分组。其主要作用就是对页面的内容进行分块或者对文章的内容进行分段。 &lt;article&gt; 用于定义文章或者其它独立的信息，代表一个页面中自成一体的内容，例如论坛的帖子、博客上的文章、一篇用户的评论等。 &lt;aside&gt; 用于定义网页内容以外的部分，例如网页的侧边栏。 &lt;footer&gt; 用于定义网页的底部，例如作者、版权等信息。 &lt;details&gt; 用于定义一些详细信息，并且可以根据需要隐藏或显示这些详细信息。 &lt;summary&gt; 用于为&lt;details&gt;标签定义标题。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"HTML","slug":"HTML","permalink":"http://peapod.top/tags/HTML/"}],"author":"taweizhong"},{"title":"HTML标签的属性","slug":"HTML标签的属性","date":"2022-08-26T10:59:55.000Z","updated":"2022-09-08T07:20:48.000Z","comments":true,"path":"2022/08/26/HTML标签的属性/","link":"","permalink":"http://peapod.top/2022/08/26/HTML%E6%A0%87%E7%AD%BE%E7%9A%84%E5%B1%9E%E6%80%A7/","excerpt":"","text":"HTML属性属性包含了标签的额外信息，例如： href 属性可以为 标签提供链接地址； src 属性可以为 标签提供图像的路径； style 属性可以为几乎所有标签定义 CSS 样式。 属性需要添加在开始标签中，语法格式为： 12attr=&quot;value&quot;attr 表示属性名，value 表示属性值。属性值必须使用双引号&quot; &quot;或者单引号&#x27; &#x27;包围。 说明： 标签中的 src 属性用来定义图像的路径，alt 属性用来定义图像的描述信息，当图像出现异常无法正常显示时就会显示 alt 中的信息。 标签的 href 属性用来定义链接的地址，target 属性用来定义新页面在浏览器中的打开方式。 通用属性1) idid 属性用来赋予某个标签唯一的名称（标识符），当我们使用 CSS 或者 JavaScript 来操作这个标签时，就可以通过 id 属性来找到这个标签。 2) class与 id 属性类似，class 属性也可以为标签定义名称（标识符），不同的是 class 属性在整个 HTML 文档中不必是唯一的，我们可以为多个标签定义相同的 class 属性值。另外，还可以为一个 HTML 标签定义多个 class 属性值。 3) titletitle 属性用来对标签内容进行描述说明，当鼠标移动到该标签上方时会显示出 title 属性的值。 4) style使用 style 属性我们可以在 HTML 标签内部为标签定义 CSS 样式","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"HTML","slug":"HTML","permalink":"http://peapod.top/tags/HTML/"}],"author":"taweizhong"},{"title":"HTML标签的语法格式","slug":"HTML标签的语法格式","date":"2022-08-26T10:59:38.000Z","updated":"2022-09-08T07:22:22.000Z","comments":true,"path":"2022/08/26/HTML标签的语法格式/","link":"","permalink":"http://peapod.top/2022/08/26/HTML%E6%A0%87%E7%AD%BE%E7%9A%84%E8%AF%AD%E6%B3%95%E6%A0%BC%E5%BC%8F/","excerpt":"","text":"标签的语法格式一个 HTML 标签由开始标签、属性、内容和结束标签组成，标签的名称不区分大小写。 注意： 所有 HTML 标签都必须放在尖括号&lt; &gt;内； HTML 中不同的标签可以实现不同的效果； 如果使用了某个标签，则必须使用对应的结束标签来结尾（自闭和标签除外）。 自闭和标签12345&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;hr /&gt;&lt;br /&gt;&lt;input type=&quot;text&quot; /&gt;&lt;!-- --&gt; 表示 HTML 注释","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"HTML","slug":"HTML","permalink":"http://peapod.top/tags/HTML/"}],"author":"taweizhong"},{"title":"HTML简介","slug":"HTML简介","date":"2022-08-26T10:59:12.000Z","updated":"2022-09-08T07:23:20.000Z","comments":true,"path":"2022/08/26/HTML简介/","link":"","permalink":"http://peapod.top/2022/08/26/HTML%E7%AE%80%E4%BB%8B/","excerpt":"","text":"HTML简介HTML 英文全称是 Hyper Text Markup Language，中文译为“超文本标记语言”，专门用来设计和编辑网页。 1) 超文本也即超越纯文本，这意味着 HTML 文档不仅能包含文本（文字），还能包含图片、音视频、表格、列表、链接、按钮、输入框等高级内容。 2) 标记语言HTML 是一种计算机语言，但它不能编程，只能用来标记网页中的内容。HTML 通过不同的标签来标记不同的内容、格式、布局等。 HTML标签HTML 是一种标记语言，使用各种标签来格式化内容，标签的特点如下所示： HTML 标签由尖括号包围的关键词构成，比如 ； 除了少数标签外，大多数 HTML 标签都是成对出现的； 成对出现的标签中，第一个标签称为开始标签，第二个标签称为结束标签（闭合标签）。 HTML文档结构123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;mate charset=&quot;utf8&quot;&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;&lt;/p&gt; &lt;h1&gt;&lt;/h1&gt; &lt;input type=&quot;text&quot;/&gt; &lt;/body&gt;&lt;/html&gt; 说明： ：该标签是 HTML 页面的根标签，其他所有的标签都需要在 和 标签之间定义； ：该标签中用来定义 HTML 文档的一些信息，例如标题、编码格式等等； ：用来指明当前网页采用 UTF-8 编码，UTF-8 是全球通用的编码格式，绝大多数网页都采用 UTF-8 编码； ：该标签用来定义网页的标题，网页标题会显示在浏览器的标签栏； ：该标签用来定义网页中我们能通过浏览器看到的所有内容，例如段落、标题、图片、链接等等；","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"HTML","slug":"HTML","permalink":"http://peapod.top/tags/HTML/"}]},{"title":"Go函数","slug":"Go函数","date":"2022-08-26T08:31:43.000Z","updated":"2022-09-08T07:38:44.000Z","comments":true,"path":"2022/08/26/Go函数/","link":"","permalink":"http://peapod.top/2022/08/26/Go%E5%87%BD%E6%95%B0/","excerpt":"","text":"第六章：函数简介函数是基本的代码块。函数编写的顺序是无关紧要的，最好把 main() 函数写在文件的前面。 简单的 return 语句也可以用来结束 for 死循环，或者结束一个协程（goroutine）。 Go里面的函数： 普通函数 匿名函数 方法 除了main()、init()函数外，其它所有类型的函数都可以有参数与返回值。 函数参数、返回值以及它们的类型被统称为函数签名。 函数是一等值（first-class value）：它们可以赋值给变量，就像 add := binOp 一样。 函数不能在其它函数里面声明（不能嵌套），不过我们可以通过使用匿名函数 函数参数与返回值函数定义时，它的形参一般是有名字的，不过我们也可以定义没有形参名的函数，只有相应的形参类型，就像这样：func f(int, int, float64)。 在函数调用时，像切片（slice）、字典（map）、接口（interface）、通道（channel）这样的引用类型都是默认使用引用传递（即使没有显式的指出指针）。 命名返回值 命名返回值作为结果形参（result parameters）被初始化为相应类型的零值，当需要返回的时候，我们只需要一条简单的不带参数的return语句。 123456func getX2AndX3_2(input int) (x2 int, x3 int) &#123; x2 = 2 * input x3 = 3 * input // return x2, x3 return&#125; 改变外部变量 传递指针给函数不但可以节省内存（因为没有复制变量的值），而且赋予了函数直接修改外部变量的能力，所以被修改的变量不再需要使用 return 返回。 1234567891011121314package mainimport ( &quot;fmt&quot;)// this function changes reply:func Multiply(a, b int, reply *int) &#123; *reply = a * b&#125;func main() &#123; n := 0 reply := &amp;n Multiply(10, 5, reply) fmt.Println(&quot;Multiply:&quot;, *reply) // Multiply: 50&#125; 变长参数函数的最后一个参数是采用 ...type 的形式，那么这个函数就可以处理一个变长的参数 123456789101112131415161718192021package mainimport &quot;fmt&quot;func main() &#123; x := min(1, 3, 2, 0) fmt.Printf(&quot;The minimum is: %d\\n&quot;, x) slice := []int&#123;7,9,3,5,1&#125; x = min(slice...) fmt.Printf(&quot;The minimum in the slice is: %d&quot;, x)&#125;func min(s ...int) int &#123; if len(s)==0 &#123; return 0 &#125; min := s[0] for _, v := range s &#123; if v &lt; min &#123; min = v &#125; &#125; return min&#125; 变长参数的类型不相同 使用结构体 使用空接口 使用默认的空接口 interface&#123;&#125;，这样就可以接受任何类型的参数 new 和 make 均是用于分配内存：new 用于值类型和用户定义的类型，如自定义结构，make 用于内置引用类型（切片、map 和管道）。 new(T) 分配类型 T 的零值并返回其地址，也就是指向类型 T 的指针 make(T) 返回类型 T 的初始化之后的值，因此它比 new 进行更多的工作。 defer和追踪关键字 defer 允许我们推迟到函数返回之前（或任意位置执行 return 语句之后）一刻才执行某个语句或函数。 123456789101112package mainimport &quot;fmt&quot;func P()&#123; fmt.Print(&quot;P&quot;)&#125;func main()&#123; fmt.Print(&quot;111&quot;) defer P() fmt.Print(&quot;222&quot;)&#125; 当有多个 defer 行为被注册时，它们会以逆序执行 123456789101112package mianimport ( &quot;file&quot;)func main()&#123; //关闭文件 defer file.close() //解锁 mu.Lock() defer mu.Unlock() //关闭数据库连接 defer disconnectFromDB()&#125; 函数作为参数1234567891011package mainimport &quot;fmt&quot;func add(i,j int) int &#123; return i+j&#125;func b(c int, f func (i,j int) int )&#123; return f(c, 2)&#125;func main()&#123; fmt.Print(b(1, add))&#125; 闭包匿名函数的使用 12345678910package mainimport &quot;fmt&quot;func main ()&#123; // 匿名函数 func(i, j int) int &#123;return i+j&#125; // 将匿名函数赋值给变量 变量使用匿名函数 ter := func(i, j int) int &#123;return i+j&#125; ter(2,3) // 匿名函数直接的调用 func(a, b int) int &#123;return a-b&#125; (3, 2)&#125; 函数作为返回值123456789101112package mainimport &quot;fmt&quot;func add(j int) func (i int) int&#123; return func (i int) int&#123; return j +i &#125;&#125;func main()&#123; add(12)&#125; 12345678910111213141516171819package mainimport &quot;fmt&quot;func add() func(i int) int &#123; var x int fmt.Printf(&quot;x: %v\\n&quot;, x) return func(i int) int &#123; x += i return x &#125;&#125;func main() &#123; f := add() fmt.Printf(&quot;f(1): %v\\n&quot;, f(1)) fmt.Printf(&quot;f(2): %v\\n&quot;, f(20))&#125; 闭包函数保存并积累其中的变量的值，不管外部函数退出与否，它都能够继续操作外部函数中的局部变量。 计算函数的执行时间12345678910111213141516171819package mainimport ( &quot;fmt&quot; &quot;time&quot;)func add() &#123; for i := 0; i &lt; 100; i++ &#123; fmt.Printf(&quot;i: %v\\n&quot;, i) &#125;&#125;func main() &#123; start := time.Now() add() end := time.Now() fmt.Print(end.Sub(start))&#125;","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Go控制结构","slug":"Go控制结构","date":"2022-08-26T08:31:25.000Z","updated":"2022-09-08T07:37:16.000Z","comments":true,"path":"2022/08/26/Go控制结构/","link":"","permalink":"http://peapod.top/2022/08/26/Go%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/","excerpt":"","text":"第五章：控制结构if-else结构12345if condition &#123; //&#125; else &#123; //&#125; 当 if 结构内有 break、continue、goto 或者 return 语句时，Go 代码的常见写法是省略 else 部分 1234if condition &#123; return x&#125;return y 1234if err != nil &#123; fmt.Printf(&quot;Program stopping with error %v&quot;, err) os.Exit(1)&#125; swith结构它可以接受任意形式的表达式： 12345678switch var1 &#123; case val1: ... case val2: ... default: ...&#125; 变量 var1 可以是任何类型，而 val1 和 val2 则可以是同类型的任意值。 一旦成功地匹配到某个分支，在执行完相应代码后就会退出整个 switch 代码块。 继续执行后续分支的代码，可以使用 fallthrough 关键字 12345switch i &#123; case 0: fallthrough case 1: f() // 当 i == 0 时函数也会被调用&#125; 可选的 default 分支可以出现在任何顺序，但最好将它放在最后。它的作用类似与 if-else 语句中的 else，表示不符合任何已给出条件时，执行相关语句。 switch 语句的第二种形式是不提供任何被判断的值（实际上默认为判断是否为 true），然后在每个 case 分支中进行测试不同的条件。 12345678switch &#123; case i &lt; 0: f1() case i == 0: f2() case i &gt; 0: f3()&#125; for结构基于计数器的迭代 1234567package mainimport &quot;fmt&quot;func main() &#123; for i := 0; i &lt; 5; i++ &#123; fmt.Printf(&quot;This is the %d iteration\\n&quot;, i) &#125;&#125; 基于条件判断的迭代 123456789package mainimport &quot;fmt&quot;func main() &#123; var i int = 5 for i &gt;= 0 &#123; i = i - 1 fmt.Printf(&quot;The variable i is now: %d\\n&quot;, i) &#125;&#125; for-range结构 for ix, val := range coll &#123; &#125;。 val 始终为集合中对应索引的值拷贝，因此它一般只具有只读性质，对它所做的任何修改都不会影响到集合中原有的值 123for pos, char := range str &#123;...&#125; 标签和gotofor、switch 或 select 语句都可以配合标签（label）形式的标识符使用，即某一行第一个以冒号（:） 12345678910111213package mainimport &quot;fmt&quot;func main() &#123;LABEL1: // 一般建议使用全部大写字母 for i := 0; i &lt;= 5; i++ &#123; for j := 0; j &lt;= 5; j++ &#123; if j == 4 &#123; continue LABEL1 &#125; fmt.Printf(&quot;i is: %d, and j is: %d\\n&quot;, i, j) &#125; &#125;&#125;","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Go基本数据类型","slug":"Go基本数据类型","date":"2022-08-26T08:31:00.000Z","updated":"2024-02-27T10:46:52.000Z","comments":true,"path":"2022/08/26/Go基本数据类型/","link":"","permalink":"http://peapod.top/2022/08/26/Go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"第四章（下）：基本数据类型常量常量使用关键字 const 定义，用于存储不会改变的数据。 存储在常量中的数据类型只可以是布尔型、数字型（整数型、浮点型和复数）和字符串型。 1const Pi = 3.14 常量的值必须是能够在编译时就能够确定的。 因为在编译期间自定义函数均属于未知，因此无法用于常量的赋值，但内置函数可以使用，如：len()。 12const Ln2 = 0.693147180559945309417232121458\\ 176568075500134360255254120680009 反斜杠 \\ 可以在常量表达式中作为多行的连接符使用。 常量并行赋值 1const beef,two,c = &quot;eat&quot;,2,&quot;vag&quot; iota 可以被用作枚举值： 12345const ( a = iota b = iota c = iota) 简单地讲，每遇到一次 const 关键字，iota 就重置为 0。. 变量声明变量的一般形式是使用 var 关键字：var identifier type。 123456789var a intvar b boolvar str stringvar ( a int b bool str string) 变量的命名规则遵循骆驼命名法。 全局变量希望能够被外部包所使用，则需要将首个单词的首字母也大写。 变量可以编译期间就被赋值，赋值给变量使用运算符等号 =，可以在运行时对变量进行赋值操作。 12345var a intvar b boola = 15b = true 声明与赋值（初始化）语句也可以组合起来。 12var a int = 15var b bool = false 自动类型推断 12345678910var a = 15var b = falsevar ( a = 15 b = false str = &quot;Go says hello to the world!&quot; numShips = 50 city string) 在函数体内声明局部变量时，应使用简短声明语法 :=，例如： 1a := 1 实例： 123456789101112package mainimport ( &quot;fmt&quot; &quot;runtime&quot; &quot;os&quot;)func main ()&#123; goos := runtime.GOOS fmt.Printf(&quot;%s\\n&quot;,goos) var path string = os.Getenv(&quot;PATH&quot;) fmt.Printf(&quot;%s\\n&quot;,path)&#125; 值类型和引用类型 int、float、bool 和 string 这些基本类型都属于值类型，使用这些类型的变量直接指向存在内存中的值。 数组和结构体这些复合类型是值类型。 指针、切片、映射和通道是引用类型。被引用的变量会存储在堆中，以便进行垃圾回收，且比栈拥有更大的内存空间。 函数 fmt.Sprintf 与 Printf 的作用是完全相同的，不过前者将格式化后的字符串以返回值的形式返回给调用者。 在相同的代码块中，我们不可以再次对于相同名称的变量使用初始化声明，例如：a := 20 就是不被允许的。 1a, b, c := 5, 7, &quot;abc&quot; 交换两个变量的值，则可以简单地使用 a, b = b, a。 init函数 变量除了可以在全局声明中初始化，也可以在 init 函数中初始化。 每个源文件都只能包含一个 init 函数。初始化总是以单线程执行，并且按照包的依赖关系顺序执行。 用途是在开始执行程序之前对数据进行检验或修复，以保证程序状态的正确性。 123456package transimport &quot;math&quot;var Pi float64func init()&#123; Pi = 4*math.Atan(1)&#125; 123456789package mainimport ( &quot;fmt&quot; &quot;./trans&quot;)var twoPi = 2*trams.Pifunc main()&#123; fmt.Printf(twoPi)&#125; init 函数也经常被用在当一个程序开始之前调用后台执行的 goroutine。 1234func init() &#123; // setup preparations go backend()&#125; 基本类型与运算符bool类型只有两个类型相同的值才可以进行比较，如果值的类型是接口，它们也必须都实现了相同的接口。 布尔型的常量和变量也可以通过和逻辑运算符（非 !、和 &amp;&amp;、或 ||）结合来产生另外一个布尔值。 ！非运算符用于取得和布尔值相反的结果。 &amp;&amp;两边的值都为 true 的时候，结果才是 true。 ||两边的值都为 false 的时候，结果才是 false。 在格式化输出时，你可以使用 %t 来表示你要输出的值为布尔型。 数字类型Go 语言支持整型和浮点型数字，并且原生支持复数，其中位的运算采用补码。 Go 也有基于架构的类型，例如：int、uint 和 uintptr。 这些类型的长度都是根据运行程序所在的操作系统类型所决定的： int 和 uint 在 32 位操作系统上，它们均使用 32 位（4 个字节），在 64 位操作系统上，它们均使用 64 位（8 个字节）。 uintptr 的长度被设定为足够存放一个指针即可。 Go 语言中没有 float 类型。（Go语言中只有 float32 和 float64）没有double类型。 int 型是计算最快的一种类型。 float32 精确到小数点后 7 位，float64 精确到小数点后 15 位。 尽可能地使用 float64，因为 math 包中所有有关数学运算的函数都会要求接收这个类型。 前缀 0 来表示 8 进制数（如：077），增加前缀 0x 来表示 16 进制数（如：0xFF），以及使用 e 来表示 10 的连乘（如： 1e3 &#x3D; 1000，或者 6.022e23 &#x3D; 6.022 x 1e23）。 可以使用 a := uint64(0) 来同时完成类型转换和赋值操作，这样 a 的类型就是 uint64。 Go 中不允许不同类型之间的混合使用，但是对于常量的类型限制非常少，因此允许常量之间的混合使用： 12345678package mainfunc main()&#123; var a int var b int32 a = 15 b = a+a //编译错误 b = b+5 //5是常量，可以编译&#125; 格式化说明符 %d 用于格式化整数（%x 和 %X 用于格式化 16 进制表示的数字），%g 用于格式化浮点型（%f 输出浮点数，%e 输出科学计数表示法），%0nd 用于规定输出长度为n的整数，其中开头的数字 0 是必须的。 %n.mg 用于表示数字 n 并精确到小数点后 m 位，除了使用 g 之外，还可以使用 e 或者 f，例如：使用格式化字符串 %5.2e 来输出 3.4 的结果为 3.40e+00。 / 对于整数运算而言，结果依旧为整数，例如：9 / 4 -&gt; 2。 取余运算符只能作用于整数：9 % 4 -&gt; 1。 对于整数和浮点数，你可以使用一元运算符 ++（递增）和 --（递减），但只能用于后缀。 ++ 和 -- 的只能作为语句，而非表达式，因此 n = i++ 这种写法是无效的。 随机数 rand 包实现了伪随机数的生成。 123456789101112131415161718192021package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func main()&#123; for i:=0; i&lt;5; i++&#123; a := rand.Int() fmt.Printf(&quot;%d\\n&quot;,r) &#125; for i := 0; i &lt; 5; i++ &#123; r := rand.Intn(8) fmt.Printf(&quot;%d / &quot;, r) &#125; times := int64(time.Now().Nanosecond()) rand.Seed(times) for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%2.2f / &quot;, 100*rand.Float32()) &#125;&#125; 函数 rand.Intn 返回介于 [0, n) 之间的伪随机数。 类型别名在 type TZ int 中，TZ 就是 int 类型的新名称（用于表示程序中的时区），然后就可以使用 TZ 来操作 int 类型的数据。 新类型不会拥有原类型所附带的方法。 字符类型byte 类型是 uint8 的别名。 Go 同样支持 Unicode（UTF-8），因此字符同样称为 Unicode 代码点或者 runes，并在内存中使用 int 来表示。 rune 也是 Go 当中的一个类型，并且是 int32 的别名。 1var ch byte = 65 或 var ch byte = &#x27;\\x41&#x27; var ch byte = &#39;A&#39;；字符使用单引号括起来。 Unicode 至少占用 2 个字节，所以我们使用 int16 或者 int 类型来表示。如果需要使用到 4 字节，则会加上 \\U 前缀；前缀 \\u 则总是紧跟着长度为 4 的 16 进制数，前缀 \\U 紧跟着长度为 8 的 16 进制数。 123456789101112var ch int = &#x27;\\u0041&#x27;var ch2 int = &#x27;\\u03B2&#x27;var ch3 int = &#x27;\\U00101234&#x27;fmt.Printf(&quot;%d - %d - %d\\n&quot;, ch, ch2, ch3) // integerfmt.Printf(&quot;%c - %c - %c\\n&quot;, ch, ch2, ch3) // characterfmt.Printf(&quot;%X - %X - %X\\n&quot;, ch, ch2, ch3) // UTF-8 bytesfmt.Printf(&quot;%U - %U - %U&quot;, ch, ch2, ch3) // UTF-8 code point65 - 946 - 1053236A - β - r41 - 3B2 - 101234U+0041 - U+03B2 - U+101234 判断是否为字母：unicode.IsLetter(ch) 判断是否为数字：unicode.IsDigit(ch) 判断是否为空白符号：unicode.IsSpace(ch) 包 utf8 拥有更多与 rune 类型相关的函数。 字符串字符串是一种值类型，且值不可变，字符串是字节的定长数组。 Go 中的字符串是根据长度限定，而非特殊字符\\0。 函数 len() 来获取字符串所占的字节长度。 在循环中使用加号 + 拼接字符串并不是最高效的做法，更好的办法是使用函数 strings.Join()。 使用字节缓冲（bytes.Buffer）拼接更加给力。 strings和strconv包Go 中使用 strings 包来完成对字符串的主要操作。 12345678910111213141516171819202122232425262728293031strings.HasPrefix(s, prefix string) bool// 判断字符串 s 是否以 prefix 开头strings.HasSuffix(s, suffix string) bool// 判断字符串 s 是否以 suffix 结尾strings.Contains(s, substr string) bool// 判断字符串 s 是否包含 substrstrings.Index(s, str string) int// Index 返回字符串 str 在字符串 s 中的索引strings.LastIndex(s, str string) int// LastIndex 返回字符串 str 在字符串 s 中最后出现位置的索引strings.IndexRune(s string, r rune) int// 非 ASCII 编码的字符在父字符串中的位置strings.Replace(str, old, new, n) string// Replace 用于将字符串 str 中的前 n 个字符串 old 替换为字符串 new，并返回一个新的字符串，如果 n = -1 则替换所有字符串 old 为字符串 newstrings.Count(s, str string) int// Count 用于计算字符串 str 在字符串 s 中出现的非重叠次数strings.Repeat(s, count int) string// Repeat 用于重复 count 次字符串 s 并返回一个新的字符串strings.TrimSpace(s) 来剔除字符串开头和结尾的空白符号；如果你想要剔除指定字符，则可以使用 strings.Trim(s, &quot;cut&quot;) 来将开头和结尾的 cut 去除掉。strings.Split(s, sep) 用于自定义分割符号来对指定字符串进行分割，同样返回 slice。strings.Join(sl []string, sep string) string// Join 用于将元素类型为 string 的 slice 使用分割符号来拼接组成一个字符串 与字符串相关的类型转换都是通过 strconv 包实现的。 12345678910strconv.Itoa(i int) string// 返回数字 i 所表示的字符串类型的十进制数。strconv.FormatFloat(f float64, fmt byte, prec int, bitSize int) string // 将 64 位浮点型的数字转换为字符串strconv.Atoi(s string) (i int, err error) // 将字符串转换为 int 型。strconv.ParseFloat(s string, bitSize int) (f float64, err error) // 将字符串转换为 float64 型。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Go基本结构","slug":"Go基本结构","date":"2022-08-26T08:30:29.000Z","updated":"2022-09-08T07:38:28.000Z","comments":true,"path":"2022/08/26/Go基本结构/","link":"","permalink":"http://peapod.top/2022/08/26/Go%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84/","excerpt":"","text":"第四章（上）：基本结构文件名、关键字与标识符文件名均由小写字母组成，如 scanner.go 。如果文件名由多个部分组成，则使用下划线 _ 对它们进行分隔，scanner_test.go 。 有效的标识符必须以字母（可以使用任何 UTF-8 编码的字符或 _）开头。 _ 本身就是一个特殊的标识符，被称为空白标识符。 程序一般由关键字、常量、变量、运算符、类型和函数组成。 程序的基本结构和要素包、导入与可见性包是结构化代码的一种方式：每个程序都由包（通常简称为 pkg）的概念组成，可以使用自身的包或者从其它包中导入内容。 每个 Go 文件都属于且仅属于一个包。一个包可以由许多以 .go 为扩展名的源文件组成，因此文件名和包名一般来说都是不相同的。 package main表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。 所有的包名都应该使用小写字母。 属于同一个包的源文件必须全部被一起编译，一个包即是编译时的一个单元，因此根据惯例，每个目录都只包含一个包。 每一段代码只会被编译一次 导入包的方式 1234567891011import &quot;fmt&quot;import &quot;os&quot;import &quot;fmt&quot;;import &quot;os&quot;import ( &quot;fmt&quot; &quot;os&quot;)import (&quot;fmt&quot;;&quot;os&quot;) 可见性规则 当标识符以一个大写字母开头，就可以被外部包的代码所使用，这被称为导出；标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用。 可以像面向对象语言那样使用点标记来调用：pack1.Thing 函数1func functionname() main 函数是每一个可执行程序所必须包含的，一般来说都是在启动后第一个执行的函数（如果有 init() 函数则会先执行该函数）。 函数简短 1func Sum(a,b int) int &#123;return a+b&#125; 只有当某个函数需要被外部包调用的时候才使用大写字母开头。 注释注释不会被编译，但可以通过 godoc 来使用。 以 // 开头的单行注释。多行注释也叫块注释，均已以 /* 开头，并以 */ 结尾 每一个包应该有相关注释，在 package 语句之前的块注释将被默认认为是这个包的文档说明。 几乎所有全局作用域的类型、常量、变量、函数和被导出的对象都应该有一个合理的注释。如果这种注释（称为文档注释）出现在函数前面，例如函数 Abcd，则要以 &quot;Abcd...&quot; 作为开头。 12345// enterOrbit causes Superman to fly into low Earth orbit, a position// that presents several possibilities for planet salvation.func enterOrbit() error &#123; ...&#125; 类型类型可以是基本类型，如：int、float、bool、string；结构化的（复合的），如：struct、array、slice、map、channel；只描述类型的行为的，如：interface。 结构化的类型没有真正的值，它使用 nil 作为默认值。Go 语言中不存在类型继承。 函数也可以是一个确定的类型，就是以函数作为返回类型。 一个函数可以拥有多返回值，返回类型之间需要使用逗号分割，并使用小括号 () 将它们括起来，如： 1func Functionname (a int,b int) (c int,d int) type 关键字可以定义你自己的类型，你可能想要定义一个结构体，但是也可以定义一个已经存在的类型的别名，如： 1type IZ int 并不是真正意义上的别名，使用这种方法定义之后的类型可以拥有更多的特性，且在类型转换时必须显式转换。 多个类型定义： 12345type ( IZ int FZ float64 STR string) 程序的一般结构 在完成包的 import 之后，开始对常量、变量和类型的定义或声明。 如果存在 init 函数的话，则对该函数进行定义。 如果当前包是 main 包，则定义 main 函数。 然后定义其余的函数，首先是类型的方法，接着是按照 main 函数中先后调用的顺序来定义相关函数。 123456789101112131415161718192021package mainimport ( &quot;fmt&quot;)const PI = 3.14var h float32 = 4type Yuan struct&#123; r float32&#125;func init()&#123;&#125;func main()&#123; y :=&amp;Yuan&#123;9&#125; Fun(y.mianji() * h)&#125;func (y Yuan) mianji() float32&#123; return PI * y.r * y.r&#125;func Fun(v float32)&#123; fmt.Printf(&quot;mianji%f&quot;,v)&#125; 类型转换 Go 语言不存在隐式类型转换，因此所有的转换都必须显式说明。 类型 B 的值 &#x3D; 类型 B(类型 A 的值) 12a := 5.0b := int(5.0)","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Go编辑与调试","slug":"Go编辑与调试","date":"2022-08-26T08:29:58.000Z","updated":"2024-02-27T10:57:09.000Z","comments":true,"path":"2022/08/26/Go编辑与调试/","link":"","permalink":"http://peapod.top/2022/08/26/Go%E7%BC%96%E8%BE%91%E4%B8%8E%E8%B0%83%E8%AF%95/","excerpt":"","text":"第三章：编辑与调试编辑器与调试器编辑器：**Sublime Text、LiteIDE、GoClipse** 调试器：可用的调试器是 gdb。 基本调试： 在合适的位置使用打印语句输出相关变量的值。 在 fmt.Printf 中使用下面的说明符 %+v 打印包括字段在内的实例的完整信息 %#v 打印包括字段和限定类型名称在内的实例的完整信息。 %T 打印某个类型的完整说明 构建格式化工具 gofmt 并保存格式化后的源文件。 构建应用程序： go build 编译自身包和依赖包。 go install 编译并安装自身包和依赖包。 格式化代码go fmt（gofmt）。这个工具可以将你的源代码格式化成符合官方统一标准的风格，属于语法风格层面上的小型重构。 gofmt –w program.go 会格式化该源文件的代码然后将格式化后的代码覆盖原始内容。 gofmt -w *.go 会格式化并重写所有 Go 源文件。 gofmt map1 会格式化并重写 map1 目录及其子目录下的所有 Go 源文件。。 gofmt 也可以通过在参数 -r 后面加入用双引号括起来的替换规则实现代码的简单重构，规则的格式：&lt;原始内容&gt; -&gt; &lt;替换内容&gt;。 1gofmt -r &#x27;(a) -&gt; a&#x27; -w *.go 生成代码文档go doc 工具会从 Go 程序和包文件中提取顶级声明的首行注释以及每个对象的相关注释，并生成相关文档。 一般用法 go doc package获取包的文档注释 go doc package/subpackage 获取子包的文档注释 go doc package function 获取某个函数在某个包中的文档注释","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Go安装与运行","slug":"Go安装与运行","date":"2022-08-26T08:29:40.000Z","updated":"2022-09-08T07:39:32.000Z","comments":true,"path":"2022/08/26/Go安装与运行/","link":"","permalink":"http://peapod.top/2022/08/26/Go%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/","excerpt":"","text":"第二章：安装与运行环境架构2个版本的编译器：Go 原生编译器 gc 和非原生编译器 gccgo，这两款编译器都是在类 Unix 系统下工作 。 Go从1.5版本开始已经实现自举。 Go 语言源文件的扩展名很显然就是 .go。 创建目录时，文件夹名称永远不应该包含空格，而应该使用下划线 “_” 或者其它一般符号代替。 环境变量 $GOROOT 表示 Go 在你的电脑上的安装位置 $GOARCH 表示目标机器的处理器架构 $GOBIN 表示编译器和链接器的安装位置 $GOPATH三个规定的目录：src、pkg 和 bin，这三个目录分别用于存放源码文件、包文件和可执行文件。 Go 编译器支持交叉编译，可以使用 $GOHOSTOS 和 $GOHOSTARCH 设置本地机器的操作系统名称和编译体系结构。 安装目录 /bin：包含可执行文件 /doc：包含示例程序，代码工具，本地文档等 /lib：包含文档模版 /src：包含源代码构建脚本和标准库的包的完整源代码 Go运行时（runtime）代码仍旧运行在 Go 的 runtime当中。似 Java 和 .NET 语言所用到的虚拟机，它负责管理包括内存分配、垃圾回收）、栈处理、goroutine、channel、切片（slice）、map 和反射（reflection）等等。 垃圾回收器Go 拥有简单却高效的标记-清除回收器。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Go起源与发展","slug":"Go起源与发展","date":"2022-08-26T08:29:16.000Z","updated":"2022-09-08T07:36:44.000Z","comments":true,"path":"2022/08/26/Go起源与发展/","link":"","permalink":"http://peapod.top/2022/08/26/Go%E8%B5%B7%E6%BA%90%E4%B8%8E%E5%8F%91%E5%B1%95/","excerpt":"","text":"第一章：起源于发展起源与发展Go 语言起源 2007 年，并于 2009 年正式对外发布。 时间轴： 2007 年 9 月 21 日：雏形设计 2009 年 11 月 10日：首次公开发布 2010 年 1 月 8 日：当选 2009 年年度语言 2010 年 5 月：谷歌投入使用 2011 年 5 月 5 日：Google App Engine 支持 Go 语言 主要特性发展目标：将静态语言的安全性和高效性与动态语言的易开发性进行有机结合。是对于网络通信、并发和并行编程的极佳支持，从而更好地利用大量的分布式和多核的计算机。 Go 语言是一门类型安全和内存安全的编程语言。虽然 Go 语言中仍有指针的存在，但并不允许进行指针运算。 重要的特性： 构建速度（编译和链接到机器代码的速度）快。 使用包模式的依赖管理更加的清晰。 执行速度快。 没有类和继承的概念，通过接口（interface）的概念来实现多态性。 使用静态类型，所以它是类型安全的一门语言。 强类型语言，隐式的类型转换是不被允许。 动态语言的特性（通过关键字 var）。 支持交叉编译。 LALR 是 Go 语言的语法标准。 Go语言的用途： 应用于搭载 Web 服务器，存储集群或类似用途的巨型中央服务器的系统编程语言。 实现所谓的复杂事件处理（CEP）。 Go 语言不适合用来开发对实时性要求很高的软件。 通过 recover 和 panic 来替代异常机制","categories":[{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"}],"author":"taweizhong"},{"title":"Git入门指南","slug":"Git入门指南","date":"2022-08-25T14:06:50.000Z","updated":"2024-04-06T06:28:13.000Z","comments":true,"path":"2022/08/25/Git入门指南/","link":"","permalink":"http://peapod.top/2022/08/25/Git%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/","excerpt":"","text":"Git入门指南创建仓库1git init 添加12git add *git add &lt;file&gt; 提交1git commit -m &quot;提交信息&quot; 推送1git push origin master","categories":[{"name":"版本控制器","slug":"版本控制器","permalink":"http://peapod.top/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%99%A8/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://peapod.top/tags/Git/"}],"author":"taweizhong"},{"title":"服务器部署","slug":"服务器部署","date":"2022-08-25T12:10:38.000Z","updated":"2022-09-06T13:39:44.000Z","comments":true,"path":"2022/08/25/服务器部署/","link":"","permalink":"http://peapod.top/2022/08/25/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"使用指南","slug":"使用指南","date":"2022-08-25T10:11:34.000Z","updated":"2022-09-08T07:35:42.000Z","comments":true,"path":"2022/08/25/使用指南/","link":"","permalink":"http://peapod.top/2022/08/25/%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","excerpt":"","text":"说明front-matter配置 Key Type Description cover string 封面 layout stirng 页面类型(只有在page页面下生效) subtitle string 小标题&#x2F;描述(只有在page页面生效) toc boolean 是否开启TOC功能(只有在post页面下生效) aplayer boolean 是否启用aplayer播放器(只有在post,page页面下生效) dplayer boolean 是否启用dplayer播放器(只有在post,page页面下生效) tags string 标签（不适用于分页） categories string 分类（不适用于分页） 媒体使用方法image1234&#123;% image url=&quot;https://qiniu.sukoshi.xyz/src/images/68686407_p0.jpg&quot; title=&quot;带描述带图片&quot;%&#125; aplayer 12345678&#123;% aplayer url=&quot;https://qiniu.sukoshi.xyz/public/music/鹿乃 - アイロニ.mp3&quot; name=&quot;アイロニ&quot; artist=&quot;鹿乃&quot; cover=&quot;https://qiniu.sukoshi.xyz/public/music/鹿乃 - アイロニ.jpg&quot; lrc=&quot;https://qiniu.sukoshi.xyz/public/music/鹿乃 - アイロニ.lrc&quot; lrcType=&quot;3&quot;%&#125; dplayer 1234&#123;% dplayer url=&quot;https://qiniu.sukoshi.xyz/video/%E7%BE%8E.mp4&quot; pic=&quot;https://qiniu.sukoshi.xyz/video/%E7%BE%8E.mp4?vframe/jpg/offset/10&quot;%&#125;","categories":[],"tags":[{"name":"说明","slug":"说明","permalink":"http://peapod.top/tags/%E8%AF%B4%E6%98%8E/"}],"author":"taweizhong"},{"title":"","slug":"Go入门指南","date":"2022-08-14T04:24:34.000Z","updated":"2022-08-14T04:24:34.000Z","comments":true,"path":"2022/08/14/Go入门指南/","link":"","permalink":"http://peapod.top/2022/08/14/Go%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/","excerpt":"","text":"第一部分：学习Go语言第一章：起源于发展起源与发展Go 语言起源 2007 年，并于 2009 年正式对外发布。 时间轴： 2007 年 9 月 21 日：雏形设计 2009 年 11 月 10日：首次公开发布 2010 年 1 月 8 日：当选 2009 年年度语言 2010 年 5 月：谷歌投入使用 2011 年 5 月 5 日：Google App Engine 支持 Go 语言 主要特性发展目标：将静态语言的安全性和高效性与动态语言的易开发性进行有机结合。是对于网络通信、并发和并行编程的极佳支持，从而更好地利用大量的分布式和多核的计算机。 Go 语言是一门类型安全和内存安全的编程语言。虽然 Go 语言中仍有指针的存在，但并不允许进行指针运算。 重要的特性： 构建速度（编译和链接到机器代码的速度）快。 使用包模式的依赖管理更加的清晰。 执行速度快。 没有类和继承的概念，通过接口（interface）的概念来实现多态性。 使用静态类型，所以它是类型安全的一门语言。 强类型语言，隐式的类型转换是不被允许。 动态语言的特性（通过关键字 var）。 支持交叉编译。 LALR 是 Go 语言的语法标准。 Go语言的用途： 应用于搭载 Web 服务器，存储集群或类似用途的巨型中央服务器的系统编程语言。 实现所谓的复杂事件处理（CEP）。 Go 语言不适合用来开发对实时性要求很高的软件。 通过 recover 和 panic 来替代异常机制 第二章：安装与运行环境架构2个版本的编译器：Go 原生编译器 gc 和非原生编译器 gccgo，这两款编译器都是在类 Unix 系统下工作 。 Go从1.5版本开始已经实现自举。 Go 语言源文件的扩展名很显然就是 .go。 创建目录时，文件夹名称永远不应该包含空格，而应该使用下划线 “_” 或者其它一般符号代替。 环境变量 $GOROOT 表示 Go 在你的电脑上的安装位置 $GOARCH 表示目标机器的处理器架构 $GOBIN 表示编译器和链接器的安装位置 $GOPATH三个规定的目录：src、pkg 和 bin，这三个目录分别用于存放源码文件、包文件和可执行文件。 Go 编译器支持交叉编译，可以使用 $GOHOSTOS 和 $GOHOSTARCH 设置本地机器的操作系统名称和编译体系结构。 安装目录 /bin：包含可执行文件 /doc：包含示例程序，代码工具，本地文档等 /lib：包含文档模版 /src：包含源代码构建脚本和标准库的包的完整源代码 Go运行时（runtime）代码仍旧运行在 Go 的 runtime当中。似 Java 和 .NET 语言所用到的虚拟机，它负责管理包括内存分配、垃圾回收）、栈处理、goroutine、channel、切片（slice）、map 和反射（reflection）等等。 垃圾回收器Go 拥有简单却高效的标记-清除回收器。 第三章：编辑与调试编辑器与调试器编辑器：**Sublime Text、LiteIDE、GoClipse** 调试器：可用的调试器是 gdb。 基本调试： 在合适的位置使用打印语句输出相关变量的值。 在 fmt.Printf 中使用下面的说明符 %+v 打印包括字段在内的实例的完整信息 %#v 打印包括字段和限定类型名称在内的实例的完整信息。 %T 打印某个类型的完整说明 构建格式化工具 gofmt 并保存格式化后的源文件。 构建应用程序： go build 编译自身包和依赖包。 go install 编译并安装自身包和依赖包。 格式化代码go fmt（gofmt）。这个工具可以将你的源代码格式化成符合官方统一标准的风格，属于语法风格层面上的小型重构。 gofmt –w program.go 会格式化该源文件的代码然后将格式化后的代码覆盖原始内容。 gofmt -w *.go 会格式化并重写所有 Go 源文件。 gofmt map1 会格式化并重写 map1 目录及其子目录下的所有 Go 源文件。。 gofmt 也可以通过在参数 -r 后面加入用双引号括起来的替换规则实现代码的简单重构，规则的格式：&lt;原始内容&gt; -&gt; &lt;替换内容&gt;。 1gofmt -r &#x27;(a) -&gt; a&#x27; -w *.go 生成代码文档go doc 工具会从 Go 程序和包文件中提取顶级声明的首行注释以及每个对象的相关注释，并生成相关文档。 一般用法 go doc package获取包的文档注释 go doc package/subpackage 获取子包的文档注释 go doc package function 获取某个函数在某个包中的文档注释 第四章：基本结构和基本数据类型文件名、关键字与标识符文件名均由小写字母组成，如 scanner.go 。如果文件名由多个部分组成，则使用下划线 _ 对它们进行分隔，scanner_test.go 。 有效的标识符必须以字母（可以使用任何 UTF-8 编码的字符或 _）开头。 _ 本身就是一个特殊的标识符，被称为空白标识符。 程序一般由关键字、常量、变量、运算符、类型和函数组成。 程序的基本结构和要素包、导入与可见性包是结构化代码的一种方式：每个程序都由包（通常简称为 pkg）的概念组成，可以使用自身的包或者从其它包中导入内容。 每个 Go 文件都属于且仅属于一个包。一个包可以由许多以 .go 为扩展名的源文件组成，因此文件名和包名一般来说都是不相同的。 package main表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。 所有的包名都应该使用小写字母。 属于同一个包的源文件必须全部被一起编译，一个包即是编译时的一个单元，因此根据惯例，每个目录都只包含一个包。 每一段代码只会被编译一次 导入包的方式 1234567891011import &quot;fmt&quot;import &quot;os&quot;import &quot;fmt&quot;;import &quot;os&quot;import ( &quot;fmt&quot; &quot;os&quot;)import (&quot;fmt&quot;;&quot;os&quot;) 可见性规则 当标识符以一个大写字母开头，就可以被外部包的代码所使用，这被称为导出；标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用。 可以像面向对象语言那样使用点标记来调用：pack1.Thing 函数1func functionname() main 函数是每一个可执行程序所必须包含的，一般来说都是在启动后第一个执行的函数（如果有 init() 函数则会先执行该函数）。 函数简短 1func Sum(a,b int) int &#123;return a+b&#125; 只有当某个函数需要被外部包调用的时候才使用大写字母开头。 注释注释不会被编译，但可以通过 godoc 来使用。 以 // 开头的单行注释。多行注释也叫块注释，均已以 /* 开头，并以 */ 结尾 每一个包应该有相关注释，在 package 语句之前的块注释将被默认认为是这个包的文档说明。 几乎所有全局作用域的类型、常量、变量、函数和被导出的对象都应该有一个合理的注释。如果这种注释（称为文档注释）出现在函数前面，例如函数 Abcd，则要以 &quot;Abcd...&quot; 作为开头。 12345// enterOrbit causes Superman to fly into low Earth orbit, a position// that presents several possibilities for planet salvation.func enterOrbit() error &#123; ...&#125; 类型类型可以是基本类型，如：int、float、bool、string；结构化的（复合的），如：struct、array、slice、map、channel；只描述类型的行为的，如：interface。 结构化的类型没有真正的值，它使用 nil 作为默认值。Go 语言中不存在类型继承。 函数也可以是一个确定的类型，就是以函数作为返回类型。 一个函数可以拥有多返回值，返回类型之间需要使用逗号分割，并使用小括号 () 将它们括起来，如： 1func Functionname (a int,b int) (c int,d int) type 关键字可以定义你自己的类型，你可能想要定义一个结构体，但是也可以定义一个已经存在的类型的别名，如： 1type IZ int 并不是真正意义上的别名，使用这种方法定义之后的类型可以拥有更多的特性，且在类型转换时必须显式转换。 多个类型定义： 12345type ( IZ int FZ float64 STR string) 程序的一般结构 在完成包的 import 之后，开始对常量、变量和类型的定义或声明。 如果存在 init 函数的话，则对该函数进行定义。 如果当前包是 main 包，则定义 main 函数。 然后定义其余的函数，首先是类型的方法，接着是按照 main 函数中先后调用的顺序来定义相关函数。 123456789101112131415161718192021package mainimport ( &quot;fmt&quot;)const PI = 3.14var h float32 = 4type Yuan struct&#123; r float32&#125;func init()&#123;&#125;func main()&#123; y :=&amp;Yuan&#123;9&#125; Fun(y.mianji() * h)&#125;func (y Yuan) mianji() float32&#123; return PI * y.r * y.r&#125;func Fun(v float32)&#123; fmt.Printf(&quot;mianji%f&quot;,v)&#125; 类型转换 Go 语言不存在隐式类型转换，因此所有的转换都必须显式说明。 类型 B 的值 &#x3D; 类型 B(类型 A 的值) 12a := 5.0b := int(5.0) 常量常量使用关键字 const 定义，用于存储不会改变的数据。 存储在常量中的数据类型只可以是布尔型、数字型（整数型、浮点型和复数）和字符串型。 1const Pi = 3.14 常量的值必须是能够在编译时就能够确定的。 因为在编译期间自定义函数均属于未知，因此无法用于常量的赋值，但内置函数可以使用，如：len()。 12const Ln2 = 0.693147180559945309417232121458\\ 176568075500134360255254120680009 反斜杠 \\ 可以在常量表达式中作为多行的连接符使用。 常量并行赋值 1const beef,two,c = &quot;eat&quot;,2,&quot;vag&quot; iota 可以被用作枚举值： 12345const ( a = iota b = iota c = iota) 简单地讲，每遇到一次 const 关键字，iota 就重置为 0。. 变量声明变量的一般形式是使用 var 关键字：var identifier type。 123456789var a intvar b boolvar str stringvar ( a int b bool str string) 变量的命名规则遵循骆驼命名法。 全局变量希望能够被外部包所使用，则需要将首个单词的首字母也大写。 变量可以编译期间就被赋值，赋值给变量使用运算符等号 =，可以在运行时对变量进行赋值操作。 12345var a intvar b boola = 15b = true 声明与赋值（初始化）语句也可以组合起来。 12var a int = 15var b bool = false 自动类型推断 12345678910var a = 15var b = falsevar ( a = 15 b = false str = &quot;Go says hello to the world!&quot; numShips = 50 city string) 在函数体内声明局部变量时，应使用简短声明语法 :=，例如： 1a := 1 实例： 123456789101112package mainimport ( &quot;fmt&quot; &quot;runtime&quot; &quot;os&quot;)func main ()&#123; goos := runtime.GOOS fmt.Printf(&quot;%s\\n&quot;,goos) var path string = os.Getenv(&quot;PATH&quot;) fmt.Printf(&quot;%s\\n&quot;,path)&#125; 值类型和引用类型 int、float、bool 和 string 这些基本类型都属于值类型，使用这些类型的变量直接指向存在内存中的值。 数组和结构体这些复合类型是值类型。 指针、切片、映射和通道是引用类型。被引用的变量会存储在堆中，以便进行垃圾回收，且比栈拥有更大的内存空间。 函数 fmt.Sprintf 与 Printf 的作用是完全相同的，不过前者将格式化后的字符串以返回值的形式返回给调用者。 在相同的代码块中，我们不可以再次对于相同名称的变量使用初始化声明，例如：a := 20 就是不被允许的。 1a, b, c := 5, 7, &quot;abc&quot; 交换两个变量的值，则可以简单地使用 a, b = b, a。 init函数 变量除了可以在全局声明中初始化，也可以在 init 函数中初始化。 每个源文件都只能包含一个 init 函数。初始化总是以单线程执行，并且按照包的依赖关系顺序执行。 用途是在开始执行程序之前对数据进行检验或修复，以保证程序状态的正确性。 123456package transimport &quot;math&quot;var Pi float64func init()&#123; Pi = 4*math.Atan(1)&#125; 123456789package mainimport ( &quot;fmt&quot; &quot;./trans&quot;)var twoPi = 2*trams.Pifunc main()&#123; fmt.Printf(twoPi)&#125; init 函数也经常被用在当一个程序开始之前调用后台执行的 goroutine。 1234func init() &#123; // setup preparations go backend()&#125; 基本类型与运算符bool类型只有两个类型相同的值才可以进行比较，如果值的类型是接口，它们也必须都实现了相同的接口。 布尔型的常量和变量也可以通过和逻辑运算符（非 !、和 &amp;&amp;、或 ||）结合来产生另外一个布尔值。 ！非运算符用于取得和布尔值相反的结果。 &amp;&amp;两边的值都为 true 的时候，结果才是 true。 ||两边的值都为 false 的时候，结果才是 false。 在格式化输出时，你可以使用 %t 来表示你要输出的值为布尔型。 数字类型Go 语言支持整型和浮点型数字，并且原生支持复数，其中位的运算采用补码。 Go 也有基于架构的类型，例如：int、uint 和 uintptr。 这些类型的长度都是根据运行程序所在的操作系统类型所决定的： int 和 uint 在 32 位操作系统上，它们均使用 32 位（4 个字节），在 64 位操作系统上，它们均使用 64 位（8 个字节）。 uintptr 的长度被设定为足够存放一个指针即可。 Go 语言中没有 float 类型。（Go语言中只有 float32 和 float64）没有double类型。 int 型是计算最快的一种类型。 float32 精确到小数点后 7 位，float64 精确到小数点后 15 位。 尽可能地使用 float64，因为 math 包中所有有关数学运算的函数都会要求接收这个类型。 前缀 0 来表示 8 进制数（如：077），增加前缀 0x 来表示 16 进制数（如：0xFF），以及使用 e 来表示 10 的连乘（如： 1e3 &#x3D; 1000，或者 6.022e23 &#x3D; 6.022 x 1e23）。 可以使用 a := uint64(0) 来同时完成类型转换和赋值操作，这样 a 的类型就是 uint64。 Go 中不允许不同类型之间的混合使用，但是对于常量的类型限制非常少，因此允许常量之间的混合使用： 12345678package mainfunc main()&#123; var a int var b int32 a = 15 b = a+a //编译错误 b = b+5 //5是常量，可以编译&#125; 格式化说明符 %d 用于格式化整数（%x 和 %X 用于格式化 16 进制表示的数字），%g 用于格式化浮点型（%f 输出浮点数，%e 输出科学计数表示法），%0nd 用于规定输出长度为n的整数，其中开头的数字 0 是必须的。 %n.mg 用于表示数字 n 并精确到小数点后 m 位，除了使用 g 之外，还可以使用 e 或者 f，例如：使用格式化字符串 %5.2e 来输出 3.4 的结果为 3.40e+00。 / 对于整数运算而言，结果依旧为整数，例如：9 / 4 -&gt; 2。 取余运算符只能作用于整数：9 % 4 -&gt; 1。 对于整数和浮点数，你可以使用一元运算符 ++（递增）和 --（递减），但只能用于后缀。 ++ 和 -- 的只能作为语句，而非表达式，因此 n = i++ 这种写法是无效的。 随机数 rand 包实现了伪随机数的生成。 123456789101112131415161718192021package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func main()&#123; for i:=0; i&lt;5; i++&#123; a := rand.Int() fmt.Printf(&quot;%d\\n&quot;,r) &#125; for i := 0; i &lt; 5; i++ &#123; r := rand.Intn(8) fmt.Printf(&quot;%d / &quot;, r) &#125; times := int64(time.Now().Nanosecond()) rand.Seed(times) for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%2.2f / &quot;, 100*rand.Float32()) &#125;&#125; 函数 rand.Intn 返回介于 [0, n) 之间的伪随机数。 类型别名在 type TZ int 中，TZ 就是 int 类型的新名称（用于表示程序中的时区），然后就可以使用 TZ 来操作 int 类型的数据。 新类型不会拥有原类型所附带的方法。 字符类型byte 类型是 uint8 的别名。 Go 同样支持 Unicode（UTF-8），因此字符同样称为 Unicode 代码点或者 runes，并在内存中使用 int 来表示。 rune 也是 Go 当中的一个类型，并且是 int32 的别名。 1var ch byte = 65 或 var ch byte = &#x27;\\x41&#x27; var ch byte = &#39;A&#39;；字符使用单引号括起来。 Unicode 至少占用 2 个字节，所以我们使用 int16 或者 int 类型来表示。如果需要使用到 4 字节，则会加上 \\U 前缀；前缀 \\u 则总是紧跟着长度为 4 的 16 进制数，前缀 \\U 紧跟着长度为 8 的 16 进制数。 123456789101112var ch int = &#x27;\\u0041&#x27;var ch2 int = &#x27;\\u03B2&#x27;var ch3 int = &#x27;\\U00101234&#x27;fmt.Printf(&quot;%d - %d - %d\\n&quot;, ch, ch2, ch3) // integerfmt.Printf(&quot;%c - %c - %c\\n&quot;, ch, ch2, ch3) // characterfmt.Printf(&quot;%X - %X - %X\\n&quot;, ch, ch2, ch3) // UTF-8 bytesfmt.Printf(&quot;%U - %U - %U&quot;, ch, ch2, ch3) // UTF-8 code point65 - 946 - 1053236A - β - r41 - 3B2 - 101234U+0041 - U+03B2 - U+101234 判断是否为字母：unicode.IsLetter(ch) 判断是否为数字：unicode.IsDigit(ch) 判断是否为空白符号：unicode.IsSpace(ch) 包 utf8 拥有更多与 rune 类型相关的函数。 字符串字符串是一种值类型，且值不可变，字符串是字节的定长数组。 Go 中的字符串是根据长度限定，而非特殊字符\\0。 函数 len() 来获取字符串所占的字节长度。 在循环中使用加号 + 拼接字符串并不是最高效的做法，更好的办法是使用函数 strings.Join()。 使用字节缓冲（bytes.Buffer）拼接更加给力。 strings和strconv包Go 中使用 strings 包来完成对字符串的主要操作。 12345678910111213141516171819202122232425262728293031strings.HasPrefix(s, prefix string) bool// 判断字符串 s 是否以 prefix 开头strings.HasSuffix(s, suffix string) bool// 判断字符串 s 是否以 suffix 结尾strings.Contains(s, substr string) bool// 判断字符串 s 是否包含 substrstrings.Index(s, str string) int// Index 返回字符串 str 在字符串 s 中的索引strings.LastIndex(s, str string) int// LastIndex 返回字符串 str 在字符串 s 中最后出现位置的索引strings.IndexRune(s string, r rune) int// 非 ASCII 编码的字符在父字符串中的位置strings.Replace(str, old, new, n) string// Replace 用于将字符串 str 中的前 n 个字符串 old 替换为字符串 new，并返回一个新的字符串，如果 n = -1 则替换所有字符串 old 为字符串 newstrings.Count(s, str string) int// Count 用于计算字符串 str 在字符串 s 中出现的非重叠次数strings.Repeat(s, count int) string// Repeat 用于重复 count 次字符串 s 并返回一个新的字符串strings.TrimSpace(s) 来剔除字符串开头和结尾的空白符号；如果你想要剔除指定字符，则可以使用 strings.Trim(s, &quot;cut&quot;) 来将开头和结尾的 cut 去除掉。strings.Split(s, sep) 用于自定义分割符号来对指定字符串进行分割，同样返回 slice。strings.Join(sl []string, sep string) string// Join 用于将元素类型为 string 的 slice 使用分割符号来拼接组成一个字符串 与字符串相关的类型转换都是通过 strconv 包实现的。 12345678910strconv.Itoa(i int) string// 返回数字 i 所表示的字符串类型的十进制数。strconv.FormatFloat(f float64, fmt byte, prec int, bitSize int) string // 将 64 位浮点型的数字转换为字符串strconv.Atoi(s string) (i int, err error) // 将字符串转换为 int 型。strconv.ParseFloat(s string, bitSize int) (f float64, err error) // 将字符串转换为 float64 型。 第五章：控制结构if-else结构12345if condition &#123; //&#125; else &#123; //&#125; 当 if 结构内有 break、continue、goto 或者 return 语句时，Go 代码的常见写法是省略 else 部分 1234if condition &#123; return x&#125;return y 1234if err != nil &#123; fmt.Printf(&quot;Program stopping with error %v&quot;, err) os.Exit(1)&#125; swith结构它可以接受任意形式的表达式： 12345678switch var1 &#123; case val1: ... case val2: ... default: ...&#125; 变量 var1 可以是任何类型，而 val1 和 val2 则可以是同类型的任意值。 一旦成功地匹配到某个分支，在执行完相应代码后就会退出整个 switch 代码块。 继续执行后续分支的代码，可以使用 fallthrough 关键字 12345switch i &#123; case 0: fallthrough case 1: f() // 当 i == 0 时函数也会被调用&#125; 可选的 default 分支可以出现在任何顺序，但最好将它放在最后。它的作用类似与 if-else 语句中的 else，表示不符合任何已给出条件时，执行相关语句。 switch 语句的第二种形式是不提供任何被判断的值（实际上默认为判断是否为 true），然后在每个 case 分支中进行测试不同的条件。 12345678switch &#123; case i &lt; 0: f1() case i == 0: f2() case i &gt; 0: f3()&#125; for结构基于计数器的迭代 1234567package mainimport &quot;fmt&quot;func main() &#123; for i := 0; i &lt; 5; i++ &#123; fmt.Printf(&quot;This is the %d iteration\\n&quot;, i) &#125;&#125; 基于条件判断的迭代 123456789package mainimport &quot;fmt&quot;func main() &#123; var i int = 5 for i &gt;= 0 &#123; i = i - 1 fmt.Printf(&quot;The variable i is now: %d\\n&quot;, i) &#125;&#125; for-range结构 for ix, val := range coll &#123; &#125;。 val 始终为集合中对应索引的值拷贝，因此它一般只具有只读性质，对它所做的任何修改都不会影响到集合中原有的值 123for pos, char := range str &#123;...&#125; 标签和gotofor、switch 或 select 语句都可以配合标签（label）形式的标识符使用，即某一行第一个以冒号（:） 12345678910111213package mainimport &quot;fmt&quot;func main() &#123;LABEL1: // 一般建议使用全部大写字母 for i := 0; i &lt;= 5; i++ &#123; for j := 0; j &lt;= 5; j++ &#123; if j == 4 &#123; continue LABEL1 &#125; fmt.Printf(&quot;i is: %d, and j is: %d\\n&quot;, i, j) &#125; &#125;&#125; 第六章：函数简介函数是基本的代码块。函数编写的顺序是无关紧要的，最好把 main() 函数写在文件的前面。 简单的 return 语句也可以用来结束 for 死循环，或者结束一个协程（goroutine）。 Go里面的函数： 普通函数 匿名函数 方法 除了main()、init()函数外，其它所有类型的函数都可以有参数与返回值。 函数参数、返回值以及它们的类型被统称为函数签名。 函数是一等值（first-class value）：它们可以赋值给变量，就像 add := binOp 一样。 函数不能在其它函数里面声明（不能嵌套），不过我们可以通过使用匿名函数 函数参数与返回值函数定义时，它的形参一般是有名字的，不过我们也可以定义没有形参名的函数，只有相应的形参类型，就像这样：func f(int, int, float64)。 在函数调用时，像切片（slice）、字典（map）、接口（interface）、通道（channel）这样的引用类型都是默认使用引用传递（即使没有显式的指出指针）。 命名返回值 命名返回值作为结果形参（result parameters）被初始化为相应类型的零值，当需要返回的时候，我们只需要一条简单的不带参数的return语句。 123456func getX2AndX3_2(input int) (x2 int, x3 int) &#123; x2 = 2 * input x3 = 3 * input // return x2, x3 return&#125; 改变外部变量 传递指针给函数不但可以节省内存（因为没有复制变量的值），而且赋予了函数直接修改外部变量的能力，所以被修改的变量不再需要使用 return 返回。 1234567891011121314package mainimport ( &quot;fmt&quot;)// this function changes reply:func Multiply(a, b int, reply *int) &#123; *reply = a * b&#125;func main() &#123; n := 0 reply := &amp;n Multiply(10, 5, reply) fmt.Println(&quot;Multiply:&quot;, *reply) // Multiply: 50&#125; 变长参数函数的最后一个参数是采用 ...type 的形式，那么这个函数就可以处理一个变长的参数 123456789101112131415161718192021package mainimport &quot;fmt&quot;func main() &#123; x := min(1, 3, 2, 0) fmt.Printf(&quot;The minimum is: %d\\n&quot;, x) slice := []int&#123;7,9,3,5,1&#125; x = min(slice...) fmt.Printf(&quot;The minimum in the slice is: %d&quot;, x)&#125;func min(s ...int) int &#123; if len(s)==0 &#123; return 0 &#125; min := s[0] for _, v := range s &#123; if v &lt; min &#123; min = v &#125; &#125; return min&#125; 变长参数的类型不相同 使用结构体 使用空接口 使用默认的空接口 interface&#123;&#125;，这样就可以接受任何类型的参数 new 和 make 均是用于分配内存：new 用于值类型和用户定义的类型，如自定义结构，make 用于内置引用类型（切片、map 和管道）。 new(T) 分配类型 T 的零值并返回其地址，也就是指向类型 T 的指针 make(T) 返回类型 T 的初始化之后的值，因此它比 new 进行更多的工作。 defer和追踪关键字 defer 允许我们推迟到函数返回之前（或任意位置执行 return 语句之后）一刻才执行某个语句或函数。 123456789101112package mainimport &quot;fmt&quot;func P()&#123; fmt.Print(&quot;P&quot;)&#125;func main()&#123; fmt.Print(&quot;111&quot;) defer P() fmt.Print(&quot;222&quot;)&#125; 当有多个 defer 行为被注册时，它们会以逆序执行 123456789101112package mianimport ( &quot;file&quot;)func main()&#123; //关闭文件 defer file.close() //解锁 mu.Lock() defer mu.Unlock() //关闭数据库连接 defer disconnectFromDB()&#125; 函数作为参数1234567891011package mainimport &quot;fmt&quot;func add(i,j int) int &#123; return i+j&#125;func b(c int, f func (i,j int) int )&#123; return f(c, 2)&#125;func main()&#123; fmt.Print(b(1, add))&#125; 闭包匿名函数的使用 12345678910package mainimport &quot;fmt&quot;func main ()&#123; // 匿名函数 func(i, j int) int &#123;return i+j&#125; // 将匿名函数赋值给变量 变量使用匿名函数 ter := func(i, j int) int &#123;return i+j&#125; ter(2,3) // 匿名函数直接的调用 func(a, b int) int &#123;return a-b&#125; (3, 2)&#125; 函数作为返回值123456789101112package mainimport &quot;fmt&quot;func add(j int) func (i int) int&#123; return func (i int) int&#123; return j +i &#125;&#125;func main()&#123; add(12)&#125; 12345678910111213141516171819package mainimport &quot;fmt&quot;func add() func(i int) int &#123; var x int fmt.Printf(&quot;x: %v\\n&quot;, x) return func(i int) int &#123; x += i return x &#125;&#125;func main() &#123; f := add() fmt.Printf(&quot;f(1): %v\\n&quot;, f(1)) fmt.Printf(&quot;f(2): %v\\n&quot;, f(20))&#125; 闭包函数保存并积累其中的变量的值，不管外部函数退出与否，它都能够继续操作外部函数中的局部变量。 计算函数的执行时间12345678910111213141516171819package mainimport ( &quot;fmt&quot; &quot;time&quot;)func add() &#123; for i := 0; i &lt; 100; i++ &#123; fmt.Printf(&quot;i: %v\\n&quot;, i) &#125;&#125;func main() &#123; start := time.Now() add() end := time.Now() fmt.Print(end.Sub(start))&#125; 第七章：数组与切片数组12345678package mainimport &quot;fmt&quot;func main()&#123; var a [10]int //声明 for i := 0; i&lt;10 ; i++ &#123; fmt.Print(a[i]) &#125;&#125; 数组是 可变的。 Go 语言中的数组是一种 值类型，所以可以通过 new() 来创建： 123a := new([10]int)var b = new([10]int)var c [10]int b的类型是*[10]int, c的类型是[10]int。 初始化 1234567package mainimport &quot;fmt&quot;func main()&#123; var a = [10]int&#123;1,2,3,4&#125; var b = [...]int&#123;5,6,7,8&#125; var c = [10]string&#123;1:&quot;ta&quot;, 2:&quot;wei&quot;&#125; // key: value 语法&#125; 切片切片（slice）是对数组一个连续片段的引用，所以切片是一个引用类型。切片是一个 长度可变的数组。 切片是可索引的，并且可以由 len() 函数获取长度。计算容量的函数 cap() 可以测量切片最长可以达到多少。 123456package mainimport &quot;fmt&quot;func main()&#123; var a []int // 不需要说明长度 var b = []int&#123;1,2,3,4,5&#125; // 初始化&#125; make创建数组 123456package mainimport &quot;fmt&quot;func main()&#123; var a []int = make([]int, 10) b := make([]int, 10)&#125; 1.slice、map以及channel都是golang内建的一种引用类型，三者在内存中存在多个组成部分， 需要对内存组成部分初始化后才能使用，而make就是对三者进行初始化的一种操作方式 2. new 获取的是存储指定变量内存地址的一个变量，对于变量内部结构并不会执行相应的初始化操作， 所以slice、map、channel需要make进行初始化并获取对应的内存地址，而非new简单的获取内存地址","categories":[],"tags":[]}],"categories":[{"name":"后端","slug":"后端","permalink":"http://peapod.top/categories/%E5%90%8E%E7%AB%AF/"},{"name":"golang标准库","slug":"golang标准库","permalink":"http://peapod.top/categories/golang%E6%A0%87%E5%87%86%E5%BA%93/"},{"name":"数据库","slug":"数据库","permalink":"http://peapod.top/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/categories/%E7%AC%94%E8%AE%B0/"},{"name":"云原生","slug":"云原生","permalink":"http://peapod.top/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"name":"Web前端","slug":"Web前端","permalink":"http://peapod.top/categories/Web%E5%89%8D%E7%AB%AF/"},{"name":"区块链","slug":"区块链","permalink":"http://peapod.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"分布式系统","slug":"分布式系统","permalink":"http://peapod.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"实用","slug":"实用","permalink":"http://peapod.top/categories/%E5%AE%9E%E7%94%A8/"},{"name":"Web","slug":"Web","permalink":"http://peapod.top/categories/Web/"},{"name":"说明","slug":"说明","permalink":"http://peapod.top/categories/%E8%AF%B4%E6%98%8E/"},{"name":"前端","slug":"前端","permalink":"http://peapod.top/categories/%E5%89%8D%E7%AB%AF/"},{"name":"版本控制器","slug":"版本控制器","permalink":"http://peapod.top/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%99%A8/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"http://peapod.top/tags/LLM/"},{"name":"C++","slug":"C","permalink":"http://peapod.top/tags/C/"},{"name":"GRPC","slug":"GRPC","permalink":"http://peapod.top/tags/GRPC/"},{"name":"Go","slug":"Go","permalink":"http://peapod.top/tags/Go/"},{"name":"mysql","slug":"mysql","permalink":"http://peapod.top/tags/mysql/"},{"name":"redis","slug":"redis","permalink":"http://peapod.top/tags/redis/"},{"name":"blog","slug":"blog","permalink":"http://peapod.top/tags/blog/"},{"name":"笔记","slug":"笔记","permalink":"http://peapod.top/tags/%E7%AC%94%E8%AE%B0/"},{"name":"python","slug":"python","permalink":"http://peapod.top/tags/python/"},{"name":"微服务框架","slug":"微服务框架","permalink":"http://peapod.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6/"},{"name":"微服务","slug":"微服务","permalink":"http://peapod.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"测试","slug":"测试","permalink":"http://peapod.top/tags/%E6%B5%8B%E8%AF%95/"},{"name":"Vue3","slug":"Vue3","permalink":"http://peapod.top/tags/Vue3/"},{"name":"javascript","slug":"javascript","permalink":"http://peapod.top/tags/javascript/"},{"name":"Git","slug":"Git","permalink":"http://peapod.top/tags/Git/"},{"name":"Hyperledger Fabric进阶","slug":"Hyperledger-Fabric进阶","permalink":"http://peapod.top/tags/Hyperledger-Fabric%E8%BF%9B%E9%98%B6/"},{"name":"JSON","slug":"JSON","permalink":"http://peapod.top/tags/JSON/"},{"name":"Hyperledger Fabric","slug":"Hyperledger-Fabric","permalink":"http://peapod.top/tags/Hyperledger-Fabric/"},{"name":"clash","slug":"clash","permalink":"http://peapod.top/tags/clash/"},{"name":"beego","slug":"beego","permalink":"http://peapod.top/tags/beego/"},{"name":"说明","slug":"说明","permalink":"http://peapod.top/tags/%E8%AF%B4%E6%98%8E/"},{"name":"Gin","slug":"Gin","permalink":"http://peapod.top/tags/Gin/"},{"name":"css","slug":"css","permalink":"http://peapod.top/tags/css/"},{"name":"vim","slug":"vim","permalink":"http://peapod.top/tags/vim/"},{"name":"HTML","slug":"HTML","permalink":"http://peapod.top/tags/HTML/"}]}